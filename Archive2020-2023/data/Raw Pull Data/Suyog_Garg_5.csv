pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
678561028,Add MRT format writer to `cds.py` [GSoC21a],"<!-- This comments are hidden when you submit the pull request,
so you do not need to remove them! -->

<!-- Please be sure to check out our contributing guidelines,
https://github.com/astropy/astropy/blob/main/CONTRIBUTING.md .
Please be sure to check out our code of conduct,
https://github.com/astropy/astropy/blob/main/CODE_OF_CONDUCT.md . -->

<!-- If you are new or need to be re-acquainted with Astropy
contributing workflow, please see
http://docs.astropy.org/en/latest/development/workflow/development_workflow.html .
There is even a practical example at
https://docs.astropy.org/en/latest/development/workflow/git_edit_workflow_examples.html#astropy-fix-example . -->

<!-- Astropy coding style guidelines can be found here:
https://docs.astropy.org/en/latest/development/codeguide.html#coding-style-conventions
Our testing infrastructure enforces to follow a subset of the PEP8 to be
followed. You can check locally whether your changes have followed these by
running the following command:

tox -e codestyle

-->

<!-- Please just have a quick search on GitHub to see if a similar
pull request has already been posted.
We have old closed pull requests that might provide useful code or ideas
that directly tie in with your pull request. -->

<!-- We have several automatic features that run when a pull request is open.
They can appear daunting but do not worry because maintainers will help
you navigate them, if necessary. -->

### Description
<!-- Provide a general description of what your pull request does.
Complete the following sentence and add relevant details as you see fit. -->

<!-- In addition please ensure that the pull request title is descriptive
and allows maintainers to infer the applicable subpackage(s). -->

Discussion continued from #11835.

This Pull Request is part of the 2021 Google Summer of Code work I am doing together with mentors @aaryapatil and @hamogu.
It primarily aims to address issue #11257.

<!-- If the pull request closes any open issues you can add this.
If you replace <Issue Number> with a number, GitHub will automatically link it.
If this pull request is unrelated to any issues, please remove
the following line. -->

### Checklist for package maintainer(s)
<!-- This section is to be filled by package maintainer(s) who will
review this pull request. -->

This checklist is meant to remind the package maintainer(s) who will
review this pull request of some common things to look for. This list
is not exhaustive.

- [x] Do the proposed changes actually accomplish desired goals?
- [x] Do the proposed changes follow the [Astropy coding guidelines](https://docs.astropy.org/en/latest/development/codeguide.html)?
- [x] Are tests added/updated as required? If so, do they follow the [Astropy testing guidelines](https://docs.astropy.org/en/latest/development/testguide.html)?
- [x] Are docs added/updated as required? If so, do they follow the [Astropy documentation guidelines](https://docs.astropy.org/en/latest/development/docguide.html#astropy-documentation-rules-and-guidelines)?
- [x] Is rebase and/or squash necessary? If so, please provide the author with appropriate instructions. Also see [""When to rebase and squash commits""](https://docs.astropy.org/en/latest/development/when_to_rebase.html).
- [x] Did the CI pass? If no, are the failures related? If you need to run daily and weekly cron jobs as part of the PR, please apply the `Extra CI` label.
- [x] Is a change log needed? If yes, did the change log check pass? If no, add the `no-changelog-entry-needed` label.
- [x] Is a milestone set? Milestone must be set but `astropy-bot` check might be missing; do not let the green checkmark fool you.
- [x] If the milestone set requires a backport to release branch(es), apply the appropriate `backport-X.Y.x` label(s) *before* merge.
",True,11897,https://api.github.com/repos/astropy/astropy/pulls/11897,https://github.com/astropy/astropy/pull/11897,closed,1257,12,6,38,61,135,2,0,"[{'name': 'io.ascii'}, {'name': 'whatsnew-needed'}]",2021-06-27 18:27:29+00:00,2021-08-30 20:25:53+00:00,5536704.0,"64 days, 1:58:24","[{'comment_id': 660931186, 'comment_body': 'This goes beyond the scope of this PR, but I wonder @taldcroft - do we still need these author metadata? I suppose the copyright to SAO is not changeable to ""Astropy"" that easily, but the author info/history is pretty well tracked by git itself.', 'comment_created': datetime.datetime(2021, 6, 29, 20, 13, 4, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 661041418, 'comment_body': ""I suggest to put `delimiter = ''` into the class. Then, it will always have a value and you don't need to test  with or here. (Unless, of course, someone actively removed the delimiter attribute, but if they do that, it's clearly their own fault.). The advantage is that you can see the default by just looking at the class (`print(CdsSplitter.<TAB>` in ipython) without reading through the code of the methods."", 'comment_created': datetime.datetime(2021, 6, 30, 0, 6, 8, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661043740, 'comment_body': ""It's always a little bit of a judgement call what to put into the separate functions and what to just keep inline. It's not obvious to me from the function name what this function does. So when I see `self.__strFmt(col.fortran_format)` further down in the code, I need to scroll up to find out. Is having a separate function really better than `'' if col.fortran_format is None else col.fortran_format`?"", 'comment_created': datetime.datetime(2021, 6, 30, 0, 13, 22, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661044849, 'comment_body': 'Should maybe be smaller? We never have data values this long.', 'comment_created': datetime.datetime(2021, 6, 30, 0, 16, 59, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661045930, 'comment_body': ""Easier as a dict: `type_from_dtype = {'i': int, 'f': float, ...}` and then use it like this: `type_from_dtype[col.dtype.name[0]]`. No need to code up a function that looks up a value based on a key - that's exactly what dictionaries are for.\r\n"", 'comment_created': datetime.datetime(2021, 6, 30, 0, 20, 35, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661047178, 'comment_body': 'This seems overly general. bookend_left/right are defined to be `\'\'` just two lines above. So, adding them here does not do anything. The lines defining the bookends can be removed and this line can be \r\n```suggestion\r\n        return padded_delim.join(vals)\r\n```\r\n\r\nSimilarly, is there are need to have the padding and delimiters be flexible? Do they differ between CDS and MRT? Or between float and string? If not, we can simpy hard-dcode them them (or, if they are `\'\'` anyway, just remove them). We are writing a very specific writer for a very specific format (CDS and MRT). We don\'t need that to be flexible ""in case someone invents a new CDS format"". That\'s so unlikely, we can deal with it when it happens.', 'comment_created': datetime.datetime(2021, 6, 30, 0, 24, 33, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661048937, 'comment_body': '`fmt` is really not an input to this function, it\'s an output.\r\nSo, it should not be a parameter, if should be a return values:\r\n```\r\nreturn len(value), len(mo.group(\'int\')), len(mo.group(\'decimals\')), mo.group(\'sign\') != """", mo.group(\'exp\') != """"\r\n```\r\nNote that I\'m not returning fmt[1] separately. My thinking is that the calling routine can calculate the sum, if it need it, but it could be added here, too. Also, I\'m adding `mo.group(\'exp\') != """"` which was the only return value to the full list.\r\n\r\nNote that\r\n```\r\n        if mo.group(\'sign\') != """":\r\n            fmt[4] = True\r\n        else:\r\n            fmt[4] = False\r\n```\r\nis the same as the one line `fmt[4] = mo.group(\'sign\') != """"`, except that the latter is 1 line instead of 4.', 'comment_created': datetime.datetime(2021, 6, 30, 0, 30, 29, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661053192, 'comment_body': ""In general, I'm wondering if looking at the numpy types would be better like this\r\n```\r\nfor dtype in [np.integer, np.floating, str]:\r\n    if np.issubdtype(col.dtype, dtype):\r\n        return dtype\r\n```\r\nOr, even better, I think this entire function can be deleted. It returns the dtype, but the only space where it's used is `if xxx  == dtype`, so why not do the test right then and there? See my comment below."", 'comment_created': datetime.datetime(2021, 6, 30, 0, 44, 41, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661053623, 'comment_body': ""We can do the entire check here inline, so we don't need `__get_dtype` at all.\r\n```suggestion\r\n            if np.issubdtpye(col.dtype, np.floating):\r\n```"", 'comment_created': datetime.datetime(2021, 6, 30, 0, 46, 23, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661055186, 'comment_body': 'Is this not the same code as above? If we need it at all (see comments above), maybe it should be a function?', 'comment_created': datetime.datetime(2021, 6, 30, 0, 51, 30, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661055648, 'comment_body': ""In general, we follow numpy doc format for the doctrings. Just look elsewhere in astropy for the format. I think this function is important enough do warrant a docstring even if it's internal and not used by the user."", 'comment_created': datetime.datetime(2021, 6, 30, 0, 52, 57, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661057960, 'comment_body': ""This is premature optimization. Columns are numpy arrays and `col.max()` will do. To account for columns that are fully masked you can do something like:\r\n```\r\ncol.max = col.max()\r\nif np.is_masked(col.max):\r\n    col.max = None\r\n```\r\n[At least I think I understand the logic of this bit of code. I'm not sure. But that fact alone shows that it might be too complex.]"", 'comment_created': datetime.datetime(2021, 6, 30, 1, 0, 10, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661058327, 'comment_body': '```suggestion\r\n        nsplit = sum(sz) + 16\r\n```', 'comment_created': datetime.datetime(2021, 6, 30, 1, 1, 20, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661059604, 'comment_body': ""```suggestion\r\n            col.hasNull =  isinstance(col, MaskedColumn)\r\n```\r\nAnd then delete the three lines below this. The fact that this test is only one line long also means that we don't need the `hasNull` attribute at all. Instead, we can go through the code and replace every occurrence of\r\n`if col.hasNull` with `if isinstance(col, MaskedColumn)`. Not much longer, but save us an extra attribute. \r\n[At least, that's true until we have cases with `hasNull` that are not instances of MaskedColumn. Not sure aobut mixin columns with e.g. coordinates. So maybe it's better to leave `hasNull` for now, but the check to set True or False can still be one line only."", 'comment_created': datetime.datetime(2021, 6, 30, 1, 5, 34, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 661496059, 'comment_body': ""This code was copied from the `asciitable` package, which unfortunately does not specify a license. I think most licenses would require maintaining Copyright and Author information, but IANAL. Though I personally don't care, astropy should be strict about respecting typical license agreements when copying open source code."", 'comment_created': datetime.datetime(2021, 6, 30, 13, 52, 41, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 661507007, 'comment_body': 'However, the person controlling the copyight is @taldcroft (or SAO) here and he could, should @taldcroft/SAO could chose to do transfer the copyright or re-license under a different license if they chose to.', 'comment_created': datetime.datetime(2021, 6, 30, 14, 4, 17, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 664058959, 'comment_body': ""I do not find any difference between CDS and MRT format with regard to column separator for data part of the table.\r\nThe separator is by default a single spacing `' '`.\r\nI am hard coding it here."", 'comment_created': datetime.datetime(2021, 7, 5, 17, 14, 28, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664093948, 'comment_body': 'Okay. I am saving `col.has_null` for the time being.', 'comment_created': datetime.datetime(2021, 7, 5, 19, 4, 37, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664116575, 'comment_body': ""I think the way this part of the code works is something as follows.\r\n\r\n- The max/min values have to be found in column containing Null values. \r\n- If the min/max values themselves are masked, then we want to assign `None` to them instead of the random masked value (or NaN).\r\n- So, the null values in the column are filled with a large negative number `-999999` (a large positive number `999999`). If all the values in the column are Null values, then there won't be any number greater (smaller) than this filled value, and thus, the `col.max` (`col.min`) value will be set as `None`.\r\n\r\nI looked up this page for more info: https://docs.astropy.org/en/stable/table/masking.html\r\n\r\nI am not sure of the way in which these steps above optimize the process, since checking Min/Max will anyway depend on how well numpy functions are optimized. Maybe the default Min/Max checking is time consuming for columns with a very large number of values, in the worst case scenario and the above steps ensure lesser time?\r\n"", 'comment_created': datetime.datetime(2021, 7, 5, 20, 27, 27, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664137060, 'comment_body': 'I have added a short docstring now. Will improve upon it with time.', 'comment_created': datetime.datetime(2021, 7, 5, 21, 53, 13, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664152528, 'comment_body': 'The numpy code itself is probably written in C (much on numpy internal are), so I\'m very surprised if this Python is much faster. Maybe it is. The point is that we first want to get a code that working and that we understand. ""I think this works something as follows"" is not good enough :-)  So, I suggest to use a very simple solutions (like my three lines instead of > dozen lines with two different code path) at this point. If there is an if..else we need to write tests for both cases etc. It\'s just not worth it unless we **know** that this part of the code is a bottle neck for speed.', 'comment_created': datetime.datetime(2021, 7, 5, 23, 16, 49, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 664155226, 'comment_body': 'On a more practical note: @Suyog7130 included a number of lines straight from pycdsreadmy. That library is BSD licensed and thus we *can* include code from there into astropy, but my understanding is that we need to mark is as BSD licensed. So, we should (1) contact the authors and ask them to re-license under MIT licence, or (2) isolate all those lines into a separate file with a different license header or (3) remove that code and write it from scratch, using pycdsreadme as inspiration, but not copy code directly from there.', 'comment_created': datetime.datetime(2021, 7, 5, 23, 32, 38, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 664166869, 'comment_body': 'Minor change: Usually standard library imports go at the very top, followed by third party imports, and local imports -- You can decide whether to do this or not.', 'comment_created': datetime.datetime(2021, 7, 6, 0, 34, 31, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664169201, 'comment_body': '```suggestion\r\n                              re.VERBOSE)\r\n```\r\n\r\nAlignment -- another codestyle comment.', 'comment_created': datetime.datetime(2021, 7, 6, 0, 46, 41, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664169656, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2021, 7, 6, 0, 48, 28, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664169803, 'comment_body': '```suggestion\r\n        # Find maximum sized value in the col\r\n```\r\nComments start with a # capital letter followed by phrase or a full sentence with a .', 'comment_created': datetime.datetime(2021, 7, 6, 0, 49, 8, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664170821, 'comment_body': 'Can you explain to me the logic behind this if-else? I wonder if this could be simplified further, but would be better to first understand what your motive here is.', 'comment_created': datetime.datetime(2021, 7, 6, 0, 53, 44, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664172183, 'comment_body': 'Are you trying to create a copy here? You are using the mask-filled column``mcol`` to create a ``coltmp`` __Column__ later. ``mcol = col`` could cause issues if you want a true copy.', 'comment_created': datetime.datetime(2021, 7, 6, 0, 59, 53, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664172836, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2021, 7, 6, 1, 2, 15, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664172869, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2021, 7, 6, 1, 2, 28, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 664572480, 'comment_body': 'Also check this particular test. I ran it with other format writers and they output an empty table (with an empty header) for such a case. Ideally, the CDS writer should also do the same.\r\nRight now, because this table has no columns, an ValueError gets raised when the total line width is calculated during writing of the ByteByByte description. I think there should be some mechanism to output an empty ByteByByte/ReadMe for an empty table.', 'comment_created': datetime.datetime(2021, 7, 6, 13, 48, 26, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664606928, 'comment_body': ""This is essentially a counter-measure for calculating format and width of columns containing values both in Float (Decimal format) and the Scientific notation. Like in the column `s` of the following table.\r\n\r\n| names | e | d | s | i |\r\n| :--------- | -- | -- | -- | -- |\r\n| HD81809  | 1E-7 | 22.25608 | +2 | 67 |\r\n| HD103095 | -31.6e5 | +27.2500 | -9E34 | -30 |\r\n\r\n- First, by default, the Float column is designated as having the decimal notation, `fformat = 'F'`\r\n- Then we go through the column, record by record, to find the exact format and the width required for it.\r\n- If, upon splitting the Float string, it's found that the current value is in the Scientific notation, the column format designation is changed to `'E'`.\r\n- If the previous value was in the Decimal format, the column format would have been `'F'`. If yes, then the maxSize, maxPrec and maxDec variables are set to default as well. This is done so that the column formatting happens according the value in the Scientific notation, regardless of any other values in the Decimal format.\r\n- If the current value is not in Scientific notation and the column is marked with `'E'` (which means one of the previous values was in the Scientific notation), this particular record is simply skipped, in order to give formatting precedence to the value in Scientific notation.\r\n\r\nAll this helps correctly writing the above table as,\r\n\r\n```\r\nHD81809  1e-07  22.25608   2e+00  67\r\nHD103095 -3e+06 27.25000  -9e+34 -30\r\n```\r\n\r\nWith the ByteByByte being,\r\n\r\n```\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n 1- 8   A8     ---    names    Description of names             \r\n10-14   E5.1   ---    e       [-3160000.0/0.01] Description of e\r\n16-23   F8.5   ---    d       [22.25/27.25] Description of d    \r\n25-31   E7.1   ---    s       [-9e+34/2.0] Description of s     \r\n33-35   I3     ---    i       [-30/67] Description of i       \r\n```"", 'comment_created': datetime.datetime(2021, 7, 6, 14, 27, 39, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664611478, 'comment_body': 'But we do *know* the format - we write the data ourselves. We get to decide if we output in scientific notation or not - the relevant `Outputter` of the class that does the writing will format the numbers. I wonder if we should make use of this knowledge instead of turning it to strings and then inspecting the string to find what function we used to make that substitution.\r\n\r\nOn the other hand, I also wonder if this is the best use of our time. Since this seems to work, maybe we should move on to other steps (e.g. coordinates) and come back to possible simplify this in the end.', 'comment_created': datetime.datetime(2021, 7, 6, 14, 32, 33, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 664614534, 'comment_body': 'What do you think should happen here? Do we need to be able to write empty tables? It seems to be that that is a corner case we can deal with later if ever. How about `if len(table) == 0: raise NotImplementedError`?\r\n\r\nThen, in the very end of this project, there can be a separate PR with the title ""Enable writing empty CDS/MRT tables"". Because it\'s not a bad thing to be able to write those, but we also have a lot of other things that are much higher on the priority list (e.g. mix-in columns: coordinates, time).', 'comment_created': datetime.datetime(2021, 7, 6, 14, 36, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 664619099, 'comment_body': 'Okay. I have already implemented that in [_set_column_val_limits()](https://github.com/astropy/astropy/pull/11897/files#diff-f1aebe08fb4f3dd370b7dec776d172228663c8a0ae39b8115e9f678b8199e42bR252-R262) function.\r\nThe optimization is probably good only for extremely large tables. The current implementation poses no problems for now.', 'comment_created': datetime.datetime(2021, 7, 6, 14, 40, 59, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664627818, 'comment_body': 'Nope, copy of the column is not needed. The temporary `coltmp` is only to fill empty string in place of Null values for String columns, so that `col.dtype.str` returns proper column dtype.', 'comment_created': datetime.datetime(2021, 7, 6, 14, 50, 49, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664641659, 'comment_body': ""`# Licensed under a 3-clause BSD style license - see LICENSE.rst`\r\nThis line appears at the top of `cds.py`. Doesn't this mean that the code in `cds.py` is BSD licensed?"", 'comment_created': datetime.datetime(2021, 7, 6, 15, 5, 53, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 664645305, 'comment_body': 'Oh, good. Great. I guess I got confused about who uses which license.', 'comment_created': datetime.datetime(2021, 7, 6, 15, 10, 8, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671880214, 'comment_body': '> What do you think should happen here? Do we need to be able to write empty tables? It seems to be that that is a corner case we can deal with later if ever. How about `if len(table) == 0: raise NotImplementedError`?\r\n\r\nHave put this in place. I would like to output unfilled ReadMe with no data rows in such cases. But I agree we can deal with empty table writing later. \r\n\r\n', 'comment_created': datetime.datetime(2021, 7, 18, 18, 31, 5, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 671902326, 'comment_body': '```suggestion\r\n           72   A1     ---    DE-      Sign of Declination\r\n```', 'comment_created': datetime.datetime(2021, 7, 18, 21, 47, 38, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671902435, 'comment_body': 'Is that intentional that the lines that start  with ""["" start one position earlier than the others?', 'comment_created': datetime.datetime(2021, 7, 18, 21, 48, 19, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671902874, 'comment_body': 'Technically, we can have a column where the first element is a SkyCoord, but not all elements are SkyCoords. In practice, I don\'t see a use case where the user intentionally constructs a column like that, but it\'s legal. So, should be check here or just assume that such a case is an error? ""col = SkyCoord(col)"" will probably fail in that case and issue some more or less useful error. But we could --if we want-- check and just do something else in this case, e.g. skip the column, raise a warning, or something else? What do other people think?', 'comment_created': datetime.datetime(2021, 7, 18, 21, 51, 58, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671903945, 'comment_body': ""We need to convert a SkyCoord mixin column into string columns in a very specific form for MRT/CDS tables. That conversion is above (details may still change). So, our options are: (1) Change the table to add new columns and  remove the SkyCoord. Leave it up to the user to pass in a copy of their original table if they want to keep the original or (2) we take care of making a copy in this code. That way, the users don't have to worry about it and their original table stays undisturbed.\r\n\r\nI have a preference for (2) @taldcroft What do you think?"", 'comment_created': datetime.datetime(2021, 7, 18, 22, 1, 51, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671904792, 'comment_body': ""```suggestion\r\n                elif col.fortran_format[0] in ('E', 'F'):\r\n```"", 'comment_created': datetime.datetime(2021, 7, 18, 22, 9, 50, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671904853, 'comment_body': '```suggestion\r\n                    lim_vals = ""[{0}/{1}]"".format(math.floor(col.min * 100) / 100.,\r\n```', 'comment_created': datetime.datetime(2021, 7, 18, 22, 10, 17, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671904866, 'comment_body': '```suggestion\r\n                                                  math.ceil(col.max * 100) / 100.)\r\n```', 'comment_created': datetime.datetime(2021, 7, 18, 22, 10, 34, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671905437, 'comment_body': 'I\r\n```suggestion\r\n     (prepared by author  / astropy.io.ascii )\r\n```\r\n\r\nNo longer in pyreadme ;-)', 'comment_created': datetime.datetime(2021, 7, 18, 22, 15, 57, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 671937336, 'comment_body': ""We talked a little about this during the last meeting. I thought that it would be good to make the writer flexible enough to write a ``SkyCoord`` column if all elements of the column are ``SkyCoord`` -- however, what you've pointed out is an important case to deal with. Would it be better to do a ``try-except`` with ``col = SkyCoord(col)``, or explicitly check if all elements of the column are ``SkyCoord`, and then raise a warning + skip the column if it fails? Else, an option is to raise an error and prompt the user to remove the column/fix it themselves? I am more inclined towards the first option since it writes something while warning, but happy to hear more thoughts!"", 'comment_created': datetime.datetime(2021, 7, 19, 1, 44, 27, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 671938169, 'comment_body': ""My preference is (2) as well -- would like to hear @taldcroft's opinion!"", 'comment_created': datetime.datetime(2021, 7, 19, 1, 48, 16, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 671940750, 'comment_body': ""```suggestion\r\n                  delimiter=' ', bookend=False, delimiter_pad=None,\r\n```\r\n\r\nArguments should be aligned."", 'comment_created': datetime.datetime(2021, 7, 19, 1, 58, 34, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 671941272, 'comment_body': '```suggestion\r\n        # Get index of files\r\n```', 'comment_created': datetime.datetime(2021, 7, 19, 2, 0, 57, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 671941450, 'comment_body': '```suggestion\r\n        # Get index of files\r\n```', 'comment_created': datetime.datetime(2021, 7, 19, 2, 1, 38, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 672192470, 'comment_body': 'There is also a question what happens if a table has two SkyCoord columns, say, I cross-matched two catalogs based on their coordinates and both of the original coordinate columns are still in the table. The current code would convert the first column and then delete the original, and then later convert the second column, overwrite the names ""RAh"", etc. so that all information on the first column is silently lost. I think we need either an error, a warning, or some way for the user to select which column is the one that should be converted to ""RAH"", ...', 'comment_created': datetime.datetime(2021, 7, 19, 10, 49, 56, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 672209591, 'comment_body': '> I think we need either an error, a warning, or some way for the user to select which column is the one that should be converted to ""RAH"", ...\r\n\r\nWe also discussed about this case previously and opted to have a note in the documentation that currently tables with only one single Coordinate column are supported. There\'s no separate criteria in the code to deal with situations of two or more coordinate columns. In those cases, sometimes what you say will happen or when one column is in Ecliptic/Galactic and other is in RA/DEC, some random warnings are generated.\r\nLet\'s talk more about it in the meeting.\r\n\r\n', 'comment_created': datetime.datetime(2021, 7, 19, 11, 19, 23, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 672213699, 'comment_body': '_pycdsreadme_ because of its string formatting does this. It is not required by the format (http://cdsarc.u-strasbg.fr/ftp/cats/I/221/ReadMe). This docstring example is outdated.', 'comment_created': datetime.datetime(2021, 7, 19, 11, 26, 13, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 672376579, 'comment_body': ""Is there a reason for `realpath`? That's not typical. And although Python does some magic to make things work with linux-style path separators in Windows, the preferred idiom in astropy is\r\n```\r\nos.path.join(os.path.dirname(__file__), 'src', 'ReadMe.template')\r\n```\r\n"", 'comment_created': datetime.datetime(2021, 7, 19, 14, 57, 58, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 672405108, 'comment_body': ""I agree we don't have to support them (yet), but we do need to make sure that nothing bad happens silently. I suggest something like:\r\n```\r\nif ['Rah', 'RAm', ... 'ELAT'] in self.colnames:\r\n    warnings.warn(f'Table already has coordinate system in CDS/MRT-syle columns. Skipping column {col}')\r\n```\r\nTwo lines of code, easy to change later, but we make sure that limitations are written out, which is important before we can merge this.\r\n(Code above might not work exactly as written. Not sure is self.colnames is defined at this point.)"", 'comment_created': datetime.datetime(2021, 7, 19, 15, 30, 8, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 672411162, 'comment_body': ""I don't think we need that long comments in all three cases ;-)"", 'comment_created': datetime.datetime(2021, 7, 19, 15, 37, 29, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 672422918, 'comment_body': 'Need review by someone who is better with coordinates than I am. This ""else"" catches all other coordinates. What about e.g. cartesian coordinates?', 'comment_created': datetime.datetime(2021, 7, 19, 15, 51, 36, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675336858, 'comment_body': ""Nope, there isn't. I shall make alterations."", 'comment_created': datetime.datetime(2021, 7, 23, 6, 37, 11, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 675337821, 'comment_body': 'I can add a check for `SkyCoord` objects that have `SphericalRepresentation`.\r\nAll other coordinate columns can simply be rendered as string values within a single column.', 'comment_created': datetime.datetime(2021, 7, 23, 6, 39, 53, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 675471664, 'comment_body': 'At least one of the tests should have coordinates that are different in line 1 and line 2. Those are different stars, they in fact DO have different coordinates! For testing, we just want to make sure we would catch a bug that accidentally write the same value (e.g. the first) into every row.', 'comment_created': datetime.datetime(2021, 7, 23, 10, 37, 45, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675472153, 'comment_body': '```suggestion\r\nof a table description (ReadMe) and the table data itself. MRT differs slightly from the CDS\r\n```', 'comment_created': datetime.datetime(2021, 7, 23, 10, 38, 47, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675472423, 'comment_body': '```suggestion\r\nseparate file called ``ReadMe``. On the other hand, MRT format includes just the\r\n```', 'comment_created': datetime.datetime(2021, 7, 23, 10, 39, 19, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675472851, 'comment_body': 'Why do you set the Title in \\`\\`, but not Table caption?', 'comment_created': datetime.datetime(2021, 7, 23, 10, 40, 7, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675473267, 'comment_body': 'but an empty line is added to indicate where this data goes.', 'comment_created': datetime.datetime(2021, 7, 23, 10, 40, 53, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675474112, 'comment_body': '```suggestion\r\n    coordinate columns are dealt with before using ``SkyCoord`` methods.\r\n```', 'comment_created': datetime.datetime(2021, 7, 23, 10, 42, 32, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675479871, 'comment_body': 'Would it make sense to reduce this to just two examples e.g. the remove the first two and start with a table that already has units and coordinates? The output is pretty long and our purpose here is to explain how to use it, not how the format looks (that is done in the linked CDS aad MRT websites). So, I do think we need to show an example of ""your coordinate columns will be broken up automatically"", but I also think that we don\'t have to explain every step.\r\n\r\nOn the other hand, I suggest adding an example of what you said in https://github.com/Suyog7130 :\r\nSomething like ""MRT and CDS have specific naming conventions for columns (link to website). Most of those the CDS writer cannot enforce because it does not know what the data inside the columns means. For example, if a column contains the mean error for the data in a column named ""label"", then the column should be names ""e_label"". Since astropy cannot know how columns in the table are related, it is up to the user to use `Table.rename_colums` to appropriately rename any columns before write the MRT/CDS table."" You could add an example for that, which will have lines like\r\n```\r\n[... set up table here ...]\r\nouttab = tab.copy()  # so that changes don\'t affect the original table\r\nouttab.rename_column(\'error\', \'e_flux\')\r\n# re-order so that columns have good order\r\nouttab = outtab[\'coord\', \'name\', \'flux\', \'e_flux\']  # set up your original table just that error and flux are not next to each other\r\n# Or leave out the re-orderting. Not sure if it is useful as an example here. What do you think?\r\nouttabl.write(...)\r\n', 'comment_created': datetime.datetime(2021, 7, 23, 10, 54, 24, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675489109, 'comment_body': 'Because the MRT template has a field named _Title_ that needs to be manually filled. The Table Caption field is actually named _Table_, which can be ambiguous here. Also, the _Title_ refers to the paper/publication title in which this table is included.', 'comment_created': datetime.datetime(2021, 7, 23, 11, 13, 35, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 675710107, 'comment_body': 'Well, the error and other related columns are often put next to each other. So, I suppose, it would be good to add that.\r\nShould I show the rearranged table too, or simply write out the code? I think it would be understood how the column rearrangement would look like.', 'comment_created': datetime.datetime(2021, 7, 23, 17, 3, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 675773024, 'comment_body': 'I have added a `table = table.copy()` in `Cds.write()` and a small test for this purpose.\r\n', 'comment_created': datetime.datetime(2021, 7, 23, 18, 31, 2, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 675828942, 'comment_body': ""> We talked a little about this during the last meeting. I thought that it would be good to make the writer flexible enough to write a `SkyCoord` column if all elements of the column are `SkyCoord` -- however, what you've pointed out is an important case to deal with. Would it be better to do a `try-except` with `col = SkyCoord(col)`, or explicitly check if all elements of the column are ``SkyCoord`, and then raise a warning + skip the column if it fails? Else, an option is to raise an error and prompt the user to remove the column/fix it themselves? I am more inclined towards the first option since it writes something while warning, but happy to hear more thoughts!\r\n\r\nI have implemented a ``try-except`` for the esoteric cases where a column has first value as a ``SkyCoord`` object but not others. However, these types of columns cannot be parsed properly for generation of the Byte-By-Byte, even when they are `Column` objects, because consistency across the whole column is expected. Also, that singleton ``SkyCoord`` object or others if present in the column, will need to be converted to float/string values. The data would in any case be wrong.\r\nThese columns are converted to ``Column`` object and then skipped from further editing. However, they may still result in failure."", 'comment_created': datetime.datetime(2021, 7, 23, 19, 44, 38, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 675863134, 'comment_body': 'I checked with other `mix-in` type columns, for instance, the various coordinate Representations. The `write_byte_by_byte` function fails to interpret the `size` and `format` for all such columns, because their values are of `object` type and not any of the `float`, `int` or `string` types for which functions are provided.\r\n\r\nFor these `mix-in` columns and columns with partial `SkyCoord` values, I first make a `Column` object and convert each of the column values to `str`. Henceforth, those columns are then treated as normal string columns, with the `label` been put as `Unknown`.\r\n\r\nThe earlier traceback from the writer while writing these `mix-in` columns was as given below. Now, the table is written as given the tests `test_write_mixin_and_broken_cols`.\r\n\r\n```\r\n(.virtualenvs) $ python3.8 cdsWriterAstropyRun.py check_otherMixInCols\r\nTraceback (most recent call last):\r\n  File ""cdsWriterAstropyRun.py"", line 540, in <module>\r\n    func()\r\n  File ""cdsWriterAstropyRun.py"", line 487, in check_otherMixInCols\r\n    ascii.write(t, format=\'cds\')\r\n  File ""/media/suyog/DATA/Python/astropy_fork/astropy/io/ascii/ui.py"", line 845, in write\r\n    lines = writer.write(table)\r\n  File ""/media/suyog/DATA/Python/astropy_fork/astropy/io/ascii/cds.py"", line 845, in write\r\n    return super().write(table)\r\n  File ""/media/suyog/DATA/Python/astropy_fork/astropy/io/ascii/core.py"", line 1488, in write\r\n    self.write_header(lines, table.meta)\r\n  File ""/media/suyog/DATA/Python/astropy_fork/astropy/io/ascii/core.py"", line 1443, in write_header\r\n    self.header.write(lines)\r\n  File ""/media/suyog/DATA/Python/astropy_fork/astropy/io/ascii/cds.py"", line 633, in write\r\n    \'bytebybyte\': self.write_byte_by_byte()})\r\n  File ""/media/suyog/DATA/Python/astropy_fork/astropy/io/ascii/cds.py"", line 514, in write_byte_by_byte\r\n    endb = col.meta.size + startb - 1\r\nAttributeError: \'collections.OrderedDict\' object has no attribute \'size\'\r\n```', 'comment_created': datetime.datetime(2021, 7, 23, 20, 59, 49, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 675919394, 'comment_body': 'Maybe it\'s better to just skip any column of type ""object""? We take care of mix-in coordiantes, we will take care of mix-in times and for all others users will need to do the conversion ""by hand"" before calling this writer. There is precendence - not every writer can write every column format, e.g. a csv table with multi-D columns won\'t work.', 'comment_created': datetime.datetime(2021, 7, 24, 0, 22, 5, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 675991589, 'comment_body': '> For these `mix-in` columns and columns with partial `SkyCoord` values, I first make a `Column` object and convert each of the column values to `str`. Henceforth, those columns are then treated as normal string columns, with the `label` been put as `Unknown`.\r\n\r\nUhm... But I have already add this for the `Time` and other `mix-in` columns. I personally thing it is better to output a table with string columns, than an `AttributeError` being raised later. When we have support for `Time` columns, I shall modify parts of this code. Let me push these new commits and then we can discuss further.\r\n\r\n', 'comment_created': datetime.datetime(2021, 7, 24, 12, 9, 12, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 676016559, 'comment_body': 'It the same case for extra coordinate columns. They are skipped, but later another `AttributeError` comes up because the skipped column is still a `SkyCoord` object.\r\n\r\nI would prefer to **issue warning** and **convert such col values to string**, so the writing can proceed ahead and **label all these cols as  _Unknown_**. The final output table is not useful, but the user will need to make modification anyway. I think it good to show up some output table in all situations.\r\n\r\nAny corrections for all these standalone corner cases can be incorporated individually later on.', 'comment_created': datetime.datetime(2021, 7, 24, 16, 9, 33, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 676029319, 'comment_body': ""A warning is fine, too. I just don't want to silently convert one column and overwrite the previous one without the user knowing that's happening."", 'comment_created': datetime.datetime(2021, 7, 24, 18, 18, 16, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 676038565, 'comment_body': 'I agree that converting columns behind the scenes without the user knowing is __bad__. I like the idea of issuing a warning to let the user know that they need to convert the `object` columns by hand (except co-ordinate and time columns which you will deal with either in this PR or later), but still outputting something so that the user knows where the output is failing. However, the `Table` should ideally not be converted, i.e. a copy works well.', 'comment_created': datetime.datetime(2021, 7, 24, 19, 57, 41, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 676142632, 'comment_body': 'Try make this a local import and see if it helps.', 'comment_created': datetime.datetime(2021, 7, 25, 12, 57, 51, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 680700480, 'comment_body': 'I know I suggested you move this up since it is a standard library import (which come first according to PEP8), but `os` and `math` are also standard library imports; so just move this line after `import numpy as np`.', 'comment_created': datetime.datetime(2021, 8, 2, 6, 57, 57, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 680701220, 'comment_body': 'could remove this import, and use u.Unit instead of Unit -- `from astropy import units as u` is imported right after.\r\n```suggestion\r\n```', 'comment_created': datetime.datetime(2021, 8, 2, 6, 59, 26, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 680711309, 'comment_body': 'I know that the `formats` argument is being used to mention the right precision for values. But, does finding the `size` attribute in `col.meta` automatically imply that it is for ``formats``? Should there be an additional check? If not, you could make it clear in the docstring/docs that this is expected.', 'comment_created': datetime.datetime(2021, 8, 2, 7, 19, 5, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 680711797, 'comment_body': 'You could extend this docstring slightly to explain what you do here.', 'comment_created': datetime.datetime(2021, 8, 2, 7, 20, 6, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 680713175, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2021, 8, 2, 7, 22, 28, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 680721679, 'comment_body': '```suggestion\r\n    The CDS writer currently supports automatic writing of a single coordinate column in ``Tables``. For Tables with \r\n    more than one coordinate column, only the first found coordinate column will be converted to the appropriate \r\n    component column, and the rest of the coordinate columns will be converted to string columns. Thus, any\r\n    additional coordinate columns should be dealt with before using ``SkyCoord`` methods.\r\n```', 'comment_created': datetime.datetime(2021, 8, 2, 7, 36, 27, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 680923728, 'comment_body': '```suggestion\r\nAs the CDS/MRT standard requires, for columns that have a ``Unit`` attribute, the unit names are tabulated in the Byte-By-Byte\r\n```', 'comment_created': datetime.datetime(2021, 8, 2, 12, 20, 41, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 680925896, 'comment_body': '```suggestion\r\n  >>> outtab.rename_column(\'error\', \'e_Flux\')\r\n```\r\nShould this not start with a capital letter, if the original ""Flux"" column also starts with a capital letter?', 'comment_created': datetime.datetime(2021, 8, 2, 12, 23, 57, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 681033674, 'comment_body': 'It is only when the `formats` argument is passed that the `col.meta.size` is set prior to checking and formatting for different datatypes. See [L407-408](https://github.com/astropy/astropy/pull/11897/files#diff-f1aebe08fb4f3dd370b7dec776d172228663c8a0ae39b8115e9f678b8199e42bR407-R408).\r\nI will make it more clear in the docstring.', 'comment_created': datetime.datetime(2021, 8, 2, 14, 45, 42, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 688913749, 'comment_body': 'Providing a unit of `u.year` seems not quite right. From the MRT standard, a ""year"" is a unit of delta time equal to 365.25 days. That\'s a different thing than the date expressed as `2021.25`.', 'comment_created': datetime.datetime(2021, 8, 14, 10, 35, 27, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 688940705, 'comment_body': 'Ah! I see. Maybe the unit should be `day (d)` since the resolution of values like `2021.25` is in days.', 'comment_created': datetime.datetime(2021, 8, 14, 15, 7, 22, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 693421171, 'comment_body': 'Take out the word ""currently"". The documentation refers to the current state of astropy, not what might happen in the future.', 'comment_created': datetime.datetime(2021, 8, 22, 0, 57, 40, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693490973, 'comment_body': ""This large block in the loop should be factored out to a function. \r\n\r\nDon't use a variable name like `i` over such a long context. If someone reading this code sees an `i` 80 lines later it's hard to know where it was defined and even harder to search for `i`."", 'comment_created': datetime.datetime(2021, 8, 22, 11, 59, 30, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693491839, 'comment_body': ""I'm curious why the first part of the `or` is needed."", 'comment_created': datetime.datetime(2021, 8, 22, 12, 6, 4, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693492219, 'comment_body': 'Should be lower-case `unit` not `Unit` attribute. Note that *all* columns have a `unit` attribute, so what you mean is whether the attribute is defined (or technically not `None`).', 'comment_created': datetime.datetime(2021, 8, 22, 12, 8, 51, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693492259, 'comment_body': 'Lower case `unit`.', 'comment_created': datetime.datetime(2021, 8, 22, 12, 9, 6, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693494248, 'comment_body': 'The `u.day` unit is still not appropriate, and probably worse than `u.yr`. The point here is that a `Time` does not have a unit.  A value of `2019.0` is a decimal representation of a point in time that is equivalent to `2019-01-01`, which is a string representation of that point in time. Neither of those have a meaningful unit.\r\n\r\nSorry for being pedantic, but again `u.yr` is 365.25 * 86400 sec, and `2019.0` is not 2019.0 * 365.25 * 86400 seconds since year 0.0.', 'comment_created': datetime.datetime(2021, 8, 22, 12, 23, 39, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693509882, 'comment_body': ""More easily written as:\r\n```\r\ni_byte_by_byte = lines.index('=' * 80)\r\n```"", 'comment_created': datetime.datetime(2021, 8, 22, 14, 22, 57, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693512732, 'comment_body': ""I think we are better off just not writing these limit values. They are optional and the MRT example does not show including them.\r\n\r\nThe main problem with writing them out is that you have had to make some compromises in order to not make the output very messy. \r\n```\r\nt = simple_table()\r\nt['b'] = 1 + t['b'] / 1e10\r\nascii.write(t, format='cds')\r\nTitle:\r\nAuthors:\r\nTable:\r\n================================================================================\r\nByte-by-byte Description of file: table.dat\r\n--------------------------------------------------------------------------------\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n    1  I1     ---    a       [1/3] Description of a     \r\n 3-14  F12.10 ---    b       [1.0/1.01] Description of b\r\n   16  A1     ---    c       Description of c           \r\n--------------------------------------------------------------------------------\r\nNotes:\r\n--------------------------------------------------------------------------------\r\n1 1.0000000001 c\r\n2 1.0000000002 d\r\n3 1.0000000003 e\r\n```\r\nMore importantly, the limits inside the `[...]` are supposed to be for validating legal values, not for expressing the range of existing data. Since you have no way of knowing a priori the range of legal values. This is like requiring the user to supply the correct column names for an error-bar column since the program cannot guess that.\r\n\r\nOne way to do this could be a `limits` argument to the write function which allows the user to specify limits by column name. This can be deferred for a future enhancement.\r\n\r\nAlso the `MAX_COL_INTLIMIT` is an arbitrary and hidden parameter which can confuse users if 99999 gets a limit while 100001 does not."", 'comment_created': datetime.datetime(2021, 8, 22, 14, 45, 23, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693514001, 'comment_body': 'I\'m confused about what\'s going on here with the `\'size\'` key in the column meta. Where might that get set? Is this supposed to imply ""width"" (as in the character width of the output)?', 'comment_created': datetime.datetime(2021, 8, 22, 14, 54, 51, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693514532, 'comment_body': 'In general, you should *never* be accessing attributes like `col.name` or `col.description`. Those only work for `Column` and `MaskedColumn`, but modern ""mixin-safe"" code needs to always get/set the `info` attributes like `col.info.name` or `col.info.description`. Right now the CDS writer is failing for a simple QTable because of this:\r\n```\r\nqt = QTable()\r\nqt[\'a\'] = [1,2] * u.m\r\nascii.write(qt, format=\'cds\')\r\nTitle:\r\nAuthors:\r\nTable:\r\n================================================================================\r\nByte-by-byte Description of file: table.dat\r\n--------------------------------------------------------------------------------\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n1-3  F3.1   m      Unknown [1.0/2.0] Description of Unknown\r\n--------------------------------------------------------------------------------\r\nNotes:\r\n--------------------------------------------------------------------------------\r\n1.0\r\n2.0\r\n```\r\n', 'comment_created': datetime.datetime(2021, 8, 22, 14, 59, 9, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693514895, 'comment_body': 'I think the default description if not provided should just be blank, or perhaps `---` or the column name  if there must be something there. The `Description of ...` is just adding noise but not information.', 'comment_created': datetime.datetime(2021, 8, 22, 15, 1, 57, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693515418, 'comment_body': ""I don't understand why you are attaching attributes like this to the OrderedDict `col.meta`. I suppose it works, but it is strange to attach random object attributes to `col.meta`. That is not part of the data model for column meta."", 'comment_created': datetime.datetime(2021, 8, 22, 15, 6, 12, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693517156, 'comment_body': ""This logic is not quite robust for giving a strictly-formatted header, though I guess it is probably legal from the examples I've seen.\r\n```\r\nt = Table()\r\nt['a'] = ['a'*80, 'b'*80]\r\nt['b'] = ['a'*80, 'b'*80]\r\nt['a'].info.description = ' '.join(['casdfasdf'] * 20)\r\nascii.write(t, format='cds')\r\n\r\n================================================================================\r\nByte-by-byte Description of file: table.dat\r\n--------------------------------------------------------------------------------\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n  1- 80  A80    ---    a       casdfasdf casdfasdf casdfasdf casdfasdf casdfasdf\r\n                              casdfasdf casdfasdf casdfasdf casdfasdf casdfasdf\r\n                              casdfasdf casdfasdf casdfasdf casdfasdf casdfasdf\r\n                              casdfasdf casdfasdf casdfasdf casdfasdf casdfasdf\r\n 82-161  A80    ---    b       Description of b\r\n--------------------------------------------------------------------------------\r\n```\r\n\r\n"", 'comment_created': datetime.datetime(2021, 8, 22, 15, 19, 34, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693531174, 'comment_body': 'Numpydoc format is like:\r\n```\r\nvalue : float\r\n    value to split\r\n```\r\n', 'comment_created': datetime.datetime(2021, 8, 22, 17, 15, 42, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693532439, 'comment_body': 'This expression for floats is not correct. E.g. try it with `.2` or `++-+-+5` or `+hello5`.  I think the answer https://stackoverflow.com/questions/385558/extract-float-double-value is correct.', 'comment_created': datetime.datetime(2021, 8, 22, 17, 26, 59, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693533921, 'comment_body': ""This fails in this case:\r\n```\r\nt = Table()\r\nt['b'] = [2.123456789, 2e20]\r\nascii.write(t, format='cds')\r\n\r\n================================================================================\r\nByte-by-byte Description of file: table.dat\r\n--------------------------------------------------------------------------------\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n 1- 5  E5.1   ---    b       [2.12/2e+20] Description of b\r\n--------------------------------------------------------------------------------\r\nNotes:\r\n--------------------------------------------------------------------------------\r\n2e+00\r\n2e+20\r\n```\r\n"", 'comment_created': datetime.datetime(2021, 8, 22, 17, 40, 2, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693534633, 'comment_body': 'From looking at the code I think this is the max formatted width. So can you just use `col.max_formatted_width` for clarity (or `col.formatted_width` for something slightly shorter)? In this case `size` is not telling us anything.', 'comment_created': datetime.datetime(2021, 8, 22, 17, 46, 53, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693535333, 'comment_body': ""I'm confused by this. `start_line` is not a keyword arg for `ascii.write`, so I'm wondering what this is doing here?"", 'comment_created': datetime.datetime(2021, 8, 22, 17, 52, 16, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693536555, 'comment_body': ""I don't think you need to substitute the result anywhere. Just\r\n```\r\nint(re.search(r'(\\d+)$', dtype).group(1))\r\n```\r\n"", 'comment_created': datetime.datetime(2021, 8, 22, 18, 3, 55, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693537362, 'comment_body': ""The `Format` and `Units` can both be longer than 6 characters, so I'm confused about the hardwired 6 here."", 'comment_created': datetime.datetime(2021, 8, 22, 18, 11, 32, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 693855422, 'comment_body': 'Though I guess to be fair this expression might work for parsing the bits of a string that is known to have been generated by ""normal"" Python formatting of a float value. But do remember that the format specifier for a column can be quite general, e.g. `col[\'a\'].info.format = \'++{:.2f}\'`. The current expression would accept values formatted that way, whereas the right behavior would probably be an exception since a float value is being formatted in a non-float output.\r\n\r\nSo you might test for a correctly formatted float by doing `float(value)` in a try/except.', 'comment_created': datetime.datetime(2021, 8, 23, 10, 33, 55, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 694127719, 'comment_body': 'Was this a result of the numpy ``DeprecationWarning`` issue @Suyog7130?', 'comment_created': datetime.datetime(2021, 8, 23, 16, 29, 58, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 697850620, 'comment_body': ""I see your point here and have made the correction.\r\n\r\n> but again u.yr is 365.25 * 86400 sec, and 2019.0 is not 2019.0 * 365.25 * 86400 seconds since year 0.0.\r\n\r\nHowever, doesn't the conversion of a `datetime` object to `decimalyear` uses this?"", 'comment_created': datetime.datetime(2021, 8, 28, 10, 31, 20, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 697851519, 'comment_body': 'Yeah, they can be. **6** is hardcoded to have a minimum column width when `Format` and `Units` have less than 6 characters. This also helps in the Byte-By-Byte mini-table header row alignment.', 'comment_created': datetime.datetime(2021, 8, 28, 10, 38, 56, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 697878503, 'comment_body': ""Note that this is the expected behaviour, so that code block is not failing strictly speaking.\r\n\r\nIf any column has atleast one value in exponential notation, the intent is to convert all other values of the column to this format. The number of decimal places in the integer part is governed by the number of digits after decimal of the original value given in exponential notation. Trailing zeros after decimal are discounted.\r\nThus your example above. `t['b'] = [2.123456789, 2.00e20]` would also output the table.\r\n\r\nIf it is required that the output table has a set number of digits after decimal for all column values, then the original value in exponential notation should have digits, without trailing zeroes, after the decimal in the integer part. So,\r\n\r\n```\r\nt['b'] = [2.123456789, 2.45e20]\r\nascii.write(t, format='cds')\r\n\r\n================================================================================\r\nByte-by-byte Description of file: table.dat\r\n--------------------------------------------------------------------------------\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n 1- 8  E8.3   ---    b       [2.12/2.45e+20] Description of b\r\n--------------------------------------------------------------------------------\r\nNotes:\r\n--------------------------------------------------------------------------------\r\n2.12e+00\r\n2.45e+20\r\n```"", 'comment_created': datetime.datetime(2021, 8, 28, 14, 43, 4, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 697879649, 'comment_body': 'Haan, the alignment of Byte-By-Byte mini-table header is not properly set. It is good to have that header line aligned though. So, I have done modifications to align it in one of the later PRs.', 'comment_created': datetime.datetime(2021, 8, 28, 14, 53, 30, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 697880768, 'comment_body': 'The data part of the CDS table can itself have header lines, esp. when the data is written in a separate file. The title of the Byte-By-Byte for such tables then says that rows till `start_line` are header lines.\r\nBecause such tables are not ubiquitous, adding the `start_line` keyword to `ascii.write` for allowing this feature prob skipped my mind.\r\nShould this be added? Else I can remove that `if` statement.', 'comment_created': datetime.datetime(2021, 8, 28, 15, 3, 43, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 697881665, 'comment_body': ""This would not be the expected behavior for most users. Silently dropping precision based on an undocumented / tricky rule like this will eventually lead to a bug report if this gets widely used. Consider the very different behavior of two apparently similar cases:\r\n```\r\nIn [18]: t['b'] = [2.123456789, 2.45e15]\r\n    ...: ascii.write(t, format='cds')\r\n    ...: \r\nTitle:\r\nAuthors:\r\nTable:\r\n================================================================================\r\nByte-by-byte Description of file: table.dat\r\n--------------------------------------------------------------------------------\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n 1-26  F26.9  ---    b       [2.12/2450000000000000.0] Description of b\r\n--------------------------------------------------------------------------------\r\nNotes:\r\n--------------------------------------------------------------------------------\r\n               2.123456789\r\n2450000000000000.000000000\r\n\r\nIn [19]: t['b'] = [2.123456789, 2.45e16]\r\n    ...: ascii.write(t, format='cds')\r\n    ...: \r\nTitle:\r\nAuthors:\r\nTable:\r\n================================================================================\r\nByte-by-byte Description of file: table.dat\r\n--------------------------------------------------------------------------------\r\n Bytes Format Units  Label     Explanations\r\n--------------------------------------------------------------------------------\r\n 1- 8  E8.3   ---    b       [2.12/2.45e+16] Description of b\r\n--------------------------------------------------------------------------------\r\nNotes:\r\n--------------------------------------------------------------------------------\r\n2.12e+00\r\n2.45e+16\r\n```\r\n"", 'comment_created': datetime.datetime(2021, 8, 28, 15, 11, 43, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 697884710, 'comment_body': ""There wasn't any particular reason to choose this."", 'comment_created': datetime.datetime(2021, 8, 28, 15, 39, 45, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 697885096, 'comment_body': 'Yes, the `size` key was meant for the width of the column. Thanks for the heads-up about more semantic naming.', 'comment_created': datetime.datetime(2021, 8, 28, 15, 43, 25, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 697975374, 'comment_body': 'Yeah, it was because of that. However, having both the conditions is not necessary.', 'comment_created': datetime.datetime(2021, 8, 29, 8, 3, 23, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698025885, 'comment_body': 'This strongly encourages users to put in a description for every column though, which I think is the intend of the MRT format. MRT tables will (in the use case that we are working towards, although I\'m use users will find a way to abuse that) always be edited by journal staff to put in the proper reference information of the published article, so an pretty obvious ""PUT SOEMTHING HERE"" can be useful. That said,  `---` fills the same role and is a little less obtrusive.', 'comment_created': datetime.datetime(2021, 8, 29, 14, 37, 32, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 698026057, 'comment_body': ""Points like this are exactly why we asked you, @taldcroft, to have a look! I'm not using (or writing code for) QTables."", 'comment_created': datetime.datetime(2021, 8, 29, 14, 38, 42, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 698026332, 'comment_body': ""They don't hurt and can be removed once we drop (I think) numpy 1.18, which will happen in a few months time. However, we don't want to wait this long with merging since we hope to get through all of @Suyog7130 PRs by then! So for, now this (or a similar) crutch needs to stay in."", 'comment_created': datetime.datetime(2021, 8, 29, 14, 41, 4, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 698026486, 'comment_body': ""I think `i` is fine for a counting variable - it's what most people would expect when they see `i` or `j`. However, I don't feel strongly about this and would also be OK with a more explicit name like `col_num`."", 'comment_created': datetime.datetime(2021, 8, 29, 14, 42, 21, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 698069829, 'comment_body': ""Using `i` is fine for a loop that can be easily seen in one screenful, while in this case the loop blocks are quite long.\r\n\r\nWhile I'm looking at the code, the giant block in the `write` method could be done without any index variable by making a list `new_cols = []` at the top, then looping over columns and processing each column. For the special cases then some transformation of the column happens (possibly turning one column into two or more), but for the rest you just append the original column. Then at the end `self.cols = new_cols`. This way:\r\n- You don't need an index\r\n- You preserve the original column order. The current code always puts any coordinate columns at the end of the column list."", 'comment_created': datetime.datetime(2021, 8, 29, 20, 59, 42, tzinfo=datetime.timezone.utc), 'commenter': 'taldcroft', 'type': 'User'}, {'comment_id': 698219827, 'comment_body': 'Ah,  I see. Thank you for pointing out this discrepancy in the behaviour.\r\nThis can probably be addressed by opting for highest precision.\r\nWould be good to address it separately. So, **needs an issue**.', 'comment_created': datetime.datetime(2021, 8, 30, 6, 29, 52, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698220990, 'comment_body': 'Yup, I have also thought of doing this.\r\nSince, the output of the tests will change because of different column sequence, it would be better to address this separately. So, **needs an issue**.', 'comment_created': datetime.datetime(2021, 8, 30, 6, 32, 21, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698221479, 'comment_body': 'Since, the output of the tests will change when this is done, it would be better to address this separately. So, **needs an issue**.', 'comment_created': datetime.datetime(2021, 8, 30, 6, 33, 25, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698233418, 'comment_body': ""I think the limit values are how the CDS/MRT services check if the values within the column designated by RAh, for instance, fall within the defined limits. For most cases these limits will be the max/min values of the column.\r\n\r\nCheckout the following given towards the end of section 3.4.1 in http://vizier.u-strasbg.fr/doc/catstd-3.4.htx. MRT's page also has the same (https://journals.aas.org/mrt-explanation/).\r\n\r\n> When specified, limiting numbers should represent actual limits, and not the range of all possible values which can be inferred from the format (e.g. [-999,9999] for an I4 number).\r\n> Some labels have implicit limits, listed in the column Limits of the tables in section 3.3. These defaults are overridden (for numeric columns only) by the limits specified within square brackets in the description file : writing e.g.[] as the first word of the explanation of a column labelled GLON removes the condition 0 <=GLON < 360."", 'comment_created': datetime.datetime(2021, 8, 30, 6, 46, 15, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698235721, 'comment_body': 'However, I do agree that the using `MAX_COL_INTLIMIT` and writing out max/min values inside `[...]` is not the best implementation. As you say, using a `limits` argument will be a better approach, if at all we do want to include them.\r\nThis would need some work. So, **needs an issue**.', 'comment_created': datetime.datetime(2021, 8, 30, 6, 50, 40, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698236931, 'comment_body': 'This would need some work. So, **needs an issue**.', 'comment_created': datetime.datetime(2021, 8, 30, 6, 52, 55, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698250193, 'comment_body': ""When I check `col.name` and `col.info.name` for the `qt` above, both of them are set to `None`. Whereas, `qt.info()` gives out `a float64    m Quantity`.\r\n\r\nThis may possibly be because the [`Basereader.write` func in `core.py` ](https://github.com/astropy/astropy/blob/5942ac3a222045c26db0ab4497d6128d1a9dc80c/astropy/io/ascii/core.py#L1447) takes the table columns and saves them as a list in `header.cols` using `table.columns.values()`.\r\n\r\nFor a `Table`, `t.columns.values()` is `odict_values([<Column name='b' dtype='float64' length=2>\r\n2.123456789\r\n   2.45e+20])`\r\nFor a `QTable`, `qt.columns.values()` is `odict_values([<Quantity [1., 2.] m>])`\r\n"", 'comment_created': datetime.datetime(2021, 8, 30, 7, 17, 56, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698251989, 'comment_body': 'We had not foreseen that QTables may not work with the code. Thank you for your valuable comment. :)\r\nLooks like this may need some work. So, **needs an issue**.', 'comment_created': datetime.datetime(2021, 8, 30, 7, 21, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 698405635, 'comment_body': 'I think we leave it in for now.', 'comment_created': datetime.datetime(2021, 8, 30, 11, 26, 12, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}]","[{'commit_sha': '1d063e069dff0014d41a5e486d9812f603cc343a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2494d7131911e15418b3e1751b77b69327b6f1b9', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c823ea8da849b7dca3515e151d18070253a8009e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6104b40edf5bfa2f5085c731c2aff4bdc4cefbdc', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9d7b539b55433f3e7678fad6d0a8cfecff0f56c5', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a35654400f1f1bd214a0fcf6c648eafb0b91fd34', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1a1f578ce64985b21cb8987ccecc9f956fa9f12c', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e4a0b6e060be6f8a4e6119bcabaa7e51f28ca149', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7caee2165171a72286a9e2788fbc6c5ad46a8180', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63713104eb01b0822c4c461eed1e652d61a20a19', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'faea56236649b173161f45f1e56f529775988bfb', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7457da3bd344a20682c518fbe1170fc83aec689e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'aa0798c5ccad6da9e9c9b3862e5c2f51d82d008a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c2f363720084f57c9dfc60540006c5530b8462c9', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '11c3dbd38569528581f66b274b121e204fe232d2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b737f45b349ce2f7c23ae969f64be6a7a8c106a2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '60fc9e061f4a435453cee5a21d5de13baa646972', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e8d6072d07ed674027589f4d8a3916202126bc96', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23d85a22619a70210236ecd62e7cb114226270ac', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0c7c875857003db9695c253496b8cadfd802202b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9419d28c6acaad57f6689a45383bbf76b5f8f72e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ea21df6eb416b10684a856b4fc411415f1d6fe07', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14f0cfb0766f4af6177a250ca146621998c36252', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a9fb21fa6541ff7027877e34a76cd3aa1be2cae6', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14bb02519c0a3a4b1b4d1857a83d00fd4de99a02', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fbe6a20b664277377b4a6c8ce62f832416a84a33', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '20d533775bf12c6e5156fd7d70ccbcabf4fe2e8d', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cf7481a5732681f4aca49a1196d02d10ce12c517', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a660823d3f430da5d5351a0765b7b226d1469b45', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2090a94a57295313ee7b9a781c7036323b8aea2b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b482c7a16677c287395ea5014459b3e583e08a70', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '931b2095698031f2af0270e03d3d7069d97728b0', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a303a860f8e18e14088cfc155c62dc2f7c1ef592', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e7ab7d9168cdf2246d5e8e7cd8546c6485c4284a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2ea2ffbdbe06967482e0d1675808ffb057d436b2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8d30ebc27093eb9b3b06cd2166c75b8a0c57b48f', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8edd3bc28481b41231fc3034e649bf90d7340bcd', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ec5b63e5f589c0619c72bc94b831aa742fc12357', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}]",Suyog Garg,29597910,suyog7130@gmail.com,User,,30,,175,16
706344924,Support CDS/MRT format writing for `Time` columns [GSoC21b],"<!-- This comments are hidden when you submit the pull request,
so you do not need to remove them! -->

<!-- Please be sure to check out our contributing guidelines,
https://github.com/astropy/astropy/blob/main/CONTRIBUTING.md .
Please be sure to check out our code of conduct,
https://github.com/astropy/astropy/blob/main/CODE_OF_CONDUCT.md . -->

<!-- If you are new or need to be re-acquainted with Astropy
contributing workflow, please see
http://docs.astropy.org/en/latest/development/workflow/development_workflow.html .
There is even a practical example at
https://docs.astropy.org/en/latest/development/workflow/git_edit_workflow_examples.html#astropy-fix-example . -->

<!-- Astropy coding style guidelines can be found here:
https://docs.astropy.org/en/latest/development/codeguide.html#coding-style-conventions
Our testing infrastructure enforces to follow a subset of the PEP8 to be
followed. You can check locally whether your changes have followed these by
running the following command:

tox -e codestyle

-->

<!-- Please just have a quick search on GitHub to see if a similar
pull request has already been posted.
We have old closed pull requests that might provide useful code or ideas
that directly tie in with your pull request. -->

<!-- We have several automatic features that run when a pull request is open.
They can appear daunting but do not worry because maintainers will help
you navigate them, if necessary. -->

### Description
<!-- Provide a general description of what your pull request does.
Complete the following sentence and add relevant details as you see fit. -->

<!-- In addition please ensure that the pull request title is descriptive
and allows maintainers to infer the applicable subpackage(s). -->

This Pull Request is part of the 2021 Google Summer of Code work I am doing together with mentors @aaryapatil and @hamogu.
It is a continuation of the modifications in #11897 which primarily aims to address issue #11257.

Note that the count appended at the end of the PR title, **[GSoC21a]**, **[GSoC21b]** and so on, denote the sequence in which rebasing has been (will be) done to the commits. It is preferred if the merging also takes place in this order. Also, because the previous PRs are not merged yet, the later ones contain numerous unrelated commits at the time of opening the PR.

<!-- If the pull request closes any open issues you can add this.
If you replace <Issue Number> with a number, GitHub will automatically link it.
If this pull request is unrelated to any issues, please remove
the following line. 

Fixes #<Issue Number>  -->

### Checklist for package maintainer(s)
<!-- This section is to be filled by package maintainer(s) who will
review this pull request. -->

This checklist is meant to remind the package maintainer(s) who will review this pull request of some common things to look for. This list is not exhaustive.

- [ ] Do the proposed changes actually accomplish desired goals?
- [ ] Do the proposed changes follow the [Astropy coding guidelines](https://docs.astropy.org/en/latest/development/codeguide.html)?
- [ ] Are tests added/updated as required? If so, do they follow the [Astropy testing guidelines](https://docs.astropy.org/en/latest/development/testguide.html)?
- [ ] Are docs added/updated as required? If so, do they follow the [Astropy documentation guidelines](https://docs.astropy.org/en/latest/development/docguide.html#astropy-documentation-rules-and-guidelines)?
- [ ] Is rebase and/or squash necessary? If so, please provide the author with appropriate instructions. Also see [""When to rebase and squash commits""](https://docs.astropy.org/en/latest/development/when_to_rebase.html).
- [ ] Did the CI pass? If no, are the failures related? If you need to run daily and weekly cron jobs as part of the PR, please apply the `Extra CI` label.
- [ ] Is a change log needed? If yes, did the change log check pass? If no, add the `no-changelog-entry-needed` label.
- [ ] Is a milestone set? Milestone must be set but `astropy-bot` check might be missing; do not let the green checkmark fool you.
- [ ] At the time of adding the milestone, if the milestone set requires a backport to release branch(es), apply the appropriate `backport-X.Y.x` label(s) *before* merge.

### Checklist for PR author

- [x] Give time column `format` and `scale` in Byte-By-Byte description.
- [ ] Work on other edit suggestions.
",False,12027,https://api.github.com/repos/astropy/astropy/pulls/12027,https://github.com/astropy/astropy/pull/12027,closed,203,61,4,9,26,13,4,0,"[{'name': 'io.ascii'}, {'name': 'unified-io'}, {'name': 'Close?'}, {'name': 'closed-by-bot'}]",2021-08-09 09:09:49+00:00,2022-03-02 05:36:48+00:00,17699219.0,"204 days, 20:26:59","[{'comment_id': 701303202, 'comment_body': 'I don\'t understand this sentence. Do you mean ""columns that contain Time objects are are a time mix-in column?\r\nHow about\r\n```suggestion\r\nFor columns holding `~astropy.time.Time` values, the values are\r\n```\r\nwhich can be read as ""one (= the column is a Time object) or more (the column is a list of Time objects)"".', 'comment_created': datetime.datetime(2021, 9, 2, 17, 52, 41, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 701337269, 'comment_body': 'Is there a reason why you have changed the header line?', 'comment_created': datetime.datetime(2021, 9, 2, 18, 45, 26, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 701349893, 'comment_body': ""I wonder if this should be changed to `tval.to_value('mjd', 'long')` for `longdouble` precision, and go beyond the `format='.12f'`."", 'comment_created': datetime.datetime(2021, 9, 2, 19, 5, 47, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 701352202, 'comment_body': 'This goes back to @taldcroft\'s comment \r\n\r\n> The u.day unit is still not appropriate, and probably worse than u.yr. The point here is that a Time does not have a unit. A value of 2019.0 is a decimal representation of a point in time that is equivalent to 2019-01-01, which is a string representation of that point in time. Neither of those have a meaningful unit.\r\n\r\nThis is applicable here too because Modified Julian Date is a ""date"" especially when we talk about it in terms of a `Time` column. `TimeDelta` would probably be more appropriate for using units, but I am not so sure about units being used here. However, this might be overly pedantic and maybe the MRT format doesn\'t talk about it. For now we can go ahead with this, but I will try to find out whether the format suggests a unit for time coordinates, and why does it not ask for a `scale` since it is important for interpreting and round-tripping precise times.\r\n\r\nAlso, when the time scale is UTC, one day is not exactly 86400 seconds but `u.day` is.', 'comment_created': datetime.datetime(2021, 9, 2, 19, 9, 30, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 701354938, 'comment_body': 'Even though you are using `isinstance(col, Column)` and `col.name` and `col.description` can be directly accessed for a column, but would it be better to make this the ""mixin-safe"" `col.info.name` and so on. Don\'t think it is possible to have a `Quantity` column with `Time` values, but maybe there is some ""mixin-specific"" case that we are missing...', 'comment_created': datetime.datetime(2021, 9, 2, 19, 13, 58, tzinfo=datetime.timezone.utc), 'commenter': 'aaryapatil', 'type': 'User'}, {'comment_id': 702261723, 'comment_body': ""Ya, that's what I meant there. Your suggestion is far more spot on."", 'comment_created': datetime.datetime(2021, 9, 4, 9, 30, 24, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 702262088, 'comment_body': 'That example dated back to the time we were the _pycdsreadme_ template for the ReadMe.\r\nChanged to `=` for header since the example on MRT standard homepage uses it.', 'comment_created': datetime.datetime(2021, 9, 4, 9, 33, 58, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 702262133, 'comment_body': 'Let me see that.\r\nHowever, is having greater precision than 12 decimal digits is a requirement?', 'comment_created': datetime.datetime(2021, 9, 4, 9, 34, 44, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 702262250, 'comment_body': 'Sure. Will make the change. Thanks for the input. :)', 'comment_created': datetime.datetime(2021, 9, 4, 9, 36, 13, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 702262522, 'comment_body': ""I haven't looked up the `QTable`s and `Quantity` columns. For now, I suppose using the `if` statement suffices our purpose. I can work on `Quantity` with `Time` values and other `QTable` specific scenario in a separate PR later."", 'comment_created': datetime.datetime(2021, 9, 4, 9, 39, 9, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}, {'comment_id': 702278976, 'comment_body': 'Good question. Unfortunately, I don\'t think we can have a one-size-fits-all answer. Imaging you make a long-term lightcurve over years for a variable star, going back from historical records in 1894 to today. In that case, precision to a day is enough and a precision of 12 digits would in fact be misleading. For the historical records, you won\'t know the time of the observation better than an hour (or a minute, if they were very good in writing down their notes and all notes survived to today), even for modern observations, the exposure time is often a few min to an hour for faint objects, so there is really no point to be more precise than a minute or so. Everything above that is misleading. On the other hand, the time column could hold the data for pulsar timing, where we want to measure the spin-up or spin-down of the pulsar. Typical pulse rates are 300 Hz or more, so if we want to measure spin-down, we need to be precise on the mirco or nano-second level.\r\n\r\nI\'m in fact not sure how to address that, since the ""time"" does not know about the precision needed by the user. Internally, it\'s just a variable with two floats, but for printing out for human consumption (which is what we do here, even if the format is called machine-readable), we do need that extra bit of information to make sense. For ""normal"" columns, the user can set the ""format"" to decide how many digits they want. I don\'t think time columns have that, though? Maybe @taldcroft has an idea how to address that?\r\n\r\nI don\'t know much about the mix-in columns and don\'t have time to dig into the code right now to see if this information can be attached by the user in some way, but on top of my head I think we might need to use the ""formats"" dictionary for the write function. If no format is given for the time column, we pick some default (I suggest 4 decimal digits - a few second precision) and of someone wants more or less, they can change that. (That would profit from an example in the narrative docs. Can be short, just text like ""The default is to print time in days as recommended by the MRT standard [link here] with four decimal digits. The precision can be changed like this: ``tab.write(..., formats={\'name of time colum\'}: \'%15.12f\')``."" - no need to have an example table and an executable example here, just a line of inline text woudl be enough, but we may need a test for this.)', 'comment_created': datetime.datetime(2021, 9, 4, 12, 29, 58, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 702279207, 'comment_body': '@aaryapatil became quite the expert in time systems in her GSOC, so we can trust here here!', 'comment_created': datetime.datetime(2021, 9, 4, 12, 32, 2, tzinfo=datetime.timezone.utc), 'commenter': 'hamogu', 'type': 'User'}, {'comment_id': 702333176, 'comment_body': '> This is applicable here too because Modified Julian Date is a ""date"" especially when we talk about it in terms of a `Time` column.\n\nAh, I do recall having thought over this while assigning the unit as `u.day`. The example on the MRT standard\'s page gives the unit of the BJD column as such. (https://journals.aas.org/mrt-standards/)\n\nAgain, I think the dates would have the unit of a _day_ since their resolution is a _day_, in spite of the fact that the defination of the _day_ may differ.\nHowever, likewise can be argued for date value given in other formats and for the decimal year!?\n\ncc: @taldcroft', 'comment_created': datetime.datetime(2021, 9, 4, 22, 0, 43, tzinfo=datetime.timezone.utc), 'commenter': 'Suyog7130', 'type': 'User'}]","[{'commit_sha': 'a03eb39bbf115752b38532668a4dec6f0b5dfac2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5ed4a9ae87f9fc6422c12f607e454f61f7ccefc4', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3fc6df1ae9aa383642dfca66ff1065f12f884519', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9c764aebce74b4e2309a5257d3195ffa311a40c7', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e4be210153a500d77d691c083d9830eb0e6259da', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '16aea0bf0053e0645abd42469729134ef638d764', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '626fa008dba86dcba31b847136d1d2af3add33ef', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c5f5c650c7c8e1ac6f40ea459f57142200608906', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ecadabcf4736c045b3f3d1a7d160aa86cd0aad3e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}]",Suyog Garg,29597910,suyog7130@gmail.com,User,,30,,175,16
707626788,MRT metadata input and subsequent writing [GSoC21c],"<!-- This comments are hidden when you submit the pull request,
so you do not need to remove them! -->

<!-- Please be sure to check out our contributing guidelines,
https://github.com/astropy/astropy/blob/main/CONTRIBUTING.md .
Please be sure to check out our code of conduct,
https://github.com/astropy/astropy/blob/main/CODE_OF_CONDUCT.md . -->

<!-- If you are new or need to be re-acquainted with Astropy
contributing workflow, please see
http://docs.astropy.org/en/latest/development/workflow/development_workflow.html .
There is even a practical example at
https://docs.astropy.org/en/latest/development/workflow/git_edit_workflow_examples.html#astropy-fix-example . -->

<!-- Astropy coding style guidelines can be found here:
https://docs.astropy.org/en/latest/development/codeguide.html#coding-style-conventions
Our testing infrastructure enforces to follow a subset of the PEP8 to be
followed. You can check locally whether your changes have followed these by
running the following command:

tox -e codestyle

-->

<!-- Please just have a quick search on GitHub to see if a similar
pull request has already been posted.
We have old closed pull requests that might provide useful code or ideas
that directly tie in with your pull request. -->

<!-- We have several automatic features that run when a pull request is open.
They can appear daunting but do not worry because maintainers will help
you navigate them, if necessary. -->

### Description
<!-- Provide a general description of what your pull request does.
Complete the following sentence and add relevant details as you see fit. -->

<!-- In addition please ensure that the pull request title is descriptive
and allows maintainers to infer the applicable subpackage(s). -->

This Pull Request is part of the 2021 Google Summer of Code work I am doing together with mentors @aaryapatil and @hamogu.
It is a continuation of the modifications in #11897 and #12027 which primarily aims to address issue #11257.

Note that the count appended at the end of the PR title, **[GSoC21a]**, **[GSoC21b]** and so on, denote the sequence in which rebasing has been (will be) done to the commits. It is preferred if the merging also takes place in this order. Also, because the previous PRs are not merged yet, the later ones contain numerous unrelated commits at the time of opening the PR.

<!-- If the pull request closes any open issues you can add this.
If you replace <Issue Number> with a number, GitHub will automatically link it.
If this pull request is unrelated to any issues, please remove
the following line. -->

### Checklist for package maintainer(s)
<!-- This section is to be filled by package maintainer(s) who will
review this pull request. -->

This checklist is meant to remind the package maintainer(s) who will review this pull request of some common things to look for. This list is not exhaustive.

- [ ] Do the proposed changes actually accomplish desired goals?
- [ ] Do the proposed changes follow the [Astropy coding guidelines](https://docs.astropy.org/en/latest/development/codeguide.html)?
- [ ] Are tests added/updated as required? If so, do they follow the [Astropy testing guidelines](https://docs.astropy.org/en/latest/development/testguide.html)?
- [ ] Are docs added/updated as required? If so, do they follow the [Astropy documentation guidelines](https://docs.astropy.org/en/latest/development/docguide.html#astropy-documentation-rules-and-guidelines)?
- [ ] Is rebase and/or squash necessary? If so, please provide the author with appropriate instructions. Also see [""When to rebase and squash commits""](https://docs.astropy.org/en/latest/development/when_to_rebase.html).
- [ ] Did the CI pass? If no, are the failures related? If you need to run daily and weekly cron jobs as part of the PR, please apply the `Extra CI` label.
- [ ] Is a change log needed? If yes, did the change log check pass? If no, add the `no-changelog-entry-needed` label.
- [ ] Is a milestone set? Milestone must be set but `astropy-bot` check might be missing; do not let the green checkmark fool you.
- [ ] At the time of adding the milestone, if the milestone set requires a backport to release branch(es), apply the appropriate `backport-X.Y.x` label(s) *before* merge.
",False,12039,https://api.github.com/repos/astropy/astropy/pulls/12039,https://github.com/astropy/astropy/pull/12039,closed,1824,13,7,52,13,0,4,0,"[{'name': 'io.ascii'}, {'name': 'unified-io'}, {'name': 'Close?'}, {'name': 'closed-by-bot'}]",2021-08-10 19:37:12+00:00,2022-03-18 05:36:19+00:00,18957547.0,"219 days, 9:59:07",[],"[{'commit_sha': '1d063e069dff0014d41a5e486d9812f603cc343a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2494d7131911e15418b3e1751b77b69327b6f1b9', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c823ea8da849b7dca3515e151d18070253a8009e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6104b40edf5bfa2f5085c731c2aff4bdc4cefbdc', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9d7b539b55433f3e7678fad6d0a8cfecff0f56c5', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a35654400f1f1bd214a0fcf6c648eafb0b91fd34', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1a1f578ce64985b21cb8987ccecc9f956fa9f12c', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e4a0b6e060be6f8a4e6119bcabaa7e51f28ca149', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7caee2165171a72286a9e2788fbc6c5ad46a8180', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63713104eb01b0822c4c461eed1e652d61a20a19', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'faea56236649b173161f45f1e56f529775988bfb', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7457da3bd344a20682c518fbe1170fc83aec689e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'aa0798c5ccad6da9e9c9b3862e5c2f51d82d008a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c2f363720084f57c9dfc60540006c5530b8462c9', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '11c3dbd38569528581f66b274b121e204fe232d2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b737f45b349ce2f7c23ae969f64be6a7a8c106a2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '60fc9e061f4a435453cee5a21d5de13baa646972', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e8d6072d07ed674027589f4d8a3916202126bc96', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23d85a22619a70210236ecd62e7cb114226270ac', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0c7c875857003db9695c253496b8cadfd802202b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9419d28c6acaad57f6689a45383bbf76b5f8f72e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ea21df6eb416b10684a856b4fc411415f1d6fe07', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14f0cfb0766f4af6177a250ca146621998c36252', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a9fb21fa6541ff7027877e34a76cd3aa1be2cae6', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14bb02519c0a3a4b1b4d1857a83d00fd4de99a02', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fbe6a20b664277377b4a6c8ce62f832416a84a33', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '20d533775bf12c6e5156fd7d70ccbcabf4fe2e8d', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cf7481a5732681f4aca49a1196d02d10ce12c517', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a660823d3f430da5d5351a0765b7b226d1469b45', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2090a94a57295313ee7b9a781c7036323b8aea2b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b482c7a16677c287395ea5014459b3e583e08a70', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '931b2095698031f2af0270e03d3d7069d97728b0', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '957a1c2977d0b5383110d9fed45e352163c3146a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1df0b9b629b69c5e44eda6f8bd26a95cbcff1a75', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7679dcfe1b18a2080c6c0477535e27e0a7527b46', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0c5db5f1d605b0536069c90a6b34fd3108ac09a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0af2244cfe1aed6af335010e50b6a0a490a79667', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '504648c0608ff320551378754101e07e27a36c3b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9d27395e7e08523c8ca183e273b73eac280e5a15', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3591b54ff2b7f231a7e2128ff2f81f50f72036ff', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4c094d407e22186540276a8648c3b2c24263a4a2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '54e6f3fb105cb31124c60221ae164fa754ab5e6d', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '70d4c1076cd7b44b63b77ce18b254168939c2016', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8f2633933390c49913840076e1a628a4b856f7e4', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c794b26a61acd7436ec75c91d3f41b4bcd1bc692', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c54efd18d11d3b7e9535b63179c4283e17c9f737', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '283042fab4cd6563ae7390c454d11bcf9b3f6095', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7278be1ad079af35d59948993b636b846c64c6a4', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '926dd09c24885b00232d15aa6b6c6fd272e57c87', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7ab4331d0eb44157af6ea56cad9b42be59b9ea5a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '540916418aae70310954830037d4f4ad9efad832', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b985efc9cad13073e7f173567480b6d3567f1530', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}]",Suyog Garg,29597910,suyog7130@gmail.com,User,,30,,175,16
716987945,Add CDS template to CDS/MRT writer [GSoC21d],"<!-- This comments are hidden when you submit the pull request,
so you do not need to remove them! -->

<!-- Please be sure to check out our contributing guidelines,
https://github.com/astropy/astropy/blob/main/CONTRIBUTING.md .
Please be sure to check out our code of conduct,
https://github.com/astropy/astropy/blob/main/CODE_OF_CONDUCT.md . -->

<!-- If you are new or need to be re-acquainted with Astropy
contributing workflow, please see
http://docs.astropy.org/en/latest/development/workflow/development_workflow.html .
There is even a practical example at
https://docs.astropy.org/en/latest/development/workflow/git_edit_workflow_examples.html#astropy-fix-example . -->

<!-- Astropy coding style guidelines can be found here:
https://docs.astropy.org/en/latest/development/codeguide.html#coding-style-conventions
Our testing infrastructure enforces to follow a subset of the PEP8 to be
followed. You can check locally whether your changes have followed these by
running the following command:

tox -e codestyle

-->

<!-- Please just have a quick search on GitHub to see if a similar
pull request has already been posted.
We have old closed pull requests that might provide useful code or ideas
that directly tie in with your pull request. -->

<!-- We have several automatic features that run when a pull request is open.
They can appear daunting but do not worry because maintainers will help
you navigate them, if necessary. -->

### Description
<!-- Provide a general description of what your pull request does.
Complete the following sentence and add relevant details as you see fit. -->

<!-- In addition please ensure that the pull request title is descriptive
and allows maintainers to infer the applicable subpackage(s). -->

This Pull Request is the final part in a series of PR comprising the 2021 Google Summer of Code work I have been doing since the past few months together with mentors @aaryapatil and @hamogu.
It is a continuation of the modifications in #11897, #12027 and #12039 which primarily aim to address issue #11257.

Note that the count appended at the end of the PR title, **[GSoC21a]**, **[GSoC21b]** and so on, denote the sequence in which rebasing has been (will be) done to the commits. It is preferred if the merging also takes place in this order. Also, because the previous PRs are not merged yet, the later ones contain numerous unrelated commits at the time of opening the PR.

<!-- If the pull request closes any open issues you can add this.
If you replace <Issue Number> with a number, GitHub will automatically link it.
If this pull request is unrelated to any issues, please remove
the following line. -->

### Checklist for package maintainer(s)
<!-- This section is to be filled by package maintainer(s) who will
review this pull request. -->

This checklist is meant to remind the package maintainer(s) who will review this pull request of some common things to look for. This list is not exhaustive.

- [ ] Do the proposed changes actually accomplish desired goals?
- [ ] Do the proposed changes follow the [Astropy coding guidelines](https://docs.astropy.org/en/latest/development/codeguide.html)?
- [ ] Are tests added/updated as required? If so, do they follow the [Astropy testing guidelines](https://docs.astropy.org/en/latest/development/testguide.html)?
- [ ] Are docs added/updated as required? If so, do they follow the [Astropy documentation guidelines](https://docs.astropy.org/en/latest/development/docguide.html#astropy-documentation-rules-and-guidelines)?
- [ ] Is rebase and/or squash necessary? If so, please provide the author with appropriate instructions. Also see [""When to rebase and squash commits""](https://docs.astropy.org/en/latest/development/when_to_rebase.html).
- [ ] Did the CI pass? If no, are the failures related? If you need to run daily and weekly cron jobs as part of the PR, please apply the `Extra CI` label.
- [ ] Is a change log needed? If yes, did the change log check pass? If no, add the `no-changelog-entry-needed` label.
- [ ] Is a milestone set? Milestone must be set but `astropy-bot` check might be missing; do not let the green checkmark fool you.
- [ ] At the time of adding the milestone, if the milestone set requires a backport to release branch(es), apply the appropriate `backport-X.Y.x` label(s) *before* merge.
",False,12096,https://api.github.com/repos/astropy/astropy/pulls/12096,https://github.com/astropy/astropy/pull/12096,closed,2313,13,7,71,9,0,4,0,"[{'name': 'io.ascii'}, {'name': 'unified-io'}, {'name': 'Close?'}, {'name': 'closed-by-bot'}]",2021-08-20 20:42:47+00:00,2022-03-23 05:37:12+00:00,18521665.0,"214 days, 8:54:25",[],"[{'commit_sha': '1d063e069dff0014d41a5e486d9812f603cc343a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2494d7131911e15418b3e1751b77b69327b6f1b9', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c823ea8da849b7dca3515e151d18070253a8009e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6104b40edf5bfa2f5085c731c2aff4bdc4cefbdc', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9d7b539b55433f3e7678fad6d0a8cfecff0f56c5', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a35654400f1f1bd214a0fcf6c648eafb0b91fd34', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1a1f578ce64985b21cb8987ccecc9f956fa9f12c', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e4a0b6e060be6f8a4e6119bcabaa7e51f28ca149', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7caee2165171a72286a9e2788fbc6c5ad46a8180', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63713104eb01b0822c4c461eed1e652d61a20a19', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'faea56236649b173161f45f1e56f529775988bfb', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7457da3bd344a20682c518fbe1170fc83aec689e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'aa0798c5ccad6da9e9c9b3862e5c2f51d82d008a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c2f363720084f57c9dfc60540006c5530b8462c9', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '11c3dbd38569528581f66b274b121e204fe232d2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b737f45b349ce2f7c23ae969f64be6a7a8c106a2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '60fc9e061f4a435453cee5a21d5de13baa646972', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e8d6072d07ed674027589f4d8a3916202126bc96', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23d85a22619a70210236ecd62e7cb114226270ac', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0c7c875857003db9695c253496b8cadfd802202b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9419d28c6acaad57f6689a45383bbf76b5f8f72e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ea21df6eb416b10684a856b4fc411415f1d6fe07', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14f0cfb0766f4af6177a250ca146621998c36252', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a9fb21fa6541ff7027877e34a76cd3aa1be2cae6', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14bb02519c0a3a4b1b4d1857a83d00fd4de99a02', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fbe6a20b664277377b4a6c8ce62f832416a84a33', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '20d533775bf12c6e5156fd7d70ccbcabf4fe2e8d', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cf7481a5732681f4aca49a1196d02d10ce12c517', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a660823d3f430da5d5351a0765b7b226d1469b45', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2090a94a57295313ee7b9a781c7036323b8aea2b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b482c7a16677c287395ea5014459b3e583e08a70', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '931b2095698031f2af0270e03d3d7069d97728b0', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '957a1c2977d0b5383110d9fed45e352163c3146a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1df0b9b629b69c5e44eda6f8bd26a95cbcff1a75', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7679dcfe1b18a2080c6c0477535e27e0a7527b46', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0c5db5f1d605b0536069c90a6b34fd3108ac09a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0af2244cfe1aed6af335010e50b6a0a490a79667', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '504648c0608ff320551378754101e07e27a36c3b', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9d27395e7e08523c8ca183e273b73eac280e5a15', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3591b54ff2b7f231a7e2128ff2f81f50f72036ff', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4c094d407e22186540276a8648c3b2c24263a4a2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '54e6f3fb105cb31124c60221ae164fa754ab5e6d', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '70d4c1076cd7b44b63b77ce18b254168939c2016', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8f2633933390c49913840076e1a628a4b856f7e4', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c794b26a61acd7436ec75c91d3f41b4bcd1bc692', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c54efd18d11d3b7e9535b63179c4283e17c9f737', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '283042fab4cd6563ae7390c454d11bcf9b3f6095', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7278be1ad079af35d59948993b636b846c64c6a4', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '926dd09c24885b00232d15aa6b6c6fd272e57c87', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7ab4331d0eb44157af6ea56cad9b42be59b9ea5a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '540916418aae70310954830037d4f4ad9efad832', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f2ae2e5fba6b35a6c2fbb480b505cc5d2c2b2a30', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '996c39210e8e739a626eec7c9233800ffce4f2d9', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ff6a89aa1df1e6c86162b415a8f70dea0c085625', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1bc08d12dfb415526c8a40f83e7d025becd8bd07', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6727c85156182b66276990a9f34340506a31178f', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0d4f0020bfd1c4c9ef9a5317a102365d236277b6', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b3903c1317c0816348225fcf4b4af806f5e25a1f', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2139980c11a707b2f768aa7e20c309a0c4c0b6e4', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b1b8c084fd360a3a69d38f3a144c8aeffc469ad1', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b985efc9cad13073e7f173567480b6d3567f1530', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '02829b8a7c73614ba204330823778e675fd7d7ae', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '027bebf1c806c7cd75a8c25178b884bc0da35aea', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '515e06d0dfed8cd93bdc5fb8d24fb37073ddce6e', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6bfb602dace38147536305db6338ea44d770dab7', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '13f78453ea041c4667b797b0febcdce60ea67733', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '009d597763cdc5c97717ae95ba3af5a50f4f0afb', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9f70871e24d228de15befbe1503044460cb88a9a', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b76298093aa7b2a94c03ae70241b67dcd1b271d', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a98fc4f190a10579d6e1c6be85fc74e61f7dc202', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2bed5413b00a97b0b204620e97f61a415043a9d2', 'committer_username': 'Suyog7130', 'committer_name': 'Suyog Garg', 'committer_email': 'suyog7130@gmail.com', 'commit_date': datetime.datetime(2017, 6, 21, 9, 33, tzinfo=datetime.timezone.utc)}]",Suyog Garg,29597910,suyog7130@gmail.com,User,,30,,175,16
687053758,Dropping support for python 3.7 ,"EDIT: This had to be broke up into 2 separate PRs to be able to add two changelog entries. See #11935 for dropping numpy

This is in agreement with APE18 and the email thread: https://groups.google.com/g/astropy-dev/c/Z9TPHm8DSmo/m/TgGT6BwFBAAJ?pli=1


Note: the changelog entry is not right, we will need two separate lines, both having the PR number at the end of the line when rendered.


I also expect some of the CI builds to fail, as I may not get the image names right at the first try.

- [ ] Restart CI after Debian updates upstream w.r.t. wcslib 7.6. Should happen by 2021-09-01.

### Checklist for package maintainer(s)
<!-- This section is to be filled by package maintainer(s) who will
review this pull request. -->

This checklist is meant to remind the package maintainer(s) who will review this pull request of some common things to look for. This list is not exhaustive.

- [x] Do the proposed changes actually accomplish desired goals?
- [x] Do the proposed changes follow the [Astropy coding guidelines](https://docs.astropy.org/en/latest/development/codeguide.html)?
- [x] Are tests added/updated as required? If so, do they follow the [Astropy testing guidelines](https://docs.astropy.org/en/latest/development/testguide.html)?
- [x] Are docs added/updated as required? If so, do they follow the [Astropy documentation guidelines](https://docs.astropy.org/en/latest/development/docguide.html#astropy-documentation-rules-and-guidelines)?
- [x] Is rebase and/or squash necessary? If so, please provide the author with appropriate instructions. Also see [""When to rebase and squash commits""](https://docs.astropy.org/en/latest/development/when_to_rebase.html).
- [x] Did the CI pass? If no, are the failures related? If you need to run daily and weekly cron jobs as part of the PR, please apply the `Extra CI` label.
- [x] Is a change log needed? If yes, did the change log check pass? If no, add the `no-changelog-entry-needed` label.
- [x] Is a milestone set? Milestone must be set but `astropy-bot` check might be missing; do not let the green checkmark fool you.
- [x] At the time of adding the milestone, if the milestone set requires a backport to release branch(es), apply the appropriate `backport-X.Y.x` label(s) *before* merge.
",True,11934,https://api.github.com/repos/astropy/astropy/pulls/11934,https://github.com/astropy/astropy/pull/11934,closed,47,80,12,10,37,18,9,0,"[{'name': 'testing'}, {'name': 'Docs'}, {'name': 'units'}, {'name': 'modeling'}, {'name': 'utils'}, {'name': 'installation'}, {'name': ':zzz: merge-when-ci-passes'}, {'name': 'Extra CI'}, {'name': 'utils.masked'}]",2021-07-09 21:45:24+00:00,2021-09-03 15:07:50+00:00,4814546.0,"55 days, 17:22:26","[{'comment_id': 685334826, 'comment_body': 'maybe switch directly to py39 instead of 38?', 'comment_created': datetime.datetime(2021, 8, 9, 16, 15, 31, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 685406642, 'comment_body': '@astrofrog pointed to https://docs.astropy.org/en/latest/development/testguide.html#running-image-tests but someone with server access still needs to generate and upload the new image(s).', 'comment_created': datetime.datetime(2021, 8, 9, 17, 59, 7, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 696158310, 'comment_body': 'For the record, CircleCI stuff has been resolved over at #12032 .  ', 'comment_created': datetime.datetime(2021, 8, 25, 22, 33, 23, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697478567, 'comment_body': 'Woohoo. I am glad we phased out ""mystery segfault""!  ', 'comment_created': datetime.datetime(2021, 8, 27, 14, 17, 44, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697478926, 'comment_body': 'Should also mention matplotlib and scipy bumps?', 'comment_created': datetime.datetime(2021, 8, 27, 14, 18, 16, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697546509, 'comment_body': 'certainly, I just wanted to get an overall agreement on bumping the versions first.', 'comment_created': datetime.datetime(2021, 8, 27, 15, 49, 57, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 697550870, 'comment_body': 'Consider me agreed!  ', 'comment_created': datetime.datetime(2021, 8, 27, 15, 56, 6, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697561165, 'comment_body': 'I agree.', 'comment_created': datetime.datetime(2021, 8, 27, 16, 11, 46, tzinfo=datetime.timezone.utc), 'commenter': 'larrybradley', 'type': 'User'}, {'comment_id': 697570740, 'comment_body': 'I am both happy and sad that this got removed, considering I spent time fixing it but also hated it. Haha...', 'comment_created': datetime.datetime(2021, 8, 27, 16, 27, 24, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697593678, 'comment_body': ""Yes, I'm sorry for that. (Weirdly though that build was still passing here: https://app.circleci.com/pipelines/github/astropy/astropy/6851/workflows/22d51a94-314f-43f9-8f66-1732154800d2/jobs/92719\r\n\r\nI think I should read up on a bit of how and why the version limitations for optional dependencies are ignored."", 'comment_created': datetime.datetime(2021, 8, 27, 17, 5, 41, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 697607376, 'comment_body': 'Looks like bullseye was added in 2.0.10 https://github.com/uraimo/run-on-arch-action/releases', 'comment_created': datetime.datetime(2021, 8, 27, 17, 29, 35, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697608085, 'comment_body': 'yep, great minds...  ', 'comment_created': datetime.datetime(2021, 8, 27, 17, 30, 52, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 697623915, 'comment_body': 'This resulted in malformed sources.list . Do we even need this command now? Not sure. ', 'comment_created': datetime.datetime(2021, 8, 27, 17, 58, 10, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697629710, 'comment_body': ""Is there a favourite post-action you use for debugging? E.g. I don't see why line7 on that file should have any issue, etc."", 'comment_created': datetime.datetime(2021, 8, 27, 18, 8, 33, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 697639136, 'comment_body': ""I didn't set this up, so maybe @astrofrog can advise..."", 'comment_created': datetime.datetime(2021, 8, 27, 18, 25, 19, tzinfo=datetime.timezone.utc), 'commenter': 'pllim', 'type': 'User'}, {'comment_id': 697642374, 'comment_body': ""you're right, based on 0ff2f4f4bb2493195df42a674f349a8e8fa16edf it can be nuked."", 'comment_created': datetime.datetime(2021, 8, 27, 18, 30, 47, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 697647420, 'comment_body': ""Side effect: now we only test our oldest supported version and the dev version. I think it's OK, but it's maybe something to keep in mind, and a thing the visualization maintainers may have an opinion about.\r\ncc @Cadair @astrofrog @larrybradley "", 'comment_created': datetime.datetime(2021, 8, 27, 18, 40, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bsipocz', 'type': 'User'}, {'comment_id': 697656560, 'comment_body': 'And me!', 'comment_created': datetime.datetime(2021, 8, 27, 18, 56, 44, tzinfo=datetime.timezone.utc), 'commenter': 'mhvk', 'type': 'User'}]","[{'commit_sha': 'a0e1646c3cb242cd4b155a93aa4b330968024775', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7c0fa604bbfdca668ff75d06d8c8169dc0fd6a57', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ca171f8f561316a0c8fa62d415ec94c304a96467', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '90f32f31628534451eab78a7c07dd166374d2d1e', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9e32ba6f086ab4173351e3f8ae41d970d00f2c72', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3444bda9eb18eb986fd37d6fb821a228b903aba0', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3473312a5d85b8d6be81b40af41738db60b7fdda', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '628a7485aa7d4b5e477dad6af074227ce770ceeb', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2988006e7de5b6256e56b50b518316934034be7c', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e31867e12ff89b44a73aa786b81ae789e241aba3', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}]",Brigitta Sipcz,6788290,brigitta.sipocz@gmail.com,User,,471,,0,348
687065458,Dropping support for numpy 1.17,"Second part of #11934 due to changelog issues , dropping numpy

### Checklist for package maintainer(s)
<!-- This section is to be filled by package maintainer(s) who will
review this pull request. -->

This checklist is meant to remind the package maintainer(s) who will review this pull request of some common things to look for. This list is not exhaustive.

- [x] Do the proposed changes actually accomplish desired goals?
- [x] Do the proposed changes follow the [Astropy coding guidelines](https://docs.astropy.org/en/latest/development/codeguide.html)?
- [x] Are tests added/updated as required? If so, do they follow the [Astropy testing guidelines](https://docs.astropy.org/en/latest/development/testguide.html)?
- [x] Are docs added/updated as required? If so, do they follow the [Astropy documentation guidelines](https://docs.astropy.org/en/latest/development/docguide.html#astropy-documentation-rules-and-guidelines)?
- [x] Is rebase and/or squash necessary? If so, please provide the author with appropriate instructions. Also see [""When to rebase and squash commits""](https://docs.astropy.org/en/latest/development/when_to_rebase.html).
- [x] Did the CI pass? If no, are the failures related? If you need to run daily and weekly cron jobs as part of the PR, please apply the `Extra CI` label.
- [x] Is a change log needed? If yes, did the change log check pass? If no, add the `no-changelog-entry-needed` label.
- [x] Is a milestone set? Milestone must be set but `astropy-bot` check might be missing; do not let the green checkmark fool you.
- [x] At the time of adding the milestone, if the milestone set requires a backport to release branch(es), apply the appropriate `backport-X.Y.x` label(s) *before* merge.
",True,11935,https://api.github.com/repos/astropy/astropy/pulls/11935,https://github.com/astropy/astropy/pull/11935,closed,21,63,12,4,3,0,6,0,"[{'name': 'testing'}, {'name': 'Docs'}, {'name': 'units'}, {'name': 'utils'}, {'name': 'installation'}, {'name': 'utils.masked'}]",2021-07-09 22:18:30+00:00,2021-07-12 18:29:08+00:00,245438.0,"2 days, 20:10:38",[],"[{'commit_sha': '907be084075022bfe017d4def477af3eb7c0b037', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7aa8c902bc520d11825f83e115c52b03354c836f', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c0e2da4f6fb3907c8a046462eb44c22599e6c30c', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': '041fc82cf9cf0f660f8dfc23710882d1d3a4cdda', 'committer_username': 'bsipocz', 'committer_name': 'Brigitta Sipcz', 'committer_email': 'brigitta.sipocz@gmail.com', 'commit_date': datetime.datetime(2014, 2, 26, 0, 12, 16, tzinfo=datetime.timezone.utc)}]",Brigitta Sipcz,6788290,brigitta.sipocz@gmail.com,User,,471,,0,348

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
2081289,astropy,astropy/astropy,Python,1738,4354,139,539,37741,1344,24,98,"[{'id': 716987945, 'number': 12096, 'closed': datetime.datetime(2022, 3, 23, 5, 37, 12, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 8, 20, 20, 42, 47, tzinfo=datetime.timezone.utc), 'time_taken': 18521665.0, 'time_delta': '214 days, 8:54:25', 'additions': 2313, 'deletions': 13, 'state': 'closed'}, {'id': 707626788, 'number': 12039, 'closed': datetime.datetime(2022, 3, 18, 5, 36, 19, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 8, 10, 19, 37, 12, tzinfo=datetime.timezone.utc), 'time_taken': 18957547.0, 'time_delta': '219 days, 9:59:07', 'additions': 1824, 'deletions': 13, 'state': 'closed'}, {'id': 706344924, 'number': 12027, 'closed': datetime.datetime(2022, 3, 2, 5, 36, 48, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 8, 9, 9, 9, 49, tzinfo=datetime.timezone.utc), 'time_taken': 17699219.0, 'time_delta': '204 days, 20:26:59', 'additions': 203, 'deletions': 61, 'state': 'closed'}, {'id': 678561028, 'number': 11897, 'closed': datetime.datetime(2021, 8, 30, 20, 25, 53, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 27, 18, 27, 29, tzinfo=datetime.timezone.utc), 'time_taken': 5536704.0, 'time_delta': '64 days, 1:58:24', 'additions': 1257, 'deletions': 12, 'state': 'closed'}, {'id': 668595266, 'number': 11835, 'closed': datetime.datetime(2021, 6, 27, 18, 28, 14, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 11, 22, 2, 3, tzinfo=datetime.timezone.utc), 'time_taken': 1369571.0, 'time_delta': '15 days, 20:26:11', 'additions': 406, 'deletions': 6, 'state': 'closed'}, {'id': 668521993, 'number': 11834, 'closed': datetime.datetime(2021, 6, 11, 20, 11, 19, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 11, 20, 10, 44, tzinfo=datetime.timezone.utc), 'time_taken': 35.0, 'time_delta': '0:00:35', 'additions': 1172, 'deletions': 4, 'state': 'closed'}, {'id': 612478937, 'number': 11508, 'closed': datetime.datetime(2021, 4, 18, 21, 20, 15, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 4, 9, 13, 57, 13, tzinfo=datetime.timezone.utc), 'time_taken': 804182.0, 'time_delta': '9 days, 7:23:02', 'additions': 66, 'deletions': 0, 'state': 'closed'}]"

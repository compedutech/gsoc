pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
628316660,Add support for diagnostic tags,"This PR adds a prototypical implementation of the new diagnostic tags, which are part of LSP since 3.15.0, for Swift:

```typescript
export interface Diagnostic {
  ...
  /**
   * Additional metadata about the diagnostic.
   *
   * @since 3.15.0
   */
  tags?: DiagnosticTag[];
  ...
}

export namespace DiagnosticTag {
  /**
   * Unused or unnecessary code.
   *
   * Clients are allowed to render diagnostics with this tag faded out
   * instead of having an error squiggle.
   */
  export const Unnecessary: 1 = 1;
  /**
   * Deprecated or obsolete code.
   *
   * Clients are allowed to rendered diagnostics with this tag strike through.
   */
  export const Deprecated: 2 = 2;
}
```

These tags are used by editors like VSCode to style unused or deprecated diagnostics separately:

![image](https://user-images.githubusercontent.com/30873659/116768591-e6fa0400-aa37-11eb-9062-5d4e1b2b3c4f.png)",True,389,https://api.github.com/repos/swiftlang/sourcekit-lsp/pulls/389,https://github.com/swiftlang/sourcekit-lsp/pull/389,closed,58,9,5,7,5,4,0,0,[],2021-05-01 02:58:57+00:00,2021-05-20 14:31:46+00:00,1683169.0,"19 days, 11:32:49","[{'comment_id': 625355099, 'comment_body': 'DiagnosticTag is an open set so to keep this forward compatible, we should use a struct with a rawValue.  Something like:\r\n\r\n```swift\r\npublic struct DiagnosticTag: RawRepresentable, Codable, Hashable {\r\n  public var rawValue: Int\r\n  public init(rawValue: Int) {\r\n    self.rawValue = rawValue\r\n  }\r\n  \r\n  public static let unnecessary: DiagnosticTag = DiagnosticTag(rawValue: 1)\r\n  public static let deprecated: DiagnosticTag = DiagnosticTag(rawValue: 2)\r\n}\r\n```', 'comment_created': datetime.datetime(2021, 5, 3, 20, 42, 35, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 627634145, 'comment_body': 'Good point, thanks!', 'comment_created': datetime.datetime(2021, 5, 6, 17, 37, 3, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 635566830, 'comment_body': 'This is going to make the test fail using the currently released swift.  While we can\'t always guarantee sourcekit-lsp main branch will work with previously released toolchains, we do make an effort to keep it working when we can.\r\n\r\nSince this particular test isn\'t about the diagnostic itself, I suggest changing this to\r\n\r\n```swift\r\n    // Diagnostic returned by code actions cannot be recursive.\r\n    var expectedDiagnostic = diagnostic!\r\n    expectedDiagnostic.codeActions = nil\r\n\r\n    // Expected Fix-it: Replace `let a` with `_` because it\'s never used\r\n    let expectedTextEdit = TextEdit(range: Position(line: 1, utf16index: 2)..<Position(line: 1, utf16index: 7), newText: ""_"")\r\n    XCTAssertEqual(fixit, CodeAction(\r\n      title: ""Replace \'let a\' with \'_\'"",\r\n      kind: .quickFix,\r\n      diagnostics: [expectedDiagnostic],\r\n...\r\n```\r\n\r\nUnfortunately this means we don\'t have a good way to test this new DiagnosticTag functionality, since it depends on the new sourcekitd.  For a more complex change we would probably need to teach the test to detect whether sourcekitd has the new feature or not and skip the test if it\'s not available.  In this particular case, detecting the presence of the new sourcekitd functionality in the test is almost as much work as the change itself here.  Since the sourcekit-lsp side of this change is relatively simple I\'m okay with us not testing it for now.', 'comment_created': datetime.datetime(2021, 5, 19, 20, 36, 29, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 635627879, 'comment_body': 'Okay, I have applied the suggestion :+1: ', 'comment_created': datetime.datetime(2021, 5, 19, 22, 36, 45, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}]","[{'commit_sha': 'bcbfd0a273673b102ed4fd5e757399e0e009afa2', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f5f080caec73c245599891ec52a883090f1369af', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ac0f2b5f85746238311f5435286615ee6532bba7', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd49b833bb66194d6eceb9f662af6c957969544d8', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9b81cb25d12ce44d566a4eb7725d391d0e63245b', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7c88ddd5d9139ebbaa02ad14c2c6c08071f6587d', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3dcb649a1c1bf2ccb60ae63da216ec216e775dfa', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
633141684,[SourceKit] Add id and category to diagnostics,"This PR adds ids to SourceKit's diagnostics as proposed by @benlangmuir in https://github.com/apple/sourcekit-lsp/pull/389#pullrequestreview-650707002, primarily to let the language server provide more structured metadata about diagnostics (see https://github.com/apple/sourcekit-lsp/pull/389).

The change to the SourceKit protocol involves only added fields and should therefore be backwards compatible:

```
diagnostic ::=
{
    <key.id>:               (string)       // The internal ID of the diagnostic.
    ...
    [opt] <key.categories>: (array) [UID*] // The categories of the diagnostic. Can be:
                                           //   - source.diagnostic.category.deprecation
                                           //   - source.diagnostic.category.no_usage
}
```",True,37320,https://api.github.com/repos/swiftlang/swift/pulls/37320,https://github.com/swiftlang/swift/pull/37320,closed,228,65,31,16,19,20,0,0,[],2021-05-07 17:41:39+00:00,2021-05-17 21:25:40+00:00,877441.0,"10 days, 3:44:01","[{'comment_id': 628617712, 'comment_body': 'Could we use this in `LocalizationProducer::getMessageOr` and remove `diagnosticNameStrings` from that file?  Since that function needs to create a copy of the string anyway it seems reasonable to add the surrounding ""[]"" at that point rather than need two separate tables.  CC @HassanElDesouky @owenv ', 'comment_created': datetime.datetime(2021, 5, 7, 23, 47, 31, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 628617915, 'comment_body': 'Most of the other tables like this use `""<not a diagnostic>""`.  Should we match that?', 'comment_created': datetime.datetime(2021, 5, 7, 23, 47, 57, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 628640838, 'comment_body': ""@benlangmuir Yes sure! I can't see why can't we do that. cc @xedin "", 'comment_created': datetime.datetime(2021, 5, 8, 0, 42, 53, tzinfo=datetime.timezone.utc), 'commenter': 'HassanElDesouky', 'type': 'User'}, {'comment_id': 628776728, 'comment_body': 'Fixed!', 'comment_created': datetime.datetime(2021, 5, 8, 17, 41, 39, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 630201917, 'comment_body': 'Is the `sourcekitd_uid_t` overload being used?', 'comment_created': datetime.datetime(2021, 5, 11, 14, 7, 32, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630203910, 'comment_body': ""Buf/Str are dead (and probably don't compile)."", 'comment_created': datetime.datetime(2021, 5, 11, 14, 9, 47, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630213695, 'comment_body': ""I'm not sure it makes sense to mark a note as a deprecation.  In this particular case, the note is not indicating a deprecation but how you might silence the warning."", 'comment_created': datetime.datetime(2021, 5, 11, 14, 20, 41, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630217251, 'comment_body': 'This warning is a bit tricky. The source range that gets highlighted is the LHS, so from LSP that would be indicated as ""unused"".  But it\'s the RHS that is actually unused.  Should we remove the ""NoUsage"" from this?', 'comment_created': datetime.datetime(2021, 5, 11, 14, 24, 29, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630218570, 'comment_body': 'Similarly to the other case with a note, I don\'t think we should add ""Deprecation"" here.  The note itself is not a deprecation.', 'comment_created': datetime.datetime(2021, 5, 11, 14, 25, 55, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630221326, 'comment_body': 'This is more a comment for the LSP side: this diagnostic, like many others, only has a single source location.  Does this cause a single character to be rendered strikethrough, or does nothing get rendered strikethrough in this case?', 'comment_created': datetime.datetime(2021, 5, 11, 14, 28, 50, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630274922, 'comment_body': ""Don't think so, I mainly added it for consistency with the single UID case, which also has these two overloads."", 'comment_created': datetime.datetime(2021, 5, 11, 15, 18, 15, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 630276256, 'comment_body': ""Thanks, I didn't catch this one since I was compiling on Linux."", 'comment_created': datetime.datetime(2021, 5, 11, 15, 19, 49, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 630301412, 'comment_body': 'Fixed', 'comment_created': datetime.datetime(2021, 5, 11, 15, 45, 10, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 630320861, 'comment_body': ""Okay, let's remove the unused code ðŸ˜¸ in that case.  We can always add it if we end up needing it in the future."", 'comment_created': datetime.datetime(2021, 5, 11, 16, 5, 25, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630327536, 'comment_body': 'Okay :D', 'comment_created': datetime.datetime(2021, 5, 11, 16, 12, 12, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 630357426, 'comment_body': '@fwcd could you make this change in the current PR?  It would be nice not to introduce another copy of the table.', 'comment_created': datetime.datetime(2021, 5, 11, 16, 52, 2, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 630359666, 'comment_body': 'Sure!', 'comment_created': datetime.datetime(2021, 5, 11, 16, 55, 3, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 630469307, 'comment_body': 'If the range is zero-length (i.e. start == end), VSCode seems to highlight the entire token/word at the given position, if the range has length one, it highlights a single character. In any case, the strikethrough spans the highlight.', 'comment_created': datetime.datetime(2021, 5, 11, 19, 39, 41, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 630476793, 'comment_body': 'Good question, the element in question is not the one being unused, so it would probably be more consistent to remove it?', 'comment_created': datetime.datetime(2021, 5, 11, 19, 48, 55, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 631929026, 'comment_body': ""That's my thinking, but I'm not sure either way.  We can always change it later if needed."", 'comment_created': datetime.datetime(2021, 5, 13, 16, 12, 6, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}]","[{'commit_sha': 'f6ba1314d03acbed690ff19029d2dba72478da49', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8c0e0e2ef756a3f1da8d76cf3dcb184f36e9124d', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e22d26a16194c8c0d1d97cd8eda7d7a43ec70737', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8d35ed0fe998b43481e952bfdbded361e5c6dd07', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9f21b4a2f62169770fd9b6518122e492e72aef00', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '204827c6abef41fd0e671af584d8f33eb3485ba2', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a86d2ecd2d5939b233527e9b0fde3545857dfe7', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9e2bcd9ba90a05e5d3bfe8be3c33cc07851aa9b', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '754d19910e1b4d5e8542ee7ff567097ca55a151d', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '71a34ff428466f986c0732057cdded6b5325b7f5', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cdef2d916ae89e756b73bb9de8f2f0db55ac11d1', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c44ba1a4f6c32bd649fba688bb072782d7b59369', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3d78bd74ee4ef520e5e0715b41b7f59e38f30e4b', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fee8200e0459f1f5de6e17b1f10b9a778bf040db', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ea86221d41e1970c6237c92b550c461156a1ef39', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'da77e61d760484ea6282c4f3330ee2b60b0ccc77', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
656652813,Add server-side support for inlay hints using CollectExpressionType,"This is an early-stage draft of the [proposed](https://summerofcode.withgoogle.com/projects/#5174278531579904) inlay type hints for SourceKit-LSP.

Inlay hints let LSP clients/editors dynamically display inline type annotations, making it easier to read and understand Swift code, without requiring the programmer to spell out every type.

For this purpose, a new, non-standard request is introduced (`sourcekit-lsp/inlayHints`) that currently requires custom support on the client side. Note that this does not affect compatibility with 'vanilla' LSP clients as inlay hints follow a pull model, i.e. the client has to initiate the request.

Since inlay hints are a proposed LSP feature, however, this implementation strives to conform to the proposed request structures as faithfully as possible to make the migration easy once the feature becomes official. More details can be found here:

- https://github.com/microsoft/language-server-protocol/issues/956 (associated issue)
- https://github.com/microsoft/language-server-protocol/pull/1249 (current proposal)
- https://github.com/microsoft/vscode-languageserver-node/pull/609 (slightly older proposal, follows `rust-analyzer` implementation)

Current progress:

- [x] Add `InlayHint` and support structures on the SourceKit-LSP side
- [x] Implement request and handler on the SourceKit-LSP side
- [x] Add unit tests for the request on the SourceKit-LSP side

Next steps:

- Implement a new request on the SourceKit-side specifically for inlay hints and use it (instead of the current `DocumentSymbols` + `CollectExpressionType` combination)

Once possible:

- Migrate to the official LSP API
- Add the corresponding server/client capabilities

See also:

- #407 for VSCode support",True,406,https://api.github.com/repos/swiftlang/sourcekit-lsp/pulls/406,https://github.com/swiftlang/sourcekit-lsp/pull/406,closed,606,68,13,2,6,33,0,1,[],2021-05-28 15:13:48+00:00,2021-06-15 12:17:13+00:00,1544605.0,"17 days, 21:03:25","[{'comment_id': 643491966, 'comment_body': ""Please add `LSP Extension` to the doc comment -- see `SymbolInfoRequest` for an example.  If there's a stable place to link to for information about the proposed spec, that might also make sense to add."", 'comment_created': datetime.datetime(2021, 6, 1, 21, 30, 36, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 643495152, 'comment_body': 'Probably worth doing `.lazy.map` to avoid the intermediate array since this could be a large array', 'comment_created': datetime.datetime(2021, 6, 1, 21, 36, 32, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 643496138, 'comment_body': 'Style nitpick: the return should be on a new line.', 'comment_created': datetime.datetime(2021, 6, 1, 21, 38, 41, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 643497499, 'comment_body': ""Please add any new files to CMakeLists.txt -- don't worry if you aren't setup to do a cmake build to verify it, but usually just adding the files is enough."", 'comment_created': datetime.datetime(2021, 6, 1, 21, 41, 23, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 643949880, 'comment_body': ""Sure, I've linked the PR and noted the commit of the current proposal state."", 'comment_created': datetime.datetime(2021, 6, 2, 13, 14, 57, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 644136165, 'comment_body': '`InlayHintsRequest` should have a public memberwise initializer.', 'comment_created': datetime.datetime(2021, 6, 2, 16, 35, 36, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 644143938, 'comment_body': ""clangd has its own inlineHints extension that I would assume matches the proposal fairly exactly (since it's a clangd developer who wrote the proposal).  Should we forward this request as `clangd/inlayHints`?"", 'comment_created': datetime.datetime(2021, 6, 2, 16, 41, 10, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 644242216, 'comment_body': 'Should we not forward these requests to `clangd`, wouldnâ€™t a failure be more appropriate than an empty response?', 'comment_created': datetime.datetime(2021, 6, 2, 18, 57, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 644249048, 'comment_body': 'I donâ€™t think we should be silently dropping expression type info that fail to deserialize. That makes it hard to debug. Iâ€™d propose to add an `assert(false)` to the failure case. That way weâ€™re failing in debug builds but are not tearing the server down in release builds.\r\n\r\nA different option would be to report a failure if the SourceKit response fails to deserialize, but Iâ€™d vote for the `assert` since itâ€™s an internal inconsistency that should never happen and therefore shouldnâ€™t be exposed to the user.', 'comment_created': datetime.datetime(2021, 6, 2, 19, 8, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 644250989, 'comment_body': 'IIUC `_expressionTypeInfos` is always expected to be called on `queue`. I think it would be good to make that assumption explicit with a `dispatchPrecondition` like [here](https://github.com/apple/sourcekit-lsp/blob/09da6a4f961720b81687567ce8afea633cbd0f44/Sources/SourceKitLSP/Swift/SwiftLanguageServer.swift#L123-L126). And I know weâ€™re not doing it for the other requests.', 'comment_created': datetime.datetime(2021, 6, 2, 19, 11, 34, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 644264059, 'comment_body': ""Not sure, if clients like VSCode interpret error responses as 'something went wrong while processing the request', they might present an error dialog or similar to the user, which we perhaps wouldn't want in every (Objective-)C(++) file the user opens. My thinking was that an empty response would simply correspond to 'no hints to be presented', which would be the case as long as we don't forward them."", 'comment_created': datetime.datetime(2021, 6, 2, 19, 33, 26, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 644268090, 'comment_body': ""Yes that would be nice, `clangd` currently implements a slightly-older version of the proposal though that isn't strictly compatible from what I can tell: https://github.com/llvm/llvm-project/blob/316da54/clang-tools-extra/clangd/Protocol.h#L1488-L1527\r\n\r\nTherefore I wasn't sure whether temporarily adding a custom request for `clangd` would be worth the effort currently. WDYT?"", 'comment_created': datetime.datetime(2021, 6, 2, 19, 40, 7, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 644339492, 'comment_body': ""Errors tend to mean something unexpected happened and may be noisy in various editor.  If we don't forward the request to clangd, returning `[]` seems best to me."", 'comment_created': datetime.datetime(2021, 6, 2, 21, 41, 31, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 644497217, 'comment_body': 'That makes sense. Thanks for clarifying.', 'comment_created': datetime.datetime(2021, 6, 3, 5, 35, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 644508837, 'comment_body': 'Disclaimer: I am not at all familiar with how VSCode handles open documents and language servers.\r\n\r\nCouldnâ€™t the user in theory select some other language server for Swift and use SourceKit-LSP for C-family code only? Iâ€™m not sure if the Swift files would then be reported as part of the visible documents, but we might need a more sophisticated way of determining whether we are providing language server functionality for that file in the future.\r\n\r\nThis is fine for now though.', 'comment_created': datetime.datetime(2021, 6, 3, 6, 5, 26, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 644511835, 'comment_body': 'How would we end up in the case that `!hints`. IIUC `fetchHints` is returning `InlayHint[]` and JavaScript (thus probably also TypeScript) considers the empty array as boolean `true`.', 'comment_created': datetime.datetime(2021, 6, 3, 6, 12, 38, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 646010665, 'comment_body': ""Yes that's true, it's more of a heuristic currently. Once LSP includes inlay hints, it won't be needed anymore anyway, since VSCode would internally handle inlay hint requests and make sure they get sent to the correct language server."", 'comment_created': datetime.datetime(2021, 6, 5, 16, 39, 55, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 646010708, 'comment_body': 'Good point!', 'comment_created': datetime.datetime(2021, 6, 5, 16, 40, 20, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 649066864, 'comment_body': 'Nitpick: Iâ€™d word it â€œIf `nil`â€ instead of  â€œIf unsetâ€', 'comment_created': datetime.datetime(2021, 6, 10, 10, 43, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649069737, 'comment_body': 'I think making this comment a FIXME and leaving the implementation as-is for now would be fine.', 'comment_created': datetime.datetime(2021, 6, 10, 10, 48, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649075625, 'comment_body': 'Minor performance optimization: Since we know how many elements `expressionTypeInfos` will contain, we can reserve the capacity:\r\n\r\n```swift\r\nexpressionTypeInfos.reserveCapacity(skExpressionTypeInfos.count)\r\n```', 'comment_created': datetime.datetime(2021, 6, 10, 10, 57, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649076236, 'comment_body': 'Thereâ€™s not really any reason why we should iterating if one info failed to deserialize, right? So we should be returning `true` here.', 'comment_created': datetime.datetime(2021, 6, 10, 10, 58, 36, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649077640, 'comment_body': 'I donâ€™t think we are using this from anywhere except `expressionTypeInfos`, so it can be `private`, right?', 'comment_created': datetime.datetime(2021, 6, 10, 11, 0, 50, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649084574, 'comment_body': 'IIUC this is returning all `DocumentSymbol`s for which type hints should be displayed, correct? Could you add a doc-comment that describes it? ', 'comment_created': datetime.datetime(2021, 6, 10, 11, 12, 6, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649085794, 'comment_body': 'We are implicitly relying on the the outer expression being reported first here, right? I think thatâ€™s fine, especially since we want to move away from `collectexpressiontype` anyway but we should add a comment that describes it.', 'comment_created': datetime.datetime(2021, 6, 10, 11, 14, 12, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649134960, 'comment_body': 'Could you add a `FIXME` to these tests that the type hint should be displayed after the variable name if possible instead of after the expression?', 'comment_created': datetime.datetime(2021, 6, 10, 12, 29, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649135681, 'comment_body': 'Could you also add a test case with variables that already have type annotations and add a `FIXME` to it that we shouldnâ€™t be displaying the type hint there? ', 'comment_created': datetime.datetime(2021, 6, 10, 12, 30, 14, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649227508, 'comment_body': ""Isn't it the other way around, i.e. `return false` causes the iteration to terminate?"", 'comment_created': datetime.datetime(2021, 6, 10, 14, 17, 22, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 649245845, 'comment_body': 'Yes, but I donâ€™t think we need to terminate iteration here. We can just continue deserializing the next element. Or am I missing something?', 'comment_created': datetime.datetime(2021, 6, 10, 14, 36, 59, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 649247051, 'comment_body': 'Ah sorry, I misread your comment, sure, that makes sense.', 'comment_created': datetime.datetime(2021, 6, 10, 14, 38, 17, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 649420834, 'comment_body': 'Nitpick: `assert(false, ...)` is better expressed as `assertionFailure(...)`.', 'comment_created': datetime.datetime(2021, 6, 10, 18, 20, 37, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 649421407, 'comment_body': ""Our minimum deployment target is 10.15, so this availability check shouldn't be necessary."", 'comment_created': datetime.datetime(2021, 6, 10, 18, 21, 31, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 649421723, 'comment_body': 'Same comment about availability check', 'comment_created': datetime.datetime(2021, 6, 10, 18, 22, 1, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}]","[{'commit_sha': '3fef5145ea4cb025fc8de9a11100e2953532951d', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '29ff751ddc40ee62bc623105a5271657e0925de7', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
664908134,Add client-side support for inlay hints in VSCode,"For easier reviewability, the client-side implementation of inlay hints for VSCode (originally part of #406) is now in this PR. It implements the new (non-standard) `sourcekit-lsp/inlayHints` request and generates corresponding text decorations for inlay hints:

![image](https://user-images.githubusercontent.com/30873659/120929081-e7955280-c6e7-11eb-94ae-9251d7647e2f.png)

Inlay hints as text decorations on the client side are also a proposed part of the VSCode API, although this implementation does not use it yet, as it is only available in VSCode Insiders builds. More details can be found here:

- https://github.com/microsoft/vscode/blob/394a1ce2db/src/vs/vscode.proposed.d.ts#L2493-L2506 (proposed API)

Once inlay hints become part of LSP, this client-side implementation can be removed completely as VSCode's internal language client will then send inlay hint requests as appropriate.",True,407,https://api.github.com/repos/swiftlang/sourcekit-lsp/pulls/407,https://github.com/swiftlang/sourcekit-lsp/pull/407,closed,987,5,5,4,2,7,0,1,[],2021-06-08 13:16:03+00:00,2021-06-22 14:37:16+00:00,1214473.0,"14 days, 1:21:13","[{'comment_id': 650861099, 'comment_body': 'We only need to dispose the `updater` in the `else`-branch, right?', 'comment_created': datetime.datetime(2021, 6, 14, 11, 22, 30, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650866182, 'comment_body': 'I donâ€™t think we ever end up in the case that `hints == false`. Hints is an array and even empty arrays evaluate to `true` in TypeScript/JavaScript AFAICT.', 'comment_created': datetime.datetime(2021, 6, 14, 11, 31, 18, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650900845, 'comment_body': 'Since this shows up in the settings, I think a better wording would be \r\n```\r\nRender inlay type annotations in the editor.\r\n```\r\n\r\nI also donâ€™t think it matters much that itâ€™s enabled by default since the user will see the checkbox ticked anyway.', 'comment_created': datetime.datetime(2021, 6, 14, 12, 27, 13, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 651027331, 'comment_body': ""Oh yup, for some reason this patch didn't make it over into the new PR."", 'comment_created': datetime.datetime(2021, 6, 14, 14, 59, 11, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 651029757, 'comment_body': 'Since we are throwing away the old instance either way, I believe we always need to dispose it.', 'comment_created': datetime.datetime(2021, 6, 14, 15, 1, 36, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 651054021, 'comment_body': 'But in the `if`-branch we have `isEnabled == true`, thus `wasEnabled == false` and thus `updater === null`. Hence `updater?.dispose()` doesnâ€™t do anything. I mean, it doesnâ€™t do any harm, but it confused me for a bit.', 'comment_created': datetime.datetime(2021, 6, 14, 15, 29, 42, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 651060993, 'comment_body': 'Ah yes, you are right. Probably a question of style, but keeping it this way feels cleaner to me, especially since you can reason about the block locally (i.e. `updater` will always get disposed correctly, regardless of the surrounding condition).', 'comment_created': datetime.datetime(2021, 6, 14, 15, 38, 17, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}]","[{'commit_sha': 'c7793baf49d9c79770534fef72095a1c693e71ad', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fd2841a18ee0c7ea932ebcf7658d389199c8c62d', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b4f68040f0937fd033549073af4cf39edf66c22', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c8a5e22243e9f9fa4eb7fd3746f419940903bb26', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
670526767,Implement server-side support for inlay hints using CollectVariableType,"This is an early draft of support for inlay hints that uses the new [`CollectVariableType`](https://github.com/apple/swift/pull/37867) SourceKit request.

### Implementation Progress

- [x] Add UIDs and structures for `CollectVariableType`
- [x] Support ranged `CollectVariableType` requests
- [x] Reimplement inlay hints using `CollectVariableType`
- [x] Update existing tests
- [x] Add new test for inlay hints on closure parameters

> Note that this also requires a very recent build of the Swift toolchain, otherwise the tests will fail",True,408,https://api.github.com/repos/swiftlang/sourcekit-lsp/pulls/408,https://github.com/swiftlang/sourcekit-lsp/pull/408,closed,195,83,8,9,2,0,0,1,[],2021-06-15 15:44:07+00:00,2021-06-30 20:18:43+00:00,1312476.0,"15 days, 4:34:36",[],"[{'commit_sha': '5eaee0f235713fc1c6a3e937743d0f06b5e0bde5', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e2ae18e321ecd774774be52610eab0b0907d7a6', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '134073debaa88f19ad3fe325b7710a5bf6486526', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7e376e0f8ce02bc3b3c54badb06c9a79ac4f00e1', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fdf3b448ece72cc255b1bbb1688deb2c5d05ee76', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a6891c3d3dbd30fca81bd1e2ca33627b389883c4', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3411f319723d3d027ab87f3eb012bbd603fb4faa', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7eb2faec5af66861daf469a70fe416d9b50d291e', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e77b56715d7dee05dc227d02cd11b8c150fcd232', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
667331757,[SourceKit] Add `CollectVariableType` request,"To provide accurate support for inlay type hints in SourceKit-LSP (see apple/sourcekit-lsp#406 for details), this PR introduces a new request called `CollectVariableType`. Although similar to `CollectExpressionType`, the new request provides types for variable declarations and closure parameters specifically, together with the identifiers' ranges and a flag stating whether there already exists an explicit type annotation.

### Example

```swift
let x: Int = 3
var y = ""test""
```

yields the following response:

```
<VariableTypes>
(4, 5): Int (explicit type: 1)
(19, 20): String (explicit type: 0)
</VariableTypes>
```

### Additions to the SourceKit protocol

The request looks like this:

```
{
    <key.request>:            (UID)     <source.request.variable.type>,
    <key.sourcefile>:         (string)  // Absolute path to the file.
    <key.compilerargs>:       [string*] // Array of zero or more strings for the compiler arguments,
                                        // e.g [""-sdk"", ""/path/to/sdk""]. If key.sourcefile is provided,
                                        // these must include the path to that file.
    [opt] <key.offset>:       (int64)   // Offset of the requested range. Defaults to zero.
    [opt] <key.length>:       (int64)   // Length of the requested range. Defaults to the entire file.
}
```

The response looks like this:

```
{
    <key.variable_type_list>: (array) [var-type-info*]   // A list of variable declarations and types
}

var-type-info ::=
{
    <key.variable_offset>:       (int64)    // Offset of a variable identifier in the source file
    <key.variable_length>:       (int64)    // Length of a variable identifier an expression in the source file
    <key.variable_type>:         (string)   // Printed type of the variable declaration
    <key.variable_type_explicit> (bool)     // Whether the declaration has an explicit type annotation
}
```

### Implementation Progress

- [x] Add `VariableTypeCollector` that traverses AST and collects variable type information
- [x] Implement the new request handler
- [x] Add tests verifying basic use-cases (local variables, fields, parameters, declarations with and without type annotations)
- [x] Add support for ranged requests (`key.offset`, `key.length`)",True,37867,https://api.github.com/repos/swiftlang/swift/pulls/37867,https://github.com/swiftlang/swift/pull/37867,closed,717,0,24,5,3,78,0,1,[],2021-06-10 20:03:45+00:00,2021-06-24 06:50:46+00:00,1162021.0,"13 days, 10:47:01","[{'comment_id': 650581446, 'comment_body': 'What would be the motivation of using `true` here? I donâ€™t think weâ€™re ever doing that. Or did you just want to play around with it?', 'comment_created': datetime.datetime(2021, 6, 13, 21, 44, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650907078, 'comment_body': 'I know itâ€™s weird, but could you use capitalized variable names? Most of the rest of the file is also using capitalized variables per the LLVM coding standard.', 'comment_created': datetime.datetime(2021, 6, 14, 12, 36, 8, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650907680, 'comment_body': 'Youâ€™ve got two types named `VariableTypeCollector`. Could you rename one of them to avoid confusion?', 'comment_created': datetime.datetime(2021, 6, 14, 12, 37, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650910281, 'comment_body': 'Whatâ€™s the motivation for using `getRValueType` here? I assume youâ€™ve got a test case that requires this but Iâ€™m wondering if this would be better handled by type printing options or if we already have a type printing option that does exactly what you are trying to achieve by `getRValueType` here.', 'comment_created': datetime.datetime(2021, 6, 14, 12, 40, 38, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650912016, 'comment_body': 'Nitpick: Could you add `/*Recursive=*/` before `true`. I think it just reads better if you can tell from the call site what these constants stand for.', 'comment_created': datetime.datetime(2021, 6, 14, 12, 42, 50, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650922361, 'comment_body': 'You are printing multiple variable types, so I think this should be plural: `printVariableTypes`.', 'comment_created': datetime.datetime(2021, 6, 14, 12, 56, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650924834, 'comment_body': 'Iâ€™m not sure what you think about this, but I think it would be easier to write tests if we were using line-column based positions here instead of offset-based ones. You can convert between the two using `resolveToLineCol`.', 'comment_created': datetime.datetime(2021, 6, 14, 13, 0, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650934294, 'comment_body': 'This comment actually confused me for a bit. I think the following would be better:\r\n```cpp\r\n/// Returns the start and end offset of this string in `OS`. If it does not exist in `OS` yet, `PrintedType` will be added to `OS`.\r\n```', 'comment_created': datetime.datetime(2021, 6, 14, 13, 12, 59, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650936396, 'comment_body': 'Since the entire handling of type strings is a little bit confusing at first, I think it would be good to add some background documentation here, like.\r\n\r\n```cpp\r\nIn a SourceKit request, we transfer all type names in a single string. To describe individual types, we use offsets into that big string. `OS` builds a string that contains all null-terminated type strings. When referring to one of these types, we can use the offset at which it starts in `OS`.\r\n```', 'comment_created': datetime.datetime(2021, 6, 14, 13, 15, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650937846, 'comment_body': 'Since you already have a comment \r\n```cpp\r\n// Print type type to a temporary buffer\r\n``` \r\n\r\nabove, I think it would be good to add another one here:\r\n```cpp\r\n// Transfer the type to `OS` if needed and get the offsets of this string in `OS`.\r\n```', 'comment_created': datetime.datetime(2021, 6, 14, 13, 17, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650940114, 'comment_body': 'Since `TypeOffset` is not really self-explaining, could you add a doc-comment for it? Like\r\n```cpp\r\n/// The offset of the typeâ€™s string representation inside \\c VariableTypesInFile.TypeBuffer\r\n```', 'comment_created': datetime.datetime(2021, 6, 14, 13, 20, 24, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650940950, 'comment_body': 'Again, I think a doc-comment would be good here:\r\n```cpp\r\n/// A string containing the string representation of all types in `Results`. Entries in `Results` refer to their types by using an offset into this string.\r\n```', 'comment_created': datetime.datetime(2021, 6, 14, 13, 21, 26, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650941900, 'comment_body': 'I know we basically donâ€™t have any comments here, but I think it would be good to add one especially to describe what `Offset`, `Length` and `CanonicalType` do.', 'comment_created': datetime.datetime(2021, 6, 14, 13, 22, 31, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650945027, 'comment_body': 'As youâ€™ll see further below the use of `OS` kept confusing me. I think it would be good to clarify its interplay with `VariableTypeInfo`\r\n```cpp\r\n/// All types will be printed to \\c OS and the type offsets of the \\c VariableTypeInfos will refer into the string that backs this stream.\r\n```', 'comment_created': datetime.datetime(2021, 6, 14, 13, 26, 17, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650949212, 'comment_body': 'I donâ€™t think you are using this macro.', 'comment_created': datetime.datetime(2021, 6, 14, 13, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650953108, 'comment_body': 'Typo: custom', 'comment_created': datetime.datetime(2021, 6, 14, 13, 35, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650955134, 'comment_body': 'I think itâ€™s kind of unfortunate that we need to duplicate so much implementation between `ExpressionTypeArray` and `VariableTypeArray`. Do you think it would be feasible to share some implementation between the two? It might not be possible, I didnâ€™t checkâ€¦', 'comment_created': datetime.datetime(2021, 6, 14, 13, 38, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650973204, 'comment_body': 'The `ExpressionTypeInfo` had one, so I added it for consistency. Perhaps in the future it might be nice to have an option for displaying inlay hints with fully qualified types?', 'comment_created': datetime.datetime(2021, 6, 14, 13, 58, 44, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 650973356, 'comment_body': 'Sure!', 'comment_created': datetime.datetime(2021, 6, 14, 13, 58, 56, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 650979123, 'comment_body': 'The `sourcekitd` request actually provides a separate string for each printed type, similar to `ExpressionTypeInfo`, the printed type buffer mechanism is only used internally. But I agree, it makes sense to improve documentation here.', 'comment_created': datetime.datetime(2021, 6, 14, 14, 5, 58, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 650980903, 'comment_body': 'Honestly, I donâ€™t think thereâ€™s much value in using fully-qualified types for inlay hints, they are just too verbose. And we can always add it later if we should discover that itâ€™s needed.', 'comment_created': datetime.datetime(2021, 6, 14, 14, 8, 6, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650986266, 'comment_body': 'I thought `VariableTypeArray` used the buffer + offset to transfer the types or am I mistaken?', 'comment_created': datetime.datetime(2021, 6, 14, 14, 14, 23, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 650989811, 'comment_body': ""The `ExpressionTypeInfo` implementation uses it and I assume this is to deal with types of `inout` parameters, but I haven't looked into it too deeply yet. I'll make sure to add a test case for these. Which type printing options are you thinking of?"", 'comment_created': datetime.datetime(2021, 6, 14, 14, 18, 29, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 650993431, 'comment_body': 'Sure, this would deviate from how `printExpressionType` is named though, which, I assume, was directly named after the request.', 'comment_created': datetime.datetime(2021, 6, 14, 14, 22, 15, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 650999208, 'comment_body': ""I agree, that's a bit unfortunate. Sharing the implementation might be a bit tricky though, as many parts of this implementation make close assumptions about how `VariableType`/`ExpressionType` are structured and would require a fair bit of templating to abstract over these differences, from what I can tell."", 'comment_created': datetime.datetime(2021, 6, 14, 14, 28, 44, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 651016303, 'comment_body': 'In `VariableTypeReader` ([`VariableTypeArray.cpp`](https://github.com/fwcd/swift/blob/43b6c0a0a27fbe9a087608d037c73ef1060777a8/tools/SourceKit/tools/sourcekitd/lib/API/VariableTypeArray.cpp#L87)), the sourcekitd dictionaries are built by extracting the types at their corresponding offsets from the buffer.', 'comment_created': datetime.datetime(2021, 6, 14, 14, 47, 35, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 651021514, 'comment_body': 'I feel like offset-based positions are more in line with the request itself (which uses offset + length), slightly more compact and not much harder to test. But I would be fine either way.', 'comment_created': datetime.datetime(2021, 6, 14, 14, 53, 11, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 651046248, 'comment_body': 'If thatâ€™s the case, I think that duplicating is indeed the best optionâ€¦', 'comment_created': datetime.datetime(2021, 6, 14, 15, 20, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 651048344, 'comment_body': 'I just thought that the tests read better, because e.g. [here](https://github.com/apple/swift/pull/37867/files#diff-2a7ab5b5b0f42a4779d38a6699a951ec6013673074023b669f65cac2699dc11dR32) I canâ€™t tell at a glance what offset `230`, whereas `(19:6, 19:11)` makes it clear at first glance why variable weâ€™re referring to.', 'comment_created': datetime.datetime(2021, 6, 14, 15, 23, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 651052435, 'comment_body': 'Ah, I see. In that case I *think* that we are using the output stream to avoid allocating new memory for each string. I think @nkcsgexi implemented `ExpressionTypeInfo`, maybe heâ€™s got more background. \r\n\r\nIn any case, I think it would be cleaner to use `StringRef`s instead of the offsets we are using at the moment.', 'comment_created': datetime.datetime(2021, 6, 14, 15, 27, 50, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654756823, 'comment_body': 'This lines has more than 80 columns. I suggest you run `git-clang-format` before your commits, that should format your lines according to our style guide (which is mostly adhered to).\r\n\r\nIIRC you can install it via `brew install clang-format`.', 'comment_created': datetime.datetime(2021, 6, 19, 6, 31, 23, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654757026, 'comment_body': 'Shouldnâ€™t there also be `CHECK` lines for `z` and `w`?', 'comment_created': datetime.datetime(2021, 6, 19, 6, 33, 25, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654757504, 'comment_body': 'Iâ€™m not sure if it really makes a performance difference, but I think it would be better to use `emplace_back` here instead. That makes sure that we are directly initializing the `VariableTypeInfo` inside the `Results` `std::vector` and not creating the struct on the stack to copy it into `Results`. For that youâ€™ll need to create a constructor in `VariableTypeInfo` and call `emplace_back` without curly braces.', 'comment_created': datetime.datetime(2021, 6, 19, 6, 39, 24, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654757652, 'comment_body': 'I think this comment is out of date. We donâ€™t have `CanonicalType` anymore.', 'comment_created': datetime.datetime(2021, 6, 19, 6, 40, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654758130, 'comment_body': 'If you do the filtering for `Offset` and `Length` in `VariableTypeCollector`, you donâ€™t need this loop anymore, I think. That would also avoid copying all the result from one `std::vector` to another. And, additionally, you can avoid visiting entire subtrees of the AST if they donâ€™t contain any nodes that are in the range of interest.', 'comment_created': datetime.datetime(2021, 6, 19, 6, 46, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654758461, 'comment_body': 'Shouldnâ€™t you also only set `KeyOffset` if there is a length. I donâ€™t think having an offset but no length makes any sense.', 'comment_created': datetime.datetime(2021, 6, 19, 6, 50, 17, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654758675, 'comment_body': 'Is there a reason why you are storing all other values to print to variables above but are using the `sourcekitd_*` call for the string directly in the output here?', 'comment_created': datetime.datetime(2021, 6, 19, 6, 52, 28, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654761163, 'comment_body': 'I just looked through the code how `ExpressionTypeReader` handles its strings again and I think unfortunately the output stream + offset approach is really necessary. \r\n\r\nThis `const char *` points into `sourcekitd`â€™s address space, which is not readable by another process unless you are using `sourcektid` in process (which is only a debugging feature). \r\n\r\nThe way that `ExpressionTypeReader` handles this, is by transmitting the string with all types in the buffer created by `ExpressionTypeArrayBuilder::createBuffer`. That way all strings will actually be transmitted via XPC and are thus addressable by the client process. The string with all types now has a new address (namely one in the `llvm::MemoryBuffer` returned by `createBuffer`) which gets put into the bufferâ€™s header. That header value can then be read by [`ExpressionTypeReader`](https://github.com/apple/swift/blob/775bff003c1a41a5651e961f68a2244527b06be5/tools/SourceKit/tools/sourcekitd/lib/API/ExpressionTypeArray.cpp#L51) and all types within it can be accessed by their offset.\r\n\r\nSorry for the back and forth regarding this.', 'comment_created': datetime.datetime(2021, 6, 19, 7, 20, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 654775158, 'comment_body': 'In this case no, since we are testing ranged requests here.', 'comment_created': datetime.datetime(2021, 6, 19, 9, 44, 33, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 654849025, 'comment_body': 'Thanks, I\'ll make sure to use `clang-format`. Is this a hard limit though? In some cases I find the (slightly longer than 80 columns) current version to be more readable than the one hard-wrapped at 80 columns. Consider:\r\n\r\n```cpp\r\nsourcekitd_variant_t Item =\r\n    sourcekitd_variant_array_get_value(TypeBuffer, i);\r\nunsigned Offset =\r\n    sourcekitd_variant_dictionary_get_int64(Item, KeyVariableOffset);\r\nunsigned Length =\r\n    sourcekitd_variant_dictionary_get_int64(Item, KeyVariableLength);\r\nauto Start = resolveToLineCol(Offset, SourceBuf);\r\nauto End = resolveToLineCol(Offset + Length, SourceBuf);\r\nbool HasExplicitType =\r\n    sourcekitd_variant_dictionary_get_bool(Item, KeyVariableTypeExplicit);\r\nauto PrintedType =\r\n    sourcekitd_variant_dictionary_get_string(Item, KeyVariableType);\r\nOS << ""("" << Start.first << "":"" << Start.second << "", "" << End.first << "":""\r\n   << End.second << ""): "" << PrintedType\r\n   << "" (explicit type: "" << HasExplicitType << "")\\n"";\r\n```\r\n\r\nvs\r\n\r\n```cpp\r\nsourcekitd_variant_t Item = sourcekitd_variant_array_get_value(TypeBuffer, i);\r\nunsigned Offset = sourcekitd_variant_dictionary_get_int64(Item, KeyVariableOffset);\r\nunsigned Length = sourcekitd_variant_dictionary_get_int64(Item, KeyVariableLength);\r\nauto Start = resolveToLineCol(Offset, SourceBuf);\r\nauto End = resolveToLineCol(Offset + Length, SourceBuf);\r\nbool HasExplicitType = sourcekitd_variant_dictionary_get_bool(Item, KeyVariableTypeExplicit);\r\nauto PrintedType = sourcekitd_variant_dictionary_get_string(Item, KeyVariableType);\r\nOS << ""(""\r\n   << Start.first << "":"" << Start.second\r\n   << "", ""\r\n   << End.first << "":"" << End.second\r\n   << ""): ""\r\n   << PrintedType\r\n   << "" (explicit type: "" << HasExplicitType << "")\\n"";\r\n```', 'comment_created': datetime.datetime(2021, 6, 19, 22, 46, 24, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 654850355, 'comment_body': ""No reason, thanks for pointing this out, I'll use a variable!"", 'comment_created': datetime.datetime(2021, 6, 19, 23, 2, 49, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 654850475, 'comment_body': ""Thanks for digging into this, that makes sense, I'll make sure to revert those changes."", 'comment_created': datetime.datetime(2021, 6, 19, 23, 4, 42, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 654853713, 'comment_body': ""Thanks for the suggestion, we still need the loop though to convert from IDETypeChecking's `VariableTypeInfo` to SourceKit's `VariableType` (even though those structures have almost the same fields)."", 'comment_created': datetime.datetime(2021, 6, 19, 23, 47, 56, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 655163370, 'comment_body': 'In general the files should be formatted according to `clang-format` but thereâ€™s always exceptions. Personally, I sometimes donâ€™t like the formatting of `clang-format` sometimes and choose to overwrite it and other times people simply forget to run `clang-format`.', 'comment_created': datetime.datetime(2021, 6, 21, 8, 9, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655165332, 'comment_body': ""Ah, I didn't see that. Could you add the following lines\r\n```\r\n// CHECK-NOT: (1:5, 1:6)\r\n```\r\nand \r\n```\r\n// CHECK-NOT: (4:5, 5:6)\r\n```\r\n\r\nAt the moment, file check will pass even if these lines occur in the output because it will simply skip over lines that donâ€™t match any `CHECK` line."", 'comment_created': datetime.datetime(2021, 6, 21, 8, 12, 15, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655166019, 'comment_body': 'I *think* you can also use `-end-pos` here instead of `-length`. That would make the test case more resistent if someone chose to rename one of the variables/types/values', 'comment_created': datetime.datetime(2021, 6, 21, 8, 13, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655169736, 'comment_body': 'I would prefer to hide the `Offset` + `Length` implementation detail here and use a `SourceRange` instead. When using that you also donâ€™t need `llvm::Optional` because you can just pass an invalid `SourceRange` (created by `SourceRange()`) if the entire file should be reported.\r\n\r\nYou would probably also need to create a `overlaps` method on `SourceRange` Ã  la `CharSourceRange::overlaps` and to construct the `SourceRange`, youâ€™ll want to use `Lexer::getLocForStartOfToken`.\r\n\r\nAlso, could you include what the `None` `Offset`/`Length` (or later invalid `SourceRange` if you adopt the above suggestion) means, into the doc-comment?', 'comment_created': datetime.datetime(2021, 6, 21, 8, 18, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655176277, 'comment_body': 'I know we also use the paradigm of `Scratch` + return `ArrayRef` for `collectExpressionTypeInfo`, but wouldnâ€™t it be cleaner to just either\r\na) just return a `std::vector` and not using `Scratch`? I just checked that returning it only transfers ownership and doesnâ€™t cause the vector to be copied or\r\nb) use `Scratch` as the out parameter and make the function return `void`?', 'comment_created': datetime.datetime(2021, 6, 21, 8, 28, 23, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655177485, 'comment_body': 'Do we actually need `TypeLength` here if all types in the output stream are null-terminated? If not, I think we can avoid the conversion from `VariableTypeInfo` to `VariableType`.', 'comment_created': datetime.datetime(2021, 6, 21, 8, 30, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655187067, 'comment_body': 'Just to revive this, I think we should try it without `getRValueType` first until we have a strong motivation for using `getRValueType` here.', 'comment_created': datetime.datetime(2021, 6, 21, 8, 43, 46, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655187949, 'comment_body': 'Nitpick: The standard formatting for the labelled parameter is `/*Recursive=*/true` without spaces.', 'comment_created': datetime.datetime(2021, 6, 21, 8, 45, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655189013, 'comment_body': 'I think if a declâ€™s range is invalid, all of its childrenâ€™s ranges are also invalid, so there shouldnâ€™t be a need to visit them. Hence, we can return `false` here.', 'comment_created': datetime.datetime(2021, 6, 21, 8, 46, 32, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655190918, 'comment_body': 'A small performance optimization: You can also implement `walkToStmtPre`, `walkToExprPre` and `walkToPatternPre` to check if they overlap with the queried range. That might save us from visiting some subtrees.', 'comment_created': datetime.datetime(2021, 6, 21, 8, 49, 10, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655192907, 'comment_body': 'I donâ€™t think 256 bytes will realistically be enough to hold all types in all but the most simple of test cases, so we might as well save the stack space here and use a `std::string`.', 'comment_created': datetime.datetime(2021, 6, 21, 8, 51, 57, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655195824, 'comment_body': 'Again, I think it would be good to document what a `None` `Offset` and `Length` do. Also: What happens if `Offset` is `None` but `Length` has a value or vice versa?', 'comment_created': datetime.datetime(2021, 6, 21, 8, 55, 52, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655200639, 'comment_body': 'Shouldnâ€™t this be `PrintedTypes` (plural) instead of just `PrintedType`?', 'comment_created': datetime.datetime(2021, 6, 21, 9, 2, 6, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655204249, 'comment_body': 'I donâ€™t think `PrintedType` or `Buffer` are ever used.', 'comment_created': datetime.datetime(2021, 6, 21, 9, 7, 19, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655205302, 'comment_body': 'Nitpick: The `printedType` variable is capitalized: `printedType` -> `PrintedType`', 'comment_created': datetime.datetime(2021, 6, 21, 9, 8, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655205937, 'comment_body': 'Nitpick: Shouldnâ€™t this be `PrintedTypes` (plural)?\r\n\r\nSuggested doc comment:\r\n```cpp\r\n/// A string that contains the types of the variables that are reported by this \\c VariableTypeReader. Each type is null-terminated and \\c EntryReader references the types using offsets into this string.\r\n```', 'comment_created': datetime.datetime(2021, 6, 21, 9, 9, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655206384, 'comment_body': 'Suggested doc comment.\r\n\r\n```cpp\r\n/// A builder that builds the \\c PrintedTypes string used by \\c VariableTypeReader. See \\c VariableTypeReader::PrintedTypes for more info.\r\n```', 'comment_created': datetime.datetime(2021, 6, 21, 9, 10, 32, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655207211, 'comment_body': 'Suggested doc comment\r\n\r\n```cpp\r\n/// A builder that builds the that builds values read by \\c EntryReader in \\c VariableTypeReader. See \\c VariableTypeReader::EntryReader for more info.\r\n```', 'comment_created': datetime.datetime(2021, 6, 21, 9, 11, 46, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655226598, 'comment_body': 'Ah thanks, this change seems to have been accidentally reverted with the printed-type-buffer-change', 'comment_created': datetime.datetime(2021, 6, 21, 9, 39, 27, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 655308596, 'comment_body': ""If we avoid the conversion and use `VariableTypeInfo` in `LangSupport.h`, wouldn't that introduce a dependency on `IDETypeChecking`?"", 'comment_created': datetime.datetime(2021, 6, 21, 11, 51, 1, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 655311729, 'comment_body': ""Since we are passing in the vector reference anyway, I think making it return void and turning `Scratch` into a 'pure' output parameter would be good. That way we wouldn't rely on return value optimization to avoid the copy."", 'comment_created': datetime.datetime(2021, 6, 21, 11, 56, 7, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 655324802, 'comment_body': 'Just curious, is there a reason to use `SourceRange` over `CharSourceRange` in this case, which is already used in `walkToDeclPre`? `CharSourceRange` would have the advantage of not requiring a conversion from the length to an end position.', 'comment_created': datetime.datetime(2021, 6, 21, 12, 16, 45, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 655329923, 'comment_body': ""Wouldn't most statements, expressions and patterns occur in declarations anyway?"", 'comment_created': datetime.datetime(2021, 6, 21, 12, 24, 45, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 655336574, 'comment_body': 'I chose `SourceRange` because all AST nodes already store their `SourceRange` but not their `CharSourceRange`. If you want to convert `SourceRange` to `CharSourceRange`, you need to reach out to the lexer again to determine the length of the end token. \r\n\r\nThus, I think itâ€™s better to just do the conversion once for the requested range and avoid converting the range of every AST node.', 'comment_created': datetime.datetime(2021, 6, 21, 12, 34, 44, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655338634, 'comment_body': 'True. We could move the `VariableTypeInfo` type further into a module thatâ€™s imported by both `Sema` and `SourceKit` (e.g. `AST`) but that seems like an overkill to me. Still, I think it would be nice if both types had the same layout.', 'comment_created': datetime.datetime(2021, 6, 21, 12, 37, 48, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655341460, 'comment_body': 'Not really, simple function calls and variable assignments donâ€™t occur in declarations. Same goes for control flow constructs like `if` or `while`.\r\n\r\nFor example if I have\r\n```\r\nfunc foo() {\r\n  let x = 1\r\n  x += 1\r\n  // repeat `x += 1` 500 times\r\n}\r\n```\r\n\r\nand I only request the variable types of line 2, then thereâ€™s no need to visit the 500 `x += 1` statements.', 'comment_created': datetime.datetime(2021, 6, 21, 12, 41, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 655354755, 'comment_body': 'Yes, fair point.', 'comment_created': datetime.datetime(2021, 6, 21, 12, 59, 59, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 656139792, 'comment_body': 'If `Scratch` is a proper out parameter now, I think it should be called something else. E.g. `VariableTypeInfos` or `OutVariableTypeInfos`. I would also note that this variable is an out parameter in the doc comment, e.g. `â€¦ within the given range to \\c VariableTypeInfos`', 'comment_created': datetime.datetime(2021, 6, 22, 11, 45, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 656141296, 'comment_body': 'I think this method only needs to return the start offset now since the length is implicit by the null-termination. Also this method should then be called `getTypeOffset` (singular).', 'comment_created': datetime.datetime(2021, 6, 22, 11, 48, 12, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 656143057, 'comment_body': 'Do we need to capture `SF` by reference here? IIUC `VariableTypeCollector` shouldnâ€™t modify `SF` and a const reference `const SourceFile &SF` would thus be sufficient.', 'comment_created': datetime.datetime(2021, 6, 22, 11, 50, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 656147156, 'comment_body': 'Since weâ€™ve been talking about ranges so much lately, I got confused and thought this range encompasses the entire declarationâ€™s range, but itâ€™s only the name as I just found out. So I think `DeclNameRange` would be a better variable name.\r\n\r\nAlso, since I now know that this range is just the declarationâ€™s name, I think we should visit the declarationâ€™s children even if the nameâ€™s range is invalid (i.e. return `true` here). We could, e.g. have a struct without a name but would still want to visit its children.', 'comment_created': datetime.datetime(2021, 6, 22, 11, 56, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 656160788, 'comment_body': '`offsets` -> `offset` if `getTypeOffsets` becomes `getTypeOffset`.', 'comment_created': datetime.datetime(2021, 6, 22, 12, 15, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 656161819, 'comment_body': 'Also here, I think `SF` could be a `const` reference.', 'comment_created': datetime.datetime(2021, 6, 22, 12, 17, 24, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 656207817, 'comment_body': '`SourceEntityWalker::walk` unfortunately requires a non-const reference', 'comment_created': datetime.datetime(2021, 6, 22, 13, 13, 36, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 656226756, 'comment_body': 'Fair enough. In that case Iâ€™m fine with keeping it as-is.', 'comment_created': datetime.datetime(2021, 6, 22, 13, 34, 12, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}]","[{'commit_sha': '2703d088778c67ed86df6c5308d1ece0057061aa', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ebe1b91663f1c7412afe942946362f8461128b4b', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7a73c995109bffa50be6b28efa5e391c489afa73', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1a844efe5ebd3aafe0ffa062735ed29ca5816ded', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b904d0fc0c4f1dca274ea432ac1e6b6e698a9df5', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
677369193,[SourceKit] Determine correctly whether typed  variables in `if/guard/while-let`-statements have explicit type annotations,"As noted in https://github.com/apple/sourcekit-lsp/pull/408#issuecomment-867802689, `if/guard/while-let`s are currently (incorrectly) always reported as having no explicit type annotation as the `TypedPattern` is not the top-level-pattern in such declarations. Consider the following example:

```swift
if let x: Int = Optional.some(4) {}
```

Here we get the following AST:

```
(if_stmt ...
  (pattern
    (pattern_optional_some implicit type='Int?'  <--- this node prevents the current mechanism from discovering the type annotation
      (pattern_typed type='Int'
        (pattern_let implicit type='Int'
          (pattern_named type='Int' 'x'))
        (type_ident
          (component id='Int' bind=Swift.(file).Int))))
    (call_expr ...))
  (brace_stmt ...))
```

`sourcekitd-test` therefore reports `(explicit type: 0)` despite an explicit annotation being present:

```
<VariableTypes>
(1:8, 1:9): Int (explicit type: 0)
</VariableTypes>
```

This PR fixes the issue by including an implicitly generated `OptionalSomePattern` as a special case in `VariableTypeCollector` and also adds tests to verify that these cases are handled correctly.

cc @ahoppen ",True,38084,https://api.github.com/repos/swiftlang/swift/pulls/38084,https://github.com/swiftlang/swift/pull/38084,closed,56,5,3,3,7,2,0,1,[],2021-06-24 19:04:23+00:00,2021-07-02 10:02:32+00:00,658689.0,"7 days, 14:58:09","[{'comment_id': 658857273, 'comment_body': 'Is it strictly necessary to check if the `OptionalSomePattern` is implicit here?', 'comment_created': datetime.datetime(2021, 6, 25, 15, 35, 32, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 658873718, 'comment_body': ""I don't think that having a typed pattern in an explicit pattern is possible in Swift currently, I included this check just to be sure that we consider the expected case only though."", 'comment_created': datetime.datetime(2021, 6, 25, 15, 59, 30, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}]","[{'commit_sha': '1b74379b1abad5af62a0fe8aec9aa46cbb4c8c0b', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '157a64450e76d45cf53964a1335d9e9aea1a5b1f', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b33a20282e3fa989205714996141435fa3738fb9', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
677405414,[IDE] Fix name range of wildcard declarations,"Visiting a wildcard variable declaration (e.g. `let _ = 4`) with `SourceEntityWalker::walkToDeclPre(Decl *, CharSourceRange)` currently yields a range of length zero, whereas e.g. `let x = 4` yields a range of length 1.

The motivating use case for having a length-1-range here instead is to provide an accurate inlay type hint after the variable identifier, see https://github.com/apple/sourcekit-lsp/pull/408#issuecomment-867802689 for details

This PR therefore fixes the issue by defaulting to length 1 if the declaration doesn't have a name and an underscore occurs at the corresponding location in the source file.

cc @ahoppen",True,38085,https://api.github.com/repos/swiftlang/swift/pulls/38085,https://github.com/swiftlang/swift/pull/38085,closed,25,4,4,4,2,5,0,1,[],2021-06-24 20:10:20+00:00,2021-06-29 13:03:27+00:00,406387.0,"4 days, 16:53:07","[{'comment_id': 658261789, 'comment_body': 'I think this doesnâ€™t work if the identifier starts with an underscore. E.g. `let _foo = 2`. If it does work, I think it would be worth adding a test case for it.\r\n\r\nI also donâ€™t understand yet why this should be necessary. If the identifier is empty, then `DeclBaseName::userFacingName()` should return a `_`, which has a length of 1. ðŸ¤” \r\nhttps://github.com/apple/swift/blob/7ccc1b054a607881978b8efa0d7042d8bcd3d63f/include/swift/AST/Identifier.h#L339', 'comment_created': datetime.datetime(2021, 6, 24, 20, 30, 45, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 658267334, 'comment_body': ""If we have something like `_x`, `hasName()` returns true, so it should work. The reason why this is necessary for `_` is because it doesn't go down that branch if the identifier is empty, because `hasName()` returns false."", 'comment_created': datetime.datetime(2021, 6, 24, 20, 40, 2, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 658269450, 'comment_body': 'Perhaps we could drop the `hasName()`-check completely since `userFacingName()` returns the right thing in any case?', 'comment_created': datetime.datetime(2021, 6, 24, 20, 43, 38, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 658274357, 'comment_body': 'One thing to also consider is invalid declarations like `let = 1` or `struct {}` (not relevant for your implementation but for other users of `SemaAnnotator`), which also donâ€™t have a name and whose name isnâ€™t `_` either.\r\n\r\nJust an idea if the logic starts to get too complicated here: You could also check for the standard straightforward cases here (no backticks, name not empty) and if that doesnâ€™t match, use `Lexer::getTokenAtLocation` to look the actual source code up. The downside is that `Lexer::getTokenAtLocation` needs to set up a `Lexer` instance, which is slower (although itâ€™s not really slow either and I think weâ€™re doing it in a variety of places).', 'comment_created': datetime.datetime(2021, 6, 24, 20, 52, 4, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 658298376, 'comment_body': 'Hm yes, dropping `hasName()` also seems to cause `test/IDE/annotation.swift` to fail as the annotator now reports things like\r\n```swift\r\nvar <Var>protocolProperty1</Var>: <iStruct@>Int</iStruct> { <Accessor>g</Accessor>et }\r\n```\r\ninstead of\r\n```swift\r\nvar <Var>protocolProperty1</Var>: <iStruct@>Int</iStruct> { get }\r\n```\r\n\r\nI think the standard straightforward cases as well as the backtick and `_` case should be handled correctly with the PR implementation right now, though using a lexer might be a bit cleaner than looking up the source code directly.', 'comment_created': datetime.datetime(2021, 6, 24, 21, 37, 18, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}]","[{'commit_sha': '748f60d0f475280ddf9e37f025bf3d1d1e62f6a9', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b2fb9e4494abacde26cad946145d89909f6e2c86', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '88dd0822608e266204c2ba23c9270089a379008d', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a79268202b068c6419b1c8cd57201ec430ce550', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359
683064390,Implement semantic highlighting for Swift,"This is a reboot of @prostakm's implementation of semantic highlighting in #279, using the LSP structures from #388 and the suggestions from https://github.com/apple/sourcekit-lsp/pull/279#issuecomment-63545981.

Both lexical and semantic tokens are now stored in `Document`s and updated whenever a document is updated or changed. Lexical tokens are updated incrementally in `openDocument` and `changeDocument` and semantic tokens are updated all at once in `handleDocumentUpdate`.

![image](https://user-images.githubusercontent.com/30873659/124367162-2968d880-dc55-11eb-9355-dc79c32883fd.png)

### Implementation Progress

- [x] Parse syntax map and annotations from SourceKit
- [x] Update lexical tokens on document open and change events from SourceKit
    - [x] Remove and shift existing lexical tokens correctly on edit events in `DocumentManager`
    - [x] Handle edge cases where lexical tokens aren't removed correctly, e.g. when typing `let document = ...` the `do` stays highlighted as a keyword and isn't removed, since the edit range never overlaps with it (this is solved by checking whether an edit that is directly adjacent to a token uses a whitespace character at the adjacent position)
- [x] Update semantic tokens on document update events from SourceKit
- [x] Implement (full) semantic token requests
- [x] Implement ranged semantic token requests
- [x] Implement semantic token modifiers
- [x] Provide semantic tokens for declarations
- [x] Add test case for lexical tokens
- [x] Add test case for semantic tokens

### Future Work

- Add LSP config options so users can selectively enable/disable the different kinds of tokens (semantic, lexical)
    - This could also be useful for testing
- Implement semantic token delta responses
- Parse syntactic tokens from the edit response's `keys.substructure` (i.e. revert 1e6573065545217156c9ff82c1d4181c8868f68f) and address the performance issues in big files (see [this thread](https://github.com/apple/sourcekit-lsp/pull/414#discussion_r681774390))
    - A possible approach would be to parse the substructure asynchronously into syntactic tokens, this should be possible since they aren't updated incrementally like the lexical tokens",True,414,https://api.github.com/repos/swiftlang/sourcekit-lsp/pulls/414,https://github.com/swiftlang/sourcekit-lsp/pull/414,closed,1645,36,17,3,16,206,0,1,[],2021-07-03 18:54:24+00:00,2021-08-28 11:04:08+00:00,4810184.0,"55 days, 16:09:44","[{'comment_id': 663570496, 'comment_body': 'Is this name used anywhere? ', 'comment_created': datetime.datetime(2021, 7, 4, 23, 27, 16, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663570986, 'comment_body': 'Would be good to call out which ones are non-standard, from https://code.visualstudio.com/api/language-extensions/semantic-highlight-guide#standard-token-types-and-modifiers I think modifier and member are non-standard?', 'comment_created': datetime.datetime(2021, 7, 4, 23, 30, 55, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663571164, 'comment_body': 'Is the length given by sourcekitd inaccurate?', 'comment_created': datetime.datetime(2021, 7, 4, 23, 32, 41, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663571648, 'comment_body': 'Is it safe to merge the two - no overlap?', 'comment_created': datetime.datetime(2021, 7, 4, 23, 36, 33, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663572026, 'comment_body': ""I don't believe all clients will support this, if they don't we shouldn't send it. @benlangmuir might have thoughts on we can improve support for clients which don't support it."", 'comment_created': datetime.datetime(2021, 7, 4, 23, 40, 7, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663572340, 'comment_body': 'nit: this seems like it would be better off elsewhere e.g. in Sources/SourceKitLSP/Swift/SemanticTokenParser.swift or a related SemanticTokens file', 'comment_created': datetime.datetime(2021, 7, 4, 23, 42, 34, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663572629, 'comment_body': 'Since we know the exact size (5 * n) needed you could use `Array.init(repeating:count:)` or create an empty one and call `reserveCapacity`', 'comment_created': datetime.datetime(2021, 7, 4, 23, 45, 24, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663572741, 'comment_body': 'Is this more like `replaceSyntacticTokens` - functionally seems similar to the above but for the syntactic tokens?', 'comment_created': datetime.datetime(2021, 7, 4, 23, 46, 53, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 663573083, 'comment_body': ""Is this necessary because in the editor's request we return the cached data before we might get any data from sourcekitd? Does sourcekitd only give deltas itself (e.g. when making edits)?"", 'comment_created': datetime.datetime(2021, 7, 4, 23, 49, 27, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 664741262, 'comment_body': ""`modifier` is mentioned in the spec ([see here](https://microsoft.github.io/language-server-protocol/specifications/specification-current/#textDocument_semanticTokens)) and `member` isn't used, I think, so we could probably remove it."", 'comment_created': datetime.datetime(2021, 7, 6, 17, 16, 54, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 664747080, 'comment_body': 'Good question, I think type references for example are part of both. Should we perform some kind of filtering that excludes syntactic tokens for which we already have a semantic variant?\r\n\r\nSome other language servers provide purely semantic tokens via LSP (i.e. no keywords, etc). Doing so would probably simplify the implementation a great deal, but perhaps make it less useful to clients who want to do the complete syntax highlighting via LSP?', 'comment_created': datetime.datetime(2021, 7, 6, 17, 26, 13, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 664750161, 'comment_body': ""Yes, sourcekitd only provides deltas for syntactic tokens. For semantic tokens it wouldn't be strictly necessary, but looks nicer in the editor when the tokens don't 'bounce around'.\r\n\r\nAFAICT sourcekitd also just tells us about added tokens, so we have to remove outdated ones ourselves."", 'comment_created': datetime.datetime(2021, 7, 6, 17, 30, 39, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 664750780, 'comment_body': 'Since syntactic tokens are updated in deltas, this only adds tokens instead of replacing all tokens for a document.', 'comment_created': datetime.datetime(2021, 7, 6, 17, 31, 40, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 664830364, 'comment_body': ""Don't think so, good catch."", 'comment_created': datetime.datetime(2021, 7, 6, 19, 41, 34, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 664837538, 'comment_body': ""I've added a check that tests whether the `ClientCapabilities` includes support for refresh requests."", 'comment_created': datetime.datetime(2021, 7, 6, 19, 53, 59, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 664839153, 'comment_body': ""`length` seems to work fine for function names (which were handled as a special case, this snippet was from the old PR), so I've removed it."", 'comment_created': datetime.datetime(2021, 7, 6, 19, 56, 44, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 664898891, 'comment_body': ""I've updated the merging logic to include syntactic tokens only if no corresponding semantic token exists."", 'comment_created': datetime.datetime(2021, 7, 6, 21, 47, 3, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 665968290, 'comment_body': 'I think you renamed that file and itâ€™s now called `SemanticTokens.swift`.', 'comment_created': datetime.datetime(2021, 7, 8, 8, 9, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 665970487, 'comment_body': 'Not entirely sure what the correct behavior is, but I would prefer the `rhs` tokens not only on *duplicate* ranges but also on *overlapping* ranges because otherwise we might end up with text ranges which match to two `SemanticToken`s.\r\n\r\n----\r\n\r\nNitpick: It appears we are only using this function in `DocumentTokens.merged`. Would it make sense to move it close to its use or even just use the body as a closure to `reduce`?\r\n\r\n---\r\n\r\nLike `encodeToIntArray` and `decodeFromIntArray`, would it make sense to make this a static member of `SemanticToken` or a normal member of `Array<SemanticToken>`?', 'comment_created': datetime.datetime(2021, 7, 8, 8, 12, 48, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 665972891, 'comment_body': 'Wouldnâ€™t `mergedAndSorted` be a better name to indicate that the tokens have been merged?', 'comment_created': datetime.datetime(2021, 7, 8, 8, 16, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 665974754, 'comment_body': 'Nitpick: I think the body (in particular the implementation of `removeAllOverlapping` reads better if you name this variabel `tokens newTokens: [SemanticToken]`', 'comment_created': datetime.datetime(2021, 7, 8, 8, 18, 46, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 665977789, 'comment_body': 'Since we are using `SemanticToken` also for lexical and syntactic tokens, wouldnâ€™t `SyntaxHighlightingToken` be a better name? Or just `Token` but Iâ€™m worried that `Token` might overlap with `SwiftSyntax`â€™s definition of `Token` if we ever pull it in.', 'comment_created': datetime.datetime(2021, 7, 8, 8, 22, 51, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 665978282, 'comment_body': '`withEachKind` suggests some kind of immutability to me. Also the `Kind` bit confused me a bit because I thought kind referred to token kinds. But I canâ€™t come up with a better alternative for kind eitherâ€¦\r\n\r\nWhat do you think about `withMutableTokensOfEachKind` and then add a doc-comment like\r\n```swift\r\n/// Modifies the syntax highlighting tokens of each kind (lexical, syntactic, semantic) according to `action`.\r\n```', 'comment_created': datetime.datetime(2021, 7, 8, 8, 23, 30, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 665985844, 'comment_body': 'What do we need the `isTokenBounding` check for? Could you maybe give an example for it? Iâ€™m also worried because in all likelihood Swiftâ€™s definition of `isWhitespace`, `isPunctuation` and `isSymbol` most likely donâ€™t coincide with Swiftâ€™s parserâ€™s definition of which characters are operators etc.', 'comment_created': datetime.datetime(2021, 7, 8, 8, 33, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 665995098, 'comment_body': 'IIUC the implementation is actually doing it the other way round, removing from `document.latestTokens.lexical` instead of `tokens`.\r\n```swift\r\n// Remove all tokens from `document.latestTokens.lexical` that overlap with a token in `tokens`.\r\n```', 'comment_created': datetime.datetime(2021, 7, 8, 8, 45, 58, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666000972, 'comment_body': 'I think, previously, `uri` + `latestVersion` was sufficient to uniquely identify a document snapshot because each change to `latestLineTable` would increase the `latestVersion` and `language` was constant for the `uri` (at least I donâ€™t think we support changing the language of a document in-flight). \r\n\r\nIâ€™m a little concerned that we can now have multiple snapshots of the document that have the same version but different `tokens`. I think, we should \r\n- either call this out in a doc comment\r\n- or make sure we increase the `version` whenever we update `tokens`. IIRC LSP only demands a monotonically increasing version, so there shouldnâ€™t be a problem if the client never gets to see some internal version numbers.', 'comment_created': datetime.datetime(2021, 7, 8, 8, 53, 45, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666002613, 'comment_body': 'Nitpick: Name this file `SemanticToken.swift` (singular). `SemanticTokens.swift` suggests to me that there are multiple definitions of different semantic tokens in it.', 'comment_created': datetime.datetime(2021, 7, 8, 8, 55, 44, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666003117, 'comment_body': 'As commented above, we also use it for syntactic highlightingâ€¦', 'comment_created': datetime.datetime(2021, 7, 8, 8, 56, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666007538, 'comment_body': 'Not really necessary, but since Iâ€™ve been wondering, I think it would be good to add a doc comment that the integer value doesnâ€™t need to be stable because itâ€™s transmitted as part of the `SemanticTokensLegend`.\r\n\r\nIf it needed to be stable, I would have asked you to add explicit integer values to all types so that itâ€™s resistent to reordering ðŸ˜‰ \r\n\r\n-----\r\n\r\nIn the rest of LSP weâ€™ve refrained from using enums with associated values so we can handle unknown cases (like [here](https://github.com/apple/sourcekit-lsp/blob/13d3d93d8b706ff93bd88644aa1a4b6a2c054a81/Sources/LanguageServerProtocol/SupportTypes/Diagnostic.swift#L94-L105)). I donâ€™t think this makes sense here because we need the string -> int conversion for known kinds, but I think it would be worth pointing out in a comment that thatâ€™s a deliberate decision.\r\n\r\n------\r\n\r\nLSP calls these `TokenTypes` ([link](https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#semanticTokensLegend)). Should we be consistent and also call it `Type` or `TokenType`, even though I donâ€™t like the ambiguity with types in the type system? ', 'comment_created': datetime.datetime(2021, 7, 8, 9, 1, 59, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666008736, 'comment_body': 'This assumes that tokens donâ€™t range over multiple lines. I think thatâ€™s fair, but it would be good to point that out. Ideally in an assertion but I donâ€™t think thatâ€™s viable here, so a comment should be fine.\r\n\r\nMaybe add a test case containing a multi-line comment though as this is the most likely candidate I can see of breaking the assumption.', 'comment_created': datetime.datetime(2021, 7, 8, 9, 3, 36, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666009989, 'comment_body': 'Again, I think it would be good to have a comment that the raw value doesnâ€™t need to be stable. Because the time will come that someone renames/removes/reorders these and is then wondering if he can reuse raw values.', 'comment_created': datetime.datetime(2021, 7, 8, 9, 5, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666012591, 'comment_body': 'How did you come up with this list? Iâ€™m just confused because it doesnâ€™t match the one in the [LSP spec](https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#semanticTokenTypes), both in order and in the values.\r\n\r\n`label` isnâ€™t part of the LSP spec AFAICT and we are missing `enumMember` and `event` from the spec.', 'comment_created': datetime.datetime(2021, 7, 8, 9, 9, 4, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666021462, 'comment_body': 'More of a general question: Do you have an idea how to handle semantic highlighting coming from `clangd`. AFAICT we can only have a single `SemanticTokensLegend`. So if `clangd`â€™s legend doesnâ€™t match ours, we need to translate token types and token modifiers from the integer coming from `clang` to their LSP name and back into our integer representation. \r\n\r\nWe would also need to figure out what to do with tokens whose type we donâ€™t have in our hard-coded legend. Weâ€™d either need to incorporate `clangd`â€™s legend into ours or drop themâ€¦\r\n\r\nIIRC we donâ€™t support semantic highlighting through `clangd` (please correct me if Iâ€™m wrong), so I donâ€™t think we need a thorough answer here. ', 'comment_created': datetime.datetime(2021, 7, 8, 9, 21, 1, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666026975, 'comment_body': 'IIUC we donâ€™t expect to ever end up with a modifier thatâ€™s not known to us (i.e. not in `allCases`) because then it wonâ€™t be in our legend and the editor wonâ€™t know what to do with it.\r\n\r\nSo, I think it would be better to make this `fatalError` in the `default` case and add an assertion to the initializer\r\n```swift\r\npublic init(rawValue: UInt32) {\r\n  self.rawValue = rawValue\r\n  assert(allCases.contains(self), ""Unknown modifier?"")\r\n}\r\n```', 'comment_created': datetime.datetime(2021, 7, 8, 9, 28, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666030316, 'comment_body': 'As I donâ€™t think this format is very intuitive, I think it would be good to add some documentation what the individual entries represent, e.g. copied the comment from the LSP spec. \r\n\r\nI think the most confusing ones are actually the first two, so it might also be sufficient to store the value of the subtractions variables and maybe add a short comment to those.', 'comment_created': datetime.datetime(2021, 7, 8, 9, 32, 28, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666034788, 'comment_body': ""I donâ€™t think the `previous` position makes any meaningful sense other than that it stores two integers that yield the correct results for `deltaLine` and `deltaStart`.\r\n\r\nI think it would be cleaner to just compute `deltaLine` and `deltaStart` on their own. E.g.\r\n\r\n```swift\r\n// rename the variable 'current' to 'previous'\r\nlet deltaLine = token.start.line - previous.line\r\nlet deltaStart: UInt32\r\nif previous.line == token.start.line {\r\n  deltaStart = token.start.utf16index - previous.utf16index\r\n} else {\r\n  deltaStart = token.start.utf16index - previous.utf16index\r\n}\r\n```\r\n\r\nThis would also make it easier to document the first two entries (see next review comment below)"", 'comment_created': datetime.datetime(2021, 7, 8, 9, 38, 31, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666036260, 'comment_body': ""What do you think about a `assert(rawTokens.count.isMultiple(of: 5))` sanity check? If that doesn't pass, something is horribly wrong and Iâ€™d prefer to bail out early. Otherwise, I think itâ€™ll fail when we are trying to access `rawTokens[i + <offset>]` below."", 'comment_created': datetime.datetime(2021, 7, 8, 9, 40, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666037550, 'comment_body': 'Wouldnâ€™t it make more sense to make `encodeToIntArray` and `decodeFromIntArray` static members of `SemanticToken` (or even normal members of `Array<SemanticToken>`). I donâ€™t really like having a generic name like `encodeToIntArray` on the top level.\r\n\r\n--- \r\n\r\nThis also assumes that the tokens are sorted. I think that would deserve a comment + assertion.', 'comment_created': datetime.datetime(2021, 7, 8, 9, 42, 24, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666041029, 'comment_body': 'This is only for testing, right? In that case, I think it would better live in `SKTestSupport` or even just the test case itself.', 'comment_created': datetime.datetime(2021, 7, 8, 9, 47, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666045787, 'comment_body': 'When do you need to set `useName = true`. Is it something that modifies behavior, or would we produce incorrect results if `useName` has the wrong value because either `keys.nameoffset` or `keys.offset` doesnâ€™t exist in `response`?', 'comment_created': datetime.datetime(2021, 7, 8, 9, 53, 21, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666049377, 'comment_body': 'I donâ€™t really like mixing configuration options and state in the initializer. That way itâ€™s not clear whether `SemanticTokenParser` is intended to be a throw-away type that can only be used to parse one response or whether it can be used multiple times. Also itâ€™s too easy to accidentally re-use a parser thatâ€™s got an old snapshot stored in it.\r\n\r\nIâ€™d prefer either of\r\n- Only accept configuration options (`sourcekitd` and `useName`) in the initializer and pass `snapshot` to `parseTokens`\r\n- Make `init` private and add static entry methods that create a throwaway `SemanticTokenParser` on which they invoke `parseTokens` and just return the `[SemanticToken]` result.\r\n- Make `SemanticTokenParser` an `enum` and work with static methods only', 'comment_created': datetime.datetime(2021, 7, 8, 9, 58, 15, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666053424, 'comment_body': 'Any reason for making subscripts functions instead of methods? I think theyâ€™ve got more of a method-flare to them, because they operate on an object.\r\n\r\nRegarding constructors, I think of them as static methods. And since you classify static methods as methods as well, I would do the same for constructors.', 'comment_created': datetime.datetime(2021, 7, 8, 10, 3, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666055652, 'comment_body': 'Same discussion about constructors and subscripts here. And destructors are IMHO normal (non-static) methods.', 'comment_created': datetime.datetime(2021, 7, 8, 10, 7, 12, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666057718, 'comment_body': 'What do you think about adding some low-level logging here if we encounter a kind thatâ€™s not handled, e.g. on the warning level? That way we would have a way of noticing if new kinds are added to SourceKit that we donâ€™t handle here yet. In that case youâ€™d need to add a case for `value.decl_var_parameter` that returns `nil` without logging.\r\n\r\n---\r\n\r\nI think youâ€™re also missing a few syntax kinds here. For example, thereâ€™s no `syntaxtype_identifier`. You could probably catch most of them by looking through [UIDs.py](https://github.com/apple/swift/blob/main/utils/gyb_sourcekit_support/UIDs.py) again and by enabling the logging.', 'comment_created': datetime.datetime(2021, 7, 8, 10, 10, 12, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666064321, 'comment_body': 'Just to clarify, the syntax map is providing delta updates whereas `substructure` is always a full update, right?', 'comment_created': datetime.datetime(2021, 7, 8, 10, 20, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666070931, 'comment_body': 'This should be guarded by `queue`, either through a `queue.async` or by requiring that itâ€™s called on `queue. Based on how `updateLexicalAndSyntacticTokens` is called right now, I think the latter is what we want. Could you add a comment and assertion for that?', 'comment_created': datetime.datetime(2021, 7, 8, 10, 29, 45, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666071103, 'comment_body': 'Same regarding the guard on `queue`. Could you add an assertion for that?', 'comment_created': datetime.datetime(2021, 7, 8, 10, 30, 2, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666071436, 'comment_body': 'Typo: `updating lexical` -> `updating syntactic`', 'comment_created': datetime.datetime(2021, 7, 8, 10, 30, 31, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666073211, 'comment_body': 'I would move the code to inform the client to a new function. Right now, we assume that `updateSemanticTokens` is called after `updateLexicalAndSyntacticTokens` to transfer the syntax information to the client. But that doesnâ€™t necessarily need to be the case, right?', 'comment_created': datetime.datetime(2021, 7, 8, 10, 33, 9, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666074930, 'comment_body': 'Would it be worth transmitting the new syntax information to the client here already instead of waiting for semantic highlighting? Otherwise, we wonâ€™t have any SourceKit-LSP-provided highlighting in case `sourcekitd` crashes (which pauses semantic requests for 10-20 seconds but still provides syntactic functionality) or if the semantic requests take too long for some other reason.', 'comment_created': datetime.datetime(2021, 7, 8, 10, 35, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666078522, 'comment_body': 'Itâ€™s better to use `self.expectation` to construct expectations and `self.wait` to wait for them. That way `XCTestCase` verifies that you didnâ€™t set up any expectations but forgot to wait for them. `self.wait` will also fail the test case if the expectation wasnâ€™t fulfilled in the timeout.', 'comment_created': datetime.datetime(2021, 7, 8, 10, 41, 27, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666080210, 'comment_body': 'Would it be worth to have variables/numbers of different lengths? At the moment, the test case would also succeed if we returned results for lines 0 and 1 instead of 1 and 2.', 'comment_created': datetime.datetime(2021, 7, 8, 10, 43, 59, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666080838, 'comment_body': 'Worth moving this case up to the test case as itâ€™s slightly lower level then the rest, which are operating on source files?', 'comment_created': datetime.datetime(2021, 7, 8, 10, 44, 52, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666081942, 'comment_body': 'As commented above, I think a test case with a multi-line comment would be good.\r\n\r\n---\r\n\r\nAlso a test case with doc comments (both `///` and `/**`) would be good.', 'comment_created': datetime.datetime(2021, 7, 8, 10, 46, 46, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666084440, 'comment_body': 'Do you think it would be useful to have some kind of debugging option with which we can turn lexical/syntactic/semantic tokens on or off as a source for the semantic tokens request? That way, we could add tests that selectively only enable one of them and verify that they are actually providing information which is incorporated in the response.\r\n\r\nOr do you think that would be too difficult to wire up?', 'comment_created': datetime.datetime(2021, 7, 8, 10, 50, 48, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666275815, 'comment_body': ""Is there a way to log these uids with their string representation?\r\n\r\n`syntaxtype_identifier` is one I deliberately ignored for now since it's kind of ambiguous (is it a variable? a function? a method? a parameter?) and makes the syntax highlighting actually less specific than VSCode's default highlighter."", 'comment_created': datetime.datetime(2021, 7, 8, 15, 0, 6, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 666276467, 'comment_body': 'Yes, that is correct, as far as I understood it.', 'comment_created': datetime.datetime(2021, 7, 8, 15, 0, 45, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 666279442, 'comment_body': ""I thought about this one too. LSP calls all tokens 'semantic tokens' and to me `SemanticToken` feels like a structure that directly reflects the LSP representation. But I can see your point, perhaps it would be better to rename it, since we internally have different 'kinds' of tokens."", 'comment_created': datetime.datetime(2021, 7, 8, 15, 3, 59, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 666281610, 'comment_body': ""E.g. changing `let` to `alet` should remove the token, `[space]let` should not.\r\n\r\nI agree, the logic here is a bit ad-hoc, I'm not sure what the optimal solution is though. Ideally, sourcekitd could tell us which tokens get removed from the syntaxmap after an edit, that way we wouldn't have to deal with edge cases like multi-line comments, where tokens outside the edit range have to be removed automatically."", 'comment_created': datetime.datetime(2021, 7, 8, 15, 6, 35, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 666286157, 'comment_body': 'Good question, perhaps @DavidGoldman, who implemented the clangd forwarding IIUC, has some ideas on this?', 'comment_created': datetime.datetime(2021, 7, 8, 15, 12, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 666295940, 'comment_body': 'You should be able to use `uid_get_string_ptr` like here:\r\nhttps://github.com/apple/sourcekit-lsp/blob/13d3d93d8b706ff93bd88644aa1a4b6a2c054a81/Sources/SourceKitLSP/Swift/SemanticRefactorCommand.swift#L75', 'comment_created': datetime.datetime(2021, 7, 8, 15, 23, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666297942, 'comment_body': 'I would argue that if the type was defined in the `LanguageServerProtocol` module, we should stick to the LSP terminology. But this is more of an internal data structure IMO and we only â€œupgradeâ€ lexical and syntactic tokens to semantic tokens on the LSP boundary. Thatâ€™s my opinion anyway. I can see your point as well.', 'comment_created': datetime.datetime(2021, 7, 8, 15, 25, 48, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666321620, 'comment_body': 'I just looked up how the syntax map is used and AFAICT there shouldnâ€™t be any special handling regarding whitespaces necessary. All tokens whose start position is `>=` end position of the edit should be kept.\r\n\r\nI didnâ€™t have time to look at it in too much detail, but `key.offset` and `key.length` from the SourceKit response to the edit might be exactly the range for which a new syntax map is being provided. Like [here](https://github.com/apple/swift/blob/ad6a6e46561427992bc88317816ad2ea5bd14990/test/SourceKit/SyntaxMapData/syntaxmap-edit-block-comment.swift#L46-L47) where we get a `key.length > 1` for an edit of length 1.', 'comment_created': datetime.datetime(2021, 7, 8, 15, 54, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 666333450, 'comment_body': ""Yes, but that wouldn't solve the example I gave, if I understand you correctly. `let` is a token whose start position is == the end of the edit range (thus also >=) that wouldn't be removed if the user changes it into e.g. `alet`.\r\n\r\nAlso, what happens e.g. if the user types\r\n```\r\n[1. edit: /*]\r\nlet x = 4\r\n[2. edit: */]\r\n```\r\n\r\nSince the `let` token overlaps with neither edit, how would sourcekit-lsp know that `let` should be removed?"", 'comment_created': datetime.datetime(2021, 7, 8, 16, 9, 42, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 666758795, 'comment_body': 'The `offset` and `length` returned by `sourcekitd` should include the `let` token. And I think the same goes for comments. So, you would need to do all the checks not based on the length and offset you pass in the request, but based on the ones you get back in the response, if that makes sense.\r\n\r\nFor example, when I change `let x = 1` to `alet = 1` I get the following response with offset 0 and length 4:\r\n```bash\r\n$ cat ~/Desktop/test.swift\r\nlet x = 1\r\n$ ./sourcekitd-test -req=open /Users/alex/Desktop/test.swift -- /Users/alex/Desktop/test.swift == -req=edit -offset=0 -length=0 -replace=""a"" /Users/alex/Desktop/test.swift -print-raw-response -- /Users/alex/Desktop/test.swift\r\n```\r\n<details>\r\n<summary>Response</summary>\r\n\r\n```\r\n{\r\n  key.request: source.request.editor.open,\r\n  key.name: ""/Users/alex/Desktop/test.swift"",\r\n  key.compilerargs: [\r\n    ""/Users/alex/Desktop/test.swift""\r\n  ],\r\n  key.sourcefile: ""/Users/alex/Desktop/test.swift""\r\n}\r\n{\r\n  key.request: source.request.editor.replacetext,\r\n  key.name: ""/Users/alex/Desktop/test.swift"",\r\n  key.compilerargs: [\r\n    ""/Users/alex/Desktop/test.swift""\r\n  ],\r\n  key.offset: 0,\r\n  key.length: 0,\r\n  key.sourcefile: ""/Users/alex/Desktop/test.swift"",\r\n  key.sourcetext: ""a""\r\n}\r\n{\r\n  key.offset: 0, // <---- These are the important information SourceKit is passing back to us\r\n  key.length: 4, // <---- These are the important information SourceKit is passing back to us\r\n  key.diagnostic_stage: source.diagnostic.stage.swift.parse,\r\n  key.syntaxmap: [\r\n    {\r\n      key.kind: source.lang.swift.syntaxtype.identifier,\r\n      key.offset: 0,\r\n      key.length: 4\r\n    }\r\n  ],\r\n  key.substructure: [\r\n  ],\r\n  key.diagnostics: [\r\n    {\r\n      key.line: 1,\r\n      key.column: 5,\r\n      key.filepath: ""/Users/alex/Desktop/test.swift"",\r\n      key.severity: source.diagnostic.severity.error,\r\n      key.id: ""statement_same_line_without_semi"",\r\n      key.description: ""consecutive statements on a line must be separated by \';\'"",\r\n      key.diagnostic_stage: source.diagnostic.stage.swift.parse,\r\n      key.fixits: [\r\n        {\r\n          key.offset: 4,\r\n          key.length: 0,\r\n          key.sourcetext: "";""\r\n        }\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\n</details>', 'comment_created': datetime.datetime(2021, 7, 9, 8, 9, 38, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 667349510, 'comment_body': '`.Type` IIRC is already reserved by Swift. The term `Kind` is taken from SourceKit and if we consider this an internal structure, I think deviating from the LSP convention here is fine (similar to the renaming to `SyntaxHighlightingToken`).', 'comment_created': datetime.datetime(2021, 7, 10, 14, 59, 2, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667352926, 'comment_body': ""Combinations of modifiers would have multiple names, since this is an `OptionSet`, therefore `lspName` should be an optional IMO.\r\n\r\nThe assertion is a good idea, I don't think we can do so directly by checking whether `allCases.contains(self)`, since `Modifier` is an `OptionSet`, where the `rawValue` potentially is a bitwise-ORed combination of multiple modifiers listed in `allCases`.\r\n\r\nI could however imagine that we could zero out all known bits from `allCases` in `rawValue` and check whether the result is zero."", 'comment_created': datetime.datetime(2021, 7, 10, 15, 32, 27, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667354727, 'comment_body': 'Also we have to be careful not to have cyclic definitions here (i.e. `allCases` references the cases which references `init(rawValue:)` which references `allCases`).\r\n\r\nI would argue that the current solution would avoid introducing a lot of complexity for an assertion that we are unlikely to accidentally run into anyway (since these modifiers are rarely constructed from raw values outside of the static constants).', 'comment_created': datetime.datetime(2021, 7, 10, 15, 50, 23, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667357962, 'comment_body': ""Yes, that would however complicate testing a fair bit AFAICT. Right now, every refresh request indicates that the server knows all tokens, both semantic and syntactic. Since the refresh request doesn't state which kind of tokens the server has computed, we would have to make fragile assumptions, e.g. that the server sends exactly 2 refresh requests (syntactic + semantic) until we get the right tokens. But since syntactic tokens are updated in several places, it would be easy to introduce more refresh requests that accidentally break these tests."", 'comment_created': datetime.datetime(2021, 7, 10, 16, 22, 24, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667358104, 'comment_body': 'Also note that clients like VSCode request tokens whenever they want to, e.g. after opening or editing a document, not first after the refresh request, so the highlighting should be responsive in any case.', 'comment_created': datetime.datetime(2021, 7, 10, 16, 23, 41, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667359254, 'comment_body': ""I've added a doc comment to clarify this."", 'comment_created': datetime.datetime(2021, 7, 10, 16, 35, 42, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667359382, 'comment_body': 'I took this list from the previous PR, but I can see how this would be confusing, therefore I updated the list to match the LSP spec.', 'comment_created': datetime.datetime(2021, 7, 10, 16, 37, 4, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667359453, 'comment_body': ""I've added them as extensions to `Array<SemanticToken>`."", 'comment_created': datetime.datetime(2021, 7, 10, 16, 37, 58, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667359633, 'comment_body': 'Yes, `keys.offset`/`keys.length` refers to e.g. the entire function declaration rather than just its name span, in the AST structures sourcekitd provides.', 'comment_created': datetime.datetime(2021, 7, 10, 16, 40, 15, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667359693, 'comment_body': 'I went with the first option, passing the snapshot directly to the parse methods.', 'comment_created': datetime.datetime(2021, 7, 10, 16, 40, 39, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667360036, 'comment_body': ""I've moved the refresh logic into a separate method. Clients (notably VSCode) however don't _need_ these refresh requests, they automatically request tokens after every edit, so we get responsive highlighting one way or the other. See also the discussion below regarding testability.\r\n\r\nSince semantic tokens are updated asynchronously, I think it makes sense for them to cause a refresh request, this doesn't apply to the syntactic/lexical tokens however."", 'comment_created': datetime.datetime(2021, 7, 10, 16, 44, 44, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667375920, 'comment_body': ""I think that would definitely be nice to have, ideally we could even expose that as an LSP config option so clients could selectively enable/disable different 'kinds' of tokens (lexical/syntactic/semantic). Perhaps it would be a good candidate for a future PR, since this one has already gotten pretty large?"", 'comment_created': datetime.datetime(2021, 7, 10, 19, 22, 12, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667376548, 'comment_body': ""Yes, overlapping ranges would definitely be preferable, however also less efficient to compute since we can't just use a set there. I think there are specialized data structures like interval trees that let us implement that in linear time, but I'm not sure if it's worth the complexity there.\r\n\r\nTo me it feels cleaner to keep this method separate from its use in `DocumentTokens`, since it is not really specific to use in a document, even though that is currently the only place where it's used."", 'comment_created': datetime.datetime(2021, 7, 10, 19, 29, 6, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 667948072, 'comment_body': 'I see, the performance consideration makes sense. Iâ€™m fine with keeping it as-is then.\r\n\r\n---\r\n\r\nFair enough. What do you think about making it a (static) member of `SemanticToken`? I donâ€™t like global functions too much because they are less discoverable IMO.', 'comment_created': datetime.datetime(2021, 7, 12, 13, 50, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 667951172, 'comment_body': 'Good point. `Kind` is fine with me then. Especially as itâ€™s not in the `LanguageServerProtocol` module, as you noted.', 'comment_created': datetime.datetime(2021, 7, 12, 13, 53, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 667954902, 'comment_body': 'Good point. I didnâ€™t consider that it was an option set. Leaving it as-is sounds good to me.', 'comment_created': datetime.datetime(2021, 7, 12, 13, 57, 57, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 667956147, 'comment_body': 'I think it would be good to add this description in a doc comment.', 'comment_created': datetime.datetime(2021, 7, 12, 13, 59, 26, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 667959164, 'comment_body': 'Sounds good to me as that change probably wonâ€™t be too small either ðŸ‘', 'comment_created': datetime.datetime(2021, 7, 12, 14, 2, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 667994008, 'comment_body': 'I donâ€™t think itâ€™s an issue right now because `SwiftLanguageServer` serializes all requests on its queue, but Iâ€™m a little worried that if we should drop that guarantee, weâ€™ll end up in a race condition where we process the semantics tokens request before getting the response from the edit.\r\n\r\nAlso, after looking at the documentation of `WorkspaceSemanticTokensRefreshRequest` some more, sending it every time we re-computed semantic tokens seems a bit of an over-kill to me, as it causes a *workspace-wide* refresh of all semantic tokens. IIUC the LSP idea for this request would be that we donâ€™t send the response until we actually have the *semantic* tokens for that file. I am really not sure how to approach this best and would like to hear your opinion. As far as I see it, we have the following options:\r\n\r\n* Leave the implementation as-is, providing syntactic highlighting as LSPâ€™s semantic highlight directly and sending a `WorkspaceSemanticTokensRefreshRequest` once semantic tokens are available\r\n  * Advantages:\r\n    * We directly provide syntactic highlighting information to the editor\r\n    * Changes in one file reflect as semantic highlighting changes in the other files. E.g. if file A declares `struct Foo { static func bar() } }` and file B calls `Foo.bar()`, we rename `bar -> baz` in file A, then file B will stop coloring `bar` as a member. We donâ€™t seem to have this support in Xcode at the moment either, so I would say that itâ€™s not a super important feature to have\r\n  * Disadvantages:\r\n    *  Potentially impacts performance because we request a *project-wide* refresh of semantic tokens, which stops the editor from doing more local, scoped requests (which starts to become relevant as soon as we implement ranged semantic highlighting)\r\n* Only reply to the semantic tokens request once we actually have semantic tokens\r\n  * Advantages:\r\n    * I think this is closer to how LSP envisions semantic tokens support\r\n    * Less of a performance-impact\r\n  * Disadvantages:\r\n    * No way to provide our syntactic highlighting information until we have semantic tokens\r\n    * We would need to have at least some limited concurrent request support in SourceKit-LSP, Iâ€™m not sure how hard that would be to implement.\r\n  * Questions:\r\n    * Would we still want to merge the information with our syntactic highlighting information or leave the syntactic highlighting to the editor?', 'comment_created': datetime.datetime(2021, 7, 12, 14, 42, 50, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 668782356, 'comment_body': ""It's currently a member of `Array<SemanticToken>` as per your second suggestion, not sure, should it be a static member in `SemanticToken` instead?"", 'comment_created': datetime.datetime(2021, 7, 13, 13, 49, 39, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 668834577, 'comment_body': ""This should hopefully be fixed with 0505ece for now, i.e. the language whose service first registers the capability gets semantic tokens and the others don't. More advanced handling would be a candidate for a future PR."", 'comment_created': datetime.datetime(2021, 7, 13, 14, 44, 28, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 668836235, 'comment_body': ""We'll keep it like this (using refresh requests) for now, since it seems to work correctly and leave callback-based handling up for future consideration, as discussed."", 'comment_created': datetime.datetime(2021, 7, 13, 14, 46, 5, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 668836823, 'comment_body': ""We'll leave it like this for now, see the discussion above."", 'comment_created': datetime.datetime(2021, 7, 13, 14, 46, 48, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 668842032, 'comment_body': 'Oh, I missed that you moved it. Ignore my second comment.', 'comment_created': datetime.datetime(2021, 7, 13, 14, 52, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 670791240, 'comment_body': ""Should we modify `current.line` and `current.utf16Index` before this potential `continue` so that the position is updated even if we don't recognize the kind?"", 'comment_created': datetime.datetime(2021, 7, 15, 20, 41, 46, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 671346417, 'comment_body': 'You also need to add `Array+SyntaxHighlightingToken.swift` to `CMakeLists.txt`. Could you also check if you added other files that need to be included here?', 'comment_created': datetime.datetime(2021, 7, 16, 15, 32, 48, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671348547, 'comment_body': 'Do we even need this variable? Might be worth making it private or removing it altogether so that you donâ€™t accidentally use `merged` where you wanted `mergedAndSorted`.', 'comment_created': datetime.datetime(2021, 7, 16, 15, 35, 57, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671364023, 'comment_body': 'Do we need this still? I would really prefer not to have special handling logic unless itâ€™s either solving a pressing problem or itâ€™s guaranteed to be correct.\r\n\r\nIf the results are still looking good, Iâ€™d propose that we remove all the `isTokenBounding` logic, only remove the tokens that overlap with the edited range and let the lexical SourceKit update remove all tokens that changed semantics because of the edit.', 'comment_created': datetime.datetime(2021, 7, 16, 15, 59, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671365624, 'comment_body': 'Nitpick but wouldnâ€™t this read better as a trailing closure to `document.latestTokens.withMutableTokensOfEachKind`? That way youâ€™d directly know what `update` is being used for (and that itâ€™s only used in one place)', 'comment_created': datetime.datetime(2021, 7, 16, 16, 1, 24, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671370158, 'comment_body': 'Nitpick: `tokens -> newTokens`', 'comment_created': datetime.datetime(2021, 7, 16, 16, 8, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671370781, 'comment_body': 'Why do we need to check for `newTokens.isEmpty` here? Shouldnâ€™t `newTokens == []` mean that we want to remove all lexical tokens in that range?', 'comment_created': datetime.datetime(2021, 7, 16, 16, 9, 46, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671373143, 'comment_body': 'I donâ€™t think weâ€™ve got a notion about â€œboundingâ€ here anymore. Would probably be fine to just say ``Remove all tokens in `range` ``', 'comment_created': datetime.datetime(2021, 7, 16, 16, 13, 25, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671376779, 'comment_body': 'Looking at the implementation of `registration(for:in:)`, this checks if we have a registration for either of the languages in `languages`. I think this might become confusing if the set of languages in `languages` doesnâ€™t align with the languages provided by the LSP providers (e.g. if `languages == [.swift, .cpp]`). Since we only ever pass in one language, Iâ€™d suggest we make this method only take a single language as well.', 'comment_created': datetime.datetime(2021, 7, 16, 16, 19, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671378835, 'comment_body': 'Superfluous newline?', 'comment_created': datetime.datetime(2021, 7, 16, 16, 22, 13, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671388651, 'comment_body': 'This seems really unfortunate because previously all edits were guaranteed to be applied together because the loop `for edit in edits` was geared by the `DocumentManager`â€™s `queue`. Now there could be other edits coming in from different threads that interleave with this change notification.\r\n\r\nWouldnâ€™t it be possible to make the `editCallback` return the `DocumentSnapshot` with syntax highlighting tokens applied?', 'comment_created': datetime.datetime(2021, 7, 16, 16, 38, 18, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671393006, 'comment_body': 'What do you think about, instead of putting the responsibility to worry about `SyntaxHighlightingToken`s being on one line only to the user of `SyntaxHighlightingToken`, make `SyntaxHighlightingToken` have an `end: Position`, constructing that end position like here in `SyntaxHighlightingTokenParser` and adding a comment about the same-line assumption there? That way the assumption is closer to the location that is actually providing the guarantee that itâ€™s fulfilled and you donâ€™t have to worry about the more verbose `sameLineEnd` everywhere else.\r\n\r\nActually, looking at the implementation of `SyntaxHighlightingTokenParser` we might be able to remove `splitToSingleLineTokens` altogether and just have multi-line tokens here, not sure how VSCode handles them.', 'comment_created': datetime.datetime(2021, 7, 16, 16, 45, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671393473, 'comment_body': 'I think you can drop the `name`. Itâ€™s never used.', 'comment_created': datetime.datetime(2021, 7, 16, 16, 46, 38, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671396331, 'comment_body': 'Would you mind making this internal and adding a \r\n\r\n```swift\r\n/// **Public for testing.**\r\npublic var _lspName: String {\r\n  return lspName\r\n}\r\n```\r\nwrapper for testing?\r\n\r\nThat way you donâ€™t accidentally use it from a different module just because you didnâ€™t read the doc comment.', 'comment_created': datetime.datetime(2021, 7, 16, 16, 51, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671396829, 'comment_body': 'Same. Can you add an underscored wrapper for the public testing variant?', 'comment_created': datetime.datetime(2021, 7, 16, 16, 52, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671397936, 'comment_body': 'Do you think an\r\n```swift\r\nassert(lineDelta >= 0)\r\nassert(charDelta >= 0)\r\n```\r\nwould be useful to assert that the tokens are indeed sorted?', 'comment_created': datetime.datetime(2021, 7, 16, 16, 54, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671405864, 'comment_body': 'I think this needs to be `name.split(separator: ""("").first?.utf8.count`. `count` returns the number of grapheme clusters in the string, but we are counting the length as number of UTF-8 code points.\r\n\r\nIt would probably be worth adding a test case that has an emoji or something like that as a function name.', 'comment_created': datetime.datetime(2021, 7, 16, 17, 8, 55, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671409103, 'comment_body': 'I think it would be better to crash here instead of silently dropping the token. If the token is not in the snapshot, thatâ€™s a serious violation of our assumptions and Iâ€™d rather get crash reports about it than vague bug reports saying that tokens are not being highlighted.', 'comment_created': datetime.datetime(2021, 7, 16, 17, 14, 39, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671413619, 'comment_body': 'Could you also add a test cases for an edits? I think it would be good to at least have test cases for\r\n- Empty edit (replace zero-length by empty string)\r\n- Replace until the middle of a token\r\n- Replace until the end of a token\r\n- Perform an edit that adds/removes a newline\r\n- Perform an edit thatâ€™s similar to multi-cursor support, e.g. rename all occurrences of a variable', 'comment_created': datetime.datetime(2021, 7, 16, 17, 22, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 671698529, 'comment_body': ""I haven't found a `CMakeLists.txt` for `SKTestSupport`. Do we support testing with CMake?"", 'comment_created': datetime.datetime(2021, 7, 17, 13, 35, 59, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 671700772, 'comment_body': ""VSCode currently doesn't support multi-line tokens (though other LSP clients may, there is a client capability for that).\r\n\r\nRemoving the single-line assumption sounds good though, perhaps we could just equip `SyntaxHighlightingToken` with a `Range<Position>` field, assuming it might be multi-line by default, and split them into single-line tokens in `SwiftLanguageServer`, before sending them to the client? (I would vote to keep the `splitToSingleLineTokens` method in `SyntaxHighlightingToken` though)\r\n\r\nThat might actually make it easier to provide multi-line tokens for clients that support them, since we could just query the `clientCapabilities` there."", 'comment_created': datetime.datetime(2021, 7, 17, 13, 57, 44, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 671700873, 'comment_body': ""We don't, good catch."", 'comment_created': datetime.datetime(2021, 7, 17, 13, 58, 43, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 671703269, 'comment_body': 'Since LSP generally deals with positions in terms of UTF-16 code units (not code points, IIUC), I think it has to be\r\n\r\n```swift\r\nname.split(separator: ""("").first?.utf16.count\r\n```\r\n\r\nBut good catch, thanks!', 'comment_created': datetime.datetime(2021, 7, 17, 14, 22, 20, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 671704692, 'comment_body': ""Hm, defining tokens only in terms of `start` and `end: Position` (or a `Range<Position>`), without being able to assume that the tokens are on a single line, requires document snapshots in quite a few more places, in particular during encoding and decoding, since both SourceKit and LSP talk about lengths. This also significantly complicates testing, e.g. the token coding can no longer be tested in isolation from the text it operates on.\r\n\r\nNot actually sure what the cleanest solution here would be. Assuming tokens to be on a single line makes it a lot easier to reason about them and doesn't require snapshots."", 'comment_created': datetime.datetime(2021, 7, 17, 14, 36, 4, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 671705901, 'comment_body': 'Actually, I think the way we are handling the lengths currently is slightly inconsistent:\r\n\r\n- SourceKit gives us the length in UTF-8 code units (I think)\r\n- `splitToSingleLineTokens` computes the length in terms of grapheme cluster count\r\n- LSP expects the length in UTF-16 code units\r\n\r\nNot sure what the ideal internal representation of `SyntaxHighlightingToken` would be (lengths in UTF-8 or UTF-16 code units). Or perhaps just using an `end: Position`, possibly requiring access to snapshots during en-/decoding as discussed [here](https://github.com/apple/sourcekit-lsp/pull/414#discussion_r671700772)?', 'comment_created': datetime.datetime(2021, 7, 17, 14, 47, 36, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 671830881, 'comment_body': ""Currently we expect all changes to lexical and syntactic tokens to go through `updateLexicalAndSyntacticTokens` on `SwiftLanguageServer`'s queue, which synchronously funnels them through `DocumentManager`'s `replaceLexical/SyntacticTokens` on its own queue.\r\n\r\nIf we were to update the tokens through modified snapshots, I am worried that we may end up duplicating a lot of logic that previously was cleanly categorized into the `replaceXTokens` functions in `DocumentManager`.\r\n\r\nIf we were to stay on `DocumentManager`'s queue by calling `updateLexicalAndSyntacticTokens` from the edit callback, we would have to weaken the restriction that `updateLexicalAndSyntacticTokens` runs on `SwiftLanguageServer`'s queue and be careful not to run into deadlocks with `DocumentManager`'s queue when calling `replaceLexical/SyntacticTokens`. Note that `openDocument` would still call `updateLexicalAndSyntacticTokens` in that case.\r\n\r\nNot sure what a good solution would be here, either one feels a bit unsatisfying."", 'comment_created': datetime.datetime(2021, 7, 18, 11, 54, 5, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 672966258, 'comment_body': 'Probably not. I didnâ€™t realize it `Array+SyntaxHighlightingToken.swift` was in a test target. Sorry.', 'comment_created': datetime.datetime(2021, 7, 20, 9, 36, 8, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 672967705, 'comment_body': 'We donâ€™t check for bounding tokens anymore, could you also remove it from the comment?', 'comment_created': datetime.datetime(2021, 7, 20, 9, 38, 13, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 672971415, 'comment_body': 'I know, Iâ€™m a little obsessed about comments, but I think the check would be better described as \r\n```swift\r\n// Remove all tokens overlapping `range` ...\r\n```', 'comment_created': datetime.datetime(2021, 7, 20, 9, 43, 27, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 672971739, 'comment_body': 'Why do we need the check for `$0.isEmpty`?', 'comment_created': datetime.datetime(2021, 7, 20, 9, 43, 52, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 672972404, 'comment_body': 'Nitpick: `languages` should be singular now.', 'comment_created': datetime.datetime(2021, 7, 20, 9, 44, 48, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 672989221, 'comment_body': 'What do you think about the following: \r\n\r\nThe only instance member that `updateLexicalAndSyntacticTokens` accesses is `documentManager`, so itâ€™s not really accessing any state private to `SwiftLanguageServer` and doesnâ€™t really need to run on the serverâ€™s queue.\r\nIf we now change `updateLexicalAndSyntacticTokens` to return `DocumentTokens` instead of updating the `documentManager`, we can make `updateLexicalAndSyntacticTokens` static and definitely remove the requirement to run on `SwiftLanguageServer`â€™s queue.\r\n\r\nNow, the `editCallback` could return `DocumentTokens` to the document manager, which could incorporate them into the current document.\r\n\r\nSo, weâ€™d have method signatures like:\r\n```swift\r\n// SwiftLanguageServer\r\nprivate static func updateLexicalAndSyntacticTokens(response: SKDResponseDictionary, for snapshot: DocumentSnapshot) -> DocumentTokens\r\n\r\n// DocumentManager\r\npublic func edit(_ uri: DocumentURI, newVersion: Int, edits: [TextDocumentContentChangeEvent], editCallback: ((_ before: DocumentSnapshot, TextDocumentContentChangeEvent) -> DocumentTokens?)? = nil) throws -> DocumentSnapshot\r\n```', 'comment_created': datetime.datetime(2021, 7, 20, 10, 9, 8, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673000670, 'comment_body': 'I think the cleanest solution would probably be to have `SyntaxHighlightingToken` have a `start` and `end` position. Together with a document snapshot, we can compute the length in any encoding we want. That gives us most flexibility and I think it the best abstraction. Good catch finding this!', 'comment_created': datetime.datetime(2021, 7, 20, 10, 27, 8, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673005662, 'comment_body': ""I have tried implementing this and am concerned that it complicates especially testing a fair bit (see [here](https://github.com/apple/sourcekit-lsp/pull/414#discussion_r671704692)), since we would move away from LSP's representation of tokens. E.g. we now have to worry about accessing snapshots from within tests, cannot test the coding without a snapshot, ...\r\n\r\nI think using UTF-16 lengths like LSP in `SyntaxHighlightingToken` would be worth giving a try."", 'comment_created': datetime.datetime(2021, 7, 20, 10, 35, 22, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 673014333, 'comment_body': 'Should we do this for the other update methods too, to be consistent?', 'comment_created': datetime.datetime(2021, 7, 20, 10, 50, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 673108438, 'comment_body': 'Updated as per our discussion by using `Range<Position>` internally and asserting that tokens are on a single line.', 'comment_created': datetime.datetime(2021, 7, 20, 13, 11, 37, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 673114054, 'comment_body': 'I think it has to be an instance method, since we need `sourcekitd.keys`.', 'comment_created': datetime.datetime(2021, 7, 20, 13, 18, 42, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 673167976, 'comment_body': 'Nitpick: The other function now also has an `afterCallback:` so this should be \r\n`edit(_:newVersion:edits:beforeCallback:afterCallback:)`', 'comment_created': datetime.datetime(2021, 7, 20, 14, 19, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673176193, 'comment_body': 'Do you have a test case that requires this behavior? If yes, I would be interested what it is, if not, I think it would be good to add one. ðŸ˜‰ ', 'comment_created': datetime.datetime(2021, 7, 20, 14, 28, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673181464, 'comment_body': 'Whatâ€™s the reason for not using the `snapshot` variable returned by `self.documentManager.edit` anymore? That one provided the guarantee that we are using the snapshot that resulted from the edit whereas a new snapshot might exist by the time that `latestSnapshot(uri)` is called.', 'comment_created': datetime.datetime(2021, 7, 20, 14, 34, 21, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673186298, 'comment_body': 'Do you think it would be worth adding a special fast case if the range is already on the same line. E.g.\r\n```swift\r\nif lowerBound.line == upperBound.line {\r\n  return [self]\r\n}\r\n```\r\n\r\nThat would save us the performance overhead of all the string manipulation for the common case.', 'comment_created': datetime.datetime(2021, 7, 20, 14, 39, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673191485, 'comment_body': 'I think these setters on `start`, `end` and `utf16length` are super neat but do we use them anywhere? I couldnâ€™t find any uses on first glance, but I might be missing something.', 'comment_created': datetime.datetime(2021, 7, 20, 14, 45, 34, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673221332, 'comment_body': 'Yes, in `DocumentManager.edit`: https://github.com/apple/sourcekit-lsp/pull/414/files#diff-26f557ea9c60d8fce5d02dca22daaa0e00acca75f46bd1bedc1bb1d359d73d3cR200-R206', 'comment_created': datetime.datetime(2021, 7, 20, 15, 18, 29, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 673222675, 'comment_body': 'Yes, `testEmptyEdit` requires this, there we have an empty range that returns an empty substructure too (apparently).', 'comment_created': datetime.datetime(2021, 7, 20, 15, 20, 7, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 673233219, 'comment_body': 'Ah thanks, I forgot to change this one back.', 'comment_created': datetime.datetime(2021, 7, 20, 15, 31, 56, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 673688317, 'comment_body': 'Ah, thanks. I missed that ðŸ‘ ', 'comment_created': datetime.datetime(2021, 7, 21, 6, 14, 31, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673696033, 'comment_body': 'Looking at it locally, an empty edit doesnâ€™t have an `offset` and `length` in the response, so this should be handled by the `guard` above (which, in that case, shouldnâ€™t log an error, I think ðŸ˜‰).\r\n\r\n<details>\r\n<summary>Empty edit through sourcekitd-test</summary>\r\n\r\n```\r\n./sourcekitd-test -req=open /Users/alex/Desktop/test.swift -- /Users/alex/Desktop/test.swift == -req=edit -offset=0 -length=0 -replace="""" /Users/alex/Desktop/test.swift -print-raw-response -- /Users/alex/Desktop/test.swift\r\n{\r\n  key.request: source.request.editor.open,\r\n  key.name: ""/Users/alex/Desktop/test.swift"",\r\n  key.compilerargs: [\r\n    ""/Users/alex/Desktop/test.swift""\r\n  ],\r\n  key.sourcefile: ""/Users/alex/Desktop/test.swift""\r\n}\r\n{\r\n  key.request: source.request.editor.replacetext,\r\n  key.name: ""/Users/alex/Desktop/test.swift"",\r\n  key.compilerargs: [\r\n    ""/Users/alex/Desktop/test.swift""\r\n  ],\r\n  key.offset: 0,\r\n  key.length: 0,\r\n  key.sourcefile: ""/Users/alex/Desktop/test.swift"",\r\n  key.sourcetext: """"\r\n}\r\n{\r\n  key.diagnostic_stage: source.diagnostic.stage.swift.sema,\r\n  key.syntaxmap: [\r\n  ],\r\n  key.substructure: [\r\n  ],\r\n  key.diagnostics: [\r\n    {\r\n      key.line: 2,\r\n      key.column: 7,\r\n      key.filepath: ""/Users/alex/Desktop/test.swift"",\r\n      key.severity: source.diagnostic.severity.warning,\r\n      key.id: ""pbd_never_used"",\r\n      key.description: ""initialization of immutable value \'x\' was never used; consider replacing with assignment to \'_\' or removing it"",\r\n      key.diagnostic_stage: source.diagnostic.stage.swift.sema,\r\n      key.fixits: [\r\n        {\r\n          key.offset: 15,\r\n          key.length: 5,\r\n          key.sourcetext: ""_""\r\n        }\r\n      ],\r\n      key.categories: [\r\n        source.diagnostic.category.no_usage\r\n      ]\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n</details>', 'comment_created': datetime.datetime(2021, 7, 21, 6, 31, 25, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 673899269, 'comment_body': ""The issue might be that `SKDResponseDictionary`'s subscript implementation\r\n\r\n```swift\r\npublic subscript(key: sourcekitd_uid_t?) -> Int? {\r\n  return Int(sourcekitd.api.variant_dictionary_get_int64(dict, key))\r\n}\r\n```\r\n\r\nnever actually returns `nil`, not even if the value isn't present."", 'comment_created': datetime.datetime(2021, 7, 21, 11, 44, 19, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 674134320, 'comment_body': 'You can fix these to actually return an optional like this:\r\n```swift\r\n    let value = sourcekitd.api.variant_dictionary_get_value(dict, key)\r\n    if sourcekitd.api.variant_get_type(value) == SOURCEKITD_VARIANT_TYPE_INT64 {\r\n      return Int(sourcekitd.api.variant_int64_get_value(value))\r\n    } else {\r\n      return nil\r\n    }\r\n```', 'comment_created': datetime.datetime(2021, 7, 21, 16, 13, 24, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674149057, 'comment_body': 'Nitpick: this deserves its own file, and could use a brief doc comment such as ""Syntax highlighting tokens for a particular document""', 'comment_created': datetime.datetime(2021, 7, 21, 16, 30, 30, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674154037, 'comment_body': 'This handles identical ranges, but does not consider overlapping ranges.  Is that possibility handled somewhere else?', 'comment_created': datetime.datetime(2021, 7, 21, 16, 37, 5, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674161846, 'comment_body': 'Since we\'re actually returning values here, I think we could use a more specific name than ""callback"" and we might as well improve the ""before"" one as well.  I suggest something like:\r\nbeforeCallback -> willEditDocument\r\nafterCallback -> updateDocumentTokens', 'comment_created': datetime.datetime(2021, 7, 21, 16, 47, 50, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674170894, 'comment_body': 'Apologies if you\'ve answered this already, I haven\'t read all the earlier comments on this PR, but have you explored the performance of this yet in a large file? It would be good to understand the impact on\r\n\r\n* Performance of opening a large file - ideally > 5000 lines.\r\n* Performance of making an edit in a large file (presumably fast with deltas)\r\n* Performance of making an edit in a large file when using ""full document"" edits. Some editors may not have incremental edit support.\r\n* Performance of updating the semantic tokens in a large file.', 'comment_created': datetime.datetime(2021, 7, 21, 17, 0, 7, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674243591, 'comment_body': '@benlangmuir Should we add this check to the other subscripts too?', 'comment_created': datetime.datetime(2021, 7, 21, 18, 50, 16, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 674245166, 'comment_body': ""I think we've discussed this briefly here: https://github.com/apple/sourcekit-lsp/pull/414#discussion_r665970487"", 'comment_created': datetime.datetime(2021, 7, 21, 18, 52, 50, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 674246569, 'comment_body': 'Bool, Int and SKDResponseArray should be updated to use that approach, yes.  String and UID subscripts should already correct, because they already return NULL directly from the sourcekitd API.', 'comment_created': datetime.datetime(2021, 7, 21, 18, 55, 2, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674336689, 'comment_body': ""I find this behaviour it fairly subtle.  I would not expect that modifying `start` would affect `end` for a position range. And if I did, I would find it weird that modifying start affects end, but modifying end does not affect start.  I suggest either keeping start independent of end or making a method for the specific kind of modification you want to make so that it's clear what is going on.  E.g. `mutating func move(to start: Position)`."", 'comment_created': datetime.datetime(2021, 7, 21, 20, 51, 18, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674338104, 'comment_body': 'Nitpick: The second sentence should be a new paragraph so that the ""brief"" documentation text will be ""The token type"".', 'comment_created': datetime.datetime(2021, 7, 21, 20, 53, 36, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674341683, 'comment_body': 'This should not be `CaseIterable` since `allCases` would really mean all combinations of the options -- i.e. every value 0 to 512.  I would suggest removing the conformance and naming the static property `allModifiers` or something similar.\r\n\r\nAlso same nitpick about adding a second paragraph to doc comment.', 'comment_created': datetime.datetime(2021, 7, 21, 20, 59, 26, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674344669, 'comment_body': ""Nitpick: this deserves its own file; it's quite substantial on its own."", 'comment_created': datetime.datetime(2021, 7, 21, 21, 4, 13, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674391871, 'comment_body': 'I agree, this behavior is a bit subtle. The main advantage of using a property setter here is that it makes shifting the tokens e.g. by line very convenient, i.e. we can write\r\n\r\n```swift\r\ntoken.start.line += ...\r\n```\r\n\r\nwithout having to construct new positions manually. Previously tokens were defined in terms of start + length and this setter basically preserves those semantics.\r\n\r\nBut I can see how it would be better to make this more explicit with a method.', 'comment_created': datetime.datetime(2021, 7, 21, 22, 41, 22, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 674401092, 'comment_body': 'Just an idea: `move(lineDelta: Int, utf16IndexDelta: Int? = nil)`', 'comment_created': datetime.datetime(2021, 7, 21, 23, 5, 40, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 674799785, 'comment_body': ""I have experimented a bit with using the highlighting in big files (~ 6700 lines) with VSCode and it seems to be pretty responsive. Highlighting shows up in <1s and even when performing multiple edits in rapid succession, we get new tokens pretty quickly.\r\n\r\nPerformance for making edits in a large file with an editor that only supports full document edits would be similar to opening a new document each time, I think, i.e. slightly less responsive highlighting, but still with sub-second update times.\r\n\r\nDo note, however, that while edits to the document are sent in deltas to the language server and SourceKit updates the lexical tokens (from syntaxmaps) in deltas, the updated tokens are transferred in full every time to the client (Although LSP's encoding seems pretty efficient, we might want to support delta responses in the future. This would require more sophisticated diffing logic on the server though, that I would consider out-of-scope for this PR)."", 'comment_created': datetime.datetime(2021, 7, 22, 13, 33, 52, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 675004921, 'comment_body': '> Highlighting shows up in <1s and even when performing multiple edits in rapid succession, we get new tokens pretty quickly.\r\n\r\nFor opening the file this seems pretty good, but for edits I think we need more precise numbers.  I\'m less concerned about the latency of getting the highlighting itself than the time spent processing and serializing the tokens where it blocks the primary server queues. Sub-second could be completely fine, or it could still be too slow if it is delaying code-completion.\r\n\r\nTo give some guidelines, I think anything over ~10 ms is bad and over ~100 ms is probably unacceptable if it\'s blocking the server queues after every edit, and especially if it ""stacks up"" work that is done redundantly when there are several edits in a row.  For example, when we are filtering down an existing code-completion as you type an identifier, that is something we are aiming for more like 10-20 ms total so that it could conceivably be 1-2 frames in the UI.\r\n\r\nDrilling down a bit:\r\n* Updating the tokens immediately after an edit. This seems performance critical since it likely blocks any possible code-completion requests. I think this needs to be <= 10 ms, or else we will need to move it to a background queue.\r\n\r\n* Updating the tokens after the semantic update is received. This is less critical than the syntactic case, because edits get coalesced inside sourcekitd, and building the AST takes time, so it may _usually_ happen after any code-completion request. The processing time could still cause ""jittery"" behaviour where requests sometimes get delayed due to a semantic update from an earlier edit.  My guideline would be this should be < 100 ms if it\'s blocking the server queue, but it\'s possible we could get away with a bit more depending on the timing of the update and the other requests that are happening.\r\n\r\n* Converting the tokens to their LSP format. The highlighting request itself is at least under the control of the editor, so in principle they can always choose to make the request for tokens when it won\'t block code-completion. I don\'t know if that\'s true in practice though, so we still should be mindful of the performance.\r\n\r\nIf it\'s a problem, we always have the option of moving the processing and conversion to lsp format of the tokens onto a background queue that doesn\'t block other requests, although it might make synchronization of state more complex.  So this all seems very solvable to me.', 'comment_created': datetime.datetime(2021, 7, 22, 17, 22, 15, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 676226882, 'comment_body': ""Are the individual arrays sorted? If so we could merge them in a sorted manner more efficiently here, but doesn't seem like they are."", 'comment_created': datetime.datetime(2021, 7, 26, 0, 33, 21, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 676227237, 'comment_body': ""Could you explain the reasoning behind this - when would this be called if we haven't registered support with the client? Is this for clients that don't support dynamic registration?"", 'comment_created': datetime.datetime(2021, 7, 26, 0, 35, 26, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 676227679, 'comment_body': 'Is this the only case where this should happen?', 'comment_created': datetime.datetime(2021, 7, 26, 0, 38, 27, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 676231017, 'comment_body': 'Is there anything to mark system symbols like Array/UIView so we can use the `defaultlibrary` modifier?', 'comment_created': datetime.datetime(2021, 7, 26, 0, 57, 30, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 676232007, 'comment_body': 'Does this work properly with empty lines if omittingEmptyRanges is true and we have text after newlines?', 'comment_created': datetime.datetime(2021, 7, 26, 1, 2, 50, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 676234774, 'comment_body': ""This was (briefly) discussed in https://github.com/apple/sourcekit-lsp/pull/414#discussion_r666021462.\r\n\r\nThe idea is to make sure semantic tokens aren't provided in a Swift file if `clangd`'s semantic tokens provider (with its own legend, etc.) was already registered, which IIUC happens if the user opens an (Obj)C(++) file first. Although it would be nice to support semantic tokens in both Swift and (Obj)C(++) files simultaneously, coordinating the (possibly different) legends and recoding the tokens if needed would add quite a bit of complexity that I would consider out-of-scope for this PR."", 'comment_created': datetime.datetime(2021, 7, 26, 1, 16, 53, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 676237093, 'comment_body': ""We currently only support dynamic registration for semantic highlighting - we don't register static capabilities [here](https://github.com/apple/sourcekit-lsp/blob/7c9ccf26d5f758a23679ca04a2ddf6238e94af3a/Sources/SourceKitLSP/SourceKitServer.swift#L527) and we dynamically register support [here](https://github.com/apple/sourcekit-lsp/blob/7c9ccf26d5f758a23679ca04a2ddf6238e94af3a/Sources/SourceKitLSP/SourceKitServer.swift#L573), so this is unnecessary. If we wanted to support both clangd and a Swift/sourcekit-lsp legend with static registration then we'd need more logic like you mentioned. But dynamic registration lets us restrict this to certain languages to avoid this problem."", 'comment_created': datetime.datetime(2021, 7, 26, 1, 27, 46, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 676553897, 'comment_body': ""Ah, so the dynamic registration mechanism already takes care of ensuring that we only register a semantic tokens provider for one language service and we can remove this extra check? That's nice."", 'comment_created': datetime.datetime(2021, 7, 26, 12, 23, 10, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 676563844, 'comment_body': 'Interestingly yes, there seems to be `key.is_system`, which we can use for that. (Though I am not sure whether UIKit counts as system module) Thanks!', 'comment_created': datetime.datetime(2021, 7, 26, 12, 37, 30, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 676566036, 'comment_body': ""I think so, yes, at least I'm not aware of any other cases where the range would be missing."", 'comment_created': datetime.datetime(2021, 7, 26, 12, 40, 23, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 676571559, 'comment_body': ""They aren't (`syntactic` and `semantic` might be, but `lexical` definitely isn't in general, since we update those in deltas by appending to the array).\r\n\r\nPerhaps we could perform those updates on a sorted array in a more efficient manner, but I am not sure whether it's worth the complexity there, considering that sorting is also just O(n log n)."", 'comment_created': datetime.datetime(2021, 7, 26, 12, 48, 9, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 676768264, 'comment_body': 'Interesting. The meaning of the `defaultLibrary` modifier is not documented at all in LSP. In VSCode, it\'s documented as ""For symbols that are part of the standard library"".  I guess it depends on how broad a definition of ""standard library"" we want to use. When describing it in words, we usually distinguish the standard library (e.g. Swift module) from the broader Apple SDK (e.g. UIKit). Both modules are considered ""system"", which includes the stdlib, the SDK and also any system search paths provided to the compiler (e.g. via `-Fsystem`).\r\n\r\nFor things like symbol colouring we\'ve always used ""is_system"" in the past, so I\'m happy to treat all system library symbols as `defaultLibrary` for now unless we get further clarification in the spec that makes us change our mind.', 'comment_created': datetime.datetime(2021, 7, 26, 16, 37, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 677035547, 'comment_body': ""Yeah, I added similar support to clangd in https://reviews.llvm.org/D101554, I think this behavior is fine - I'm not sure of any precedent from other languages like Java/Python. `defaultLibrary` seems to make sense since it's the closest modifier in the spec (and therefore themes can easily support it)."", 'comment_created': datetime.datetime(2021, 7, 27, 0, 44, 4, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 677036249, 'comment_body': 'Yeah, this seems fine for now, definitely simplest.', 'comment_created': datetime.datetime(2021, 7, 27, 0, 46, 3, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 677330097, 'comment_body': ""It doesn't, good catch."", 'comment_created': datetime.datetime(2021, 7, 27, 10, 41, 32, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 677342460, 'comment_body': 'I have fixed the implementation and added a test case ensuring that it works correctly, especially when multiple newlines are involved.', 'comment_created': datetime.datetime(2021, 7, 27, 11, 1, 8, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 677380136, 'comment_body': ""I have profiled performing a bunch of edits in quick succession on a large (~6000 line) document and the main overhead involved seems to be parsing the tokens from SourceKit, especially due to expensive UTF-8 to UTF-16 conversions (which are, however, unavoidable):\r\n\r\n[flamegraph.zip](https://github.com/apple/sourcekit-lsp/files/6885122/flamegraph.zip)\r\n\r\nLogging the execution times of the methods that parse and convert the tokens while editing the large file confirms that these are potentially expensive operations if run synchronously:\r\n\r\n<details>\r\n\r\n```\r\n2021-07-27 13:45:28.431 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 110.22 ms to execute\r\n2021-07-27 13:45:28.738 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 113.87 ms to execute\r\n2021-07-27 13:45:28.931 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 80.92 ms to execute\r\n2021-07-27 13:45:29.133 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 85.72 ms to execute\r\n2021-07-27 13:45:29.262 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 0.01 ms to execute\r\n2021-07-27 13:45:29.521 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 0.01 ms to execute\r\n2021-07-27 13:45:29.563 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 0.01 ms to execute\r\n2021-07-27 13:45:29.673 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 83.71 ms to execute\r\n2021-07-27 13:45:29.921 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 101.14 ms to execute\r\n2021-07-27 13:45:30.103 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 103.39 ms to execute\r\n2021-07-27 13:45:30.264 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 79.71 ms to execute\r\n2021-07-27 13:45:30.774 sourcekit-lsp[108644:b67fc700] updatedSemanticTokens(response:for:) took 8.83 ms to execute\r\n2021-07-27 13:45:32.685 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 0.01 ms to execute\r\n2021-07-27 13:45:32.951 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 84.30 ms to execute\r\n2021-07-27 13:45:33.123 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 88.88 ms to execute\r\n2021-07-27 13:45:33.305 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 84.37 ms to execute\r\n2021-07-27 13:45:33.491 sourcekit-lsp[108644:b67fc700] updatedLexicalAndSyntacticTokens(response:for:) took 0.01 ms to execute\r\n```\r\n\r\n</details>\r\n\r\nSo ideally we would want to do this asynchronously. I am, however, not sure how well that would play with the request flow for semantic tokens, we may have to await processing the (lexical/syntactic) tokens from the semanticTokens request handler, since we might otherwise end up with an outdated view of the document's tokens after the edit (and a potential race condition)."", 'comment_created': datetime.datetime(2021, 7, 27, 11, 59, 22, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 677651868, 'comment_body': ""Remind me: what exactly do we need the document sub-structure for in the token handling that isn't already part of the lexical tokens or the semantic tokens?  I'm assuming that's the expensive part of `updatedLexicalAndSyntacticTokens` since the lexical tokens are a delta update only.\r\n\r\n> we may have to await processing the (lexical/syntactic) tokens from the semanticTokens request handler, since we might otherwise end up with an outdated view of the document's tokens after the edit (and a potential race condition).\r\n\r\nWe need the tokens to be range-shifted and possibly discarded if they overlap the edit, but that doesn't require them to be up to date semantically, and we would send the notification when that happens anyway.  Can we handle the range-shifting and handle the lexical tokens (which are only an incremental update) synchronously with the edit, but handle the rest asynchronously?"", 'comment_created': datetime.datetime(2021, 7, 27, 17, 20, 56, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 677942028, 'comment_body': 'Does this need to be a parameter - looks like we never set it to false?', 'comment_created': datetime.datetime(2021, 7, 28, 3, 15, 19, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 677942347, 'comment_body': 'Just to confirm that this is intentional - we would generate a SemanticToken for this, right?', 'comment_created': datetime.datetime(2021, 7, 28, 3, 16, 33, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 677942886, 'comment_body': ""IIRC the end position here is exclusive, so having them be the same doesn't quite make sense, right?"", 'comment_created': datetime.datetime(2021, 7, 28, 3, 18, 34, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 681774390, 'comment_body': ""We currently use the document substructure to provide accurate syntactic tokens e.g. for identifiers of declared variables, since we ignore lexical tokens of kind `keys.substructure.syntaxtype_identifier` (mostly because they are generally less specific than VSCode's default highlighting, causing tokens to 'flicker' between the semantic color and the general `syntaxtype_identifier` color, see https://github.com/apple/sourcekit-lsp/pull/414#discussion_r666275815). \r\n\r\n> Can we handle the range-shifting and handle the lexical tokens (which are only an incremental update) synchronously with the edit, but handle the rest asynchronously?\r\n\r\nI think so, I'm currently looking into that."", 'comment_created': datetime.datetime(2021, 8, 3, 13, 46, 1, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 681779534, 'comment_body': 'Good catch, thanks!', 'comment_created': datetime.datetime(2021, 8, 3, 13, 51, 39, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 681787814, 'comment_body': 'Traversing and parsing the syntactic tokens from the document substructure seems to be the most expensive part of `updatedLexicalAndSyntacticTokens`, if we only process lexical tokens after edits (synchronously), our processing time drops to 0-3 ms for edits in > 6000 line files.', 'comment_created': datetime.datetime(2021, 8, 3, 14, 0, 41, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 682497005, 'comment_body': 'Would it make sense to use `lazy` here to avoid creating the intermediate arrays for `map`? ', 'comment_created': datetime.datetime(2021, 8, 4, 10, 38, 6, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 682767067, 'comment_body': '> if we only process lexical tokens after edits (synchronously), our processing time drops to 0-3 ms for edits in > 6000 line files.\r\n\r\nNice!', 'comment_created': datetime.datetime(2021, 8, 4, 16, 18, 2, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 685328771, 'comment_body': ""Another option would be to simply skip syntactic tokens if the file length exceeds a certain threshold. Since only a small subset of the tokens are syntactic (mostly just the identifiers of declared variables), I think it wouldn't look too different either. What do you think?"", 'comment_created': datetime.datetime(2021, 8, 9, 16, 7, 32, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 685496597, 'comment_body': ""I would prefer not to have that kind of limit.  If it was a really large limit that you wouldn't hit before maybe 20,000 lines I think that might be okay, but we're talking about fairly realistic file sizes.  In the best case it will result in inconsistent behaviour between small and large files.\r\n\r\n> I think it wouldn't look too different either.\r\n\r\nIf users notice the difference it will feel buggy, and if they don't notice the difference then arguably we could just not include the syntactic tokens at all.  I would argue we either make it fast enough to always have enabled or we skip the syntactic tokens always."", 'comment_created': datetime.datetime(2021, 8, 9, 20, 25, 2, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 685497164, 'comment_body': ""Note: it's always an option to change our mind later too, so we could disable these tokens for now and put in the work to enable them later if we think it's worth it."", 'comment_created': datetime.datetime(2021, 8, 9, 20, 26, 3, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 686131053, 'comment_body': ""Timeouts for anything involving semantic operations should probably be 60 seconds minimum. Testing locally these will typically be very fast, but we've seen extremely slow behaviour in CI systems. "", 'comment_created': datetime.datetime(2021, 8, 10, 16, 16, 49, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 686272517, 'comment_body': 'Instead of updating the test, I have updated the `documentSymbol` request implementation to always return an array of children. This feels cleaner to me and would also reflect the previous behavior (we never actually entered the `else` case).\r\n\r\nWhat do you think?', 'comment_created': datetime.datetime(2021, 8, 10, 19, 46, 4, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 686276616, 'comment_body': 'SGTM.', 'comment_created': datetime.datetime(2021, 8, 10, 19, 52, 55, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 687440829, 'comment_body': 'Nitpick: we no longer have syntactic tokens.', 'comment_created': datetime.datetime(2021, 8, 12, 7, 0, 27, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687443659, 'comment_body': 'Nit: Isnâ€™t this more like `deletedLineCount`? `previousLineCount` suggested to me that itâ€™s the number of lines the document had before the edit.', 'comment_created': datetime.datetime(2021, 8, 12, 7, 5, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687446169, 'comment_body': 'Wonâ€™t `lastLineReplaceLength` be negative if I make an edit form e.g. `1:3 - 2:4`.\r\n\r\nI *think* the `range.lowerBound.line == range.upperBound.line` check should be on `range.lowerBound.utf16index` instead of the upper bound.\r\n\r\nIf not, I think it would be good to throw an assertion in here which guarantees that `lastLineReplaceLength >= 0`.', 'comment_created': datetime.datetime(2021, 8, 12, 7, 9, 38, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687463589, 'comment_body': 'If we didnâ€™t get a response from the sourcekitd replacetext request, wouldnâ€™t it be better if we removed all `DocumentTokens` instead of showing potentially stale ones? I.e. shouldnâ€™t we be returning `DocumentTokens()` here and make `updateDocumentTokens` return a non-optional?', 'comment_created': datetime.datetime(2021, 8, 12, 7, 36, 21, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687469166, 'comment_body': 'I think with this change thereâ€™s no reason for `children` on `DocumentSymbols` to be an `Optional` anymore. Could you update the `DocumentSymbol` initializer and `children` property to a non-optional array?', 'comment_created': datetime.datetime(2021, 8, 12, 7, 44, 34, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687474722, 'comment_body': 'Nit: `allCases` -> `allModifiers`', 'comment_created': datetime.datetime(2021, 8, 12, 7, 52, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687478982, 'comment_body': 'I donâ€™t think we need `useName` anymore since you removed syntactic tokens.', 'comment_created': datetime.datetime(2021, 8, 12, 7, 58, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687491847, 'comment_body': 'Could you also add a test case for identifiers that only have a backtick on one side?\r\n\r\nE.g.\r\n```swift\r\nlet `onLeft = 1\r\nlet onRight` = 2\r\n```\r\n\r\nI think we would currently be adding 2 to the identifierâ€™s length even if there is only one backtick.', 'comment_created': datetime.datetime(2021, 8, 12, 8, 17, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687499499, 'comment_body': 'Should we maybe move this one to the other helper methods on the top of the test case?\r\n\r\nAlso: Is there a reason why this isnâ€™t a `fileprivate` extension on `Token`. I think `Token(â€¦)` would read nicer than `makeToken`, but I donâ€™t have too strong an opinion on this one.', 'comment_created': datetime.datetime(2021, 8, 12, 8, 28, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 687699606, 'comment_body': ""Interestingly, this already seems to work correctly as-is, since the parser won't include the backtick in the identifier if it is only present on one side (probably due to it being a syntax error). I will add a test case that verifies this."", 'comment_created': datetime.datetime(2021, 8, 12, 13, 14, 44, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 687701539, 'comment_body': 'It is the number of lines that the document had within the edit range before the edit. I can see how `deletedLineCount` would be clearer though.', 'comment_created': datetime.datetime(2021, 8, 12, 13, 16, 58, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 687702635, 'comment_body': ""I think `replacedLineCount` sounds even better and would be consistent with the other variables' naming, e.g. `lastLineReplaceLength`."", 'comment_created': datetime.datetime(2021, 8, 12, 13, 18, 20, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 687890725, 'comment_body': 'Should we pass in `result` as an inout parameter to avoid the intermediate array?', 'comment_created': datetime.datetime(2021, 8, 12, 16, 16, 12, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 687948128, 'comment_body': ""Yes, I think this logic wasn't quite correct and I am not entirely sure why it worked in the first place. I have updated it and added another test case."", 'comment_created': datetime.datetime(2021, 8, 12, 17, 31, 12, tzinfo=datetime.timezone.utc), 'commenter': 'fwcd', 'type': 'User'}, {'comment_id': 694577471, 'comment_body': 'Nitpick: Isnâ€™t this more of a `lastLineCharDelta`? `charDelta` implies to me that it should be applied in the same locations that `lineDelta` is applied.', 'comment_created': datetime.datetime(2021, 8, 24, 7, 31, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 694580327, 'comment_body': 'I think `updateDocumentTokens` can return a non-optional now (see https://github.com/apple/sourcekit-lsp/pull/414#discussion_r687469166)\r\n```suggestion\r\n    updateDocumentTokens: ((_ after: DocumentSnapshot) -> DocumentTokens)? = nil\r\n```', 'comment_created': datetime.datetime(2021, 8, 24, 7, 35, 31, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 713191033, 'comment_body': ""FYI the change to `DocumentSymbol.children` is reverted in #428. We need it to remain optional in the API because that's how it's specified and clangd makes use of it being optional."", 'comment_created': datetime.datetime(2021, 9, 21, 16, 3, 46, tzinfo=datetime.timezone.utc), 'commenter': 'benlangmuir', 'type': 'User'}, {'comment_id': 717092811, 'comment_body': ""Is this related to why `SourceKitServer` responds without `semanticTokensProvider`? I'm talking about this response\r\n\r\nhttps://github.com/apple/sourcekit-lsp/blob/1cb9e070ea8aeca381ba26a7847625287129ddad/Sources/SourceKitLSP/SourceKitServer.swift#L547-L553"", 'comment_created': datetime.datetime(2021, 9, 27, 22, 36, 23, tzinfo=datetime.timezone.utc), 'commenter': 'krzyzanowskim', 'type': 'User'}, {'comment_id': 717691561, 'comment_body': 'We dynamically register the `semanticTokensProvider` here\r\nhttps://github.com/apple/sourcekit-lsp/blob/1cb9e070ea8aeca381ba26a7847625287129ddad/Sources/SourceKitLSP/SourceKitServer.swift#L309-L310\r\n\r\nwith `semanticTokensProvider` being set here for Swift\r\nhttps://github.com/apple/sourcekit-lsp/blob/1cb9e070ea8aeca381ba26a7847625287129ddad/Sources/SourceKitLSP/Swift/SwiftLanguageServer.swift#L358-L363\r\n\r\nIIUC the reason for the dynamic registration is that we can only support a single semantic tokens provider at the moment (see initial comment in this discussion). That is we only support semantic tokens for **either** clang-based languages **or** Swift. As a heuristic the language that gets opened first wins at the moment.\r\n\r\nDoes this answer your question?', 'comment_created': datetime.datetime(2021, 9, 28, 15, 21, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ahoppen', 'type': 'User'}, {'comment_id': 718059357, 'comment_body': ""Dynamic registration lets us work around the fact that clangd has its own separate semantic token legends, distinct from the one we maintain for Swift - otherwise we'd have to unify them somehow (e.g. using clangd's or converting it to a single format). Since dynamic registration supports per-language registration (see [here](https://microsoft.github.io/language-server-protocol/specifications/specification-3-17/#textDocumentRegistrationOptions)), it gives us semantic highlighting for both ObjC/Swift as long as the editor supports it.\r\n\r\nIn the short term, for editors that don't support dynamic registration, we could maybe do something like I've done [here](https://github.com/apple/sourcekit-lsp/pull/429/files#diff-74f7ae001022599e910e900d4fb40255212cfe8887ad1322918aa2657b733e46R531) to at least give us support for Swift semantic highlighting."", 'comment_created': datetime.datetime(2021, 9, 29, 0, 33, 54, tzinfo=datetime.timezone.utc), 'commenter': 'DavidGoldman', 'type': 'User'}, {'comment_id': 718304219, 'comment_body': ""> Does this answer your question?\r\n\r\nthank you both! it does answer my question.\r\n\r\nSide note: It does feel like sourcekit-lsp is a bit of stretch for the LSP specification while trying to bridge `clangd`. Maybe we're close to the point where sourcekit-lsp should have launch argument to enable/disable clangd - this would make it more predictable."", 'comment_created': datetime.datetime(2021, 9, 29, 9, 1, 39, tzinfo=datetime.timezone.utc), 'commenter': 'krzyzanowskim', 'type': 'User'}]","[{'commit_sha': '17f656865ddc7abe6273ec8752b596578232d440', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eaa8c66b256c7e6df2f151719e70664769e9c65c', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f83f7f287e1f3dc7342f7ea01216e97b3b06f45a', 'committer_username': 'fwcd', 'committer_name': 'fwcd', 'committer_email': None, 'commit_date': datetime.datetime(2017, 8, 9, 17, 1, 53, tzinfo=datetime.timezone.utc)}]",fwcd,30873659,,User,,232,,157,359

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
154773196,sourcekit-lsp,swiftlang/sourcekit-lsp,Swift,270,3248,163,113,2965,81,27,11,"[{'id': 2032566065, 'number': 1639, 'closed': None, 'created': datetime.datetime(2024, 8, 22, 16, 38, 54, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 95, 'deletions': 119, 'state': 'open'}, {'id': 1551112853, 'number': 892, 'closed': datetime.datetime(2024, 6, 21, 15, 27, 56, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 10, 11, 2, 8, 47, tzinfo=datetime.timezone.utc), 'time_taken': 21993549.0, 'time_delta': '254 days, 13:19:09', 'additions': 116, 'deletions': 3, 'state': 'closed'}, {'id': 1551049492, 'number': 891, 'closed': datetime.datetime(2023, 10, 11, 21, 9, 7, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 10, 11, 0, 59, 56, tzinfo=datetime.timezone.utc), 'time_taken': 72551.0, 'time_delta': '20:09:11', 'additions': 1, 'deletions': 1, 'state': 'closed'}, {'id': 992112695, 'number': 584, 'closed': datetime.datetime(2022, 7, 12, 10, 36, 2, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 7, 9, 0, 31, 9, tzinfo=datetime.timezone.utc), 'time_taken': 295493.0, 'time_delta': '3 days, 10:04:53', 'additions': 15, 'deletions': 4, 'state': 'closed'}, {'id': 987736250, 'number': 582, 'closed': datetime.datetime(2022, 7, 11, 10, 40, 34, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 7, 5, 18, 42, 19, tzinfo=datetime.timezone.utc), 'time_taken': 489495.0, 'time_delta': '5 days, 15:58:15', 'additions': 390, 'deletions': 3, 'state': 'closed'}, {'id': 987349359, 'number': 581, 'closed': datetime.datetime(2022, 7, 5, 14, 39, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 7, 5, 12, 1, 4, tzinfo=datetime.timezone.utc), 'time_taken': 9522.0, 'time_delta': '2:38:42', 'additions': 151, 'deletions': 0, 'state': 'closed'}, {'id': 984194946, 'number': 578, 'closed': datetime.datetime(2022, 7, 5, 13, 33, 53, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 6, 30, 19, 12, 26, tzinfo=datetime.timezone.utc), 'time_taken': 411687.0, 'time_delta': '4 days, 18:21:27', 'additions': 317, 'deletions': 21, 'state': 'closed'}, {'id': 981647292, 'number': 575, 'closed': datetime.datetime(2022, 6, 30, 10, 48, 32, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 6, 28, 16, 39, 35, tzinfo=datetime.timezone.utc), 'time_taken': 151737.0, 'time_delta': '1 day, 18:08:57', 'additions': 85, 'deletions': 117, 'state': 'closed'}, {'id': 966941748, 'number': 570, 'closed': datetime.datetime(2022, 6, 22, 15, 43, 9, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 6, 14, 13, 32, 24, tzinfo=datetime.timezone.utc), 'time_taken': 699045.0, 'time_delta': '8 days, 2:10:45', 'additions': 299, 'deletions': 85, 'state': 'closed'}, {'id': 873690722, 'number': 465, 'closed': datetime.datetime(2022, 6, 14, 13, 10, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 3, 8, 0, 22, 7, tzinfo=datetime.timezone.utc), 'time_taken': 8513286.0, 'time_delta': '98 days, 12:48:06', 'additions': 299, 'deletions': 85, 'state': 'closed'}, {'id': 683064390, 'number': 414, 'closed': datetime.datetime(2021, 8, 28, 11, 4, 8, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 7, 3, 18, 54, 24, tzinfo=datetime.timezone.utc), 'time_taken': 4810184.0, 'time_delta': '55 days, 16:09:44', 'additions': 1645, 'deletions': 36, 'state': 'closed'}, {'id': 670526767, 'number': 408, 'closed': datetime.datetime(2021, 6, 30, 20, 18, 43, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 15, 15, 44, 7, tzinfo=datetime.timezone.utc), 'time_taken': 1312476.0, 'time_delta': '15 days, 4:34:36', 'additions': 195, 'deletions': 83, 'state': 'closed'}, {'id': 664908134, 'number': 407, 'closed': datetime.datetime(2021, 6, 22, 14, 37, 16, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 8, 13, 16, 3, tzinfo=datetime.timezone.utc), 'time_taken': 1214473.0, 'time_delta': '14 days, 1:21:13', 'additions': 987, 'deletions': 5, 'state': 'closed'}, {'id': 656652813, 'number': 406, 'closed': datetime.datetime(2021, 6, 15, 12, 17, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 5, 28, 15, 13, 48, tzinfo=datetime.timezone.utc), 'time_taken': 1544605.0, 'time_delta': '17 days, 21:03:25', 'additions': 606, 'deletions': 68, 'state': 'closed'}, {'id': 644026564, 'number': 393, 'closed': datetime.datetime(2021, 5, 13, 18, 39, 51, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 5, 13, 14, 47, 45, tzinfo=datetime.timezone.utc), 'time_taken': 13926.0, 'time_delta': '3:52:06', 'additions': 2, 'deletions': 1, 'state': 'closed'}, {'id': 628316660, 'number': 389, 'closed': datetime.datetime(2021, 5, 20, 14, 31, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 5, 1, 2, 58, 57, tzinfo=datetime.timezone.utc), 'time_taken': 1683169.0, 'time_delta': '19 days, 11:32:49', 'additions': 58, 'deletions': 9, 'state': 'closed'}, {'id': 261288078, 'number': 93, 'closed': datetime.datetime(2019, 3, 15, 0, 45, 22, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2019, 3, 14, 18, 25, 50, tzinfo=datetime.timezone.utc), 'time_taken': 22772.0, 'time_delta': '6:19:32', 'additions': 16, 'deletions': 8, 'state': 'closed'}]"
44838949,swift,swiftlang/swift,C++,10323,67196,2473,1415,171281,7524,526,888,"[{'id': 1023358414, 'number': 60502, 'closed': datetime.datetime(2022, 8, 12, 2, 0, 24, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 8, 11, 1, 54, 15, tzinfo=datetime.timezone.utc), 'time_taken': 86769.0, 'time_delta': '1 day, 0:06:09', 'additions': 12, 'deletions': 6, 'state': 'closed'}, {'id': 677405414, 'number': 38085, 'closed': datetime.datetime(2021, 6, 29, 13, 3, 27, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 24, 20, 10, 20, tzinfo=datetime.timezone.utc), 'time_taken': 406387.0, 'time_delta': '4 days, 16:53:07', 'additions': 25, 'deletions': 4, 'state': 'closed'}, {'id': 677369193, 'number': 38084, 'closed': datetime.datetime(2021, 7, 2, 10, 2, 32, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 24, 19, 4, 23, tzinfo=datetime.timezone.utc), 'time_taken': 658689.0, 'time_delta': '7 days, 14:58:09', 'additions': 56, 'deletions': 5, 'state': 'closed'}, {'id': 667331757, 'number': 37867, 'closed': datetime.datetime(2021, 6, 24, 6, 50, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 10, 20, 3, 45, tzinfo=datetime.timezone.utc), 'time_taken': 1162021.0, 'time_delta': '13 days, 10:47:01', 'additions': 717, 'deletions': 0, 'state': 'closed'}, {'id': 633141684, 'number': 37320, 'closed': datetime.datetime(2021, 5, 17, 21, 25, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 5, 7, 17, 41, 39, tzinfo=datetime.timezone.utc), 'time_taken': 877441.0, 'time_delta': '10 days, 3:44:01', 'additions': 228, 'deletions': 65, 'state': 'closed'}, {'id': 572728810, 'number': 35949, 'closed': datetime.datetime(2021, 6, 13, 20, 22, 58, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 2, 12, 19, 20, 8, tzinfo=datetime.timezone.utc), 'time_taken': 10458170.0, 'time_delta': '121 days, 1:02:50', 'additions': 2, 'deletions': 2, 'state': 'closed'}]"

pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
1404939570,gsoc2023: net: http: culminating pull request,"This PR includes all commits for the gsoc2023 HTTP project.

Please see each commit message for details.",False,59669,https://api.github.com/repos/zephyrproject-rtos/zephyr/pulls/59669,https://github.com/zephyrproject-rtos/zephyr/pull/59669,closed,3915,3,61,41,7,187,2,2,"[{'name': 'area: Networking'}, {'name': 'GSoC'}]",2023-06-23 11:45:09+00:00,2023-10-26 19:56:59+00:00,10829510.0,"125 days, 8:11:50","[{'comment_id': 1243469551, 'comment_body': 'This should not be part of the test. Currently it duplicates functionality from https://github.com/zephyrproject-rtos/zephyr/pull/59669/commits/287d7b1dc1c5eb3997a195bd44bbe2d2e078c336.', 'comment_created': datetime.datetime(2023, 6, 27, 9, 54, 46, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1243493415, 'comment_body': ""This is more of a sample than a library at the moment. \r\n\r\nHaving a sample is fine - and we should have one, but `subsys/` is not where it belongs. And the sample should make actual use of the library we're working on.\r\n\r\nGenerally, we really need to think on how should the HTTP2 server library look like. For sure we'll need a public API (as I wrote on Discord, the public header should be defined in `include/zephyr/net/http`). You need to think on what public functions should be exposed to the application. The most basic ones that come up to me  would be:\r\n* `http2_server_init()`\r\n* `http2_server_start()` \r\n* `http2_server_stop()`\r\n\r\nFor the resource (webpage) representation in the server, you should have a look at the API added some time ago by @cfriedt (which could likely provide more details about it): https://github.com/zephyrproject-rtos/zephyr/blob/main/include/zephyr/net/http/service.h#L19\r\n\r\nFinally, the sample app should make use of the above to create a HTTP2 server. And we should cover those functionalities in tests, just as listed in the GSoC umbrella issue."", 'comment_created': datetime.datetime(2023, 6, 27, 10, 10, 21, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1248754381, 'comment_body': 'This file should be generated at build time. Please remove it with `git rm`, and then `git commit --fixup <commit>`, followed by a `git rebase -i --autosquash <prev_commit>` ', 'comment_created': datetime.datetime(2023, 7, 1, 10, 8, 22, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1248754488, 'comment_body': 'Same here', 'comment_created': datetime.datetime(2023, 7, 1, 10, 8, 42, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1251834629, 'comment_body': ""I think it'd be easier for apps to work with binary IP representation (we have `struct net_addr` that covers family and binary IP address)."", 'comment_created': datetime.datetime(2023, 7, 4, 10, 24, 57, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251835706, 'comment_body': ""nit, but I'd use `uint8_t *` here."", 'comment_created': datetime.datetime(2023, 7, 4, 10, 25, 59, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251836485, 'comment_body': 'No PascalCase please (here and in other places), we should stick to the so called ""snake_case"". So `http2_frame`.', 'comment_created': datetime.datetime(2023, 7, 4, 10, 26, 44, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251856349, 'comment_body': '@cfriedt I think we should settle whether we want to stick to POSIX socket APIs, or use `zsock_*` prefixed ones. The former approach proved to be problematic in the past (as we still have two ways to enable socket POSIX APIs). Not sure if we need the dependency to POSIX either in a networking component.', 'comment_created': datetime.datetime(2023, 7, 4, 10, 45, 54, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251864290, 'comment_body': ""We don't use typedefs in Zephyr. Just define `struct http2_frame`."", 'comment_created': datetime.datetime(2023, 7, 4, 10, 54, 2, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251868144, 'comment_body': ""We should think of some kind of client context for variables like this, `struct http2_server_ctx` should then have a predefined array of the contexts of MAX_CLIENTS size, which would keep an individual set of variables for each client.\r\n\r\nGenerally, global variables like this don't scale well (what if we get 2 client connections?). So any variable/array that corresponds to the state of communication with indvidual client, should end up in the context structure."", 'comment_created': datetime.datetime(2023, 7, 4, 10, 57, 20, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251869304, 'comment_body': 'Eventually, we should use Zephyr logger in Zephyr component (`LOG_XXX()` macros). See https://docs.zephyrproject.org/latest/services/logging/index.html', 'comment_created': datetime.datetime(2023, 7, 4, 10, 58, 16, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251872518, 'comment_body': ""We should not use `exit()` in the library code - we don't want to break the system in case of simple errors. Just return a negative error code here (`return -errno`)."", 'comment_created': datetime.datetime(2023, 7, 4, 11, 1, 25, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251877080, 'comment_body': ""There's `ip_addr` field in the config structure, we should make use of it."", 'comment_created': datetime.datetime(2023, 7, 4, 11, 5, 41, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251879986, 'comment_body': 'A small suggestion here - if you do something like\r\n```\r\n if (!(ctx->client_fds[i].revents & POLLIN)) {\r\n\tcontinue;\r\n}\r\n```\r\nYou will save yourself one extra level of indentation. This will become especially useful, if we use proper (8-space tab length) everywhere.\r\n\r\n', 'comment_created': datetime.datetime(2023, 7, 4, 11, 8, 49, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251880587, 'comment_body': 'We should also check for POLLERR, POLLHUP and react as in case of a socket error/disconnect.', 'comment_created': datetime.datetime(2023, 7, 4, 11, 9, 18, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251881695, 'comment_body': ""I believe I've already mentioned that some time ago, but 0 is still a valid socket descriptor. So in case you want to mark unused `fds` entries, you should use negaive value (most commonly used -1), not 0."", 'comment_created': datetime.datetime(2023, 7, 4, 11, 10, 26, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251883123, 'comment_body': ""I don't think I understand this part. Shouldn't `ctx->num_client` simply be incremented by 1?"", 'comment_created': datetime.datetime(2023, 7, 4, 11, 11, 52, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251885618, 'comment_body': ""Shouldn't the HTTP1 parser be executed only after we identify we deal with HTTP1 request?"", 'comment_created': datetime.datetime(2023, 7, 4, 11, 14, 32, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251886854, 'comment_body': 'General note - please avoid so called ""magic numbers"" (24 in this case). It\'s always difficult to identify where did the value come from (and is error prone).\r\n\r\nBetter to use `strlen(preface)` in this case. ', 'comment_created': datetime.datetime(2023, 7, 4, 11, 15, 44, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251887509, 'comment_body': 'Why would we need to NULL terminate this buffer anyway?', 'comment_created': datetime.datetime(2023, 7, 4, 11, 16, 25, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251890874, 'comment_body': ""Also, please note that we may not have received the entire preface in a single `recv()` call. In case we've received only half for example, we'll start to handle the data as HTTP1, even though it may be a perfectly valid half of the HTTP2 preface.\r\n\r\nThe code dealing with STREAM sockets should always be smart enough to deal with such cases. So for example here, on a new connection we should repeat the `recv()` until we get a full preface, and only then proceed with parsing."", 'comment_created': datetime.datetime(2023, 7, 4, 11, 19, 25, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251898960, 'comment_body': ""We should provide the actual number of bytes received to the parser, not `BUFFER_SIZE`. Also, as mentioned earlier we should not assume that we've received the full request in a single receive call.\r\n\r\nSee how the HTTP client lib deals with the parser - https://github.com/zephyrproject-rtos/zephyr/blob/main/subsys/net/lib/http/http_client.c#L452, it's always a recv()/http_parser_execute() pair."", 'comment_created': datetime.datetime(2023, 7, 4, 11, 27, 32, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251900936, 'comment_body': 'I think this conceptually belong to the HTTP1 parsing part - update header is part of HTTP1 request. IMO we only need to reply for that and take no further action (i. e. expect HTTP2 request in the next step).', 'comment_created': datetime.datetime(2023, 7, 4, 11, 29, 30, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251905514, 'comment_body': 'As we discussed last week - we may lose stream data here (overwrite it). If the initial `recv()` call received more data than only preface, we lose it here.\r\n\r\nAlso, think we should rethink the design here. `recv()` should only be caleld after the `poll()` call reports there is new data to read - otherwise we may block inside `handle_http2_request()`, effectively preventing the server from handling other requests. ', 'comment_created': datetime.datetime(2023, 7, 4, 11, 34, 3, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251906105, 'comment_body': ""Wasnt' this already done in `http2_server_start()`?"", 'comment_created': datetime.datetime(2023, 7, 4, 11, 34, 40, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251907413, 'comment_body': 'We should really avoid declaring large buffers on a stack. I think we should have one buffer statically allocated per client, and use only it for communication.', 'comment_created': datetime.datetime(2023, 7, 4, 11, 36, 5, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251917228, 'comment_body': ""And actually it should be even needed to copy the buffers, just offset the orignal buffer when providing the pointer to the function (so you don't provide `buffer` directly, but `buffer + some_offset`)."", 'comment_created': datetime.datetime(2023, 7, 4, 11, 45, 54, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1251927067, 'comment_body': ""We still should be prepared for this case. I. e. the actual paylaod size may exceed the buffer we're processing, so that in case of the next `recv()` call we should treat the remainig data as a payload for the previous frame, and not try to parse the new frame header."", 'comment_created': datetime.datetime(2023, 7, 4, 11, 55, 18, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1258025318, 'comment_body': 'yes, this was for an HTTP/1 client after it was upgraded to HTTP/2', 'comment_created': datetime.datetime(2023, 7, 10, 10, 10, 37, tzinfo=datetime.timezone.utc), 'commenter': 'Emna-Rekik', 'type': 'User'}, {'comment_id': 1258027001, 'comment_body': 'I called here because I needed to see if there is an upgrade: h2c in the header field.', 'comment_created': datetime.datetime(2023, 7, 10, 10, 12, 24, tzinfo=datetime.timezone.utc), 'commenter': 'Emna-Rekik', 'type': 'User'}, {'comment_id': 1258337787, 'comment_body': ""It seems that you've accidently removed TFTP library in https://github.com/zephyrproject-rtos/zephyr/pull/59669/commits/212bf4c5e931cc396ed0fa558ecce2b86b13607e, and then recommited it in https://github.com/zephyrproject-rtos/zephyr/pull/59669/commits/a2a34522d08a0ea825606f419100775feb7b3a90. We should not introduce such changes in the history, please amend the former commit so that it does not touch anything unrelated."", 'comment_created': datetime.datetime(2023, 7, 10, 14, 15, 34, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1258375034, 'comment_body': '`int server_fd` as an argument here seems redundant - the server socket is already part of `struct http2_server_ctx`', 'comment_created': datetime.datetime(2023, 7, 10, 14, 43, 13, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1258376421, 'comment_body': 'Should be defined in the public header. `struct http2_server_ctx*` as an argument.', 'comment_created': datetime.datetime(2023, 7, 10, 14, 44, 10, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1258380384, 'comment_body': 'This should not be a shell command, but a regular API function. For testing purposes, you could define a shell command which calls this API function (in `main.c`) but the `http2_server_stop()` should have no references to shell, only server context.', 'comment_created': datetime.datetime(2023, 7, 10, 14, 46, 56, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1258386747, 'comment_body': ""I believe this approach is not exactly what @cfriedt proposed during the call (i. e. to use [eventfd write](https://github.com/zephyrproject-rtos/zephyr/blob/main/include/zephyr/posix/sys/eventfd.h#L63)), but I guess this could also be okayish.\r\n\r\nThe advantage of using eventfd is that once you call `http2_server_stop()` the server should terminate almost immediately. With this approach, you'd need to wait for the next `poll()` timeout before it terminates. @cfriedt WDYT.\r\n\r\nAlso, in any case, any shutdown-related variables (semaphore in this case) should be a part of the `struct http2_server_ctx`."", 'comment_created': datetime.datetime(2023, 7, 10, 14, 51, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1258394458, 'comment_body': 'You cannot assume that the data received over a socket is a NULL terminated string. What would it print in case of HTTP2 request, which is not a text-based protocol?', 'comment_created': datetime.datetime(2023, 7, 10, 14, 55, 58, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1258403091, 'comment_body': ""The thing is - you cannot feed the data to the HTTP1 parser unless you're certain it's a HTTP1 request. Otherwise, you may get unexpected results. So the order of action should be:\r\n* Read data on a socket until you have `strlen(preface) bytes`\r\n* If preface matches HTTP2 request - proceed as with HTTP2 request.\r\n* Otherwise, proceed with HTTP1 request. Only now you can feed that data to the HTTP1 parser, and search for the upgrade header. If there's a header, reply and await next request (HTTP2 this time).\r\n"", 'comment_created': datetime.datetime(2023, 7, 10, 15, 2, 5, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1261437864, 'comment_body': 'I would suggest some modification of this (eventually).\r\n```suggestion\r\nstruct http2_server_ctx {\r\n\tint server_fd; // for accepting new client connections\r\n\tint event_fd;\r\n\tsize_t num_clients;\r\n\tstruct http2_client_ctx clients[CONFIG_NET_HTTP2_MAX_CLIENTS];\r\n};\r\n```', 'comment_created': datetime.datetime(2023, 7, 12, 16, 32, 56, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1261439215, 'comment_body': 'Please add a `Kconfig` item for this - e.g. `CONFIG_NET_HTTP2_MAX_CLIENTS`.\r\n```suggestion\r\n```', 'comment_created': datetime.datetime(2023, 7, 12, 16, 34, 15, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1261441200, 'comment_body': 'It might be better to define `struct http2_frame` elsewhere, e.g. in a private header. The telling part for me, is that `struct http2_frame` is not referenced anywhere in this header.', 'comment_created': datetime.datetime(2023, 7, 12, 16, 36, 16, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1261447486, 'comment_body': ""Actually, to expand on this a bit, the http service description was specifically designed to be more-or-less independent of any actual implementation details. \r\n\r\nWhat that allows us to do, for example, is to easily (for various definitions of easy) compare two or more different http server implementations in various sample applications and testsuites. There may be an implementation-specific / conditionally compiled source file here or there, but otherwise it should work.\r\n\r\nUltimately, this will allow us to quantitatively compare HTTP server implementations in Zephyr and provide graphs, evidence, etc to show that e.g. Emna's server implementation outperforms CivetWeb by a factor of 2 or something along those lines, or this implementation or that implementation is able to handle N concurrent clients while using M bytes of memory, and so on."", 'comment_created': datetime.datetime(2023, 7, 12, 16, 42, 11, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1261448117, 'comment_body': ""I'll see if I can pull the CivetWeb implementation in for reference purposes, in a way that we can easily choose this or that based on Kconfig."", 'comment_created': datetime.datetime(2023, 7, 12, 16, 42, 50, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1261448547, 'comment_body': 'Yeah, the shell is completely unnecessary here, I think.', 'comment_created': datetime.datetime(2023, 7, 12, 16, 43, 18, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1265374612, 'comment_body': 'This can be switched to `<poll.h>` as long as `CONFIG_POSIX_API` is in `prj.conf`', 'comment_created': datetime.datetime(2023, 7, 17, 13, 40, 27, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1265385614, 'comment_body': 'For apps (samples and tests), this can be `<netinet/in.h>` if you have `CONFIG_POSIX_API=y` in your `prj.conf`.\n\nFor Zephyr library code, we should use the `<zephyr/posix/...>` prefix though.', 'comment_created': datetime.datetime(2023, 7, 17, 13, 43, 47, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1265391940, 'comment_body': 'Also, the ""canonical"" way that we should include headers is now in 3 blocks.\n\nIt\'s kind of unofficial right now, but better to be future-proof.\n\nEach block is ordered alphabetically / lexically\n\n```cpp\n/* private headers */\n#include ""private_header.h""\n\n/* standard headers (e.g. ISO C, POSIX) */\n#include <errno.h>\n#include <unistd.h>\n\n/* zephyr headers */\n#include <zephyr/kernel.h>\n#include <zephyr/sys/bitarray.h>\n```', 'comment_created': datetime.datetime(2023, 7, 17, 13, 48, 26, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1265397478, 'comment_body': 'Just remember to add `CONFIG_POSIX_API=y` to your `prj.conf`.\n\nAlso, please separate the headers into the appropriate canonical blocks.\n\n```suggestion\n#include <sys/socket.h>\n#include <arpa/inet.h>\n#include <fcntl.h>\n#include <netinet/in.h>\n#include <poll.h>\n#include <zephyr/sys/atomic.h>\n#include <sys/eventfd.h>\n```\n', 'comment_created': datetime.datetime(2023, 7, 17, 13, 52, 41, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1269292866, 'comment_body': 'nit: We should follow Zephyr convention for include guards, so `ZEPHYR_INCLUDE_NET_HTTP_SERVER_H_`', 'comment_created': datetime.datetime(2023, 7, 20, 10, 55, 48, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1269294635, 'comment_body': 'It should not be needed to have a `pollfd` entry in the client context, `int client_fd` should be enough.', 'comment_created': datetime.datetime(2023, 7, 20, 10, 57, 32, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1269296693, 'comment_body': 'Please define an enum for this outside of the client context:\r\n```c\r\nenum http2_server_state {\r\n...\r\n}\r\n```\r\n\r\nAnd just define variable in the context.', 'comment_created': datetime.datetime(2023, 7, 20, 10, 59, 27, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1269300934, 'comment_body': ""What's the purpose for this variable? Looks a bit hacky considering how it's used."", 'comment_created': datetime.datetime(2023, 7, 20, 11, 2, 44, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1269303103, 'comment_body': 'Please look over your code, and use `snake_case` not `pascalCase`. So `send_data`, `stream_id` etc.', 'comment_created': datetime.datetime(2023, 7, 20, 11, 4, 58, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1269307623, 'comment_body': 'Please try to define constants for all magic numbers you use. So for example, define:\r\n```c\r\n#define HTTP2_FRAME_HEADER_SIZE 9\r\n#define HTTP2_FRAME_LENGTH_OFFSET 0\r\n#define HTTP2_FRAME_TYPE_OFFSET 3\r\n#define HTTP2_FRAME_FLAGS_OFFSET 4\r\netc.\r\n```\r\nAnd use them in the code instead. It greatly improves readability.', 'comment_created': datetime.datetime(2023, 7, 20, 11, 9, 54, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1269323253, 'comment_body': '`server_fd` and `event_fd` sockets need to be handled separately. Currently, you would call `close_client_connection() on the listening socket, if it reported an error.', 'comment_created': datetime.datetime(2023, 7, 20, 11, 25, 52, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1269462311, 'comment_body': 'This comment will be a little longer, but I\'ll try to give a general overview of how a stateful parsing could look like.\r\n\r\nFirst of all, we want to get rid of all poll()/recv() calls outside of the main server loop (so the one here). The reason for this is that we don\'t want to block the server from handling other requests, in case `recv()` would block inside `handle_http2_request()`. But even with non-blocking calls it doesn\'t work great in the current design, as in case there are no new data, you\'d stop the parsing and start over from scratch (i. e. preface handling) w/o serving the request. \r\n\r\n### Receving new data\r\n\r\nWhat I think would be needed in the first place to achieve this goal is to redesign how we recv new data, I suggest to:\r\n* Introduce a separate input buffer for each client (so make it a part of the client context).\r\n* Introduce a new `offset` variable to keep track of how many bytes are currently in the buffer. This would also affect how you `recv()` new data:\r\n```c\r\nrecv(ctx->client_fds[i].fd, buffer + offset, sizeof(buffer) - offset, 0);\r\n```\r\nAs you don\'t want to overwrite the data that is already in the buffer.\r\n\r\n### Parsing the buffer\r\n\r\nNow, `recv()` will be providing new data to the buffer, so we need `handle_http_request` to consume it. That\'s where the stateful handling kicks in. If you look at the existing HTTP1 parser implementation you\'ll see there are lots of states, the parser also works in a way that it counsumes the new data byte by byte:\r\nhttps://github.com/zephyrproject-rtos/zephyr/blob/main/subsys/net/lib/http/http_parser.c#L784\r\nI don\'t think we need it to get that complex with HTTP2 since it\'s binary, so easier to parse.\r\n\r\nFirst of all, we need to figure out what states the server can be in. The very first thing we expect from a newly connected client is a preface - therfore, it makes sense to introduce a state that represents this stage (`HTTP_PREFACE`). Once we\'ve received the preface, we can determine whether we deal with HTTP1 or HTTP2 request. \r\n\r\nFor HTTP1 I believe we don\'t need much state representation, as most of this is handled by the existing parser. `HTTP1_REQUEST` should do, but if you see a need for more states for HTTP1 parsing, don\'t hesitate to add more.\r\n\r\nFor HTTP2 it gets a bit more complex, as we need to implement the parser ourselves. So we need to figure out, what is the next data we expect to get, when we proceed with HTTP2 request. For me, it seems that we should expect frame header. So we can introduce `HTTP2_FRAME_HEADER` state. Once we\'re done with the frame header parsing, we know what type of frame we deal with. So for a header frame, we could have `HTTP2_HEADER_FRAME` in which we parse header fields one by one. Similarly, in `HTTP2_SETTINGS_FRAME` we would parse (""consume"") settings, one by one (note that they all have predefined format/size). The list goes on and on, I hope that you see where it\'s going. If certain frame type requires more complex parsing - you can define substates as well.\r\n\r\nAlso note, that with each frame header, you know exactly how much bytes in that frame to expect. So when you\'re done with parsing of the current frame (""consumed"" all of the frame data), you can get back to `HTTP2_FRAME_HEADER` state.\r\n\r\n### Some pseudocode to consider\r\n\r\nWe should consider now how could this look like in practice (note that it\'s just a pseudo-C code, I did not compile it, it\'s just for an overview).\r\n\r\nThe main input function could look like:\r\n```c\r\nint handle_http_request(struct http2_client_ctx *ctx)\r\n{\r\n\tint ret = -EINVAL;\r\n\r\n\tdo {\r\n\t\tswitch (ctx->state) {\r\n\t\tcase HTTP_PREFACE:\r\n\t\t\tret = handle_http_preface(ctx);\r\n\t\t\tbreak;\r\n\t\tcase HTTP1_REQUEST:\r\n\t\t\tret = handle_http1_request(ctx);\r\n\t\t\tbreak;\r\n\t\tcase HTTP2_FRAME_HEADER:\r\n\t\t\tret = handle_http2_frame_header(ctx);\r\n\t\t\tbreak;\r\n\t\tcase xxx:\r\n\t\t\tetc..\r\n\t\t}\r\n\t} while (ret == 0 && ctx->offset > 0);\r\n\r\n\treturn ret;\r\n}\r\n```\r\n\r\nWe need to establish some protocol for the return values. 0 could indicate successful parsing and that the function should proceed with the next state (there might still be some data in the buffer to process). `-EAGAIN` could indicate that we expect more data to come before we can proceed with parsing. Any other negative value - parsing error, we should terminate the connection.\r\n\r\nNow for example how could `handle_preface()` look like:\r\n```c\r\nint handle_http_preface(struct http2_client_ctx *ctx)\r\n{\r\n\tif (ctx->offset < strlen(preface)) {\r\n\t\t/* We don\'t have full preface yet, get more data. */\r\n\t\treturn -EAGAIN;\r\n\t}\r\n\r\n\tif (strncmp(ctx->buffer, preface, strlen(preface)) != 0) {\r\n\t\tctx->state = HTTP1_REQUEST;\r\n\t} else {\r\n\t\tctx->state = HTTP2_FRAME_HEADER;\r\n\t}\r\n\r\n\t/* Now we need to ""consume"" the already processed data from the buffer\r\n\t * For simplicity, I suggest to use memmove for starters, we can\r\n\t * optimize to some other solution if needed\r\n\t */\r\n\r\n\t/* ctx->offset will indicate remaining data in the buffer */\r\n\tctx->offset -= strlen(preface);\r\n\tmemmove(ctx->buffer, ctx->buffer + strlen(preface), ctx->offset);\r\n\r\n\treturn 0;\r\n}\r\n```\r\n\r\n', 'comment_created': datetime.datetime(2023, 7, 20, 13, 28, 38, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275044324, 'comment_body': 'All those number should have predefined symbols (`HTTP2_FRAME_TYPE_DATA` etc), preferably in form of enum (`enum http_frame_type`).', 'comment_created': datetime.datetime(2023, 7, 26, 14, 27, 39, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275050830, 'comment_body': ""You should document the arguments with doxygen (there are plenty examples across the codebase). As for now, I don't think I fully understand the purpose of the `timeout` argument here."", 'comment_created': datetime.datetime(2023, 7, 26, 14, 32, 14, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275079131, 'comment_body': ""I think I've mentioned this already, but `0` is still a valid file descriptor - it should not be used as a marker of unused slot. Use `-1` instead (preferably defined as some symbol like `INVALID_SOCK`.\r\nAlso, please make sure you follow Zephyr CS:\r\n```suggestion\r\n\t\t\t\t\tif (ctx->fds[j].fd != -1) {\r\n\t\t\t\t\t\tcontinue;\r\n\t\t\t\t\t}\r\n```"", 'comment_created': datetime.datetime(2023, 7, 26, 14, 40, 32, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275083672, 'comment_body': ""I think it'd make sense to create a helper function to initialize new client context."", 'comment_created': datetime.datetime(2023, 7, 26, 14, 43, 18, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275084536, 'comment_body': ""Question - what should we do, if we don't find a free slot?"", 'comment_created': datetime.datetime(2023, 7, 26, 14, 43, 46, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275088193, 'comment_body': ""It'd make sense to define a pointer here, `struct http2_client_ctx *client = &ctx->clients[i - 2]` here and use it instead later. It'd not only make the code look nicer, but also be less error-prone."", 'comment_created': datetime.datetime(2023, 7, 26, 14, 45, 51, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275114287, 'comment_body': ""Reinitializing the client state on each loop iteration doesn't seem right - it spoils the idea of stateful server. The main reason of the state variable is to remember at which phase are we in the request processing so you cannot reset the state on each loop iteration. The state should be initialized once - when you accept new incoming connection."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 4, 19, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275120713, 'comment_body': ""I think it'd be better to accept `struct http2_client_ctx *client` as the second parameter. Instead of doing some not-always-obvious math on the intext, the `http2_client_ctx` could simply remember which FDS slot it uses (i. e. index in the FDS table)."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 9, 20, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275123131, 'comment_body': ""I think it shouldn't be the responsibility of `handle_http_request()` or any of the subfunctions to close the connection. This function should just return an error in case of any parsing issues, and let the main loop handle this (i.e. close the connection/client context)."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 11, 5, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275124777, 'comment_body': 'A good habit to work out is to mark any private functions (i.e. which are not part of the public/internal API) as `static` to reduce the chance of name collisions.', 'comment_created': datetime.datetime(2023, 7, 26, 15, 12, 14, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275135385, 'comment_body': ""There shouldn't be a need for `is_http2` variable - whether we deal with HTTP1 or HTTP2 request should be evaluated based on the current state we're in."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 20, 18, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275137516, 'comment_body': 'I don\'t there should be a state like `INITIAL_STATE`. The states should transition from one to another smoothly based on the parsing progress - but now it seems that we have some kind of ""supervisor"" state that decides what should the next state  be.', 'comment_created': datetime.datetime(2023, 7, 26, 15, 22, 2, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275140913, 'comment_body': ""You should break the loop if `ret < 0`. And handle `-EAGAIN` as a special case - it's not an error, but an indication that more data is expected."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 24, 39, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275145351, 'comment_body': ""We can't just close the connection if there is no more data in the current iteration. As a matter of fact, here we should just switch to the next state and let the next state handler to determine what to do next. `handle_http_preface()` did its job already - parsed the PREFACE field, now we know if we should proceed with HTTP1 or HTTP2 parsing."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 27, 42, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275148478, 'comment_body': ""`determine_server_state()` will reach to the 4th byte of the buffer (frame type), but we don't know if there's enough data in the buffer (you didn't check if (offset > 4). That's why in my initial proposal I suggested to have a separate state for parsing FRAME_HEADER, in which we'd evaluate if we have enough data to parse the entire header, and then could decide what to do next."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 30, 1, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275153711, 'comment_body': ""I think we should drop this idea of having `parse_http2_frames()` which will attempt to parse as many frames there is in the buffer, and store their contents in an enormous array of frames - it won't scale well for embedded systems.\r\n\r\nWe should be parsing frames one by one - i. e. start in a FRAME_HEADER state always, and based on the content switch to a state that will be responsible of parsing the payload of the frame. In case of SETTINGS frame, parse settings one be one, until we consume all of the data in the current frame."", 'comment_created': datetime.datetime(2023, 7, 26, 15, 34, 3, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275830707, 'comment_body': '`first_flag` is not a good name - this flag was given a very specific name in the RFC, ACK. Also, we need to keep in mind, that different frame types define different flags, so we need to consider this to create an unique name (for example the same bit will be occupied by END_STREAM flag in the headers frame). Therefore for this particular case I think `settings_ack_flag` could be a good choice.', 'comment_created': datetime.datetime(2023, 7, 27, 7, 14, 36, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275834891, 'comment_body': ""According to the RFC:\r\n> A SETTINGS frame MUST be sent by both endpoints at the start of a\r\n   connection and MAY be sent at any other time by either endpoint over\r\n   the lifetime of the connection.\r\n\r\nThis means, that we shouldn't be sending our own SETTINGS frame as a response to the clients SETTINGS, but rather proactively once the connection is established. Here, we should send SETTINGS with ACK, to acknowledge client's frame."", 'comment_created': datetime.datetime(2023, 7, 27, 7, 18, 27, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1275839335, 'comment_body': ""Also please note, that generally it'd be recommended to create defines/enums for all constants specified in the spec (flags, frame types, setting types) and use them in the code, instead of using magic numbers in various places."", 'comment_created': datetime.datetime(2023, 7, 27, 7, 22, 30, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1279149778, 'comment_body': ""I'd call this `http2_frame_type` - the type is HTTP2 specific."", 'comment_created': datetime.datetime(2023, 7, 31, 11, 13, 33, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1279150931, 'comment_body': 'The enums should be prefixed for clarify, I suggest `HTTP2_FRAME_DATA` etc.', 'comment_created': datetime.datetime(2023, 7, 31, 11, 14, 49, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1279154001, 'comment_body': 'And we should ensure there is no name collisions, I suggest to suffix all of the state enums with `_STATE`.', 'comment_created': datetime.datetime(2023, 7, 31, 11, 17, 45, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1286032838, 'comment_body': 'We should parse the whole frame header here, not only the length, as this is what this state is responsible of. I suggest to do the following:\r\n1. Add `struct http2_frame current_frame` to the `struct http2_client_ctx`. This will allow to remember parameters of the current frame throughout the payload parsing stage.\r\n2. Rename `parse_http2_frame()` to `parse_http2_frame_header()`, and use it here to fill out the content of `current_frame`.\r\n3. ""Consume"" the frame header from the buffer (`memmove()`). Other states should refer to the `current_frame` content, instead of reaching to the buffer. Note, that we need to be prepared that we won\'t be able to parse/consume entire frame payload in a single for example `handle_http2_frame_headers()` call, so we cannot expect the frame header will always be present at the beginning of the buffer.', 'comment_created': datetime.datetime(2023, 8, 7, 15, 19, 47, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1286038691, 'comment_body': 'We shouldn\'t enforce/expect that we\'ll always be able to fit the entire frame in the buffer. Note that the HTTP2 RFC states that:\r\n> All implementations MUST be capable of receiving and minimally\r\n   processing frames up to 2^14 octets in length, plus the 9-octet frame\r\n   header ([Section 4.1](https://datatracker.ietf.org/doc/html/rfc7540#section-4.1)).\r\n\r\nThis doesn\'t mean that we need to allocate 16k buffer for the frame, that wouldn\'t be practical for memory-constrained systems. But we need to be prepared for that the client may choose to send such a large frame and we should be able to process it in chunks (that\'s the main reason we need ""frame"" states - so that in `handle_http_request()` we remember what frame we\'re currently parsing.\r\n\r\nSo, to summarize, we should get rid of this check and proceed with state selection.', 'comment_created': datetime.datetime(2023, 8, 7, 15, 24, 58, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1286051490, 'comment_body': ""I suggest we get rid of `determine_server_state()` - as a matter of fact, there shouldn't be a need to determine next frame  state outside of `handle_http2_frame_header()`.\r\n\r\nInstead, I suggest to add `switch(client_ctx->current_frame.type) { }` directly here. Additionally, instead of setting the `ctx_client->server_state` directly here, I propose to introduce functions that would cover state transitions, for example `int enter_http2_frame_headers_state(struct http2_client_ctx *client_ctx)`, some actions should only take place once during state transition, I'll give an example in another comment.\r\n\r\nSo for here, I'd see a something like:\r\n```c\r\nswitch(client_ctx->current_frame.type) {\r\ncase HTTP2_DATA_FRAME:\r\n\treturn enter_http2_frame_data_state(client_ctx);\r\n...\r\ndefault:\r\n\treturn enter_http_done_state(client_ctx);\r\n}\r\n```"", 'comment_created': datetime.datetime(2023, 8, 7, 15, 36, 18, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1286131581, 'comment_body': 'Two issues with this approach:\r\n * First - we shouldn\'t be really using a fixed `streams` array index, as this effectively breaks dealing with multiple streams. Having a stream counter doesn\'t work either, as this will fail if we have multiple concurrent streams.\r\n * Second - I don\'t think there\'s a need for `determine_stream_state()` function. Especially, that with current use it isn\'t really useful (note that we check frame type in there, but we already know what kind of frame (HEADERS) since we\'re in respective state handlers.\r\n\r\nFor current stream identification, we should be using stream ID instead. Therefore, I suggest to introduce two helper functions: \r\n* `struct http2_stream_ctx *find_http2_stream_context(struct http2_client_ctx *ctx_client, uint32_t stream_id)`\r\n* `struct http2_stream_ctx *allocate_http2_stream_context(struct http2_client_ctx *ctx_client, uint32_t stream_id)`\r\n\r\nFirst would loop over clients `struct http2_stream_ctx streams` and return the stream context with a matching ID, NULL if not found.\r\nSecond, would loop over clients `struct http2_stream_ctx streams` and look for an ""empty"" stream context (i. e. stream in IDLE state). If not found, return NULL.\r\n\r\nAdditionally, `struct http2_stream_ctx *current_stream` inside client context could be useful, to remember which stream the current frame belongs to.\r\n\r\nNow how I\'d use those functions. That\'s where the aforementioned state transition function can be handy. For example, we\'ve received frame header which indicates that the frame type is HEADERS frame, we call `enter_http2_frame_headers_state()` :\r\n\r\n* First, we use `find_http2_stream_context()` to find if the corresponding stream already exists\r\n* If not (NULL returned) we use `allocate_http2_stream_context()` and try to allocate new stream (remember, that only HEADERS frame can do that, i. e. spawn new streams!).\r\n* In case no empty stream can be found, reject the stream (or for now just close the connection for simplicity).\r\n* Initialize any helper variables that may be needed to track frame parsing progress (`need_pad_len` etc,  https://discord.com/channels/@me/1105531307448074281/1134064198775750658 to refresh your memory).\r\n* Otherwise, mark the stream as OPEN and enter the `HTTP2_FRAME_HEADERS_STATE`\r\n* The list can be extended, if there are additional conditions stated in the RFC (or implied by the implementation).\r\n', 'comment_created': datetime.datetime(2023, 8, 7, 16, 31, 18, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1286144739, 'comment_body': ""I don't really think we should need separate handlers for IDLE/OPEN stream state. First off, as soon we allocate the stream it should be marked as OPEN, so there shouldn't really be the case we handle IDLE state. We should focus here on parsing header fields, one by one, and on each header you parse you should decrement `current_frame->length` by the length you parsed. And when `current_frame->length` reaches 0, it means that we're done with the current frame and we should expect a new one (so state transition to HTTP2_FRAME_HEADER_STATE, again this may involve some action, like sending the response if we received STREAM_END).\r\n\r\nFor the headers that are essential for serving the request (like the resource URI the request refers to) you should have a variable within `struct stream_context`, so that once we're done with request parsing (STREAM_END received) you know which resource to fetch. There are probably more, this is just an example.\r\n\r\nAnd finally, if it turns out, that `current_frame->length` is still >0, but there's no more data in the buffer to parse, it means that we did not receive entire HEADERS frame in a single TCP packet (which can happen with TCP!). In that case, return -EAGAIN, and let `poll()`/`recv()` to fill the buffer with new data. When we're back in `handle_http_request()` it should be clear that:\r\n* we are in HTTP2_FRAME_HEADERS_STATE\r\n* we know how much data is left to parse in current frame (`current_frame->length`),\r\nso we should proceed with parsing individual headers."", 'comment_created': datetime.datetime(2023, 8, 7, 16, 43, 34, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1286285145, 'comment_body': 'I would suggest putting this at the bottom of the file. It would probably also be good to considering adding `before()`  and `after()` functions. Those should be of the form.\r\n\r\n```cpp\r\nstatic void before(void *arg)\r\n{\r\n  ARG_UNUSED(arg); // unless using ZTEST_F()\r\n  /* e.g. start server */\r\n}\r\n\r\nstatic void after(void *arg)\r\n{\r\n  ARG_UNUSED(arg); // unless using ZTEST_F()\r\n  /* e.g. stop server */\r\n}\r\n```', 'comment_created': datetime.datetime(2023, 8, 7, 19, 4, 18, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1286745210, 'comment_body': 'The type should be `sa_family_t`', 'comment_created': datetime.datetime(2023, 8, 8, 7, 52, 52, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286754119, 'comment_body': 'I would not advertise the slip connectivity here, It should be enough to point to network documentation like the link few lines above.', 'comment_created': datetime.datetime(2023, 8, 8, 8, 0, 39, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286754723, 'comment_body': 'Also this info should be found already in network documentation.', 'comment_created': datetime.datetime(2023, 8, 8, 8, 1, 10, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286755483, 'comment_body': 'Why do we need this, is it possible to run this without the virtual env?', 'comment_created': datetime.datetime(2023, 8, 8, 8, 1, 53, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286758643, 'comment_body': 'These look unnecessary', 'comment_created': datetime.datetime(2023, 8, 8, 8, 4, 45, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286760342, 'comment_body': 'Do we need to run dnsmasq or similar in host side in order this sample to work?', 'comment_created': datetime.datetime(2023, 8, 8, 8, 6, 13, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286871728, 'comment_body': 'Minor nit but by resufling the variables inside a struct can avoid holes in memory footprint.\r\nHere I would suggest:\r\n```\r\n\tunsigned char *payload;\r\n\tuint32_t length;\r\n\tuint32_t stream_identifier;\r\n\tuint8_t type;\r\n\tuint8_t flags;\r\n```\r\nso the largest type first, and the smallest last.\r\n\r\n', 'comment_created': datetime.datetime(2023, 8, 8, 9, 39, 49, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286873859, 'comment_body': 'No need to have empty line between setting a variable and checking its value. Please check all the code for these.', 'comment_created': datetime.datetime(2023, 8, 8, 9, 41, 43, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286874928, 'comment_body': 'Could you separate all the non sample application changes to separate commits.', 'comment_created': datetime.datetime(2023, 8, 8, 9, 42, 41, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286883490, 'comment_body': 'The bind() calls could be done once after IPv4 and IPv6 checks, so something like this:\r\n```\r\nstruct sockaddr *saddr;\r\nint saddr_len;\r\n...\r\nif (...address_family == AF_INET) {\r\n\t....\r\n\tsaddr = (struct sockaddr *)&servr_addr);\r\n\tsaddr_len = sizeof(serv_addr);\r\n} else if (...address_family == AF_INET6) {\r\n\t....\r\n\tsaddr = (struct sockaddr *)&servr_addr);\r\n\tsaddr_len = sizeof(serv_addr);\r\n}\r\n\r\nif (bind(ctx->server_fd, saddr, saddr_len) < 0) {\r\n\tLOG_ERR(""bind"");\r\n\treturn -errno;\r\n}\r\n```\r\n', 'comment_created': datetime.datetime(2023, 8, 8, 9, 49, 42, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286884535, 'comment_body': 'IPv6 handling is missing.', 'comment_created': datetime.datetime(2023, 8, 8, 9, 50, 34, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286890196, 'comment_body': 'Only difference is the error print, so perhaps these could be combined.\r\nAlso LOG_INF() has extra `\\n` and can be removed.\r\n```\r\nif (valread <= 0) {\r\n\tif (valread == 0) {\r\n\t\tLOG_INF(""Connction closed by peer"");\r\n\t} else {\r\n\t\tLOG_ERR(""...."");\r\n\t}\r\n\r\n\tclose_client_connection(ctx, i);\r\n\tcontinue;\r\n}\r\n```\r\n\r\n}\r\n', 'comment_created': datetime.datetime(2023, 8, 8, 9, 55, 21, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286891574, 'comment_body': 'I suggest that in error cases we return some meaningful -Errno value and not just plain -1', 'comment_created': datetime.datetime(2023, 8, 8, 9, 56, 33, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286892539, 'comment_body': 'Magic constants should be avoided, please set some descriptive define and use that here.', 'comment_created': datetime.datetime(2023, 8, 8, 9, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1286896382, 'comment_body': 'Why do we mix printf() and LOG_xxx() macros? Better to use LOG_xxx macros allways to get consistent output.\r\nThe printf() could be converted to LOG_DBG()', 'comment_created': datetime.datetime(2023, 8, 8, 10, 0, 38, tzinfo=datetime.timezone.utc), 'commenter': 'jukkar', 'type': 'User'}, {'comment_id': 1290288065, 'comment_body': '@rlubos - Emna & I weren\'t really sure what the tag / name should be here. I.e. ""table"" is just used everywhere for lack of a better term, but this is referring to the static HPACK table.', 'comment_created': datetime.datetime(2023, 8, 10, 15, 12, 8, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1290290287, 'comment_body': '@Emna-Rekik - please clean up the doxygen to reflect the ""table"" tag / name (or whatever the HPACK library is).', 'comment_created': datetime.datetime(2023, 8, 10, 15, 13, 45, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1290996690, 'comment_body': 'I think a combination of `hpack` and `static_table` should be used. For the test, i""d use `hpack.static_table`. \r\n\r\nFor the implementation, personally I\'d:\r\n - rename `http_table.c` to `http_hpack.c`,\r\n - rename current APIs to use `static_table` instead of `table` (not to get confused with dynamic table which we don\'t implement yet)\r\n - `http_hpack.c` leaves a room for future extenstion with dynamic table, we should aslo conisder adding header parsing logic here  (according to https://datatracker.ietf.org/doc/html/rfc7541#section-6) as it\'s part of the HPACK spec.', 'comment_created': datetime.datetime(2023, 8, 11, 7, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1291175331, 'comment_body': "">  - rename current APIs to use `static_table` instead of `table` (not to get confused with dynamic table which we don't implement yet)\n\n Given that the static and dynamic table share the same key space, it's probably better _not_ to rename public API (i.e. functions) with `static_table`, since they would just need to be renamed again later if / when dynamic table support is added. It likely does make sense internally to differentiate between static and dynamic, of course.\n\nhttps://httpwg.org/specs/rfc7541.html#index.address.space\n\nWhat would also be good, @Emna-Rekik, is to create a static inline function in the header file to say whether a given key is static.\n\nE.g.\n\n```cpp\nstatic inline bool http_hpack_key_is_static(int32_t key)\n{\n    return key >= 1 && key <= 61; /* use symbolic names */\n}\n\nstatic inline bool http_hpack_key_is_dynamic(int32_t key)\n{\n    return key > 61; /* use symbolic names */\n}\n```\n\nThe nice thing about eventually supporting a dynamic table (which would be trivial with a `hash_map`), is that there is only a simple constant offset (62) required to convert from the common key space to the dynamic key space."", 'comment_created': datetime.datetime(2023, 8, 11, 10, 28, 29, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1291181607, 'comment_body': '```suggestion\nint http_hpack_table_add(struct http2_server_ctx *ctx, uint32_t key, void *value);\nint http_hpack_table_get(struct http2_server_ctx *ctx, iint32_t key, void **value);\nint http_hpack_table_remove(struct http2_server_ctx *ctx, iint32_t key);\nint http_hpack_table_contains(struct http2_server_ctx *ctx, uint32_t key);\n```\n', 'comment_created': datetime.datetime(2023, 8, 11, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1291182434, 'comment_body': ""Might be worth it to change `HTTP_TABLE` to `HTTP_HPACK_KEY` with\r\n```shell\r\nsed -i -e 's/HTTP_TABLE/HTTP_HPACK/g' <filenames..>\r\n```\r\n\r\n```suggestion\r\nenum http_hpack_static_key {\r\n```\r\n"", 'comment_created': datetime.datetime(2023, 8, 11, 10, 37, 1, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292353078, 'comment_body': '```suggestion\r\nconfig NET_HTTP_MAX_CLIENTS\r\n```', 'comment_created': datetime.datetime(2023, 8, 12, 15, 45, 52, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292353116, 'comment_body': ""Please drop the `2` from `HTTP2` for Kconfig options. For enumerations and constants that are strictly related to http 2.0, it's fine, but please omit this for Zephyr Kconfig options.\r\n\r\nAlso for Zephyr API, please omit 2 from `http2` as well.\r\n```suggestion\r\nconfig NET_HTTP_MAX_STREAMS\r\n```"", 'comment_created': datetime.datetime(2023, 8, 12, 15, 46, 4, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292353242, 'comment_body': 'I would even go further to say that Kconfig options specific to the server should have the prefix `NET_HTTP_SERVER_`.', 'comment_created': datetime.datetime(2023, 8, 12, 15, 47, 22, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292355007, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2023, 8, 12, 15, 53, 34, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292360646, 'comment_body': 'Changes to this Kconfig file should have been made as part of [this commit](https://github.com/zephyrproject-rtos/zephyr/pull/59669/commits/caaf12d464cc59c8f9c7d15ffe2f25a948838375) instead of [this commit](https://github.com/zephyrproject-rtos/zephyr/pull/59669/commits/83587a3cbca9317d955763542b0a177b5202b7bd).\r\n\r\nCan you please fix-up and reword the commit messages?', 'comment_created': datetime.datetime(2023, 8, 12, 16, 7, 34, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292365090, 'comment_body': 'These should be switched from `HTTP2_` (and `HTTP1_`) to `HTTP_`. The server will need to support all protocol version states, but the protocol version should be handled in code, not as a special server state.\r\n\r\nAlso, I would highly recommend that http-server-specific enumerations and constants be namespaced - e.g. `HTTP_SERVER_FOO`.', 'comment_created': datetime.datetime(2023, 8, 12, 16, 17, 36, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292365185, 'comment_body': 'I would highly recommend that http-server-specific enumerations be namespaced - e.g. `HTTP_SERVER_FOO`.', 'comment_created': datetime.datetime(2023, 8, 12, 16, 17, 48, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292367991, 'comment_body': ""Please move this file to `subsys/net/lib/http/server/server.c` so that it can be built into Zephyr's HTTP server library and subsequently used by both samples and tests.\r\n\r\nThat's kind of a high priority.\r\n\r\nI can sort of guess why it was added here initially, but it probably should not have been checked in here with git. This will likely also result in a cascade of git commit errors. We won't even have time to clean-up the git commit history, but it will need to be cleaned up before being merged to `main`.\r\n\r\nI see modifications to this for test code, sample code, etc. Code commits need to be separate from sample and test commits."", 'comment_created': datetime.datetime(2023, 8, 12, 16, 23, 23, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292371709, 'comment_body': ""so again, we are doing more than http2, so please replace `http2` with `http` everywhere, unless it's a header specifically describing http2-only protocol bits."", 'comment_created': datetime.datetime(2023, 8, 12, 16, 31, 36, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292377573, 'comment_body': 'This likely needs to be moved along with `server.c` to `subsys/net/lib/http/` and I might be wrong, but it looks to me like some of this may be crossing the line between private and public API.', 'comment_created': datetime.datetime(2023, 8, 12, 16, 43, 38, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292381174, 'comment_body': '```suggestion\r\n#include <stdint.h>\r\n\r\n#if !defined(__ZEPHYR__) || defined(CONFIG_POSIX_API)\r\n#include <poll.h>\r\n#else\r\n#include <zephyr/posix/poll.h>\r\n#endif\r\n```', 'comment_created': datetime.datetime(2023, 8, 12, 16, 53, 35, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1292385909, 'comment_body': 'Can we move this to its own header? Maybe `include/zephyr/net/http/frame.h`?', 'comment_created': datetime.datetime(2023, 8, 12, 17, 4, 36, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1294584300, 'comment_body': 'I would remove this for now. The assumption that the app could build against native_posix was based on word-of-mouth statement from the POSIX arch maintainer that POSIX API could work on ARCH POSIX, but that is certainly not the case.', 'comment_created': datetime.datetime(2023, 8, 15, 13, 15, 44, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1295986821, 'comment_body': ""Shouldn't this header be called `hpack.h`?"", 'comment_created': datetime.datetime(2023, 8, 16, 14, 16, 3, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1295994227, 'comment_body': '`key < HTTP_HPACK_SIZE` - `HTTP_HPACK_SIZE` is not a valid static table index.', 'comment_created': datetime.datetime(2023, 8, 16, 14, 21, 11, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1295999726, 'comment_body': ""IMO it'd be better if the function returned `bool`. Currently, it's easy to misuse the function, for example `if (http_hpack_table_contains())` will be true if there is **no entry**, not very intuitive."", 'comment_created': datetime.datetime(2023, 8, 16, 14, 24, 59, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296000265, 'comment_body': 'All public functions should be prefixed (`http_hpack_`).', 'comment_created': datetime.datetime(2023, 8, 16, 14, 25, 20, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296002503, 'comment_body': 'No magic numbers please - you should define symbols for `0x80`,  `0x7F`, 0x40` etc constants.', 'comment_created': datetime.datetime(2023, 8, 16, 14, 26, 54, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296018636, 'comment_body': ""I think we've gone through this last time - we **can't** assume that the entire HTTP2 frame will fit into our buffer."", 'comment_created': datetime.datetime(2023, 8, 16, 14, 38, 20, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296022956, 'comment_body': ""There's no need to go byte-by-byte when parsing the header. The previous parsing code was okayish, you only need to make sure that the entire frame header is already present in the buffer (so `ctx_client->offset >= HTTP_FRAME_HEADER_SIZE`)."", 'comment_created': datetime.datetime(2023, 8, 16, 14, 41, 6, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296029137, 'comment_body': '`current_frame.length` definitely **should not** be consumed in this state, only frame header.', 'comment_created': datetime.datetime(2023, 8, 16, 14, 45, 24, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296031808, 'comment_body': 'You just want to change the state here, not call `handle_http_frame_headers()` function. Calling `handle_http_frame_headers()` should only be done from `handle_http_request()`.', 'comment_created': datetime.datetime(2023, 8, 16, 14, 47, 13, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296034469, 'comment_body': 'You should return a specific error code here (`-ENOMEM` for example), using `errno` makes little sense here as nobody set its value.', 'comment_created': datetime.datetime(2023, 8, 16, 14, 49, 10, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296037502, 'comment_body': 'This is checked in the wrong place, you should enter `HTTP_FRAME_HEADERS_STATE` unconditionally. END_HEADERS should be verified when you leave `HTTP_FRAME_HEADERS_STATE`, so that you know whether to expect CONTINUATION frame or not.', 'comment_created': datetime.datetime(2023, 8, 16, 14, 51, 21, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296070668, 'comment_body': 'This function needs a considerable design change. We should not be ""requesting"" anything from the parsing function. Instead, we need to provide it with buffers for header name and value, and let it fill it out with content.\r\n\r\nI suggest that a single function call parse a single HPACK header entry (therefore it\'d make sense to call it `http_hpack_parse_header()`).\r\n\r\nParsing HPACK entry is a bit trickier than parsing frame header from insteance, as we don\'t know beforehand what length to expect, so you need to always check during the parsing whether there is enough data in the buffer to proceed (for example if you read Literal Header ""Name Length"" field, and it would indicate that the actual string is longer than the remaining data in the buffer, you can return `-EAGAIN` and start over from scratch on the next loop iteration (when more data arrives).\r\n\r\nI think that for simplicity, we can assume that we only support HPACK headers of size lower than `CONFIG_NET_HTTP_CLIENT_BUFFER_SIZE` - otherwise it\'ll become much more complex task to provide a HPACK parser able to deal with partial (incomplete) headers. IMO, for embedded system this is a reasonable tradeoff, I doubt we\'ll have a need to support very long header fields any time soon (like cookies).\r\n\r\nAnd once the function finally returns a success - it should be the caller who decides what to do with the new data. If it\'s a header of interest for us (like URL, Method etc), store it. If it\'s not, just ignore it and proceed to the next entry.', 'comment_created': datetime.datetime(2023, 8, 16, 15, 15, 40, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1296303312, 'comment_body': 'These two defines conflict with the `enum http_hpack_static_key` entries of the same name', 'comment_created': datetime.datetime(2023, 8, 16, 18, 47, 41, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1297821492, 'comment_body': '```suggestion\n\treturn key > HTTP_HPACK_INVALID && key <=         HTTP_HPACK_WWW_AUTHENTICATE;\n```\n', 'comment_created': datetime.datetime(2023, 8, 17, 22, 46, 39, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1297821970, 'comment_body': '```suggestion\n\treturn key >         HTTP_HPACK_WWW_AUTHENTICATE;\n```\n', 'comment_created': datetime.datetime(2023, 8, 17, 22, 47, 31, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1297822152, 'comment_body': '```suggestion\nstatic const void *http_hpack_table_static[] = {\n```\n', 'comment_created': datetime.datetime(2023, 8, 17, 22, 47, 56, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1298334071, 'comment_body': 'We need to verify the result of `handle_http_request()` here - in case of any parsing errors, the connection with the client should be closed. With exception to `-EAGAIN` which we agreed to be a special code to indicate that more data is expected by the parser.', 'comment_created': datetime.datetime(2023, 8, 18, 11, 16, 58, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298334391, 'comment_body': 'Missing `break`.', 'comment_created': datetime.datetime(2023, 8, 18, 11, 17, 20, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298335693, 'comment_body': 'This looks like a serious issue for the server to enter unrecognized state - could event be an assert condition. But for now, we should at least set `ret` to some error code, and break the loop (in consequence, close the connection).', 'comment_created': datetime.datetime(2023, 8, 18, 11, 18, 32, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298338161, 'comment_body': ""We should take a uniform appraoch here, the current mixup of `return enter_http_xxx_state()`; and `enter_http_xxx_state(); break;` doesn't look well. I suggest to do any processing needed in current state **before** the switch instruction, and follow the `return enter_http_xxx_state()` pattern."", 'comment_created': datetime.datetime(2023, 8, 18, 11, 21, 38, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298340806, 'comment_body': 'This would be an exception, as unrecognized frame type is clearly a parsing error. Entering DONE state is ok, but the function should explicitly return an error code here.', 'comment_created': datetime.datetime(2023, 8, 18, 11, 24, 51, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298343272, 'comment_body': '`parse_http_frame_header()` could simply return those codes, instead of making it return some arbitrary values and translating it here. Then you can simply check if parsing was successful or not:\r\n```c\r\nif (parse_result < 0) {\r\n\treturn parse_result;\r\n}\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 11, 28, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298346112, 'comment_body': 'This function should be prepared to parse any additional HPACK headers.', 'comment_created': datetime.datetime(2023, 8, 18, 11, 31, 40, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298351903, 'comment_body': ""My previous comment on this seems to have been lost in action (https://github.com/zephyrproject-rtos/zephyr/pull/59669#discussion_r1275834891),  but again, we should not be sending a SETTINGS frame as a response to the client's settings frame. To comply with the RFC, it should be sent as soon as connection is established (so when the preface indicates we deal with HTTP2, we should send it rightaway then)."", 'comment_created': datetime.datetime(2023, 8, 18, 11, 38, 44, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298353842, 'comment_body': ""I don't think I understand this part, WINDOW_UPDATE has nothing to do with headers."", 'comment_created': datetime.datetime(2023, 8, 18, 11, 41, 5, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1298371858, 'comment_body': ""This part was for h2c upgrade, it was a special case because it initially sent me a request using the HTTP/1.1 protocol, then upgraded to HTTP/2.0. I dont receive headers frame from it that's why I had to handle it request in different way"", 'comment_created': datetime.datetime(2023, 8, 18, 12, 2, 58, tzinfo=datetime.timezone.utc), 'commenter': 'Emna-Rekik', 'type': 'User'}, {'comment_id': 1298372371, 'comment_body': ""I tried to do this, but the client was blocked. I'll look into it further."", 'comment_created': datetime.datetime(2023, 8, 18, 12, 3, 35, tzinfo=datetime.timezone.utc), 'commenter': 'Emna-Rekik', 'type': 'User'}, {'comment_id': 1298398593, 'comment_body': ""So it seems that the client decided to send a frame control (WINDOW_UPDATE) frame first instead of a headers frame (which is perfectly fine according to RFC, WINDOW_UPDATE can be received at any time).\r\n\r\nIf you look into RFC (https://datatracker.ietf.org/doc/html/rfc9113#name-window_update) you'll see that each WINDOW_UPDATE frame, apart of the frame header, carries a 4 byte payload, which should be processed (consumed) in this state. So a proper approach in this case would be:\r\n* Check `ctx_client->offset` to see how many bytes we have in the buffer. If it's less than 4, return -EAGAIN, as we cannot read the entire `Window Size Increment` field (which is the frame payload) from the buffer. This should lead us back to `poll()`/`recv()` wchich will fill the buffer with a new stream data, once available.\r\n* In case there are more than 4 bytes in the buffer, we need to consume the payload, even if we don't implement flow control for now. Otherwise, you won't be able to parse the next frame header, as the payload will still be sitting in the buffer. So we need to call `memove()` and decrease `offset` by the payload size.\r\n* Only after this, we set the state back to `HTTP_FRAME_HEADER_STATE`, as the next data expected on the TCP stream is a frame header, and return. The control will be returned back to `handle_http_request()`, and as the state machine is  now in `HTTP_FRAME_HEADER_STATE`, it will attempt to parse the next frame header.\r\n\r\nSimilar approach should be taken to any other frame type, even if we don't fully implement/support them yet. So  PRIORITY, GO_AWAY, RST_STREAM etc., even if we don't parse the payload yet, we need to take it off the stream (consume it), to unblock processing of further frames."", 'comment_created': datetime.datetime(2023, 8, 18, 12, 32, 58, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1302892172, 'comment_body': ""Shouldn't this be part of the `subsys/net/...`? We want the http server code to load TLS credentials for users of the http server, don't we?\r\n\r\nI think the correct way to pass that information in would be using the `detail` argument for `HTTP_SERVICE_DEFINE()`, but really, the `detail` argument should be a pointer to implementation-defined compile-time-const `config` and / or mutable `data` struct."", 'comment_created': datetime.datetime(2023, 8, 23, 11, 42, 46, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302897803, 'comment_body': 'Why is this here, and not in `subsys/net/lib/http/http_server.c`? The http server library should contain the http server code. It should not be copy-pasted between tests', 'comment_created': datetime.datetime(2023, 8, 23, 11, 48, 12, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302899430, 'comment_body': ""I think it seems we're missing `HTTP_SERVICE_DEFINE()` and so on. Where is the service actually defined for this test?"", 'comment_created': datetime.datetime(2023, 8, 23, 11, 49, 50, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302903841, 'comment_body': '```suggestion\r\nZTEST(http_hpack, test_path)\r\n```', 'comment_created': datetime.datetime(2023, 8, 23, 11, 54, 2, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302904259, 'comment_body': '```suggestion\r\nZTEST(http_hpack, test_method)\r\n```', 'comment_created': datetime.datetime(2023, 8, 23, 11, 54, 25, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302904679, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2023, 8, 23, 11, 54, 47, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302905285, 'comment_body': '```suggestion\r\nZTEST_SUITE(table, NULL, NULL, NULL, NULL, NULL);\r\n```', 'comment_created': datetime.datetime(2023, 8, 23, 11, 55, 20, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302906273, 'comment_body': 'Why is this here, and not in `subsys/net/lib/http/http_server.c`? The http server library should contain the http server code. It should not be copy-pasted between tests', 'comment_created': datetime.datetime(2023, 8, 23, 11, 56, 14, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302911284, 'comment_body': '`HTTP_SERVER_HPACK_SIZE` here is actually incorrect, and I believe Robert pointed that out over a week ago. I believe the upper limit should be `HTTP_SERVER_HPACK_WWW_AUTHENTICATE`, inclusively.\r\n\r\nPlease use `uint32_t` instead of `int32_t`.', 'comment_created': datetime.datetime(2023, 8, 23, 12, 0, 56, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302911882, 'comment_body': '`HTTP_SERVER_HPACK_SIZE` here is actually incorrect, and I believe Robert pointed that out over a week ago. I believe the check should use `HTTP_SERVER_HPACK_WWW_AUTHENTICATE`.\r\n\r\nPlease use `uint32_t` instead of `int32_t`.', 'comment_created': datetime.datetime(2023, 8, 23, 12, 1, 27, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302913204, 'comment_body': 'remove the cast please. ', 'comment_created': datetime.datetime(2023, 8, 23, 12, 2, 38, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302913338, 'comment_body': 'remove the cast please', 'comment_created': datetime.datetime(2023, 8, 23, 12, 2, 46, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302919841, 'comment_body': 'This may be better to place in `http_parser.c` since it\'s really just parsing http requests using the ""public"" http_hpack API', 'comment_created': datetime.datetime(2023, 8, 23, 12, 9, 7, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302927410, 'comment_body': '```suggestion\r\n/* there may be a better way to do this... is it possible to use sizeof() with string literals? */\r\n/* not sure if the naming here could be better */\r\n#define _http_server_hpack_method_strlen 8\r\n#define _http_server_hpack_pack_strlen 6\r\n\r\n\tsize_t i = 0;\r\n```', 'comment_created': datetime.datetime(2023, 8, 23, 12, 15, 29, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302928275, 'comment_body': '```suggestion\r\n\t\t\t\tif (requested_data == HTTP_SERVER_HPACK_METHOD) {\r\n\t\t\t\t\treturn (char *)value + _http_server_hpack_method_strlen;\r\n\t\t\t\t} else if (requested_data == HTTP_SERVER_HPACK_PATH) {\r\n\t\t\t\t\treturn (char *)value + _http_server_hpack_path_strlen;\r\n\t\t\t\t}\r\n```', 'comment_created': datetime.datetime(2023, 8, 23, 12, 16, 14, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302929638, 'comment_body': ""This seems to be test-specific data in the generic http server code. I don't think it belongs here.\r\n"", 'comment_created': datetime.datetime(2023, 8, 23, 12, 17, 32, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302933988, 'comment_body': ""Just to reduce clutter, rather than to have `#ifdef`s everywhere, it probably makes sense to use `CONFIG_NET_SOCKETS_POSIX_NAMES` in `prj.conf` and to use regular POSIX names in `http_server.c` and elsewhere.\r\n\r\nIdeally, we would just use `CONFIG_POSIX_API`, but I believe that it is still incompatible with `CONFIG_ARCH_POSIX`.\r\n\r\nBuilding for Linux was really only supposed to be to get a jumpstart, so I don't even think we necessarily need to support that use case anymore."", 'comment_created': datetime.datetime(2023, 8, 23, 12, 21, 28, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302936505, 'comment_body': 'This should probably go into `http_service.h` and be properly namespaced - i.e.`HTTP_SERVICE_CA_CERT_TAG`..', 'comment_created': datetime.datetime(2023, 8, 23, 12, 23, 46, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302940704, 'comment_body': 'This should use the ""host"" field specified via `HTTP_SERVICE_DEFINE()`.', 'comment_created': datetime.datetime(2023, 8, 23, 12, 27, 14, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302944818, 'comment_body': 'Why is a test-specific resource (""/result"") hard-coded in the generic http server library code?\r\n\r\nThe http_server in it\'s present state very much lacks a **CRITICAL** piece of functionality - i.e. ""routing"" a request to a handler based on the name and other application-specific properties of the resource.\r\n\r\nResources must be defined using `HTTP_RESOURCE_DEFINE()`. This will place all http resources into [Iterable Sections](https://docs.zephyrproject.org/latest/kernel/iterable_sections/index.html).\r\n\r\nThat is the only way that the server can reasonably expect to iterate over a collection (array) of resources that are declared in separate compilation units.\r\n\r\nThere are already test cases demonstrating how that is done.\r\n\r\nThe idea is to iterate over each resource associated with a particular service (defined by `HTTP_SERVICE_DEFINE()`). The resource ""path"" can then be compared with the http request path, etc...', 'comment_created': datetime.datetime(2023, 8, 23, 12, 31, 4, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302945345, 'comment_body': 'Again, why is an application-specific resource (""/"") hard-coded in the http_server library code?', 'comment_created': datetime.datetime(2023, 8, 23, 12, 31, 33, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1302956742, 'comment_body': 'again, why do we have a hard-coded application-specific path in the generic http server code? \r\n\r\nSee ""routing"" comments earlier', 'comment_created': datetime.datetime(2023, 8, 23, 12, 41, 16, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1303010421, 'comment_body': ""I don't think we'll get to the mutual authentication, I think that for now it'd be enough to focus on the server certificate/priv key pair."", 'comment_created': datetime.datetime(2023, 8, 23, 13, 19, 26, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1303034317, 'comment_body': ""This is service-specific code, shouldn't be part of the HTTP server header."", 'comment_created': datetime.datetime(2023, 8, 23, 13, 36, 15, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1303062549, 'comment_body': ""This section does not seem correct here - we should enter `HTTP_SERVER_FRAME_HEADERS_STATE` unconditionally, currently if there's no END_HEADERS/STREAM flag, we'll break the stream (HPACK headers are ignored).\r\n\r\nThe flag check should take place **after** we're done parsing all of the HEADERS frame content (that's why we store flags in `current_frame` structure, so we can reference this information in other states). \r\n\r\n"", 'comment_created': datetime.datetime(2023, 8, 23, 13, 55, 11, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1303098089, 'comment_body': 'We cannot assume we\'ll fit entire frame payload into the buffer, this imposes a serious limitation (I remind you that the minimum frame size we have to support is 16k of bytes, and there\'s no way around it as it\'s the minimum specified by the RFC).\r\n\r\nThat\'s why I suggested that `http_hpack_parse_header` needs to be reworked (https://github.com/zephyrproject-rtos/zephyr/pull/59669#discussion_r1296070668). We should not be requesting the function to find a header in the buffer, instead, it should parse a single header (next in the buffer).\r\n\r\nThe function should:\r\n * return -EAGAIN if the header is not yet complete (for compressed headers it simple, as its a single byte only, but literal headers need to check for name length and value length fields to determine whether the header is complete)\r\n * if complete, return the header contents (strings) by filling user provided buffers (that would be the simplest approach). \r\n * The function could return number of bytes parsed, or a negative error code in case of parsing errors. \r\n \r\n And of course, once header has been parsed, we should ""consume"" the bytes from the buffer (`memmove()`) and decrease `current_frame->length` by the number of bytes consumed. Tracking `current_frame->length` allows us to detect, when there are no more headers to be expected (i. e. we\'ve parsed the entire frame, `current_frame->length == 0`).', 'comment_created': datetime.datetime(2023, 8, 23, 14, 20, 23, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1303135761, 'comment_body': ""Relating to my previous comment about flags parsing, we should check `current_frame->flags` after we've parsed the entire frame content (so `current_frame->length == 0`). In such case:\r\n* If **no** END_HEADERS flag is present, this means a CONTINUATION frame is expected - we should set a bool in the stream context that we expect CONTINUATION frame, and check it when we parse the next frame header - if any other frame arrives for a stream, it should be treated as an error.\r\n* If END_STREAM flag is present, we should be sending the response. Hovewer, there's a caveat here - in case of END_STREAM and **no** END_HEADERS flags combination, we should wait for the CONTINUATION frame before sending the reply (we may not have all info needed yet, for example URI could be sent in the CONTINUATION frame). Therefore, again we should be keeping the information that client closed the stream in the stream context structure, and sending the reply **after** getting the final CONTINUATION frame with END_HEADERS flag.\r\n* And finally if END_HEADERS is present and **no** END_STREAM is present, no action is needed yet - this means that client sent all of the headers, but will also be sending DATA frame (which should contain END_STREAM flag). Only then we should be sending reply.\r\n\r\n"", 'comment_created': datetime.datetime(2023, 8, 23, 14, 46, 25, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1303137521, 'comment_body': 'CONTINUATION frame should be handled similarily to HEADERS frame - it carries additional HPACK headers.', 'comment_created': datetime.datetime(2023, 8, 23, 14, 47, 41, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1304213537, 'comment_body': ""> We cannot assume we'll fit entire frame payload into the buffer, this imposes a serious limitation (I remind you that the minimum frame size we have to support is 16k of bytes, and there's no way around it as it's the minimum specified by the RFC).\r\n\r\nWe might be able to get away with explicitly listing that as a deviation in e.g. docs, Kconfig. I would shy away from a runtime warning, but potentially a compile-time warning would be nice.\r\n\r\nNothing should prevent end users / system designers / product makers from configuring 16k on systems that have sufficient memory, but we can likely get away with far less."", 'comment_created': datetime.datetime(2023, 8, 24, 11, 55, 45, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1304215459, 'comment_body': ""I agree - it's definitely better to parse the http request in a step that is separate from acting on the http request.\r\n\r\nIn an asynchronous design, the parsing step / state could even be revisited multiple times before moving to the next state."", 'comment_created': datetime.datetime(2023, 8, 24, 11, 57, 29, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307358666, 'comment_body': 'this seems to be very application-specific. Why is it part of the generic server?', 'comment_created': datetime.datetime(2023, 8, 28, 12, 26, 28, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307360417, 'comment_body': 'this seems to be some state that should probably be part of an http request detail, rather than a global variable.', 'comment_created': datetime.datetime(2023, 8, 28, 12, 28, 11, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307368102, 'comment_body': 'I think the point of the HTTP server supporting CRiMe, is that we want the server to serve the compressed resource and we want to obtain the resource via an HTTP GET request.\r\n\r\nThis test does not exercise any HTTP server code paths at all, from what I can tell.', 'comment_created': datetime.datetime(2023, 8, 28, 12, 35, 52, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307368894, 'comment_body': 'An HTTP service should be defined as well as one or more static HTTP resources. While some custom endpoints might require a custom handler, serving compressed static resources should have a default handler built-in to the server.', 'comment_created': datetime.datetime(2023, 8, 28, 12, 36, 42, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307372943, 'comment_body': 'The HTTP Server should define its own thread stack, I would assume.\r\n\r\nReally, the application should just be defining resources, metadata, and potentially custom handlers.', 'comment_created': datetime.datetime(2023, 8, 28, 12, 40, 45, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307374473, 'comment_body': 'Is it possible to use the existing http client library to perform a get request?', 'comment_created': datetime.datetime(2023, 8, 28, 12, 42, 13, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307376275, 'comment_body': 'the server thread should really be an implementation detail in `subsys/net/.../http_server.c`', 'comment_created': datetime.datetime(2023, 8, 28, 12, 44, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1307377763, 'comment_body': 'this should be a part of the http server implementation not the app?', 'comment_created': datetime.datetime(2023, 8, 28, 12, 45, 22, tzinfo=datetime.timezone.utc), 'commenter': 'cfriedt', 'type': 'User'}, {'comment_id': 1308965306, 'comment_body': ""`printf()` shouldn't be mixed with LOG macros, use `LOG_HEXDUMP_DBG()` instead."", 'comment_created': datetime.datetime(2023, 8, 29, 14, 56, 16, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1308968917, 'comment_body': 'REST type resource is not static, there should have a separate struct defined for it.', 'comment_created': datetime.datetime(2023, 8, 29, 14, 58, 51, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1308971193, 'comment_body': ""Any details related to a particular service shouldn't be a part of a generic HTTP server codebase."", 'comment_created': datetime.datetime(2023, 8, 29, 15, 0, 28, tzinfo=datetime.timezone.utc), 'commenter': 'rlubos', 'type': 'User'}, {'comment_id': 1335472381, 'comment_body': ""Isn't this an issue if there is more than 1 service? The `server_fd` member will have the value of the last socket, which is an issue for accepting new clients."", 'comment_created': datetime.datetime(2023, 9, 25, 7, 9, 42, tzinfo=datetime.timezone.utc), 'commenter': 'pdgendt', 'type': 'User'}]","[{'commit_sha': 'b17e7ac29f85696609884cf5b8dfd6d2dec8ec0b', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cb27186940ec40628ab8d57dc75e601c07201110', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f2316956df0568113e998628e9e53c117ac11b94', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '41a6274895e076f8a683e630e61f5e5fecdb933d', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e6af2bd253d8f4e1e4d47df98d5c152f79c15715', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2a5b77362aa368fcb5741bfdd298cc85e913d858', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4158fd603d0a73cbdd28aa5e53e92b07a809f8c', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f97a20993123567d6ecdf9383c5158614f44edc2', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0f4df8fa48c901258687dc5a286cbe4579c522d3', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4a25696e57a39ca3c0e36ee233ce4b9a38d9e878', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '08dbe8ae33d0f0a2f0cd593c203d48f2e4cb120f', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '21e945f22639844759b89c7fce048ce56afcdaf5', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '90cd9b50528950b18ea8add5b07a761ad625044d', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2de2989768298f9b7e8330ff74b747c1ac5ff8fc', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ce8ced45fe63a45b1d98f1a65c5a0b90f1fdf264', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '96f4306eceeb3313f70cdf98522cffe18f4aa7d6', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6dedfa0cdd0eb628573199bf36281f59cd12733d', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4514f5856d0cc5ea96a8323f004417fa9f7fa4e', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5281de614945db025f556b868d88f052f6c9d273', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9fa167a2008d2f14d402ba47101401f57656b80', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e40e8a9ef261b86e13fa0c08dbaafb25bc28632', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4b6e1405e0c38c321b3ed2a2077ad8f7e4f736e', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '95ce02a7f259440d512873bd92332e80139aed62', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c24193018cd90e2b429b074e20fccd3fc3fce58d', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e030abedfd45543f22a8fbf03699b028c3019aec', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a49e5c5bd808986ce420cc186b8dfec073879de3', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4fd132ee2a69f97eb3d3ff6bf95c10d357e061db', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '76f183261d8e42d7eddd4ac4ac6a3e0b22fbc5f7', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '03ac200de3f3a9354e4253a6bb14bde8b2fbf15e', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd277b5503dc50f7b157aa9043d642fadd36bc273', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5c5033347756c5be96324be440ef86b3920ebcc8', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e6922be65a6643cc468de582cc3c23fb006f6f18', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '156a4e32e93b61ac91f32e6e02202e5ec7587325', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c2eed4c7642297768defac9569cfbce473459f9b', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4b7051a677b18fac39785f3dedece046ba411b9c', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7d716a85932fac382b544121f46d9946b13d646d', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '44871e19b74c7e61d955ae0aee2bce47928304b9', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7bcc4ec7f8718d801cfea69d700a5c0b1deb4f01', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0e5a4eb6cded7006ed0eaa44b274283d457b9317', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f53668137548910f1b0390403092e9ef7ee54dac', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ab212337c914e506b7a11e2f35c69895fad91ea6', 'committer_username': 'Emna-Rekik', 'committer_name': 'Emna Rekik', 'committer_email': None, 'commit_date': datetime.datetime(2021, 9, 1, 9, 52, 12, tzinfo=datetime.timezone.utc)}]",Emna Rekik,89909599,,User,,11,,0,1

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
59771425,zephyr,zephyrproject-rtos/zephyr,C,6337,10348,406,2731,100667,2665,112,888,"[{'id': 1404939570, 'number': 59669, 'closed': datetime.datetime(2023, 10, 26, 19, 56, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 23, 11, 45, 9, tzinfo=datetime.timezone.utc), 'time_taken': 10829510.0, 'time_delta': '125 days, 8:11:50', 'additions': 3915, 'deletions': 3, 'state': 'closed'}, {'id': 1383138912, 'number': 59032, 'closed': datetime.datetime(2023, 7, 21, 10, 42, 20, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 7, 18, 0, 41, tzinfo=datetime.timezone.utc), 'time_taken': 3775299.0, 'time_delta': '43 days, 16:41:39', 'additions': 165, 'deletions': 0, 'state': 'closed'}]"

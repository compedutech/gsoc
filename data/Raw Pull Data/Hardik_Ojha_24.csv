pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
463969021,Add aggregation example,"Add aggregation example to test the aggregation feature (which is in development mode).

This feature will be introduced via [#336](https://github.com/glotzerlab/signac-flow/pull/336)",True,15,https://api.github.com/repos/glotzerlab/signac-examples/pulls/15,https://github.com/glotzerlab/signac-examples/pull/15,closed,376,8,2,14,18,4,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-08-06 11:33:25+00:00,2021-10-09 16:42:55+00:00,37084170.0,"429 days, 5:09:30","[{'comment_id': 467496404, 'comment_body': 'I would add comments or something in the text that explains how each of these decorators work', 'comment_created': datetime.datetime(2020, 8, 8, 19, 26, 52, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 467496983, 'comment_body': ' add display(project) here for clarity', 'comment_created': datetime.datetime(2020, 8, 8, 19, 34, 32, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 475928247, 'comment_body': ""<p>Since this is a tutorial, it should explain a little about how <code>make_aggregates</code> works. What is <code>aggregates</code>, and how is it generated from the 2 arguments that got passed to <code>make_aggregates</code>? </p><p> </p><p>Edit: I guess what I'm getting at is that it should be easy for someone to look at this and know how to apply it to their own project.</p>\n<br/>\n\n _Reply via <a href='https://app.reviewnb.com/glotzerlab/signac-examples/pull/15/discussion/'>ReviewNB</a>_ <div id='ReviewNBCommentContext-DoNotDelete' style='display:none' data-state='OPEN' data-cellIndex='11'/>"", 'comment_created': datetime.datetime(2020, 8, 24, 22, 25, 15, tzinfo=datetime.timezone.utc), 'commenter': 'tcmoore3', 'type': 'User'}, {'comment_id': 479665085, 'comment_body': ""Yes, that's true. I'll add the explaination"", 'comment_created': datetime.datetime(2020, 8, 29, 16, 19, 12, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}]","[{'commit_sha': 'a08251e5df8bf83db41dc75ce43f1d503c7437f0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '56c7031810319275fcc9860bd2b99d74c60a1836', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '548f63ecec6f22381aaf7eaf1e4b64f5b11a8fcc', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8543e9713b3f4269cff6ae58ee030798a4c61a45', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'da085cac3228446af8dec2365c77b427fcaa8f71', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf4c2c5d308e95957b02d8ea4838aa6d0c071719', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4853b92dc3df6a025c6f3eae60753e351add635d', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9782f20cedef0d358e4f231cb94136f23255e48a', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5a4d62e6a22e923a6eafe44030f41fddf0a452c6', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a5a1eefed6d86bfa654919458169ba5278cc3954', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd17900b39f15a33abf8a6468b0880e775dd273fa', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bff39a6af844b99164c94d97546928fd3d8a442b', 'committer_username': 'pre-commit-ci[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2020, 6, 13, 0, 9, 59, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1178f4255596f781ba8cc6322c305576c16e436f', 'committer_username': 'pre-commit-ci[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2020, 6, 13, 0, 9, 59, tzinfo=datetime.timezone.utc)}, {'commit_sha': '665ab430c627c495082f63207ac6cb8fcb4dc4ed', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
442300907,Make FlowCondition class private,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
This pull request makes the `FlowCondition` class private.

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Since the `FlowCondition` class is not user-facing hence it needs to be private.
Resolves #307 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,315,https://api.github.com/repos/glotzerlab/signac-flow/pulls/315,https://github.com/glotzerlab/signac-flow/pull/315,closed,10,7,2,4,6,0,1,1,[{'name': 'GSoC'}],2020-06-30 21:19:45+00:00,2020-07-09 20:57:08+00:00,776243.0,"8 days, 23:37:23",[],"[{'commit_sha': '5a4d7b7b876d54ca771a5cc68cb68478ff18b4c9', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '004ebc8f5f4da4dfab408e4b3ba03355dbb7a230', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'edf4ec27a0bfb027c375a4f656a976fa9dba0ae4', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fae29b775871ee796be7569ec47b7979b9cc6df1', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
452200957,Make FlowOperation Callable,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Removes the internal logic:
```
if isinstance(op, FlowCmdOperation):
    func = op._cmd
else:
    func = self._operation_functions[op_name]
```

Replace the above with:
```
if isinstance(op, FlowCmdOperation):
    func = op._cmd
else:
    func = op._op_func
```
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Resolves #308 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,326,https://api.github.com/repos/glotzerlab/signac-flow/pulls/326,https://github.com/glotzerlab/signac-flow/pull/326,closed,18,17,1,3,3,3,1,1,[{'name': 'GSoC'}],2020-07-18 23:22:51+00:00,2020-07-22 20:29:50+00:00,335219.0,"3 days, 21:06:59","[{'comment_id': 457544298, 'comment_body': 'There is no need for the `try` `except` block any more.', 'comment_created': datetime.datetime(2020, 7, 20, 16, 36, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 457567645, 'comment_body': '@b-butler I removed the block.', 'comment_created': datetime.datetime(2020, 7, 20, 17, 16, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 458399241, 'comment_body': '```suggestion\r\n            # The operation function is of an instance of FlowCmdOperation:\r\n```', 'comment_created': datetime.datetime(2020, 7, 21, 21, 29, 14, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}]","[{'commit_sha': '8b204a00524bbd739882d4f69b2d3761f4ab90f7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '91d343bf9b5f3e04df30efe8c3787c48a1156f8e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '77268c3221c1f566fb9a997b533134ea5866611c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
452170276,Deprecate JobOperation and the methods which uses its instances ,"<!-- Provide a general summary of your changes in the Title above -->
## Description
<!-- Describe your changes in detail -->
This PR deprecates the class `JobOperation` and the methods which use the `JobOperation` instances as their parameters.
User is warned via a deprecation warning.

Made SubmissionJobOperation private without any deprecation because this class is not exposed anywhere to the user.

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Resolves #313 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [x] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,325,https://api.github.com/repos/glotzerlab/signac-flow/pulls/325,https://github.com/glotzerlab/signac-flow/pull/325,closed,201,72,3,20,5,27,1,1,[{'name': 'GSoC'}],2020-07-18 22:09:52+00:00,2020-07-27 20:31:31+00:00,771699.0,"8 days, 22:21:39","[{'comment_id': 456833096, 'comment_body': '```suggestion\r\n        The id of this JobOperation instance. The id should be unique.\r\n```', 'comment_created': datetime.datetime(2020, 7, 18, 22, 14, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456833102, 'comment_body': '```suggestion\r\n        The name of the JobOperation.\r\n```', 'comment_created': datetime.datetime(2020, 7, 18, 22, 14, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 457616367, 'comment_body': ""We don't need the underscore here, we don't plan on having even an internal function here."", 'comment_created': datetime.datetime(2020, 7, 20, 18, 42, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 457617705, 'comment_body': '```suggestion\r\nclass JobOperation(_JobOperation):\r\n```\r\n\r\nThis will allow the class name to remain the same while moving all the functionality to a private class.', 'comment_created': datetime.datetime(2020, 7, 20, 18, 44, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 457620081, 'comment_body': 'Never mind, we use the `deprecation` rather than `deprecated` Python package. The `deprecated` package offers a wrapper that works with classes as well rather than just methods and functions.', 'comment_created': datetime.datetime(2020, 7, 20, 18, 49, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 457636149, 'comment_body': ""@b-butler I didn't understand your comment, can you please clarify? Currently `script` uses `JobOperation` instance and I think that we should deprecate `script`."", 'comment_created': datetime.datetime(2020, 7, 20, 19, 18, 25, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 457658125, 'comment_body': ""We should, but we don't need an internal function since we will just remove both when the user facing function is removed."", 'comment_created': datetime.datetime(2020, 7, 20, 20, 0, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 457730054, 'comment_body': ""This suggestion should work fine. Did you try it and find that it didn't? For instance:\r\n\r\n```\r\n>>> from deprecation import deprecated\r\n>>> @deprecated()\r\n... class Foo():\r\n...     pass\r\n...\r\n>>> Foo()\r\n<stdin>:1: DeprecatedWarning: Foo is deprecated\r\n<__main__.Foo object at 0x7fdd6fcf9fa0>\r\n```"", 'comment_created': datetime.datetime(2020, 7, 20, 22, 36, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 458724511, 'comment_body': '@b-butler \r\nThis internal function is used for the command `python project.py script`.\r\nRemoving the internal function means that are we planning to remove the command line argument, `script`?', 'comment_created': datetime.datetime(2020, 7, 22, 11, 30, 39, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 458782387, 'comment_body': ""See the discussion on #311. The appropriate solution is to have the script CLI call the underlying `submit` API (temporarily mocking the environment as `StandardEnvironment`). In the interest of keeping PRs small, though I'd be fine with adding this underscore function in this PR and then making a follow-up PR where you refactor the CLI script call to not rely on this method anymore. Does that make sense? @b-butler let me know if I missed something here, but if not, then I think no further changes are needed in this PR."", 'comment_created': datetime.datetime(2020, 7, 22, 13, 15, 56, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 459747853, 'comment_body': 'That is fine for now then since we have an issue.', 'comment_created': datetime.datetime(2020, 7, 23, 21, 49, 59, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 459748776, 'comment_body': 'I would just make `JobOperation` inherit from `_JobOperation` then it should work without the need to keep all the code in two places.', 'comment_created': datetime.datetime(2020, 7, 23, 21, 52, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 459750075, 'comment_body': '@b-butler I tried that but this code gives an error that super method requires a class \r\nnot a function.\r\n`super(JobOperation, self).__init__(*args)`\r\n\r\n[UPDATE]\r\nIt works fine if I manually specify the arguments', 'comment_created': datetime.datetime(2020, 7, 23, 21, 55, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 459751142, 'comment_body': '```suggestion\r\n            Sequence of instances of :class:`.JobOperation`\r\n```\r\nPublic facing methods even with deprecation should reference the public class even if that is also deprecated.', 'comment_created': datetime.datetime(2020, 7, 23, 21, 57, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 459752439, 'comment_body': '```suggestion\r\n            A sequence of instances of :py:class:`.JobOperation`\r\n```', 'comment_created': datetime.datetime(2020, 7, 23, 22, 0, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 459753878, 'comment_body': 'Here we do return `_JobOperation` objects. I am not sure what the policy here is, @vyasr. We could transform from `_JobOperation` to `JobOperation` but that seems like too much work.', 'comment_created': datetime.datetime(2020, 7, 23, 22, 4, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 459754129, 'comment_body': 'Just use the `_next_operations` function no need to wrap in `pytest.deprecated_call`.', 'comment_created': datetime.datetime(2020, 7, 23, 22, 4, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 459754345, 'comment_body': ""Isn't this deprecated now?\r\n"", 'comment_created': datetime.datetime(2020, 7, 23, 22, 5, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460050353, 'comment_body': 'I think as long as JobOperation exists and is deprecated but not removed, that transformation is unfortunately probably necessary.', 'comment_created': datetime.datetime(2020, 7, 24, 13, 25, 48, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 460077462, 'comment_body': ""Okay, that makes sense. @kidrahahjo It might be easiest to use the existing `_JobOperation` object's data to create corresponding `JobOperation` objects."", 'comment_created': datetime.datetime(2020, 7, 24, 14, 11, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460083258, 'comment_body': 'It worked locally for me. Don\'t use super just do\r\n````python\r\n@deprecated(...)\r\nclass JobOperation(_JobOperation):\r\n    """"""Docstring here.""""""\r\n    pass\r\n````', 'comment_created': datetime.datetime(2020, 7, 24, 14, 20, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460145662, 'comment_body': 'We still have the `__init__` method which is also unnecessary.', 'comment_created': datetime.datetime(2020, 7, 24, 16, 2, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460912893, 'comment_body': 'It will be deprecated in `0.11`\r\n```suggestion\r\n    @deprecated(deprecated_in=""0.11"", removed_in=""0.13"", current_version=__version__)\r\n```', 'comment_created': datetime.datetime(2020, 7, 27, 14, 2, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460915293, 'comment_body': 'We need to this to also transform `_JobOperation` objects into `JobOperation` objects. This should be doable as the necessary information is stored in the `_JobOperation` objects.', 'comment_created': datetime.datetime(2020, 7, 27, 14, 6, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460920250, 'comment_body': 'This can be resolved by not returning `self._next_operations(arugements)` but rather we could copy the code and in `next_operations` we should yield JobOperation(op.name, op.id, op.job, ...)`', 'comment_created': datetime.datetime(2020, 7, 27, 14, 13, 28, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 460925994, 'comment_body': 'That works too. I am fine with either solution.', 'comment_created': datetime.datetime(2020, 7, 27, 14, 21, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 461129469, 'comment_body': ""The docstring should be inherited if you don't do anything to change it\r\n\r\n```suggestion\r\n    pass\r\n```"", 'comment_created': datetime.datetime(2020, 7, 27, 19, 49, 35, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}]","[{'commit_sha': '203330769d2a8795b6a9fb61c2355dce818fd704', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '742e0971c629c9d9a4224342bea07142c1bcda28', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '78fb9c0565407e548254cc83cbea7ae96f56d8c0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0a09149de60681e964b3e207576e1630c308e6b0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1f379206a848a9c4cdcf8fbd457ea90e4a2cb9e5', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '472014dccd47ee05d0c7f6edd82e28b88ba9891f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b25c6fbd3104197b3f534bd4bb4b3bc3b558f3bb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '355bf7177cbb8a532df787e389f48da743de2273', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e2bedc58a5f14da0400caa3de0497660a5d3d504', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c23dfdadf9c1c8b8aa171d56475679467d9d4988', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5a72688ba5e41116244d5e56e2831e1c4b56a679', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ce8d29f69bc9d3deda76d72347be05b4d6e60197', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ae73fb6ebb7c5da6f408d1a02e67612520c3184f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '663daa89ddaaf19a110d2b02f2dff0d59312b37f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5dd1de8879c36da2da121a5f09e4afa06bd7446a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '54332cfd26b3c58044c2af70e279f560d3adee00', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f9898b6aa0a73e951f79e1010ea8e2053c589da6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '958ac9d746860e239f82531830a8df5049fcbf76', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eee876b6078692a4bad250f98db3d510fc971c79', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b39a98421fbb7a53e44348c33804e254c7683e62', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
465562071,Deprecate eligible and complete methods of FlowGroup and BaseFlowOper…,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
This pull request is deprecates the methods `FlowGroup.eligible`, `FlowGroup.complete`, `BaseFlowOperation.eligible`, `BaseFlowOperation.complete` from the user API.

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Suggested by @csadorf in #324 [comment](https://github.com/glotzerlab/signac-flow/pull/324#discussion_r467845326)
## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [ ] New feature
- [x] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [x] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,337,https://api.github.com/repos/glotzerlab/signac-flow/pulls/337,https://github.com/glotzerlab/signac-flow/pull/337,closed,76,18,3,2,0,0,0,1,[],2020-08-10 15:11:28+00:00,2020-08-10 15:51:44+00:00,2416.0,0:40:16,[],"[{'commit_sha': '05057cf5db74651218ae29b370a6529a393b6ff4', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5f1813ff57feb0db49b613460e0b9c08b7fde872', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
450158537,Enable aggregate logic in flow,"<!-- Provide a general summary of your changes in the Title above -->
Enabling aggregate logic in `flow` (enabling internal handling of lists) without any change in the API.

## Description
<!-- Describe your changes in detail -->
The original PR for enabling aggregate operations #289  is too large.
This PR reduces the scope of that PR by handling only aggregates of 1.

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Suggested by @glotzerlab/signac-gsoc-mentors 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,324,https://api.github.com/repos/glotzerlab/signac-flow/pulls/324,https://github.com/glotzerlab/signac-flow/pull/324,closed,316,194,2,38,14,194,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-07-16 12:31:10+00:00,2020-08-12 15:43:35+00:00,2344345.0,"27 days, 3:12:25","[{'comment_id': 455881297, 'comment_body': ""Is `num = 0` valid? I don't think that makes sense."", 'comment_created': datetime.datetime(2020, 7, 16, 15, 37, 58, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455881666, 'comment_body': ""I don't see what code is being copied from that webpage here. If you're just _using_ `zip_longest` then you don't need this comment."", 'comment_created': datetime.datetime(2020, 7, 16, 15, 38, 28, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455883599, 'comment_body': ""I think this will trigger `except Exception` and raise the `TypeError` instead. That isn't the desired behavior, consider catching something more specific than `Exception`."", 'comment_created': datetime.datetime(2020, 7, 16, 15, 41, 16, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455883814, 'comment_body': ""```suggestion\r\n                            'or an iterable of Jobs, got {}.'.format(type(obj)))\r\n```"", 'comment_created': datetime.datetime(2020, 7, 16, 15, 41, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455884941, 'comment_body': ""I think I'd prefer to make the class public in its original namespace, if we expose it as public here."", 'comment_created': datetime.datetime(2020, 7, 16, 15, 43, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455888661, 'comment_body': 'Should this be ""not any"" or ""not all""? I\'m not sure what users will expect here.\r\n\r\nIt might be worth adding a `not_any` condition if this one is designed to be ""not all"" but I think I would prefer to leave that to users to write a lambda function for what they really want.', 'comment_created': datetime.datetime(2020, 7, 16, 15, 48, 40, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455890229, 'comment_body': ""There's a function that returns the minimum number of characters for a unique id. Use that instead of hard coding 8. https://docs.signac.io/projects/core/en/latest/api.html#signac.Project.min_len_unique_id"", 'comment_created': datetime.datetime(2020, 7, 16, 15, 50, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455894077, 'comment_body': 'Is this part complete? I would think the status saving needs to be handled differently for aggregates.', 'comment_created': datetime.datetime(2020, 7, 16, 15, 56, 9, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455894431, 'comment_body': 'Does this need to be handled differently (or raise an error) for aggregates?', 'comment_created': datetime.datetime(2020, 7, 16, 15, 56, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455896830, 'comment_body': 'The parameter is actually `*jobs`, not `jobs`. However, if you just add an asterisk, Sphinx will interpret the asterisk as ""beginning bold text."" This is annoying, but you can fix it by changing this to a raw string (`r""""""`) and escaping the asterisk like this:\r\n\r\n```\r\nr""""""Docstring header.\r\n\r\n:param \\*jobs:\r\n    A list of signac job handles.\r\n:type \\*jobs:\r\n    list of :class:`~signac.contrib.job.Job`\r\n""""""\r\n```\r\nPlease use that pattern in all docstrings accepting `*jobs`.', 'comment_created': datetime.datetime(2020, 7, 16, 16, 0, 6, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456021300, 'comment_body': 'This is there only for backward compatibility. We might have to warn users to use `jobs` instead.', 'comment_created': datetime.datetime(2020, 7, 16, 19, 25, 58, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456021973, 'comment_body': ""It's not supposed to be 0. I will change the condition"", 'comment_created': datetime.datetime(2020, 7, 16, 19, 27, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456040104, 'comment_body': ""For now (if we allow only one job in an aggregate) I think it's complete. If you wan't I can start implementing the behaviour we discussion (storing the ids for status check)"", 'comment_created': datetime.datetime(2020, 7, 16, 19, 53, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456040265, 'comment_body': 'Thanks for the link', 'comment_created': datetime.datetime(2020, 7, 16, 19, 53, 48, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456043902, 'comment_body': ""Actually this is a documentation confusion.\r\n\r\n>    Evaluates to True if the provided condition function returns\r\nFalse when the jobs in the aggregate passed to the condition function.\r\n\r\nI'll edit the doc string\r\n"", 'comment_created': datetime.datetime(2020, 7, 16, 20, 0, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456110699, 'comment_body': ""I think it's fine to leave this for the current PR since it's 100% backwards compatible. We just need to track this carefully so that we change it in a future PR."", 'comment_created': datetime.datetime(2020, 7, 16, 22, 20, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456111562, 'comment_body': 'Even though this is for backwards compatibility, we might avoid user errors like this:\r\n```suggestion\r\n        if len(self.jobs) == 1:\r\n            return self.jobs[0]\r\n        else:\r\n            raise AttributeError(""This object holds multiple jobs. Use the jobs attribute instead."")\r\n```', 'comment_created': datetime.datetime(2020, 7, 16, 22, 22, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456128499, 'comment_body': ""Yes, I'll definitely track this carefully for future work."", 'comment_created': datetime.datetime(2020, 7, 16, 23, 12, 57, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456129037, 'comment_body': ""@bdice I think we should also raise a deprecation warning here. I'll make the changes after your approval for the warning."", 'comment_created': datetime.datetime(2020, 7, 16, 23, 14, 38, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456142930, 'comment_body': 'I would also recommend only having `num = int(num)` in the try block. This prevents catching undesired errors as well.', 'comment_created': datetime.datetime(2020, 7, 16, 23, 58, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456143451, 'comment_body': 'can we be more specific than the `obj` parameter.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 0, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456144633, 'comment_body': '```suggestion\r\n        if len(aggregated_jobs) == 0:\r\n            return []\r\n```\r\n\r\nThis is a bit more explicit.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 4, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456148312, 'comment_body': '@bdice this PR is designed to only change the internals. I would vote to keep this property for now, and then we can decide on what to do with this class later. We have an issue #313 about making this class private in general.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 17, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456148387, 'comment_body': 'Make this private for now.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 17, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456148625, 'comment_body': 'Also, since we internally use this class check if the `job` parameter is a list, so we can store it appropriately. I know this is a bit more of a hassle for now.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 18, 29, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456150953, 'comment_body': '```suggestion\r\n            return ""{}-{}: ({}-{})"".format(\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 0, 26, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456151227, 'comment_body': 'This is technically API breaking but that is fine for now.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 27, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456151817, 'comment_body': 'This does change the API of a user facing class and method. In this case, I am not sure what to do, but it is worth noting.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 29, 59, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456152071, 'comment_body': 'If this is only changing the internals, then this should not be exposed to the user yet.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 30, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456152328, 'comment_body': ""You can change the internal docs accordingly, but we shouldn't change the external docs to include aggregation."", 'comment_created': datetime.datetime(2020, 7, 17, 0, 31, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456152453, 'comment_body': 'No user facing yet.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 32, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456153447, 'comment_body': 'This will work, but we may want to think on this before the finish aggregation, as this could lead to a huge command line command depending on number of jobs.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 36, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456153708, 'comment_body': 'Is user facing, and the API changes. Once again, this may be unavoidable but noting it.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 37, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456153946, 'comment_body': ""docs don't need to change yet."", 'comment_created': datetime.datetime(2020, 7, 17, 0, 37, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456154125, 'comment_body': 'Should we just do this at the creation of the `FlowGroup`?', 'comment_created': datetime.datetime(2020, 7, 17, 0, 38, 28, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456154314, 'comment_body': 'This might be worth being a static method of the class. Something like `_verify_aggregate`.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 39, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456154429, 'comment_body': 'We only do it here and check in other places that require it through `_generate_id`.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 39, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456154686, 'comment_body': 'Is there a reason this is split into two lines now?', 'comment_created': datetime.datetime(2020, 7, 17, 0, 40, 35, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456155000, 'comment_body': 'As this is an internal function, we should never have this branch of the conditional be true, if we do that is an inconsistency in the internals.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 41, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456155145, 'comment_body': 'If it is already supposed to be a list, why do we convert to a list here?', 'comment_created': datetime.datetime(2020, 7, 17, 0, 42, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456155339, 'comment_body': 'See comment on `_create_submission_job_operations`.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 42, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456155482, 'comment_body': 'Centralizing this would be helpful.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 43, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456155560, 'comment_body': 'Aggregate should be internal not public.', 'comment_created': datetime.datetime(2020, 7, 17, 0, 43, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456157496, 'comment_body': ""This isn't related, but I don't think this is true any more."", 'comment_created': datetime.datetime(2020, 7, 17, 0, 50, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 456291101, 'comment_body': 'This logic is to support multiple aggregations associated with an operation (if it also there in some group).\r\nThis is not necessary for now, but I think this is the right way to do it)', 'comment_created': datetime.datetime(2020, 7, 17, 8, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456617929, 'comment_body': 'Will insert an assert statement', 'comment_created': datetime.datetime(2020, 7, 17, 18, 52, 10, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456621589, 'comment_body': 'I changed the way we printed `id` but then realized that it may not be something we should change in this PR. Forgot to change it back to the original state, will do it now.\r\nThank you for pointing out ', 'comment_created': datetime.datetime(2020, 7, 17, 18, 59, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456623817, 'comment_body': ""This means then I'd have to edit the tests."", 'comment_created': datetime.datetime(2020, 7, 17, 19, 4, 43, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456624666, 'comment_body': 'Should I make a separate PR for this?', 'comment_created': datetime.datetime(2020, 7, 17, 19, 6, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456771127, 'comment_body': '@b-butler I personally think a custom error will be helpful ', 'comment_created': datetime.datetime(2020, 7, 18, 9, 31, 47, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 460148833, 'comment_body': 'This is just to note that we will need to move the deprecation of `JobOperation` first. We will then need to give `JobOperation` the ability to take in a single job for backwards compatibility.', 'comment_created': datetime.datetime(2020, 7, 24, 16, 8, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460222573, 'comment_body': 'This is also changing behavior, it is fine since this will be mostly internal, just marking it, since we will need to change it for `JobOperation` not `_JobOperation` per #325', 'comment_created': datetime.datetime(2020, 7, 24, 18, 34, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460222803, 'comment_body': 'This will only need to be implemented on `JobOperation` in #325', 'comment_created': datetime.datetime(2020, 7, 24, 18, 34, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460223354, 'comment_body': 'This is incorrect.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 35, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460224689, 'comment_body': ""This is technically a breaking change. I don't think we use `job=None` anywhere internally though. We do need to change this to work with list of jobs though. Maybe just use `(self, *jobs)`. This allows no jobs to be passed. Then we just do `return self._cmd(*jobs).format(*jobs)`. If we want to catch `None` then we could check the list length."", 'comment_created': datetime.datetime(2020, 7, 24, 18, 38, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460225122, 'comment_body': 'This also may be a good reason to deprecate the call method of `FlowOperation` so as to not need to keep the signature valid between versions.\r\n\r\nEdit: I am not referring to removing the functionality, just not making it available to the user.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 39, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460227133, 'comment_body': 'This function should take one aggregate not create them.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 44, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460227358, 'comment_body': 'It may be worth doing that, and we could just merge right away. No need for a changelog even.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 44, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460229129, 'comment_body': 'This for loop should still exist, it should just yield lists of jobs.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 48, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460229678, 'comment_body': '`job` should be a list of jobs here.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 49, 51, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460230288, 'comment_body': 'This still has to have the same behavior as before since it is user facing. The changes will exist though in private method that takes over this functionality #325.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 51, 8, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460231136, 'comment_body': 'This sentence does not make sense any more.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 53, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460533019, 'comment_body': 'The `aggregate` parameter, when associated with a group, will have that behaviour. \r\nBut for now, I think passing [job] in should be enough.', 'comment_created': datetime.datetime(2020, 7, 26, 14, 15, 40, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 460544669, 'comment_body': 'Addressed in #327. I will merge that PR.', 'comment_created': datetime.datetime(2020, 7, 26, 16, 7, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 461611870, 'comment_body': 'remove extra line', 'comment_created': datetime.datetime(2020, 7, 28, 14, 12, 20, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 461650325, 'comment_body': ""For this and the below instances where this happens: why is it okay to return just the first job, and why doesn't this cause problems when different aggregates both start with the same job? (if this has been discussed somewhere else, just point me to that conversation)\r\n"", 'comment_created': datetime.datetime(2020, 7, 28, 14, 58, 24, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 461684479, 'comment_body': 'I dont understand why we need to pass [job] in as a list? Would this be better if handled in `_create_run_job_operations()`?\r\n', 'comment_created': datetime.datetime(2020, 7, 28, 15, 45, 42, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 461689297, 'comment_body': ""The plan is to pass in a single aggregate (which is a list of jobs) to every internal method. Since we're currently dealing with aggregates of 1 in this PR and all the internal methods (of `FlowGroup`) now take a list of jobs, I thought that to maintain consistency, we should to pass `[job]` instead of `job`."", 'comment_created': datetime.datetime(2020, 7, 28, 15, 52, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 461692532, 'comment_body': ""This is meant to be only implemented in `JobOperation` and not `_JobOperation`. I thought if I implemented it in `_JobOperation` then the test wouldn't have to be changed.\r\nAs suggested by @b-butler in a previous comment (which I accidentally forgot to address) I should remove this from `_JobOperation` and implement it only in `JobOperation` (Where we only take a single job as an argument)."", 'comment_created': datetime.datetime(2020, 7, 28, 15, 56, 48, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 463641709, 'comment_body': 'Forget the deprecation comment for now, we do need to use `*jobs` here though. We should do the `None` check mentioned in the first comment and give users a deprecation warning when they pass in `None`.', 'comment_created': datetime.datetime(2020, 7, 31, 14, 23, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 463644670, 'comment_body': 'In the aggregation PR proper, I think it may be worth adding a command line option something like `--aggregate [aggregate_id, ]` where we would read in the file that contains the definitions of submitted aggregates.', 'comment_created': datetime.datetime(2020, 7, 31, 14, 29, 9, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 463653056, 'comment_body': '@atravitz The plan is as Hardik says to prepare for general aggregation with this PR. For internal methods we always want to deal with lists of jobs (or generators or sequences in general), as this simplifies the code and prevents `isinstance` checks everywhere. Right now though this does not do anything since we are artificially moving everything internally to sequences without adding any real aggregation.', 'comment_created': datetime.datetime(2020, 7, 31, 14, 43, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 463657418, 'comment_body': 'So you mean something like `for job_list in group.aggregate(jobs)`?', 'comment_created': datetime.datetime(2020, 7, 31, 14, 50, 59, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 463662711, 'comment_body': ""This is loosely related to the PR, but given the recent internalization of `_next_operations` we should use a list rather than the `*list` syntax. If you don't feel it is related enough, you could make another PR doing this. I know this was the previous behavior, but I think it is more consistent to use a list here now looking at the rest of the code.\r\n\r\nGiven aggregation though, will `_next_operations` even be used? If this ends up not being useful in aggregation, we could just remove it altogether when `next_operations` is deprecated."", 'comment_created': datetime.datetime(2020, 7, 31, 14, 59, 59, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 463686149, 'comment_body': 'This is not user facing, we should use `jobs`.', 'comment_created': datetime.datetime(2020, 7, 31, 15, 42, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 463753283, 'comment_body': ""I think this is related to this PR in some manner. I'll change this in this PR only.\r\nAlso, yes, `_next_operation` is used in `_get_pending_operations` and `_main_next`. I think we should keep this method as for the CLA `next` it'll show all the aggregates which are eligible for an operation."", 'comment_created': datetime.datetime(2020, 7, 31, 18, 1, 3, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 463754162, 'comment_body': 'Noted. Thanks for the suggestion. ', 'comment_created': datetime.datetime(2020, 7, 31, 18, 3, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464176328, 'comment_body': 'Change docstring to be consistent with refactoring.\r\n```suggestion\r\n        """"""Returns ``not condition(*jobs)`` for the provided condition function.""""""\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 3, 28, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464176957, 'comment_body': ""Why only lists? Inputs of tuples or generators aren't allowed? Converting to a tuple internally might actually be better since it's immutable (immutability ensures it's safer, and though performance isn't an important consideration here, `tuple` is more efficient than `list` since it doesn't have to be dynamic).\r\n```suggestion\r\n        self._jobs = tuple(jobs)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 3, 3, 31, 53, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464178061, 'comment_body': 'This isn\'t necessarily unique. (Could have another aggregate with the same number of jobs and same first/last jobs.) Does that matter? I don\'t know where the `str` is used. Also you don\'t have to provide a starting index of 0 when slicing:\r\n```suggestion\r\n            return ""{}-{}: ({}-{})"".format(\r\n                self.name, len(self._jobs), str(self._jobs[0])[:minimum],\r\n                str(self._jobs[-1])[:minimum])\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 3, 37, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464178312, 'comment_body': 'What is ""This""? Clarify that it\'s the command (not the `JobOperation` object).\r\n```suggestion\r\n    executable command. The shell executable command won\'t be used if it is determined that the group can be\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 3, 38, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464178691, 'comment_body': '```suggestion\r\n        The command that executes this operation. Can be a callable that when\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 3, 40, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464179026, 'comment_body': 'Use ""job(s)"" to indicate ""one or more jobs.""\r\n```suggestion\r\n                \'for job(s) {jobs}.\'.format(name=self._callback.__name__,\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 3, 42, 9, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464179090, 'comment_body': ""Comma-separate lists of jobs when printing them to an output.\r\n```suggestion\r\n                                         jobs=', '.join(map(str, jobs)))) from e\r\n```"", 'comment_created': datetime.datetime(2020, 8, 3, 3, 42, 28, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464179469, 'comment_body': 'If you\'re not using `*jobs` then this doesn\'t have to be a raw string.\r\n```suggestion\r\n        """"""Eligible, when all pre-conditions are true and at least one post-condition is false,\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 3, 44, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464180117, 'comment_body': ""`nr*nt` doesn't work if `nr` or `nt` are lists (or whatever `nranks(*jobs)` returns). I'm not sure if changing that should go into this PR or a subsequent PR."", 'comment_created': datetime.datetime(2020, 8, 3, 3, 47, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464180680, 'comment_body': '@b-butler @kidrahahjo In practice I don\'t think that a large number of job ids will be a significant problem here. It might make for messy ""--pretend"" output but it will almost certainly work as intended. Schedulers can handle large input scripts with no problems. The change you\'re suggesting would require logic for parsing an aggregate id into a list of jobs, which sounds like unnecessary work to me. Could be ""nice to have"" someday but that is not something I would prioritize. Since there\'s still plenty to do this summer, maybe it\'s best to just document this in an issue as a potential improvement for the future.', 'comment_created': datetime.datetime(2020, 8, 3, 3, 50, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464181323, 'comment_body': 'One counterpoint that would make me reconsider the ""priority"" is if we decide that an aggregate is more than ""a list of jobs."" If the aggregate has a meaningful name, for instance, that means we have to inject two pieces of metadata via the command line (aggregate name *and* the list of jobs) which might be easier to parse from the stored aggregate info, located by the aggregate id.', 'comment_created': datetime.datetime(2020, 8, 3, 3, 54, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464181632, 'comment_body': '```suggestion\r\n            Specify if pre and/or post conditions are to be ignored while checking eligibility.\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 3, 55, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464181808, 'comment_body': ""This doesn't match the signature (`jobs` vs. `*jobs`)."", 'comment_created': datetime.datetime(2020, 8, 3, 3, 56, 22, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464182072, 'comment_body': 'Fix type.', 'comment_created': datetime.datetime(2020, 8, 3, 3, 57, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464183116, 'comment_body': ""I am having a bit of difficulty determining if this code will work correctly with large aggregates. Please make sure to check that this code behaves as you expect for large aggregates. The part I'm confused about is the section involving `MAX_LEN_ID` and how it interacts with the parts above and below (whether we have the appropriate guarantees on uniqueness of scheduler ids)."", 'comment_created': datetime.datetime(2020, 8, 3, 4, 2, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464183589, 'comment_body': ""`signac.Job` is not the correct namespace of the class. It should be `signac.contrib.job.Job`. I think this is a mistake that has spread through the docstrings, so you may have copied it from somewhere else that was also wrong. Please fix this everywhere it occurs in this PR (this is the first case I've caught).\r\n```suggestion\r\n            list of :class:`signac.contrib.job.Job`\r\n```"", 'comment_created': datetime.datetime(2020, 8, 3, 4, 5, 7, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464185071, 'comment_body': ""What is this replacing? I'm not sure I know what the old code was meant for."", 'comment_created': datetime.datetime(2020, 8, 3, 4, 12, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464342960, 'comment_body': '@bdice this is a user-facing function and I think we decided in the meeting not to change any user-facing API in this PR.', 'comment_created': datetime.datetime(2020, 8, 3, 11, 0, 44, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464344487, 'comment_body': 'This is a user-facing error message and should be edited in #306 ', 'comment_created': datetime.datetime(2020, 8, 3, 11, 4, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464347098, 'comment_body': ""I too wasn't sure how to go about that because I didn't find any code that sets the `_flow_aggregate` attribute for an operation."", 'comment_created': datetime.datetime(2020, 8, 3, 11, 10, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464348508, 'comment_body': ""`nranks` as defined [here](https://github.com/glotzerlab/signac-flow/pull/283/files#diff-dd7774bb5ebcb1df3843a90e78c026a7R257) is _The number of MPI ranks to use for this operation._\r\nI thought that it'd always return an Integer (Given any number of jobs we pass if it's a callable)"", 'comment_created': datetime.datetime(2020, 8, 3, 11, 14, 20, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464352117, 'comment_body': ""I thought `job_op_id` is of constant length for any number of jobs in aggregate.\r\nWe calculate the job_op_id in this way\r\n```\r\n    full_name = '{}%{}%{}%{}'.format(project.root_directory(),\r\n                                     '-'.join(map(str, jobs)),\r\n                                     op_string,\r\n                                     index)\r\n    job_op_id = calc_id(full_name)\r\n```\r\nBut still, I'll check and let you know the results."", 'comment_created': datetime.datetime(2020, 8, 3, 11, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464355311, 'comment_body': 'A user will be able to return aggregates or yield them in any type. We internally convert those generators/Iterables to ""nested list""\r\nThis was discussed earlier too but for now, I think consistency should be the key. For example, internally, if we use lists somewhere then we\'ll be using list throughout the code.\r\nIf @b-butler agrees, I\'ll be happy to change lists to tuples.', 'comment_created': datetime.datetime(2020, 8, 3, 11, 30, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464357217, 'comment_body': ""Yes, I agree that this isn't unique.\r\nShould we also provide `_JobOperation.id` so that users could look up in the `.aggregates/` directory to get details of specific aggregate for an operation?"", 'comment_created': datetime.datetime(2020, 8, 3, 11, 34, 59, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464359668, 'comment_body': ""We'll be storing the submission id of the aggregate in the `.aggregates/` directory which is not introduced yet but will be introduced in [#kidrahahjo/signac-flow/2](https://github.com/kidrahahjo/signac-flow/pull/2).\r\nI think that will be enough for a meta-data?"", 'comment_created': datetime.datetime(2020, 8, 3, 11, 40, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464360690, 'comment_body': ""Moreover, I think this should be addressed in #306 as we're not yet dealing with Aggregates in this PR. "", 'comment_created': datetime.datetime(2020, 8, 3, 11, 42, 47, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464995082, 'comment_body': 'It works fine for an aggregate of length 100k. ', 'comment_created': datetime.datetime(2020, 8, 4, 11, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 466455917, 'comment_body': ""If you want an input to be a `list`, it's better to _convert to a list_ than to just _assert that it is a list_. That's why I think `self._jobs = list(jobs)` (conversion, not assertion) is the right approach.\r\n\r\nChanging to `tuple` is a separate question. I think it would be the better choice from a data structure perspective -- the aggregate's jobs should be immutable, and as a secondary consideration, `tuple` is almost always faster than `list`."", 'comment_created': datetime.datetime(2020, 8, 6, 14, 31, 1, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 466456797, 'comment_body': 'Yes, especially if that makes it unique.', 'comment_created': datetime.datetime(2020, 8, 6, 14, 32, 9, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 466460346, 'comment_body': 'Sorry if this was unclear -- my actual question is ""What does `nranks(job1, job2, job3)` return?"" Does it return a list of integers (ranks for each job)? If it returns a list, then `nr` is a list. If you have `nr = [4, 2, 8]` and `nt = [1, 1, 1]`, then you have a problem because lists can\'t be multiplied (NumPy arrays _can_ be multiplied but I don\'t want to use NumPy here).', 'comment_created': datetime.datetime(2020, 8, 6, 14, 37, 16, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 466463049, 'comment_body': ""@csadorf It looks like you wrote this line around version 0.6.0. I don't see any other code referencing it, so I think it must be safe to delete?"", 'comment_created': datetime.datetime(2020, 8, 6, 14, 41, 13, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 466470152, 'comment_body': ""I don't think a list of MPI ranks should be returned here, it should only return an integer. \r\n@b-butler please suggest."", 'comment_created': datetime.datetime(2020, 8, 6, 14, 51, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 466697475, 'comment_body': ""I don't know how this code snuck onto master, but it was added as part of the original push for aggregation, see [this line](https://github.com/glotzerlab/signac-flow/pull/52/files#diff-bc465f25a5bed755976338a6fd0e34ceR186) from #52. At the time we were working actively on getting the decorator syntax etc into shape, so this line probably accidentally made its way into one of those PRs."", 'comment_created': datetime.datetime(2020, 8, 6, 21, 31, 29, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 467496705, 'comment_body': ""@bdice I gave this a thought and I don't think that we'll need this to be unique.\r\nSince `_JobOperation` is private hence users will never be able to print it by themselves.\r\nMoreover, this is mainly used in scripts and we already print the script in this manner\r\n\r\n```\r\nSubmitting cluster job 'playing-with/ee5ca9ab-6704a2f9/50/compute_sum/0000/c7033c1762ed0658882bc75c23dda4d5':\r\n - Group: compute_sum-50: (ee5-670)\r\n```\r\n Which makes a submission of `_JobOperation` readable as well as unique."", 'comment_created': datetime.datetime(2020, 8, 8, 19, 31, 6, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467826453, 'comment_body': 'But we are not changing the API, we are just accurately describing what the function does?', 'comment_created': datetime.datetime(2020, 8, 10, 10, 55, 31, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467828658, 'comment_body': ""I agree with @bdice that a `tuple` is likely the preferred data structure, but I don't agree that *converting is better than asserting* since the former triggers a potential copy operation. Since this is an internal class we can make certain assumptions about the passed arguments and the way to explicitly declare those assumptions would be to use an `assert` as was done here."", 'comment_created': datetime.datetime(2020, 8, 10, 11, 0, 33, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467829078, 'comment_body': ""I'd prefer to use f-strings whenever possible (readability + performance)."", 'comment_created': datetime.datetime(2020, 8, 10, 11, 1, 36, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467830066, 'comment_body': 'I keep repeating that I\'d like to treat all operations as similar as possible and that the ""classic single-argument"" operations are simply aggregate operations of size 1. This should be reflected here as well and I would very much prefer to use the same representation of the class for size 1 and larger. Having a fundamentally different representation for size 1 is unexpected and will likely cause a lot of confusion.\r\n\r\nThis is not a trivial issue, ensuring that users (and developers!) understand that there is nothing fundamentally different about an aggregate operation of size 1 is crucial for a good understanding of the code logic and ultimately usage.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 3, 50, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467831567, 'comment_body': ""Are the jobs sorted in some way? What if the order changes? Are we still able to retrieve this? I think I'd prefer to store this in the project-doc."", 'comment_created': datetime.datetime(2020, 8, 10, 11, 6, 53, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467831630, 'comment_body': 'Same question as above.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 7, 2, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467831790, 'comment_body': '```suggestion\r\n    The execution or submission of a :py:class:`FlowGroup` uses a passed-in command\r\n```\r\n?', 'comment_created': datetime.datetime(2020, 8, 10, 11, 7, 21, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467832108, 'comment_body': 'Why? No duck-typing allowed?', 'comment_created': datetime.datetime(2020, 8, 10, 11, 8, 2, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467832486, 'comment_body': 'Both the function itself as well as the comment appear outdated?', 'comment_created': datetime.datetime(2020, 8, 10, 11, 9, 3, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467832811, 'comment_body': 'I am a bit confused by this PR. I thought the whole point was to internally refactor to use lists instead of single job arguments in preparation for aggregation, but then some classes are somehow supporting only a single job? Can you briefly elaborate on this?', 'comment_created': datetime.datetime(2020, 8, 10, 11, 9, 50, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467833962, 'comment_body': 'I thought we had agreed that condition functions have signature `cond(*jobs)`?', 'comment_created': datetime.datetime(2020, 8, 10, 11, 12, 17, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467834043, 'comment_body': 'Same as above.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 12, 27, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467834220, 'comment_body': 'Same as above.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 12, 54, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467836154, 'comment_body': 'I think you want something like this:\r\n```suggestion\r\n    def __call__(self, *jobs, **kwargs):\r\n        job = kwargs.pop(\'job\', None)\r\n        if kwargs:\r\n            raise ValueError(f""Invalid key-word arguments: {\', \'.join(kwargs)}"")\r\n        if job is not None:\r\n            warnings.warn(...)\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 11, 17, 38, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467836384, 'comment_body': '```suggestion\r\n        # We are assuming that all the jobs belong to the same project\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 11, 18, 9, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467836749, 'comment_body': 'I think it should be an integer.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 19, 4, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467838256, 'comment_body': 'Please use f-strings.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 21, 31, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467838718, 'comment_body': 'This id does not seem sufficiently unique to me.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 22, 35, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467840220, 'comment_body': 'Looks like left-over code, probably safe to delete.', 'comment_created': datetime.datetime(2020, 8, 10, 11, 25, 53, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467845326, 'comment_body': ""This is not a pure refactoring PR, because this changes public API. I'd have preferred to have that separated out."", 'comment_created': datetime.datetime(2020, 8, 10, 11, 37, 29, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467875808, 'comment_body': ""@csadorf  I'm just trying not to change any documentation here.\r\nI think we should do all the documentation change in #336 as we'll have to change a lot of documentation in that PR.\r\n"", 'comment_created': datetime.datetime(2020, 8, 10, 12, 42, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467876333, 'comment_body': ""Thanks for this suggestion. I'll use f-strings whenever possible."", 'comment_created': datetime.datetime(2020, 8, 10, 12, 43, 12, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467877129, 'comment_body': ""That's a nice point. \r\nThanks for this!"", 'comment_created': datetime.datetime(2020, 8, 10, 12, 44, 43, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467892102, 'comment_body': ""Since we're not yet introducing the actual aggregation, I don't think there is a strong reason to implement this for this PR. The reason behind my comment is that storing is only helpful for status-check and I have implemented this is #335.\r\nThis PR only changes the internal workflow logic."", 'comment_created': datetime.datetime(2020, 8, 10, 13, 11, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467892431, 'comment_body': 'Addressed [here](https://github.com/glotzerlab/signac-flow/pull/324#discussion_r467892102)', 'comment_created': datetime.datetime(2020, 8, 10, 13, 12, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467897662, 'comment_body': ""This comment here is not outdated.\r\nWe deprecated `JobOperation` in #325 and we copied the property method `job` from `JobOperation` into `_JobOperation`.\r\nWe don't have the attribute `_job` in `JobOperation` anymore. Instead we now have `_jobs` hence to maintain backwards compatibility, this method was implemented. \r\nPlease Note: We don't need the property method `job` for `_JobOperation` (as we don't expose `_JobOperation` to users) hence I moved that method to `JobOperation`.\r\n\r\n"", 'comment_created': datetime.datetime(2020, 8, 10, 13, 20, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467900351, 'comment_body': 'While converting everything internally as a list of jobs, we have to make sure that we maintain backwards compatibility.\r\nThis means that all the methods which are public in the API and takes a single job as an argument should continue with the same behaviour.', 'comment_created': datetime.datetime(2020, 8, 10, 13, 24, 20, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467902245, 'comment_body': 'This method is internal hence we pass in a list of jobs here.\r\nAs `_FlowCondition` is also internal, @b-butler suggested me to pass in a list of jobs while calling `_FlowCondition` and then unpack the value while passing the jobs to the function.', 'comment_created': datetime.datetime(2020, 8, 10, 13, 27, 19, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467902452, 'comment_body': 'Addressed [here](https://github.com/glotzerlab/signac-flow/pull/324#discussion_r467902245)', 'comment_created': datetime.datetime(2020, 8, 10, 13, 27, 40, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467902816, 'comment_body': 'Addressed [here](https://github.com/glotzerlab/signac-flow/pull/324#discussion_r467902245)', 'comment_created': datetime.datetime(2020, 8, 10, 13, 28, 15, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467903756, 'comment_body': ""Ok, that's fine. Can you add an in-code comment so that it is easier to keep track of this?"", 'comment_created': datetime.datetime(2020, 8, 10, 13, 29, 47, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467904277, 'comment_body': '👍 ', 'comment_created': datetime.datetime(2020, 8, 10, 13, 30, 34, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467904438, 'comment_body': '👍 ', 'comment_created': datetime.datetime(2020, 8, 10, 13, 30, 48, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467904583, 'comment_body': '👍 ', 'comment_created': datetime.datetime(2020, 8, 10, 13, 31, 2, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467906196, 'comment_body': 'I don\'t think that it\'s necessary for this particular id to be unique.\r\nThis is used for the ""readable"" part of the ID. We will store every aggregate associated with jobs in #335 hence if users want, they can look up aggregates associated with that particular id in the `.aggregates/` directory', 'comment_created': datetime.datetime(2020, 8, 10, 13, 33, 30, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467907699, 'comment_body': 'This is a nice point. \r\nI can make a PR today which deprecates `eligible` and `complete` methods of `FlowGroup` and `BaseFlowOperation`', 'comment_created': datetime.datetime(2020, 8, 10, 13, 35, 50, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467908254, 'comment_body': ""I'll do that. Thank you for suggesting this"", 'comment_created': datetime.datetime(2020, 8, 10, 13, 36, 45, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467912113, 'comment_body': ""I don't have any problem with going with duck-typing. I'll make the change.\r\nThanks for suggesting this."", 'comment_created': datetime.datetime(2020, 8, 10, 13, 42, 26, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467916086, 'comment_body': 'I was not aware of #335, however in that case this variable name is misleading. An id is by definition describing the *identity*, so it **must** be unique. If this string is describing something else, then that should be reflected in the semantics here. However, I see no reason why we are not showing the actual id here?', 'comment_created': datetime.datetime(2020, 8, 10, 13, 48, 34, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467916594, 'comment_body': ""If that's not too hard to do, then I think that would be good and we can simply rebase this branch here."", 'comment_created': datetime.datetime(2020, 8, 10, 13, 49, 23, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467916943, 'comment_body': ""This is not a really hard decision to make, but can you please suggest me whether I should, for now, not check the length of jobs as I'm sure that it'll always be one?"", 'comment_created': datetime.datetime(2020, 8, 10, 13, 49, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467922546, 'comment_body': 'I can remove the substring part of the job in jobs(`[:8]`) and instead use the full job id, but if we decide to include all the job ids then this will get way too long for large aggregates.', 'comment_created': datetime.datetime(2020, 8, 10, 13, 58, 15, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 467930867, 'comment_body': 'Add `assert len(self._jobs) == 1` here and then remove it once you need to drop that assertion in a different change set.', 'comment_created': datetime.datetime(2020, 8, 10, 14, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467932023, 'comment_body': ""Please reread my comment. If it is not necessary for this to be an id, that's fine, but then please do not call it *id*."", 'comment_created': datetime.datetime(2020, 8, 10, 14, 12, 29, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 467978041, 'comment_body': ""If we want to use tuples for immutability which makes sense here we would want the structure of aggregation to be a generator or list of aggregate tuples. I don't have a strong preference for the assert. Ideally we wouldn't need an assert or explicit conversion."", 'comment_created': datetime.datetime(2020, 8, 10, 15, 18, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467978967, 'comment_body': ""This is an internal class we don't need the `len == 1` assumption. We could use this in `JobOperation` though."", 'comment_created': datetime.datetime(2020, 8, 10, 15, 19, 29, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467980238, 'comment_body': '@kidrahahjo I would make a note to do a grep through project.py for `job` for changing in #306. Otherwise, these will be easy to miss.', 'comment_created': datetime.datetime(2020, 8, 10, 15, 21, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467981170, 'comment_body': '```suggestion\r\n            warnings.warn(""The job keyword argument is deprecated as of 0.11 and will be removed ""\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 15, 22, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467982733, 'comment_body': ""I concur. We should return an integer. An aggregate operation is a singular operation that has a singular resource requirement (partitioning the resources internally is the user's responsibility)."", 'comment_created': datetime.datetime(2020, 8, 10, 15, 25, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467984821, 'comment_body': ""@kidrahahjo Bradley is referring to meta data is more than just the list of job ids. @bdice I do agree this is not a problem in the script working (long lines are not going to freeze up the scheduler). However, it would get inconvenient for users to look at their scripts. I am okay with waiting on this (I planned on doing that for this PR anyways), but I think raising an issue is important so we don't lose track of this."", 'comment_created': datetime.datetime(2020, 8, 10, 15, 28, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467988493, 'comment_body': 'This could raise errors if single jobs are not accepted for a group correct? I know that this will not be a problem in this PR, but in the future it could be. I imagine this function is to be removed or unused in the status check PR? If so, than this is fine for now; otherwise, we need to change the function to work with aggregates of jobs.', 'comment_created': datetime.datetime(2020, 8, 10, 15, 32, 32, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467991539, 'comment_body': 'Make a tuple. I would use a generator and the tuple function.', 'comment_created': datetime.datetime(2020, 8, 10, 15, 34, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467992675, 'comment_body': ""You don't need to in this PR in my opinion, but this is another example of us needing to change `job` to `jobs` in a future PR."", 'comment_created': datetime.datetime(2020, 8, 10, 15, 35, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467994693, 'comment_body': 'Given the internal nature of `_JobOperation` now this is likely not necessary once `JobOperation` is deprecated completely.\r\n\r\nI would make a developer comment regarding that for the future.', 'comment_created': datetime.datetime(2020, 8, 10, 15, 37, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 467999527, 'comment_body': 'If we change to tuples we need to change this docstring.', 'comment_created': datetime.datetime(2020, 8, 10, 15, 41, 9, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468008579, 'comment_body': ""You're right."", 'comment_created': datetime.datetime(2020, 8, 10, 15, 54, 17, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468054871, 'comment_body': 'After we include actual aggregation, this will have to change to something like.\r\n`f""{self.name}-{len(self._jobs)}: ({str(self._jobs[0])}-{str(self._jobs[-1])})""` for every aggregate (even for length 1).\r\n\r\nPlease see this [comment](https://github.com/glotzerlab/signac-flow/pull/324#discussion_r467830066) by @csadorf \r\n', 'comment_created': datetime.datetime(2020, 8, 10, 17, 12, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468056031, 'comment_body': ""@b-butler  I'm not sure I completely follow what you suggest here.\r\nCan you please help me understand?"", 'comment_created': datetime.datetime(2020, 8, 10, 17, 14, 42, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468057390, 'comment_body': ""This is not the case because we're going to iterate over `group.aggregate(jobs)` in #336 which will always raise an error if and only if the users have failed to specify the function parameters for the conditions correctly."", 'comment_created': datetime.datetime(2020, 8, 10, 17, 17, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468058431, 'comment_body': 'I have inserted a command `assert len(operation._jobs) == 1` above and throughout the codebase.\r\nThis was suggested by @csadorf so we know that what things we have to change when we include actual aggregation.', 'comment_created': datetime.datetime(2020, 8, 10, 17, 19, 3, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468088460, 'comment_body': 'I am aware. I more mean, we can do that now given this is an internal class now. We just need this behavior for `JobOperation`', 'comment_created': datetime.datetime(2020, 8, 10, 18, 12, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468089402, 'comment_body': 'Okay, as long as this is changed there.', 'comment_created': datetime.datetime(2020, 8, 10, 18, 14, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468090128, 'comment_body': ""That only works with testing as well. We won't raise the assert until we actually test aggregation, but that does help. This wasn't really an issue just an example."", 'comment_created': datetime.datetime(2020, 8, 10, 18, 15, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468091950, 'comment_body': ""Actually, I am wrong on the point above. However, I would look for where users supply jobs in the API, (e.g. `FlowProject.submit` and such) and place the verification there. I don't think we would ever be in an internal state where the jobs we gather internally that don't belong to the same project."", 'comment_created': datetime.datetime(2020, 8, 10, 18, 19, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468094490, 'comment_body': ""@b-butler If we do this, I'll have to change the template-reference-data twice(once here and another in #334 )\r\nThis will result in a lot of additional work.\r\nI think this should be addressed in #334 "", 'comment_created': datetime.datetime(2020, 8, 10, 18, 24, 3, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468122344, 'comment_body': ""This is for code security. If the team want me to remove it, I'll do that."", 'comment_created': datetime.datetime(2020, 8, 10, 19, 16, 39, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468176205, 'comment_body': 'Why are we using `JobOperation` rather than `_JobOperation`?', 'comment_created': datetime.datetime(2020, 8, 10, 20, 46, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468185796, 'comment_body': 'I think I accidentally did this', 'comment_created': datetime.datetime(2020, 8, 10, 21, 6, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468348337, 'comment_body': 'Since this is an internal class, I believe it is perfectly fine to expect a specific container type here.', 'comment_created': datetime.datetime(2020, 8, 11, 6, 12, 28, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468348764, 'comment_body': 'The assert should be in place wherever we actually make that assumption. Once that assumption is removed (e.g. in #334), the asserts will automatically alert us to spots in the code that require a revised implementation.', 'comment_created': datetime.datetime(2020, 8, 11, 6, 13, 52, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468349223, 'comment_body': 'Does this even work? The `__repr__` return value should be able to be used in `eval()` like this: `new_foo == eval(repr(foo))`.', 'comment_created': datetime.datetime(2020, 8, 11, 6, 15, 12, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468350314, 'comment_body': 'You marked this conversation as resolved, yet this is still not an f-string?', 'comment_created': datetime.datetime(2020, 8, 11, 6, 18, 8, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468451532, 'comment_body': ""@csadorf I apologize. I wrote a comment but instead of posting, I must have clicked resolved. I'll take care of this from the next time.\r\nThe comment was: \r\nThroughout the code-base, we don't use f-strings. Instead, we format the strings in this manner `'{name}-{operation}'.format(name=name, operation=op_name)`.\r\nI understand that using f-strings will be more efficient here but I think we should be consistent.\r\nIf you want, I'll use an f-string in this PR or I will make another PR which will internally convert all the string formatting to f-strings formatting to maintain consistency.\r\nPlease suggest"", 'comment_created': datetime.datetime(2020, 8, 11, 9, 33, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468463830, 'comment_body': 'This should possibly get resolved by using `map(repr, self._jobs)`', 'comment_created': datetime.datetime(2020, 8, 11, 9, 55, 20, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468530794, 'comment_body': 'I think it is totally fine to prefer the use of f-strings moving forward even if we use `""..."".format()` in other sections of the code.', 'comment_created': datetime.datetime(2020, 8, 11, 12, 7, 55, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468532668, 'comment_body': 'Will make the changes now.', 'comment_created': datetime.datetime(2020, 8, 11, 12, 11, 30, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468635706, 'comment_body': '```suggestion\r\n        jobs = (job,)\r\n        super().__init__(id, name, job, cmd, directives)\r\n```', 'comment_created': datetime.datetime(2020, 8, 11, 14, 42, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468636471, 'comment_body': 'This check is unnecessary as it is internal.', 'comment_created': datetime.datetime(2020, 8, 11, 14, 43, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468662884, 'comment_body': '@b-butler \r\nSince aggregator function is user-facing.\r\nI think this check is necessary as user can yield jobs from a different project inside that method.', 'comment_created': datetime.datetime(2020, 8, 11, 15, 19, 17, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468663871, 'comment_body': 'After using a deprecated decorator, this class behaves like a method hence we have to manually define an init method', 'comment_created': datetime.datetime(2020, 8, 11, 15, 20, 26, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 468664637, 'comment_body': 'I had forgotten thanks for the reminder.', 'comment_created': datetime.datetime(2020, 8, 11, 15, 21, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468666468, 'comment_body': 'Is `_generate_id` the right place to check this though then? If we are worried about aggregation should we not check closer to the aggregation? Even if it requires the function in a couple more places, it will be more clear to the developer as to why the check exists in the first place.', 'comment_created': datetime.datetime(2020, 8, 11, 15, 23, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469355386, 'comment_body': 'Clarified via Slack, marking as resolved. I was misunderstanding this code. Thanks @csadorf @b-butler.', 'comment_created': datetime.datetime(2020, 8, 12, 15, 41, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}]","[{'commit_sha': '4eb97a0aa25bb1b6369496af2bee6f67994a8489', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '07c5e16afdf4517ce4da4ebb833984be1f75ea90', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5cc7912fb4592e95eed90c91e70e7d3ae7f58613', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b9c465566ea6fa26e4e62504999a89744c392153', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a7ca7e18bfb338f96298cc1f6f78c08232be79f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '15b79cfe961a2d57665c48a5e497ae1acd4bef35', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'df99e5046a204f52ed38bface0de8b5a8c8727e7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5f1e0607da1063f03f6d7232e32729afc089d471', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0a33a273b73c972dc944addbb220a3a7286d4d92', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6a379207b0a2f44ba6ccc5f8b2cc411bff428df6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '39b4a3c6cf32fe56eaa80cffe9b62cd084276c7a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7478f4dd3ba19250cbb99dcbfae03886b7563b18', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b5ba89fcc826d1267181b465ea9c44102f5a8197', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b07f7b1ac8bffdc0cfc1e80cab9bb0670e10cc8', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6da1cf1a5b39455485b1d9225792370df0c09a79', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eadb0319a7a685a9be8a1fd2eed161b3ec02cb6d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a2446e54cdf2fff1d1d027d4344e1ac1dc9c0838', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b937d46c7777566664645b3844f974092b6014a0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'be56b51ed6e537328c5170f5d0660a7c8769d7f6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f266987b1ceb0c75bad48c099bf6df248bbc6f6c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4f51e2979660e104a577b8a67a2b9d67a45034c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '729dca01c12e9691f6a6add85f6acae8fec68275', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0fd78b54775bfe56b3ec16e25811cc96d77d4180', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fab2f68b758f29856df59cdef1e7038b7dabdadc', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14f9fa98dbd848e170fdc82480b9284ebcdad451', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8dc5a9551970f2103b75c014d765089965b25d1d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd26aa802ad36a6b9dd381f7790cad90612df6f9', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6306c55c2aa03a7a0029463bbbe3406420b2d709', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '81054b3f8f942fcfde78bb2fd2cb1fae783eb22e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ba54b9ce6ce9c8181161227400c57c3602abbe29', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9181b27237648566639f000c5ecd77b9a973a8d0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e8518f5e2405800f7762f00c58b11b73a58307e0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3ab294ff3aee6fb86d59cbe1dea96e9d2a3f84a7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8338517d9f6031a91eaffc7a3c3e00747020e492', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd3f5f8f9fe997d0f582f9dc466406f6d81bef4a7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2333a633f9d92acd26a02b8bd796886d6b5e8b27', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '069657f811fed28bf390b6ce926d766affe57c9b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '417f0f200101c84f70b6fe596573ab8a0d26102c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
462611191,Change the submission ID for aggregate logic,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Changes submission id for aggregation support

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
This should get merged after #324

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [ ] New feature
- [x] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [ ] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,334,https://api.github.com/repos/glotzerlab/signac-flow/pulls/334,https://github.com/glotzerlab/signac-flow/pull/334,closed,12,8,2,5,6,14,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-08-04 08:24:49+00:00,2020-08-13 15:30:34+00:00,803145.0,"9 days, 7:05:45","[{'comment_id': 464886594, 'comment_body': 'Only this should get reviewed in this pull request.', 'comment_created': datetime.datetime(2020, 8, 4, 8, 28, 27, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464887440, 'comment_body': 'I will change the template reference data after this will get reviewed', 'comment_created': datetime.datetime(2020, 8, 4, 8, 29, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 469506680, 'comment_body': 'We print the length first in `_JobOperation.__str__`. I think that order makes sense here too.', 'comment_created': datetime.datetime(2020, 8, 12, 20, 0, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469506874, 'comment_body': 'This needs to be restricted to a length of `max_len`.', 'comment_created': datetime.datetime(2020, 8, 12, 20, 0, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469741056, 'comment_body': '```suggestion\r\n        assert len(self.jobs) > 0\r\n        max_len = 3\r\n        shown = self.jobs[:max_len-2] + [\'...\'] + self.jobs[-1:] if len(self.jobs) > max_len else self.jobs\r\n        return f""{self.name}[#{len(self.jobs)}]({\', \'.join([str(element)[:8] for element in shown])})""\r\n```\r\nI do not like this representation, because it is very unusual within the Python ecosystem. I would very much prefer to follow standard conventions here and use a representation that is inspired by the representation of large numpy arrays.\r\n```\r\nmy-op[#1](26021048)\r\nmy-op[#2](26021048, 42b7b4f2)\r\nmy-op[#3](26021048, 42b7b4f2, 44550aef)\r\nmy-op[#4](26021048, ..., 4b893796)\r\n```\r\nWe could even consider to omit the length indication (`#X`), since a user could always use `print(len(op))` to obtain that information. I am not sure how helpful that is in practice.\r\n\r\n---\r\nCode to generate above output:\r\n```python\r\nfrom dataclasses import dataclass\r\nfrom typing import List\r\n\r\nimport signac\r\n\r\n@dataclass\r\nclass AgOp:\r\n    name: str\r\n    jobs: List[signac.contrib.job.Job]\r\n\r\n    def __str__(self):\r\n        assert len(self.jobs) > 0\r\n        max_len = 3\r\n        shown = self.jobs[:max_len-2] + [\'...\'] + self.jobs[-1:] if len(self.jobs) > max_len else self.jobs\r\n        return f""{self.name}[#{len(self.jobs)}]({\', \'.join([str(element)[:8] for element in shown])})""\r\n\r\njobs = list(signac.get_project())\r\nfor i in range(min(4, len(jobs))):\r\n    print(AgOp(name=\'my-op\', jobs=jobs[:i+1]))\r\n```', 'comment_created': datetime.datetime(2020, 8, 13, 7, 7, 38, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469743653, 'comment_body': ""I've stared at this for a while and I believe this should be fine. It would have been helpful to add a sample of this to the review comments."", 'comment_created': datetime.datetime(2020, 8, 13, 7, 13, 11, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469758957, 'comment_body': '@csadorf yes, I should have posted a sample so that it becomes easy for a review. I apologise.', 'comment_created': datetime.datetime(2020, 8, 13, 7, 43, 44, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 469761401, 'comment_body': ""@csadorf we could drop the length part but since `_JobOperation` is private, I'm not sure how a user would know the length of it's instance"", 'comment_created': datetime.datetime(2020, 8, 13, 7, 48, 27, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 469763697, 'comment_body': ""I don't follow the logic. If this class is private why would any user care about `__str__` then?"", 'comment_created': datetime.datetime(2020, 8, 13, 7, 52, 30, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469764914, 'comment_body': ""@csadorf \r\nAlso, if you're talking about the jobs passed in the operation function then yes I agree that users could do that but if we provide a little information from our side then I guess it'll save an extra print statement from the users. Please suggest.\r\n\r\nRegarding the `__str__` method, this output is printed out in the scripts"", 'comment_created': datetime.datetime(2020, 8, 13, 7, 54, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 469769467, 'comment_body': ""Ok, so then let's keep the length indicator. Do you like my proposed representation otherwise?"", 'comment_created': datetime.datetime(2020, 8, 13, 8, 2, 45, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469769830, 'comment_body': ""Sorry, I should have phrased that differently: It's always helpful to provide some samples etc., but absolutely no need to apologize. 👍 "", 'comment_created': datetime.datetime(2020, 8, 13, 8, 3, 26, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469775033, 'comment_body': ""@csadorf Yes, your proposed indication is very good.\r\nAlso I think we should print the full job ids in this case and not limit it to 8 characters. I don't think the output will be too long for 3 jobs.\r\n@bdice once suggested me to use `min_len_unique_id` method. I could use that method if you agree."", 'comment_created': datetime.datetime(2020, 8, 13, 8, 12, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 469782169, 'comment_body': 'I think using `min_len_unique_id` would be ideal.', 'comment_created': datetime.datetime(2020, 8, 13, 8, 25, 14, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}]","[{'commit_sha': '1d5f6cc8596c66976b072d23407be49860b5d6d5', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a9d5b1a38702729b392e4b30aceb5be95e3aede7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd54eb51d7056b688706e2759df0354f9732ad161', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8b9d207f0ff4fe852516a9500274f7c959b66699', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a5cba1704a476e77b43f7fa581d83f73cc89d151', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
474066015,Add aggregator classes in flow,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Add aggregator classes to flow.
This pull request introduces a concept of storing the aggregates in an iterable class which will be then stored throughout the `FlowProject`
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
To be merged before #335 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [x] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,348,https://api.github.com/repos/glotzerlab/signac-flow/pulls/348,https://github.com/glotzerlab/signac-flow/pull/348,closed,761,0,2,22,4,187,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-08-26 18:00:18+00:00,2020-09-01 13:55:56+00:00,503738.0,"5 days, 19:55:38","[{'comment_id': 477537468, 'comment_body': 'Is yielding any iterable of jobs okay? or should we require tuples.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 26, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477540138, 'comment_body': 'This will fail with `functool.partial` objects or callable class objects. Also, I would put the cheaper (string and Boolean) comparisons first.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 31, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477542218, 'comment_body': 'I would prefer the class name `Aggregator` as it is not really an aggregate as we have defined it, but rather a definition of aggregation.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 35, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477545603, 'comment_body': 'Needs docstring', 'comment_created': datetime.datetime(2020, 8, 26, 19, 41, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477545676, 'comment_body': 'Needs docstring', 'comment_created': datetime.datetime(2020, 8, 26, 19, 42, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477546248, 'comment_body': 'Can be a docstring.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 43, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477546668, 'comment_body': ""Won't this create a `_StoreAggregates` class for each group/operation. there is no registry that I see."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 44, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477547561, 'comment_body': ""This is not the behavior we want. The aggregate store shouldn't be callable. We need a function to regenerate aggregates, but making an object callable says something about its behavior. Here calling is just to change the state of the object which is not the correct paradigm."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 45, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477547799, 'comment_body': 'Class should be `_AggregateStore` for classes it is typical to use nouns unless the class acts as a functor.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 46, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477548515, 'comment_body': ""When this object is created, I would want to see the aggregates be computed. Otherwise, it isn't really storing anything until after it is called. This would require that it takes an iterable of jobs (typically the project) as a constructor argument as well."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 47, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477548660, 'comment_body': 'Should be a standard method not `__call__`. Also make comment into one line docstring.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 47, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477551425, 'comment_body': 'Currently this class does not provide id indexing (`__getitem__`) or checking for inclusion (`__contains__`). I would like to see both these features. The same for `_StoreAggregatesDefault`.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 53, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477552186, 'comment_body': 'Since we have multiple classes that are serving as aggregate stores, it may be helpful to create a class `_AggregateStoreBase(Mapping)` that uses the `collections.abc.Mapping` class and additionally requires a `recompute_aggregates` method, plus any other functions deemed necessary.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 54, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477556518, 'comment_body': 'To use an object as a key in a dictionary it has to support `__hash__` and `__eq__`', 'comment_created': datetime.datetime(2020, 8, 26, 20, 2, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558152, 'comment_body': 'I would prefer using `hasattr` here.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 5, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558255, 'comment_body': 'Likewise', 'comment_created': datetime.datetime(2020, 8, 26, 20, 5, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558427, 'comment_body': 'hasattr', 'comment_created': datetime.datetime(2020, 8, 26, 20, 6, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558653, 'comment_body': 'Although different in terms of syntax used; this and the previous test are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 6, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477559838, 'comment_body': 'This is also unnecessary.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 9, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477561644, 'comment_body': '```suggestion\r\n        assert [tuple(project)] == list(aggregate_instance)\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 20, 12, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477562621, 'comment_body': ""It may be worth creating a helper function that does the comparison between a function's and an `_StoreAggregate`'s aggregates given a `FlowProject`."", 'comment_created': datetime.datetime(2020, 8, 26, 20, 14, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477563096, 'comment_body': 'We should also test that the size of each aggregate is correct.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 15, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477563438, 'comment_body': 'I would assert that all of the values for `job.sp.even` are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 16, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477564158, 'comment_body': 'I would likewise test that all the values of `job.sp.half` are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 17, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478283283, 'comment_body': ""I think we should be flexible in terms of users point of view.\r\nTo convert those into tuples, we're already converting those iterables into tuples in `_create_nested_aggregate_list`"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 29, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478285406, 'comment_body': ""I thought we'd require an `__eq__` method to put these object as keys in a dictionary but I learnt that we also require the objects to be hashable and it turns out we can uniquely hash these objects (partial functions, lambda functions, or normal functions).\r\nI'll also use `__hash__` here"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 33, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478286069, 'comment_body': 'This is technically breaking the API. Should I post this on slack for further discussion?', 'comment_created': datetime.datetime(2020, 8, 27, 9, 34, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478287693, 'comment_body': ""That is why we'll be using a `__hash__` method to uniquely identify a `_StoreAggregate` instance"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 37, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478288334, 'comment_body': ""I'll use a different method `_generate_aggregates` instead"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 38, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478295728, 'comment_body': 'Hmm, I see what you mean here.\r\nI also agree, will make the necessary changes', 'comment_created': datetime.datetime(2020, 8, 27, 9, 50, 16, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478426607, 'comment_body': 'Why are we mixing two different hash functions? I would prefer to be consistent (although we of course make no promises about this in our API).', 'comment_created': datetime.datetime(2020, 8, 27, 13, 39, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478431171, 'comment_body': 'Does our style have a preference on how import multiple objects from a module/package? If not, I would prefer to either do `from itertools import groupby, zip_longest`, or use fully qualified names everywhere else and just `import itertools` here. Importing `groupby` directly is going to cause cognitive dissonance for readers of the code since we internally define `Aggregate.groupby`.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 46, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478436334, 'comment_body': ""It is breaking an API that doesn't exist yet, so you can ask, but it isn't a breaking change."", 'comment_created': datetime.datetime(2020, 8, 27, 13, 53, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478436807, 'comment_body': 'I guess I am fine then.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 53, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478438579, 'comment_body': ""The API breaking is not a concern since none of this is released yet. Use whatever names you think are appropriate. However, in this case @kidrahahjo @b-butler be mindful of the fact that this class will be used as a decorator by users. For this reason, we may want to follow naming that would not normally be appropriate. For instance, consider that the `pre` and `post` condition classes are lowercased despite being classes, precisely for this reason, and similarly for directives. Decorators should _look like_ functions IMO; while this isn't written in any style guides, it's the rule we've followed in flow because that's more intuitive for users, and it supersedes the typical class naming rule.\r\n\r\nRegarding the actual name of the decorator, consider that the first argument to the constructor of this class is called `aggregator`; it seems awkward for an `Aggregator` to require an `aggregator`. I'm having trouble thinking of a better alternative right now, though; I'll post again if I think of something."", 'comment_created': datetime.datetime(2020, 8, 27, 13, 56, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478440082, 'comment_body': 'Add a comment or two explaining why we need to treat `groupsof(1)` (the default aggregate) differently.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 58, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478440737, 'comment_body': 'I would caution against just using hash for both `__eq__` and `__hash__`. If `hash(obj) == hash(other)` the equality method is used to differentiate between objects. Here if we use it for both we end up with no way to discern the objects.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 59, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478442318, 'comment_body': ""All of this error checking feels rather un-Pythonic to me. However, I can see a good reason for this here since none of these attributes will actually get used until downstream in the aggregation pipeline, at which point the errors would be much harder for users to interpret. @bdice you're usually the style police for EAFP (I'm of the opinion that both LBYL and EAFP have their place in Python, so I'm less opposed to this on principle), what do you think?"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 1, 25, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478443539, 'comment_body': ""I don't know if I've ever said this before, but there's actually too much white space and empty lines in this block (and in various other parts of the code) and it makes it less readable. In particular, there's a newline before every `elif` or `else` clause. Can you tighten some of that up?"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 3, 12, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478445900, 'comment_body': 'Just FYI @kidrahahjo both of these methods have default implementations for any class (e.g. `class A: pass` will have default versions of both methods defined), but I assume @b-butler wants you to define a meaningful equality check here.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 6, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478446662, 'comment_body': 'How will that prevent making a new one? It seems like you will create a new one anyway in `_create_StoreAggregates`.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 7, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478450955, 'comment_body': ""Can we just combine the classes? I'm not seeing much benefit to the separation. Especially if you change the `_StoreAggregates` class to compute the aggregates on construction, then both this and the `*Default` class can just store `self._aggregates` (which would just be the project for the default case) and `yield from` that in `__iter__`. Hashing should also work transparently."", 'comment_created': datetime.datetime(2020, 8, 27, 14, 13, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478451129, 'comment_body': 'This change supports us moving away from the two class model.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 13, 31, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478452293, 'comment_body': ""I would prefer to return `jobs[0].id`, which is strictly correct and doesn't depend on us not changing the string representation of a `Job`."", 'comment_created': datetime.datetime(2020, 8, 27, 14, 15, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478458974, 'comment_body': ""@bdice another instance of type checking up front that is probably justified due to the delayed execution of aggregator.\r\n\r\n@kidrahahjo the sequence here is a little confusing though. The `TypeError` you're catching would be thrown by the first line in the `try` block, so there's no need for the rest to be there. I would move the `if num<=0` check out of the try block. Furthermore, rather than trying to convert to int like this, if we're going to type check I would do it rigorously. Currently, passing `num=3.5` will result in the code silently using `num=3`.\r\n```suggestion\r\n        if num != int(num):\r\n            raise TypeError('The num parameter should be an integer')\r\n        num = int(num)\r\n        if num <= 0:\r\n            raise ValueError('The num parameter should have a value greater than 0')\r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 24, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478460776, 'comment_body': 'Whatever you call the method, make sure it is called in the constructor (and can be called again later if necessary).', 'comment_created': datetime.datetime(2020, 8, 27, 14, 26, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478541622, 'comment_body': ""There's no specific style, but in `project.py` we import them separately."", 'comment_created': datetime.datetime(2020, 8, 27, 16, 21, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478541938, 'comment_body': 'I agree that the first constructor argument would need to change.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 21, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478542153, 'comment_body': 'That is correct.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 22, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478542689, 'comment_body': '`md5` is used to generate the id of an aggregate. No specific preference was there, it was just a suggestion that we could use `md5` for getting aggregate id.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 23, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478543545, 'comment_body': 'We could if this implementation had the complete desired behavior. However, once we add `__getitem__` and `__contains__` are implemented both of which would look different for the classes and the fact that for the default case the regeneration of aggregates is a no-op. I think having separate classes is warranted.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 24, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478544390, 'comment_body': 'Will do', 'comment_created': datetime.datetime(2020, 8, 27, 16, 25, 55, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478544846, 'comment_body': 'Are you referring to having `Aggregate` be the same class as `_AggregateStore`? or the distinction between default aggregation and non-default aggregation.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 26, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478558681, 'comment_body': 'I would like to be consistent if possible as well.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 49, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478560334, 'comment_body': 'It can be `aggregator_function`?', 'comment_created': datetime.datetime(2020, 8, 27, 16, 52, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478562832, 'comment_body': 'This is a statement about possibilities not what the function does (as it is worded).', 'comment_created': datetime.datetime(2020, 8, 27, 16, 56, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478568663, 'comment_body': 'Since only the last aggregate can be a different size. I would say something like the default size of aggregates excluding the final aggregate.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 6, 28, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478569370, 'comment_body': 'See comment about `groupsof` above.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 7, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478570265, 'comment_body': 'the key parameter needs more explanation. Also, you have the key parameter listed twice.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 9, 23, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478571041, 'comment_body': 'This is not necessarily true. A variety of things could have been passed here. I would just mention that we were passed something other than a function.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478571762, 'comment_body': ""The point of `_DefaultAggregateStore` was that we wouldn't want to compute those aggregates as aggregates of 1. We could just yield single jobs.\r\nWe could merge those two classes but the current model is a simple way to differentiate between those two."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 12, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478573408, 'comment_body': 'I would prefer if we used the id to check for inclusion. It would be constant time rather than linear then.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 14, 59, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478574129, 'comment_body': 'There is no need for either of the explicit list calls.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 16, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478576586, 'comment_body': ""We don't need this list conversion."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 20, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478576884, 'comment_body': 'Do worry about the explicit `bool` conversion.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 21, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478579017, 'comment_body': ""Here you are converting to a list again. We don't need to convert to list multiple times. `sorted` always returns a list, and `filter` does not, but if we pass it into `sorted` it will return a list."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478580328, 'comment_body': 'I think it might look cleaner to have a small function `validate_and_filter_jobs` that returns a Boolean or raises an error and just use `nested_aggregate = tuple(filter(validate_and_filter_jobs, aggregate))`', 'comment_created': datetime.datetime(2020, 8, 27, 17, 27, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478580836, 'comment_body': 'Use project id.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 28, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581268, 'comment_body': 'This is internal, should we ever be passed a list of jobs rather than a `FlowProject`? Considering we control this.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 28, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581583, 'comment_body': 'No need for two functions here.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 29, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581894, 'comment_body': '```suggestion\r\nreturn job in self._project\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 17, 29, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478582411, 'comment_body': 'Why would we ever be passed anything other than the project?', 'comment_created': datetime.datetime(2020, 8, 27, 17, 30, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478585901, 'comment_body': ""Don't convert to string here. No need."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 36, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478586175, 'comment_body': 'I would explain what this function is doing as it is not immediately apparent. I understand, but someone fresh coming to the code might not.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 37, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478586904, 'comment_body': 'Using map for these two attributes seems a bit much. Just writing it explicitly would be fine.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 38, 29, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478593082, 'comment_body': '```suggestion\r\n            return self_select == other_select and self_aggregator == other_aggregator\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 17, 49, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478607744, 'comment_body': 'We use md5 for id calculation of Jobs.\r\nI think that was the reason we were using md5 for calculating aggregate id.\r\n@b-butler @vyasr @bdice Please suggest what should be done here.', 'comment_created': datetime.datetime(2020, 8, 27, 18, 15, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478630597, 'comment_body': ""I'm not sure what you exactly mean by this.\r\nI will shift this conversion to `__init__` method of `Aggregate` but what else should I be worried about?"", 'comment_created': datetime.datetime(2020, 8, 27, 18, 58, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478634436, 'comment_body': ""Oh, I'm sorry about that. Thanks for letting me know."", 'comment_created': datetime.datetime(2020, 8, 27, 19, 5, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478687251, 'comment_body': 'I changed the functionality. Please have a look at it once you get time', 'comment_created': datetime.datetime(2020, 8, 27, 20, 49, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478688950, 'comment_body': ""@b-butler The two classes, though does the same thing, are technically not at all similar.\r\nEven if we create `_AggregateStoreBase` we'd then have to override nearly all the methods. (Because even `_register_aggregates` for both the classes registers aggregates differently."", 'comment_created': datetime.datetime(2020, 8, 27, 20, 52, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478699962, 'comment_body': 'Is there a reason to use sha1 anywhere?', 'comment_created': datetime.datetime(2020, 8, 27, 21, 15, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478701018, 'comment_body': ""This is indeed better, but the main purpose it to provide a way to compare arbitrary types that are callable, and that isn't mentioned here."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 17, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478702803, 'comment_body': '```suggestion\r\n        """"""Aggregates jobs according to matching state point key values.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 21, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478703385, 'comment_body': '```suggestion\r\n        """"""Aggregates jobs of a set group size.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 22, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709006, 'comment_body': 'If we have this class which I generally am in favor of. It should not compose an `Aggregate` object but rather take the values from the object and use them itself.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709093, 'comment_body': 'This can be a static method', 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709243, 'comment_body': ""These don't need to be in the try block."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478710118, 'comment_body': 'I may have been confusing here. If we just use `filter` without `sorted` then `jobs` will not be a list when passed to `self._aggregate._aggregator_function`. It will be a `filter` object, so if `sort_by` is `None` then we do need to explicitly cast to a list, if that is an API guarantee to the user for the aggregation function rather than promising to return an iterable of jobs.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 37, 54, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478711087, 'comment_body': 'If we make the change to `_MakeAggregates` I suggest, then we should move the `__eq__` and `__hash__` methods to it.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 39, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478714946, 'comment_body': 'If we are going to use `_MakeAggregates` then we would just want this class to have a `_MakeAggregates` object it can call when it needs to.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478716331, 'comment_body': 'Maybe a comment on how this tests hashing works properly would be helpful (i.e. mentioning that you have 11 unique aggregation definitions).', 'comment_created': datetime.datetime(2020, 8, 27, 21, 52, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478716834, 'comment_body': ""If this is to just test with lambda's versus standard functions, we don't need both tests. If this is to test two different functions then it can be in the same test."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 53, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478717487, 'comment_body': 'This does not test that each aggregate of `aggegrator.groupsof(2)` for instance has two jobs (except the last perhaps).', 'comment_created': datetime.datetime(2020, 8, 27, 21, 54, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478717818, 'comment_body': '```suggestion\r\n            assert all(even == job.sp.even for job in aggregate)\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 55, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718048, 'comment_body': ""```suggestion\r\n            assert all(assert half == job.sp.get('half', -1) for job in aggregate)\r\n                \r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 21, 55, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718457, 'comment_body': ""Thanks for the comment! Could you add how that means we don't need to check whether all the aggregate members are equivalent. Of course this is true for aggregates of size one, but just to be clear for future developers."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 56, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718621, 'comment_body': 'Use all here too.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718671, 'comment_body': 'Use all here.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 57, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478720639, 'comment_body': 'I am saying do not worry about it at all just assume it is something Boolean like.', 'comment_created': datetime.datetime(2020, 8, 27, 22, 2, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478723250, 'comment_body': 'Nope, no specific reason.\r\nIt was used while hashing `_JobOperation`, bundle id in `project.py`', 'comment_created': datetime.datetime(2020, 8, 27, 22, 9, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478724889, 'comment_body': 'the key can also be an arbitrary callable hence, according to me, users may get confused with this doc', 'comment_created': datetime.datetime(2020, 8, 27, 22, 13, 28, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479051633, 'comment_body': ""I'm not sure I see the use case of moving them to `_MakeAggregates` can you please explain?"", 'comment_created': datetime.datetime(2020, 8, 28, 9, 54, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479056580, 'comment_body': 'So, I should probably execute `jobs = list(jobs)` after we filter jobs', 'comment_created': datetime.datetime(2020, 8, 28, 9, 58, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479099813, 'comment_body': ""We'll be eventually storing the instances of `_AggregateStore` and not `_MakeAggregates`. Hence, I think it is not useful to move `__eq__` and `__hash__` method to `_MakeAggregate`"", 'comment_created': datetime.datetime(2020, 8, 28, 10, 34, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479193923, 'comment_body': ""The `_validate_and_filter_job` uses a instance attribute `_project`.\r\nIf we convert this to a static method then we'll have to execute something like this\r\n```\r\nfilter_aggregate = tuple(filter(\r\n    lambda job: _validate_and_filter_job(job, self._project), aggregate))\r\n```\r\nI'm not sure if this is a right approach or not. Please suggest"", 'comment_created': datetime.datetime(2020, 8, 28, 11, 55, 42, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479350825, 'comment_body': 'Nevermind, we do need this at first to be able to discern if an user creates multiple of the same `aggregator` objects... We will likely need a way to hash and equate `_AggregateStores` as well though.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479351768, 'comment_body': ""I don't think we need to internally store the project in this class. We can just expect it to be passed when called. Then we do not need to use `self._project` in fact such an attribute would not even exist. Then `_validate_and_filter-job` could be a closure created within the `_create_nested_aggregates` method. Sorry I missed that we were storing the project before."", 'comment_created': datetime.datetime(2020, 8, 28, 14, 43, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479353635, 'comment_body': ""I don't know why we are storing the project in this class. I know I missed this last review. I believe passing in the project to `_MakeAggregates` is the proper approach. That provides the intuitive behavior of `_MakeAggregates` as a function that takes in a project and returns aggregates."", 'comment_created': datetime.datetime(2020, 8, 28, 14, 46, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479358687, 'comment_body': 'Okay, then I would be consistent here for this file as it is a bit cleaner.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 55, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479359831, 'comment_body': 'This should accept a `FlowProject`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 56, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479360616, 'comment_body': 'This should still be done by the `_AggregateStore` class. I believe the `_MakeAggregate` class should only be responsible for correctly handing the aggregation, not the data structures used by `_AggregateStore`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 58, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479360962, 'comment_body': 'This should be moved back to `_AggregateStore`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 58, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479361333, 'comment_body': 'If we make the change I suggest. I would like to see this yield aggregates. That is just a preference though.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 59, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479370670, 'comment_body': '@b-butler \r\nIn this implementation, we do have an `__eq__` and `__hash__` methods for both `_DefaultAggregateStore` and `_AggregatesStore`', 'comment_created': datetime.datetime(2020, 8, 28, 15, 15, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479447017, 'comment_body': 'We do not need to store the project here.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 40, 8, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479447759, 'comment_body': 'We could use a classmethod for `_MakeAggregates` that takes the `aggregator` and handles this setting internally.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 41, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479448513, 'comment_body': 'We should pass in the project to this function and the `_create_nested_aggregate_list` function, or create the `_validate_and_filter_job` function in this function and pass that to `_create_nested_aggregate_list`. Either is fine with me. It is up to your preference.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 43, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479448898, 'comment_body': 'This list call is unnecessary. If we require that the aggregator function be passed a list, then we should only call list if `self._sort_by is None`.\r\n\r\n````python\r\nif self._sort_by is None:\r\n    jobs = list(jobs)\r\nelse:\r\n    jobs = sorted(...)', 'comment_created': datetime.datetime(2020, 8, 28, 17, 44, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479471676, 'comment_body': ""Why is this after `sort_by` now? With this being before the `sort_by` conditional, we only convert to a list once. Now we would do it twice if `sort_by is not None`. If we put it before, we also don't need the `list` conversion there."", 'comment_created': datetime.datetime(2020, 8, 28, 18, 33, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479472310, 'comment_body': 'I am fine because this makes errors easier for the user to manage.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 35, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479473092, 'comment_body': 'Why are we accepting `kwargs` when they are not used anywhere meaningfully?', 'comment_created': datetime.datetime(2020, 8, 28, 18, 37, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474300, 'comment_body': 'We just need to check that the aggregate ids all all the same.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 39, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474410, 'comment_body': ""We don't need to store the aggregator."", 'comment_created': datetime.datetime(2020, 8, 28, 18, 39, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474518, 'comment_body': '```suggestion\r\n        blob = str(hash(self._aggregates))\r\n```', 'comment_created': datetime.datetime(2020, 8, 28, 18, 40, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479475356, 'comment_body': 'Can we test the `__hash__` and `__eq__` of this class given the typo I found.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 42, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479477989, 'comment_body': 'These are used to check equality between two aggregator objects. I was having difficulty in comparing aggregators hence I thought that these additional parameters would be helpful to test the equality', 'comment_created': datetime.datetime(2020, 8, 28, 18, 47, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479478418, 'comment_body': 'Yes, I think I forgot to write those. Sorry about that. Will do it.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 48, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479634260, 'comment_body': 'We compare and hash the `aggregator` hence I think that we should store the aggregator', 'comment_created': datetime.datetime(2020, 8, 29, 10, 15, 6, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479634335, 'comment_body': 'Do you mean something like this\r\n`self._aggregate_ids.keys() == other._aggregate_ids.keys()` ?', 'comment_created': datetime.datetime(2020, 8, 29, 10, 16, 4, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479636475, 'comment_body': 'This should be `self._aggregator`', 'comment_created': datetime.datetime(2020, 8, 29, 10, 43, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479664323, 'comment_body': 'If this is just for testing equality, please remove it. This feature is not used for any purpose. We should deal directly with the problem of testing equality. What part was giving you difficulty?', 'comment_created': datetime.datetime(2020, 8, 29, 16, 11, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664366, 'comment_body': 'Yep.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 11, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664470, 'comment_body': 'We just need to compare aggregation_ids or hash to determine uniqueness for standard aggregate store object the default is easier with just comparing and using the project directly.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 12, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664707, 'comment_body': 'We should not assert that the length of something passed to `__contains__` here is one. It may be convenient to check for inclusion of an aggregate against all `_AggregateStore` objects default or not. If the length is not 1 then we just return false.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 15, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479665546, 'comment_body': 'The last part is unnecessary. If all the aggregate ids are the same then the store is the same for all intents and purposes, unless you think that multiple forms of aggregation may lead to the same exact aggregates.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 24, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479665574, 'comment_body': ""I would prefer to just use the aggregate ids here too. Even with a million aggregates `int(sha1(','.join(a.keys())))` is fairly fast.\r\n\r\nI think it is cleaner this way, and if we find that users like to make many huge aggregates, we can rethink that decision."", 'comment_created': datetime.datetime(2020, 8, 29, 16, 24, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479666707, 'comment_body': 'Only testing one of these would be fine.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 36, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479666770, 'comment_body': 'Only testing one or two of these would be fine. We should also test that the default aggregate store handles getitem and contains correctly as well.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 37, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479673883, 'comment_body': ""I believe we should be extra sure, there may be a case when we only have a single job in the project and two operations which groups them in groups of 2, groups of 3. Then we won't be differentiating between them. This is completely theoretical and I'll do as you suggest\r\n"", 'comment_created': datetime.datetime(2020, 8, 29, 17, 55, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479680377, 'comment_body': ""As per discussion in slack, we're now only going to compare `_AggregatesStore` object by `aggregator` attributes."", 'comment_created': datetime.datetime(2020, 8, 29, 19, 10, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479681769, 'comment_body': 'We can just set this in the `groupsof` classmethod without needing to set an attribute to the function.', 'comment_created': datetime.datetime(2020, 8, 29, 19, 25, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479682853, 'comment_body': ""I'm not sure if I follow this. The `groupsof` method returns an instance of `aggregator`.\r\nBut since we're going to introduce the tag attribute, hence I think I'll simplify this logic.\r\n\r\nEdit: I got confused and now I understand what you mean."", 'comment_created': datetime.datetime(2020, 8, 29, 19, 38, 3, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479685750, 'comment_body': '```suggestion\r\n        # check the equality based on tags provided by an user or us in a classmethod\r\n```', 'comment_created': datetime.datetime(2020, 8, 29, 20, 12, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685857, 'comment_body': 'What I meant was that we can create the object and if it is the default aggregation, change the `_is_aggregate` flag after instantiation.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 13, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685882, 'comment_body': 'Also I think `groupsof{num}` is sufficient.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 13, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685894, 'comment_body': 'just `groupby{key}-{default}` is fine.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 14, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479687378, 'comment_body': ""I pushed a code, please have a look. I hope that's what you meant."", 'comment_created': datetime.datetime(2020, 8, 29, 20, 30, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479694058, 'comment_body': 'Why do we have both of these? One should suffice.', 'comment_created': datetime.datetime(2020, 8, 29, 21, 59, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479735059, 'comment_body': ""I'm not pretty sure about this.\r\nWhat if `_aggregator` attributes are equal but the `_select` attributes are not and vice versa.\r\nI think we need both of them compared."", 'comment_created': datetime.datetime(2020, 8, 30, 7, 40, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479785142, 'comment_body': '```suggestion\r\n        A callable that performs aggregation of jobs. It takes in a list of\r\n        jobs and can return or yield subsets of jobs as an iterable. The\r\n        default behavior is creating a single aggregate of all jobs.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 47, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785223, 'comment_body': '```suggestion\r\n        Condition for filtering individual jobs. This is passed as the\r\n        callable argument to `filter`. The default behavior is no\r\n        filtering.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 47, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785385, 'comment_body': '```suggestion\r\n        elif (\r\n             self._sort_by != other._sort_by or\r\n             self._reverse_order != other._reverse_order or\r\n             self._tag != other._tag\r\n        ):\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 49, 50, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785420, 'comment_body': '```suggestion\r\n        elif (\r\n             self._select == other._select and\r\n             self._aggregator_function == other._aggregator_function\r\n        ):\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 50, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785686, 'comment_body': ""This whole function seems rather convoluted. Is it all just for optimization (checking cheaper conditions first)? How big a difference is there between the last `elif` clause (which checks identity of `select` and `aggregator_function`) and the comparison of the `__co_code`? Is it really worth doing both? I'm not sure this level of complexity is warranted, but I don't know what the benchmarks look like."", 'comment_created': datetime.datetime(2020, 8, 30, 15, 52, 35, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786151, 'comment_body': ""I would move some of this information to the docstring. If it's meant to be a user-facing feature for the purpose of distinguishing aggregators, the user needs this information so they can decide what to provide as a tag."", 'comment_created': datetime.datetime(2020, 8, 30, 15, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786270, 'comment_body': '```suggestion\r\n        If the number of jobs present in the project is not divisible by the number\r\n        provided by the user, the last aggregate will be smaller and contain all\r\n        remaining jobs.\r\n        For instance, if 10 jobs are present in a project and they are aggregated in\r\n        groups of 3, then the generated aggregates will have lengths 3, 3, 3, and 1.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 58, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786292, 'comment_body': '```suggestion\r\n        The code block below provides an example on how jobs can be aggregated in\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 59, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788500, 'comment_body': ""This solution is pretty hacky... it's abusing the fact that you can store multiple references to the same iterator and then iterate over each reference in sequence to produce chunks of the original. It certainly works, though, and maybe it is the most efficient way to do this without making copies. I assume you found this recipe somewhere, could you add a link to document that, and maybe a comment here as well describing how it works?"", 'comment_created': datetime.datetime(2020, 8, 30, 16, 21, 21, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788586, 'comment_body': '```suggestion\r\n        The below code block provides an example of how to aggregate jobs having a\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 22, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788957, 'comment_body': '```suggestion\r\n            The method by which jobs are grouped. It may be a state point\r\n            or a sequence of state points to group by specific state point\r\n            keys. It may also be an arbitrary callable of :class:`signac.Job`\r\n            when greater flexibility is needed.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 26, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479789585, 'comment_body': ""I think the intention here was to use `md5` everywhere rather than use `sha1` everywhere. We use `md5` for the `id` of jobs, so let's be consistent here. Additionally, `md5` is a faster hash function and it generates shorter hashes, which is good for keeping the directory names shorter for jobs and the strings shorter for aggregate stores. In general we're not concerned with the security implications; if that changes we'll need to change hashes everywhere in signac anyway (and we'd need to use something more secure than sha1)."", 'comment_created': datetime.datetime(2020, 8, 30, 16, 32, 51, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479789621, 'comment_body': 'See comment on import: use md5 instead of sha1.', 'comment_created': datetime.datetime(2020, 8, 30, 16, 33, 9, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479790118, 'comment_body': '```suggestion\r\n        """"""Create the actual collections of jobs to be sent to aggregate operations.\r\n        \r\n        The :class:`aggregate` class is just a decorator that provides a signal for\r\n        operation functions that should be treated as aggregate operations and\r\n        information on how to perform the aggregation. This function generates\r\n        the classes that actually hold sequences of jobs to which aggregate\r\n        operations will be applied.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 38, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479790137, 'comment_body': '```suggestion\r\n    a :class:`aggregator`.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 38, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791193, 'comment_body': ""Should this error be about a job or an aggregate? This is a forward-looking question about how the aggregate's contains method will actually be invoked, @b-butler in future work making use of this class which error would be more appropriate? It seems like we'd want the error to state something about aggregates, but since this class will become the default mode for all aggregation maybe that's not the case since this error could get thrown for operations that act on individual jobs."", 'comment_created': datetime.datetime(2020, 8, 30, 16, 47, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791509, 'comment_body': 'Since this pattern of string[->sequence of strings]->blob->hash is very common, can you define a simple internal function `_hash` that we can call everywhere? That will ensure consistency in our hashing and simplify any future changes (for instance, to which hash function we call).', 'comment_created': datetime.datetime(2020, 8, 30, 16, 51, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791700, 'comment_body': '```suggestion\r\n            even = (i % 2) == 0\r\n```\r\n\r\nRelying on operator precedence when using anything other than pure arithmetic operators always makes me uneasy.', 'comment_created': datetime.datetime(2020, 8, 30, 16, 53, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479795163, 'comment_body': ""This was originally implemented by @csadorf in #52 and that had a link from where it was copied.\r\nI'll add the link into this PR and also mention #52 "", 'comment_created': datetime.datetime(2020, 8, 30, 17, 29, 33, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479797989, 'comment_body': ""That is true.\r\nIn #335 I have added support for these classes and I believe that it should be about an aggregate because everything will become an aggregate internally.\r\nI'm curious to know what @b-butler thinks about this"", 'comment_created': datetime.datetime(2020, 8, 30, 17, 57, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479799143, 'comment_body': ""A user could do something like this\r\n```\r\n@aggregator.groupsof(2)\r\n@FlowProject.operation\r\ndef op_1(*jobs):\r\n    pass\r\n\r\n@aggregator.groupsof(2)\r\n@FlowProject.operation\r\ndef op_2(*jobs):\r\n    pass\r\n```\r\nWe won't be able to differentiate between these two if we don't use `__code__.co_code` along with `tag` attribute"", 'comment_created': datetime.datetime(2020, 8, 30, 18, 8, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479812095, 'comment_body': ""Putting #52 doesn't help very much, it requires somebody to know that it refers to a pull request (and in the event that we ever switched off of Github we could lose PRs entirely). I would include the link and mention the `grouper` recipe (that's the function at that link that implements this technique)."", 'comment_created': datetime.datetime(2020, 8, 30, 20, 27, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813348, 'comment_body': ""I can't seem to access the original thread of discussion here, so I'll just make a new comment. The point that I was trying to make about this function (the whole `__eq__` method) being complicated was not about why we need the `tag`. I get that the tag might be necessary to distinguish between two. I was asking whether this `elif` clause is worth having at all. The remainder of this method basically tries to compare either the `co_code` or the hash of the `select`s and `aggregator_function`s to determine their equality, and either of those will be basically the same speed as the equality check in this `elif` (the `co_code` is just cached in the object on creation AFAIK). So I don't see any reason not to change this `elif` to an `else` clause, remove the equality checks that are currently here, and move the code with `self_select`, `other_select`, etc into this `else` clause."", 'comment_created': datetime.datetime(2020, 8, 30, 20, 41, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813430, 'comment_body': 'Have these tests been written?', 'comment_created': datetime.datetime(2020, 8, 30, 20, 42, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813520, 'comment_body': 'Now that the information is in the docstring, you can remove this comment entirely.', 'comment_created': datetime.datetime(2020, 8, 30, 20, 43, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479814256, 'comment_body': ""Does setting tags affect correctness, or is it just a performance optimization? Now I'm actually a little confused what the goal of the tags are. Are there cases where a user would have to provide tags, otherwise we might think that two aggregates are equivalent and therefore reuse the same set of job aggregates for them even though they should actually be using different ones? That seems _highly_ problematic to me. If the worst case scenario is just that we regenerate too many aggregates, then providing tags as a way for users to speed that up is fine, but we should never be in a situation where we silently use the wrong aggregates.\r\n\r\nIt should be possible to avoid any false positives with equality, it's just not possible to avoid getting false negatives (which is where the optimization comes in). Can you give an example where the current test fails to distinguish functions without the use of tags? Does that issue get fixed if you also check `co_consts` in addition to `co_code`?"", 'comment_created': datetime.datetime(2020, 8, 30, 20, 51, 6, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479817454, 'comment_body': ""@vyasr, @b-butler asked me to check this first in order to reduce the complexity.\r\nFor example, if we're able to compare the `aggregator_function` and `select` directly then there's no need to compare the binary code. But if we fail, then we end up comparing the binary code."", 'comment_created': datetime.datetime(2020, 8, 30, 21, 25, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479817652, 'comment_body': '@vyasr yes, I have written the tests.\r\nYou can have a look at them (They are the last 4 tests of this class)', 'comment_created': datetime.datetime(2020, 8, 30, 21, 28, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479821374, 'comment_body': ""I understand, but I'm saying that I don't expect this to lead to any real performance improvement. In practice I expect users to use the provided `groupsof` and `groupby` options the vast majority of the time, and those will never pass this check because those decorators create new internal functions each time they are called. When users do bother to create custom aggregation functions, I expect them to use lambdas or something most of the time, in which case again this equality check will fail. While checking the type and then checking the sort/reverse/tag are probably useful, this branch adds complexity without any evidence that it will improve performance. That is the hallmark of premature optimization, so I'm recommending not doing this unless we see that the `__eq__` method is actually a performance bottleneck that could benefit from this extra check."", 'comment_created': datetime.datetime(2020, 8, 30, 22, 2, 38, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480117103, 'comment_body': ""I understand what you say.\r\n@b-butler It'd be really helpful to know your views on this. If you agree, then I'll go ahead and remove the block."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 7, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480117864, 'comment_body': 'I did not try `co_consts`. I will try to make that work and let you know', 'comment_created': datetime.datetime(2020, 8, 31, 13, 8, 34, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480138481, 'comment_body': ""Well first, can you give an example where the tag is _necessary_, i.e. we would think two aggregators are identical when they really aren't? I have no idea if `co_consts` would fix the problem because I don't know what it is, I just suggested that because there is more information available than `co_code` if that is insufficient to distinguish.\r\n\r\nFor a feature like this we _cannot_ rely on the user to provide tags to prevent incorrectly identifying two distinct aggregates as the same. If we really can't distinguish them for some reason, I think we would have to eat the performance cost and just copy all aggregates and not reuse any of them. Optimizations cannot result in incorrect behavior, and we can't push that responsibility onto the user."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 41, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480144754, 'comment_body': ""When we use `co_code`, we are not able to differentiate between `groupsof(2)` and `groupsof(3)`.\r\nI believe this is because the function doesn't itself store any information about the number provided.\r\nIt just references to the value stored for num.\r\nThis is where `tag` comes handy. `co_consts` will not work here because it will just provide the constants declared in the function (which we don't do).\r\n```\r\na = 1\r\ndef x():\r\n    c = a\r\n    return c\r\n```\r\nThe output of `x.__code__.co_consts` would be (None,).\r\nThis is, kind of, the similar problem we're facing currently."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 51, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480165179, 'comment_body': ""Yes that's what I would expect. In this particular case you can get around the problem by instead looking at `x.__closure__`. However, I'm not sure if this would work in *all* cases. I think if you traversed all members of `x.__code__` and `x.__closure__` and checked them each for equality with the same members of another function you could guarantee that you don't get false positive, but I'm not 100% sure about that. For this particular use case, I think guaranteeing 0 false positives is far more important than preventing false negatives; the latter is just a performance hit, whereas the former leads to incorrect behavior. Reiterating what I said in my previous comment, it's much better to store some extra aggregates than to use the wrong aggregates for operations.\r\n\r\n@b-butler what are your thoughts here?"", 'comment_created': datetime.datetime(2020, 8, 31, 14, 23, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480208372, 'comment_body': 'I agree with @vyasr here generally, hence the comment I made before.', 'comment_created': datetime.datetime(2020, 8, 31, 15, 30, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 480210882, 'comment_body': ""I was not aware of `__closure__`, but that would likely be sufficient then. I don't care about false negatives, but yes we need to be sure of no false positives. We should also be fairly sure that `groupsof` and `groupby` are not giving false negatives."", 'comment_created': datetime.datetime(2020, 8, 31, 15, 34, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 481554288, 'comment_body': 'I also prefer fully qualified names (`import itertools` and `itertools.groupby`) to avoid confusion about the similarly-named aggregate functions.', 'comment_created': datetime.datetime(2020, 9, 2, 2, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}]","[{'commit_sha': '3af7e0e7454f1a4a4d46faf5f62a7bfb6b131414', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '48e503c2eb7b3adb988756868da4833fe9013128', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd5b19bd07c901cf4d25fcaf6f9efa777462d4659', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a7712f6d50731e9bd185571cefca3e122b09080e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3d4c6af2113ab1e8a84f465b4a8499f3fbb7b3bc', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8017bc31f131cae5b16a64b896d6fe88ce3c76ac', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a8a9df2e5a42eba61db2fecd14facb3790822b4', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '749c3b2a770740487946b4f81d54dd3f17f1fd99', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63e3c0720240b9687a6d53cd1398fa51181607a6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd8dab6f27c2fc650e7164c7427b0982a9d4ad19b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e74e03d68ea347917ebf49939782c85cc4c350c0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '014e1f42f1305363049e424d39e6e8b9b63e7860', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '908d92092bbca3f1b3b4b7e96c06a9befebd01ec', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2bb9f4519afad64cb65b881b161a8ed55f507405', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf54e1723d541ea02913e903f5274d064a77ec40', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dfdaff832461783e58120b48111745a4a38d12b2', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5426b9516e6f58e175a82acc6c72a66cf479794f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9e3d4e038952a4e794b9ca3244e8048d9c9f1242', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f5db9b8b8eff07801185ab96b26e09c31eca3c81', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f2edcfdf46985bc43ce66dff52f2d161eee5b121', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ed0ae4c7e57ca55e290a66b484d2b0c4ed785768', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a578a495969c99e1c58777ebb36a5e3548020a41', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
462619895,Add default aggregate support to flow,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
This pull request adds the support of aggregator class in `project.py`

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->


## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,335,https://api.github.com/repos/glotzerlab/signac-flow/pulls/335,https://github.com/glotzerlab/signac-flow/pull/335,closed,588,277,6,69,18,382,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-08-04 08:41:31+00:00,2020-11-16 15:39:39+00:00,9010688.0,"104 days, 6:58:08","[{'comment_id': 465083439, 'comment_body': '```suggestion\r\n        formed previously but are not present currently for any\r\n```', 'comment_created': datetime.datetime(2020, 8, 4, 14, 16, 19, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 465091808, 'comment_body': '```suggestion\r\n        formed previously but are not present currently for any\r\n        operation.\r\n```', 'comment_created': datetime.datetime(2020, 8, 4, 14, 26, 34, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 465111486, 'comment_body': 'if the length is 1 why do you need to iterate over it? or is it nested?', 'comment_created': datetime.datetime(2020, 8, 4, 14, 53, 10, tzinfo=datetime.timezone.utc), 'commenter': 'atravitz', 'type': 'User'}, {'comment_id': 465200656, 'comment_body': 'This is nested so I had to iterate over it.', 'comment_created': datetime.datetime(2020, 8, 4, 17, 7, 26, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 465201290, 'comment_body': '```suggestion\r\n                jobs.append([job])\r\n```', 'comment_created': datetime.datetime(2020, 8, 4, 17, 8, 34, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 469637546, 'comment_body': 'I would like a more expansive name for this variable', 'comment_created': datetime.datetime(2020, 8, 13, 1, 11, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469638260, 'comment_body': ""Should we allow this to fail? I can see some rational for this, but we don't for bundles."", 'comment_created': datetime.datetime(2020, 8, 13, 1, 14, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469645813, 'comment_body': 'We should only open the file once to increase efficiency (less IO is beter). I would open the file in the mode necessary (you can check for existence beforehand if you need to change the mode).', 'comment_created': datetime.datetime(2020, 8, 13, 1, 33, 51, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469646617, 'comment_body': 'It is hard to follow the names with `fetched_aggregates` and `fetched_aggregate`. They are fine in themselves, but I was struggling to notice they are distinct lists.', 'comment_created': datetime.datetime(2020, 8, 13, 1, 36, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469646925, 'comment_body': 'Rather than assert just use an if and continue. It is partly a personal preference, but I  try to avoid unnecessary asserts.', 'comment_created': datetime.datetime(2020, 8, 13, 1, 37, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469647035, 'comment_body': ""Also, users can't or shouldn't change submission ids. Why are we checking for this?"", 'comment_created': datetime.datetime(2020, 8, 13, 1, 38, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469647440, 'comment_body': 'Why are we setting this key multiple times overwriting it each time?', 'comment_created': datetime.datetime(2020, 8, 13, 1, 39, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469647843, 'comment_body': 'Is this being changed when aggregation comes around? ', 'comment_created': datetime.datetime(2020, 8, 13, 1, 41, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469647919, 'comment_body': 'If so maybe mark with a `# TODO`', 'comment_created': datetime.datetime(2020, 8, 13, 1, 41, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469648154, 'comment_body': ""This should already be a lists of lists yes? So we shouldn't need to wrap this."", 'comment_created': datetime.datetime(2020, 8, 13, 1, 42, 29, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469649121, 'comment_body': 'This would append to the first error twice right?', 'comment_created': datetime.datetime(2020, 8, 13, 1, 46, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 469649191, 'comment_body': 'This is per aggregate correct?', 'comment_created': datetime.datetime(2020, 8, 13, 1, 46, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470018853, 'comment_body': 'What you are gathering is the singleton groups. I would name the variable to be explicit about that.', 'comment_created': datetime.datetime(2020, 8, 13, 15, 1, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470019648, 'comment_body': ""Why aren't we parallelizing this? We could over groups right? I know there aren't as many operations typically as jobs, but we should see some performance improvement using threads considering all the IO."", 'comment_created': datetime.datetime(2020, 8, 13, 15, 2, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470024336, 'comment_body': ""Here `result` and `results` are really close. This isn't a mistake, but it does make the code harder to read. Maybe `results_entry` would be more clear."", 'comment_created': datetime.datetime(2020, 8, 13, 15, 9, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470026057, 'comment_body': ""I think I understand now. This is only sent singleton groups with the same name as the operation right? If so we don't need the for loop just `result['operation_name'] = group.name` and make sure that we comment that this is an expectation."", 'comment_created': datetime.datetime(2020, 8, 13, 15, 12, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470037280, 'comment_body': ""Users can change the submission ids (which they shouldn't) but there's a possibility that they change the id, hence we need to check this"", 'comment_created': datetime.datetime(2020, 8, 13, 15, 27, 44, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470037767, 'comment_body': ""I'll use names which are easier to distinguish."", 'comment_created': datetime.datetime(2020, 8, 13, 15, 28, 30, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470039563, 'comment_body': ""This was failing while executing `pytest test/test_templates` that's why I used this. \r\nIt was working fine when I made a project of my own though"", 'comment_created': datetime.datetime(2020, 8, 13, 15, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470043008, 'comment_body': 'There will be pickling problems for aggregator function. We could however just use `ThreadPool()` in order to parallelize this.', 'comment_created': datetime.datetime(2020, 8, 13, 15, 36, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470048119, 'comment_body': 'Hmm, that is likely due to permission locally on your `tmp` directory. Do tests with bundles fail?', 'comment_created': datetime.datetime(2020, 8, 13, 15, 44, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470048947, 'comment_body': ""Can they change submission ids without accessing the file directly or using internal APIs? If not, I wouldn't bother checking."", 'comment_created': datetime.datetime(2020, 8, 13, 15, 45, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470048980, 'comment_body': ""No, they don't fail with bundles"", 'comment_created': datetime.datetime(2020, 8, 13, 15, 45, 17, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470054010, 'comment_body': 'We could mention that `process` parallelization only applies to the labels then.', 'comment_created': datetime.datetime(2020, 8, 13, 15, 52, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470054022, 'comment_body': 'Oh yes, sorry about that', 'comment_created': datetime.datetime(2020, 8, 13, 15, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470055150, 'comment_body': 'No, these are per job technically.\r\nerrors is a `dict` which will be something like this:\r\n`{job1: errors_related_to_job1, job2: errors_related_to_job2, ...}`', 'comment_created': datetime.datetime(2020, 8, 13, 15, 54, 48, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470152312, 'comment_body': ""They can't do that using internal API but there's a probability that they add some jobs manually into that file. We'd then display the status info of those jobs (Which technically we're not supposed to do)\r\nThe `id` is only stored to look after edge cases like these. "", 'comment_created': datetime.datetime(2020, 8, 13, 18, 12, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470159927, 'comment_body': ""@b-butler let's mark this as TODO for now. I think I'll once again try to parallelize this in #336. If that fails, then I'll add \r\n> Via 'process' parallelization you can only fetch labels for a job.\r\n"", 'comment_created': datetime.datetime(2020, 8, 13, 18, 27, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470189154, 'comment_body': 'I think that this is a leftover code hence I removed this. \r\n@b-butler @csadorf Please confirm.\r\n', 'comment_created': datetime.datetime(2020, 8, 13, 19, 16, 15, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470752987, 'comment_body': ""I don't like adding this just to make tests pass, this will be annoying for a user to hide if there ever is a permission issue "", 'comment_created': datetime.datetime(2020, 8, 14, 17, 17, 10, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 470755362, 'comment_body': ""What does it mean if we can't open the job via is when fetching aggregates? If we don't catch this error, what fails?"", 'comment_created': datetime.datetime(2020, 8, 14, 17, 22, 13, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 470756090, 'comment_body': 'What should a user use in future versions? Or are we removing this functionality from the public API as well?', 'comment_created': datetime.datetime(2020, 8, 14, 17, 23, 42, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 470769111, 'comment_body': 'why 0.2 (seconds?) ', 'comment_created': datetime.datetime(2020, 8, 14, 17, 50, 41, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 470772307, 'comment_body': 'This was there before I started editing it, I just refactored it a little bit.\r\nMaybe @csadorf or @b-butler could help explain this', 'comment_created': datetime.datetime(2020, 8, 14, 17, 57, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470773297, 'comment_body': ""@mikemhenry I don't have any problem in keeping this function but if we keep this, we should warn a user that it's not implemented for an aggregate operation (`len(jobs) > 1`).\r\nThis is because we're now storing information per aggregate and not a single job in #336 "", 'comment_created': datetime.datetime(2020, 8, 14, 17, 59, 19, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470774392, 'comment_body': ""A user may dynamically delete a job. And if a user does that, because the aggregate information is already stored in `.aggregates` directory, we'll definitely try to open it and catch an error.\r\nSo we skip that particular aggregate if we catch a `KeyError`"", 'comment_created': datetime.datetime(2020, 8, 14, 18, 1, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470777662, 'comment_body': 'Then, I am confused this is the same call that bundles makes. I would look more into this. I am not comfortable with this just being about tests passing. There has to be a reason it is raising this error. Is this error only local or does it fail on CI?', 'comment_created': datetime.datetime(2020, 8, 14, 18, 8, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470779331, 'comment_body': 'You need a read call to store the file in a string first. Otherwise we have no guarantee that we will be at the end of the file when writing.\r\n```python\r\nagg_file_contents = file.read()\r\nif aggregate_wid in agg_file_contents:\r\n    continue\r\nelse:\r\n    file.write(aggregate_wid)\r\n````', 'comment_created': datetime.datetime(2020, 8, 14, 18, 12, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470780681, 'comment_body': 'I think this is the right approach.', 'comment_created': datetime.datetime(2020, 8, 14, 18, 14, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470781345, 'comment_body': 'Why does the sequence of aggregates have to be a tuple. I get the individual aggregates, but this seems like an unnecessary copy to me.', 'comment_created': datetime.datetime(2020, 8, 14, 18, 15, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470782083, 'comment_body': 'I think we should potentially make `_get_group_status` public and encourage users to switch to that.', 'comment_created': datetime.datetime(2020, 8, 14, 18, 16, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470782984, 'comment_body': 'It is.', 'comment_created': datetime.datetime(2020, 8, 14, 18, 17, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470784577, 'comment_body': 'It helps to have an explanation of what to do.', 'comment_created': datetime.datetime(2020, 8, 14, 18, 19, 8, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470788130, 'comment_body': ""Doesn't the description need to be a keyword argument here?"", 'comment_created': datetime.datetime(2020, 8, 14, 18, 23, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470788507, 'comment_body': 'Having the default be `None` means that `map` always needs to be passed or a `TypeError` will happen right?', 'comment_created': datetime.datetime(2020, 8, 14, 18, 23, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470790316, 'comment_body': 'I think having `iterable`, `func`, and `map` be arguments would be better. Then we can just pass `singleton_gropups` to the function with `_get_group_status`.', 'comment_created': datetime.datetime(2020, 8, 14, 18, 25, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 470814569, 'comment_body': ""This fails on both, locally and CI. I'll try to resolve this issue"", 'comment_created': datetime.datetime(2020, 8, 14, 19, 1, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470816895, 'comment_body': ""@b-butler We are deprecating most of the public methods, I don't find a strong reason introducing this method in the API. Will we be later deprecating `get_group_status`?"", 'comment_created': datetime.datetime(2020, 8, 14, 19, 6, 21, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470817481, 'comment_body': 'Yes, this is true.\r\nI will change the default to `map`', 'comment_created': datetime.datetime(2020, 8, 14, 19, 7, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470818548, 'comment_body': ""@b-butler we'd then have to check the name of the function too. Because if we don't do that then we have to pass description also.\r\nAnd then this method won't be of much use as the code will be of the same length as before."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 10, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470819816, 'comment_body': ""@b-butler @mikemhenry we don't make a file while checking for bundles but we do have to make a file for aggregates.\r\nSince we're not checking for any lost aggregates in templates tests. I think it'll be best to mock the `_store_aggregates` method  too."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 13, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470823563, 'comment_body': 'yes, thank you for this', 'comment_created': datetime.datetime(2020, 8, 14, 19, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470830925, 'comment_body': 'One more reason I found to not to make it public is that it will never return the ""complete"" status of the jobs as labels are also included in a status for a job. This returns only the status of a job per operation hence I think that we\'d then have to make both `_get_job_labels` and `_get_group_status` public.\r\n ', 'comment_created': datetime.datetime(2020, 8, 14, 19, 39, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 470856978, 'comment_body': 'I must have missed that in the diff, 0.2 sounds reasonable, I was just curious how that value was chosen. Not a big deal but could be nice to add as a code comment.', 'comment_created': datetime.datetime(2020, 8, 14, 20, 45, 21, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 470967834, 'comment_body': ""I don't remember how this number was chosen, obviously it's a heuristic but I don't recall the rationale. I would suggest looking at #110, that's where it was added iirc. "", 'comment_created': datetime.datetime(2020, 8, 15, 11, 27, 13, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 470970015, 'comment_body': ""Thank you @vyasr \r\n@mikemhenry I'll add a code comment."", 'comment_created': datetime.datetime(2020, 8, 15, 11, 56, 44, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 471757813, 'comment_body': ""Why would we need to check the name of the function too? We could just pass the function. I also, don't think passing the description is necessarily a bad thing. We could use partial functions to fill out what is known beforehand and just call the partial at sight with the necessary arguments."", 'comment_created': datetime.datetime(2020, 8, 17, 20, 30, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471758617, 'comment_body': 'I get this prevents permission errors, but I really would like to know what is causing the errors in the first place.', 'comment_created': datetime.datetime(2020, 8, 17, 20, 31, 33, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471764984, 'comment_body': 'This is assuming that `jobs` is a list of string ids correct? If so, it means that we are passing not `Job` instances but their ids around within the Python API. I would prefer to pass around the jobs themselves.', 'comment_created': datetime.datetime(2020, 8, 17, 20, 44, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471766649, 'comment_body': 'This means we will regenerate all aggregates every time it is run. We want to generate once at object instantiation.', 'comment_created': datetime.datetime(2020, 8, 17, 20, 48, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471767300, 'comment_body': '```suggestion\r\n            length_jobs = len(self) if jobs is None else len(jobs)\r\n```', 'comment_created': datetime.datetime(2020, 8, 17, 20, 49, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471768082, 'comment_body': ""try except blocks aren't bad, but here I think it is cleaner to have the `agg-` check first using `str.startswith`, or just check if the id is a key in the `_aggregates` dictionary."", 'comment_created': datetime.datetime(2020, 8, 17, 20, 51, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471768160, 'comment_body': 'Why are we deepcopying now?', 'comment_created': datetime.datetime(2020, 8, 17, 20, 51, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471769547, 'comment_body': 'It is likely worth implementing the store of aggregates in such a way as to not need to store the default aggregation of a single job explicitly. The others we would need to.', 'comment_created': datetime.datetime(2020, 8, 17, 20, 54, 29, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471770141, 'comment_body': 'See other comment about proposed way of discerning between jobs and aggregate ids.', 'comment_created': datetime.datetime(2020, 8, 17, 20, 55, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471770703, 'comment_body': 'We should not have to explicitly call this. The aggregates should be generated in `__init__`. Even if we lazily load them, we should be able to pretend they have already been generated.', 'comment_created': datetime.datetime(2020, 8, 17, 20, 56, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471770876, 'comment_body': ""We don't want to pass around ids internally."", 'comment_created': datetime.datetime(2020, 8, 17, 20, 57, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471776492, 'comment_body': 'We want the job not the id.', 'comment_created': datetime.datetime(2020, 8, 17, 21, 9, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471776860, 'comment_body': 'This is akin to registering operations or groups. I would like to see this as a register function.', 'comment_created': datetime.datetime(2020, 8, 17, 21, 10, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471788046, 'comment_body': ""```suggestion\r\n            if id[0:4] != 'agg':\r\n```"", 'comment_created': datetime.datetime(2020, 8, 17, 21, 35, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471788483, 'comment_body': 'Should not be a list of ids.', 'comment_created': datetime.datetime(2020, 8, 17, 21, 36, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 471789238, 'comment_body': 'Given that aggregates are _static_, we should revert back to job ordering. This is possible because we can just check that an aggregate is valid for a job. We just need to iterate over single jobs and then any user defined aggregation.', 'comment_created': datetime.datetime(2020, 8, 17, 21, 37, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472156079, 'comment_body': ""I believe you should be able to express a bit more concise:\r\n```suggestion\r\n        return f'agg-{md5(blob.encode()).hexdigest()}'\r\n```"", 'comment_created': datetime.datetime(2020, 8, 18, 12, 48, 3, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472157365, 'comment_body': ""Why use json at all? This should suffice, no?\r\n```suggestion\r\n        blob = ''.join((job.id for job in jobs))\r\n```"", 'comment_created': datetime.datetime(2020, 8, 18, 12, 49, 24, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472205607, 'comment_body': ""This was because we were checking whether the aggregates are valid or not.\r\nWe were deleting items from the list too.\r\nI believe we don't need this anymore"", 'comment_created': datetime.datetime(2020, 8, 18, 13, 41, 3, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472207733, 'comment_body': ""If we only generate aggregates once, I'm facing with resubmission. Please have a look at the failing tests if you have some time."", 'comment_created': datetime.datetime(2020, 8, 18, 13, 44, 6, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472211547, 'comment_body': 'I also thought of this once.\r\nWe could do this is #336 marking all those functions as ""non-aggregates"" which are creating using `Aggregate.groupof(1)`', 'comment_created': datetime.datetime(2020, 8, 18, 13, 49, 38, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472213724, 'comment_body': ""Wouldn't this be too complicated? \r\nI don't have any problem with checking but I believe this will become a little bit complicated"", 'comment_created': datetime.datetime(2020, 8, 18, 13, 52, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472220853, 'comment_body': ""since `fp` didn't have jobs in it hence after adding jobs we need to register aggregates"", 'comment_created': datetime.datetime(2020, 8, 18, 14, 2, 10, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472222923, 'comment_body': ""Necessary permissions are missing to write in `/tmp` directory.\r\nThe same thing was happening for bundles hence we've mocked that method too"", 'comment_created': datetime.datetime(2020, 8, 18, 14, 5, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472241657, 'comment_body': 'Ah okay, thanks for explaining. I missed that. :+1:', 'comment_created': datetime.datetime(2020, 8, 18, 14, 30, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472242743, 'comment_body': ""It would be slower granted. Before making changes, let's discuss this in the slack channel, and post our decision in the main PR GitHub discussion."", 'comment_created': datetime.datetime(2020, 8, 18, 14, 32, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472243865, 'comment_body': ""If we did do that, I would want to make sure that we didn't have a bunch of conditionals everywhere checking for aggregation status. This might be outside the scope of GSoC, and need to be a later refactoring."", 'comment_created': datetime.datetime(2020, 8, 18, 14, 33, 32, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472247076, 'comment_body': 'I see what you mean. Given our discussion on the feature document. It makes sense to keep this function. We still need to register at `__init__`, but it will likely be necessary in the public API as well.', 'comment_created': datetime.datetime(2020, 8, 18, 14, 37, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472257317, 'comment_body': ""I didn't yet resolve this, but I will do this most probably by today"", 'comment_created': datetime.datetime(2020, 8, 18, 14, 51, 4, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472267283, 'comment_body': ""Actually in #336 I have implemented such behaviour.\r\nI checked if its a group of 1 with no `select`/`sort`/`reverse` parameters then we consider that as non aggregate and we don't print it in the aggregate details of status check.\r\n\r\nBelow is the sample status output\r\n\r\n```\r\nOverview:                                                                                                                                 \r\n\r\nTotal # of jobs: 50\r\n\r\nlabel              ratio\r\n-----------------  --------------------------------------------------\r\nidentity_computed  |████████████████████████████████████████| 100.00%\r\n\r\noperation           number of eligible aggregates\r\n----------------  -------------------------------\r\ncompute_identity                               50\r\ncompute_sum                                     1\r\n\r\nDetailed View:\r\n\r\njob_id                            operation             aggregation_status    labels\r\n--------------------------------  --------------------  --------------------  -----------------\r\nee5ca9ab62e9dbb7b6abbaaac6443d49  compute_identity [U]  non-aggregate         identity_computed\r\n                                  compute_sum [U]       aggregate - 50        identity_computed\r\n03086200817396c6083c34ac025ec4d5  compute_identity [U]  non-aggregate         identity_computed\r\n                                  compute_sum [U]       aggregate - 50        identity_computed\r\n\r\nDetailed Aggregate View:\r\n\r\noperation    jobs_in_aggregate                   length_of_aggregate  status\r\n-----------  --------------------------------  ---------------------  --------\r\ncompute_sum  ee5ca9ab62e9dbb7b6abbaaac6443d49                     50  [U]\r\ncompute_sum  03086200817396c6083c34ac025ec4d5                     50  [U]\r\ncompute_sum  92f821919b4b0a2f15d0ef3f5d433550                     50  [U]\r\ncompute_sum  5d63db8dc4821a190f690fd66e4dd0be                     50  [U]\r\ncompute_sum  6acfe44c405aca35383ffb75561e8a7d                     50  [U]\r\n\r\n```"", 'comment_created': datetime.datetime(2020, 8, 18, 15, 4, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472291905, 'comment_body': 'Yes, I agree. We are doing it now in this implementation', 'comment_created': datetime.datetime(2020, 8, 18, 15, 38, 12, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472327874, 'comment_body': 'If a user messes with a file in `.aggregates` that is on them, in my opinion.', 'comment_created': datetime.datetime(2020, 8, 18, 16, 32, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472330687, 'comment_body': 'We could keep this public now with static aggregation, but we would need to accept aggregates as well.', 'comment_created': datetime.datetime(2020, 8, 18, 16, 36, 34, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472377282, 'comment_body': '```suggestion\r\ndef _get_aggregate_id(jobs):\r\n```\r\nThe current function name makes not much sense.', 'comment_created': datetime.datetime(2020, 8, 18, 17, 51, 58, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472377598, 'comment_body': ""```suggestion\r\n        aggregate_id = generate_hashed_aggregates(jobs) if jobs is not None else ''\r\n```\r\nThe variable name should be descriptive of the underlying entity. The fact that the id was generated via a hash function is irrelevant."", 'comment_created': datetime.datetime(2020, 8, 18, 17, 52, 34, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472378828, 'comment_body': 'see comment above', 'comment_created': datetime.datetime(2020, 8, 18, 17, 54, 41, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472379533, 'comment_body': 'Please revert this change and provide a second `_fn_aggregate()` function. There is very little code duplication and the premature generalization makes the code more abstract and harder to read.', 'comment_created': datetime.datetime(2020, 8, 18, 17, 55, 45, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472385863, 'comment_body': 'We should probably verify when iterating over the passed jobs. Since this is likely to be needed multiple places, we could make it a function that returns the correct list or yields valid aggregates.', 'comment_created': datetime.datetime(2020, 8, 18, 18, 7, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472386310, 'comment_body': ""So what we're essentially storing here is:\r\n`op.name -> [operation.id <aggregate job ids>]*`\r\nIs that correct?\r\n\r\nIs there a reason that we don't just store those in the project document or so?"", 'comment_created': datetime.datetime(2020, 8, 18, 18, 7, 55, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472390163, 'comment_body': '```suggestion\r\n                    if aggregate_wid in agg_file_contents.splitlines():\r\n```', 'comment_created': datetime.datetime(2020, 8, 18, 18, 14, 46, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472390355, 'comment_body': ""```suggestion\r\n            aggregate_wid = '{} {}'.format(operation.id, ' '.join(map(str, operation._jobs)))\r\n```"", 'comment_created': datetime.datetime(2020, 8, 18, 18, 15, 3, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472390461, 'comment_body': ""```suggestion\r\n                    file.write(aggregate_wid + '\\n')\r\n```"", 'comment_created': datetime.datetime(2020, 8, 18, 18, 15, 15, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472397342, 'comment_body': 'Why not make this a generator function?', 'comment_created': datetime.datetime(2020, 8, 18, 18, 27, 19, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472398623, 'comment_body': 'This is not correct any more.', 'comment_created': datetime.datetime(2020, 8, 18, 18, 29, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472399204, 'comment_body': ""We can't just remove this, this is part of the public API. Why can we no longer support this?"", 'comment_created': datetime.datetime(2020, 8, 18, 18, 30, 42, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472401289, 'comment_body': ""This isn't really generating. You are getting the aggregate via the id."", 'comment_created': datetime.datetime(2020, 8, 18, 18, 34, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472401574, 'comment_body': 'What kind of error are we trying to catch here? This seems overly defensive with the broad except.', 'comment_created': datetime.datetime(2020, 8, 18, 18, 35, 26, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472401584, 'comment_body': 'You use this outside of the CLI. We should remove that from the name.', 'comment_created': datetime.datetime(2020, 8, 18, 18, 35, 28, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472402653, 'comment_body': 'This logic exists in multiple places. Placing this in a function would be helpful.', 'comment_created': datetime.datetime(2020, 8, 18, 18, 37, 32, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472403106, 'comment_body': 'This should be solved with static aggregation correct?', 'comment_created': datetime.datetime(2020, 8, 18, 18, 38, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472405046, 'comment_body': 'combine', 'comment_created': datetime.datetime(2020, 8, 18, 18, 42, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472407054, 'comment_body': 'Why is this a list of ids?', 'comment_created': datetime.datetime(2020, 8, 18, 18, 46, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472407515, 'comment_body': 'remove print statement.', 'comment_created': datetime.datetime(2020, 8, 18, 18, 46, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 472428084, 'comment_body': 'Yes, we could do that. Thank you for the suggestion.', 'comment_created': datetime.datetime(2020, 8, 18, 19, 24, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472429175, 'comment_body': 'I think this should be public because users would want to know the aggregate id in order to pass it to the CLI', 'comment_created': datetime.datetime(2020, 8, 18, 19, 26, 43, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472431116, 'comment_body': ""Yes we're storing the mentioned data only.\r\nAnd no there's no specific reason to do this. I thought that a structure similar to bundles would be helpful."", 'comment_created': datetime.datetime(2020, 8, 18, 19, 30, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472433212, 'comment_body': ""Aggregates are created on a per-group basis. We'd now have to iterate over aggregates hence we the `by-job` order won't be the default choice. "", 'comment_created': datetime.datetime(2020, 8, 18, 19, 34, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472433910, 'comment_body': ""I'd say the most appropriate catch would be a `TypeError` or a `ValueError`.\r\nI will add these"", 'comment_created': datetime.datetime(2020, 8, 18, 19, 36, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472434289, 'comment_body': ""I'm sorry, I missed this part of the implementation. \r\nI will change it"", 'comment_created': datetime.datetime(2020, 8, 18, 19, 36, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472434597, 'comment_body': 'Yes, this will be solved.\r\nI will parallelize it.', 'comment_created': datetime.datetime(2020, 8, 18, 19, 37, 27, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472926686, 'comment_body': ""I will make this change, but I'm not sure why are we doing this? Can you please help me understand?"", 'comment_created': datetime.datetime(2020, 8, 19, 10, 28, 6, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 472932134, 'comment_body': ""This should not be combined as a label doesn't accept multiple jobs.\r\nI'll use `elif` instead"", 'comment_created': datetime.datetime(2020, 8, 19, 10, 37, 58, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 473053303, 'comment_body': ""Python will short circuit if the logical operators if possible so `if len(job) > 1 or ...` if `len(job) > 1 == True` then it won't even run the right side of the or."", 'comment_created': datetime.datetime(2020, 8, 19, 14, 2, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 473053540, 'comment_body': 'Using an `elif` is fine, but just so you know.', 'comment_created': datetime.datetime(2020, 8, 19, 14, 2, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 473056796, 'comment_body': ""Oh okay, I didn't know about that. Thank you for letting me know.\r\nIf that's the case then I'll implement your suggestion\r\n"", 'comment_created': datetime.datetime(2020, 8, 19, 14, 7, 10, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 473193956, 'comment_body': ""That's ok, but please rename the function to something sensible."", 'comment_created': datetime.datetime(2020, 8, 19, 17, 11, 30, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 473194705, 'comment_body': 'I think we should avoid adding more files to the project space if at all possible. I believe we are using the file-based approach for bundles because we need to be able to access them in a very distributed manner. That said, the project document did not exist yet at the time when bundles were implemented.', 'comment_created': datetime.datetime(2020, 8, 19, 17, 12, 48, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 473195355, 'comment_body': ""This is in combination with the other changes I suggested. It's just a slightly cleaner approach of parsing those newline-separated files. You don't have to make that change, but I think it's overall a bit cleaner."", 'comment_created': datetime.datetime(2020, 8, 19, 17, 14, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 473195574, 'comment_body': 'This was discussed on slack, can you summarize the results of that discussion here, please?', 'comment_created': datetime.datetime(2020, 8, 19, 17, 14, 22, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 473211311, 'comment_body': 'I will do that ', 'comment_created': datetime.datetime(2020, 8, 19, 17, 41, 20, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 473211757, 'comment_body': 'Oh okay, that makes sense now. Will use project doc', 'comment_created': datetime.datetime(2020, 8, 19, 17, 42, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 473232633, 'comment_body': ""@csadorf I'm fine with this for now, but in the long term I think we should move away from using the project document for storing internal signac state information. I agree that avoiding polluting the user's project space is a good thing for now, but when we get around to implementing glotzerlab/signac#197 I would also like to change how we deal with aggregates (and status).\r\n\r\nPart of the reason for this is that (unlike state points), job documents (and therefore also project documents) are files that at least some users will choose to open and possibly even edit (for instance, to modify some progress or completion indicator) without using the signac API, and I think that's OK. That being the case, I think it would also be preferable not to clutter this file with information on signac's internal operations (aggregates, bundles, status, etc). At a conceptual level, I think we should clearly separate user and internal information, and using the project document this way breaks that separation. The other part of my reasoning is that for large data spaces, storing status (and aggregate/bundle/etc information) in the project document makes it large enough to generate noticeable performance delays with opening, modifying, and resaving the file. Buffering can of course ameliorate these performance issues, but I think we would be better off avoiding them completely.\r\n\r\nI don't think making any of the changes I've mentioned is in scope for PR, but since it's relevant here I wanted to post and gauge opinions. For now (and until we move forward on glotzerlab/signac#197) I think using the project document is fine, but if you agree then we should add this to the long-term to-do list."", 'comment_created': datetime.datetime(2020, 8, 19, 18, 19, 46, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 474089487, 'comment_body': 'The result of the discussion of slack on this topic is posted here\r\nhttps://github.com/glotzerlab/signac-flow/pull/335#issuecomment-677747896', 'comment_created': datetime.datetime(2020, 8, 20, 15, 50, 59, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474091658, 'comment_body': 'The result of the discussion of slack on this topic is posted here\r\nhttps://github.com/glotzerlab/signac-flow/pull/335#issuecomment-677747896', 'comment_created': datetime.datetime(2020, 8, 20, 15, 54, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474836929, 'comment_body': 'I should mention tuple of what', 'comment_created': datetime.datetime(2020, 8, 21, 17, 39, 39, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474837693, 'comment_body': ""```suggestion\r\n        cmd = cmd if jobs is None else cmd + f' -j {get_aggregate_id(jobs)}'\r\n```\r\nLooks more clean"", 'comment_created': datetime.datetime(2020, 8, 21, 17, 41, 15, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474842373, 'comment_body': '```suggestion\r\n            return f""{entrypoint} exec {operation_name} {get_aggregate_id(jobs)}"".lstrip()\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 17, 51, 17, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474842661, 'comment_body': '```suggestion\r\n    def _fn_bundle(self, bundle_id):\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 17, 51, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474842838, 'comment_body': ""```suggestion\r\n        return os.path.join(self.root_directory(), '.bundles', bundle_id)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 21, 17, 52, 15, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474843344, 'comment_body': '```suggestion\r\n        """"""Store aggregate information on a per operation basis.\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 17, 53, 20, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474844837, 'comment_body': '```suggestion\r\n        """"""Fetch submitted aggregates for a group.\r\n        \r\n        This enables the fetching status of lost aggregates.\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 17, 56, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474846624, 'comment_body': '```suggestion\r\n        # The group associated with the group_name contains only a\r\n        # single operation having its name equals group_name.\r\n        # Hence set the operation_name to group.name\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 17, 59, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474847739, 'comment_body': 'Since a job here is not really a ""job"" (it\'s a tuple containing a single job) hence I think we should be consistent with the names in order to avoid confusion. This ofc gets resolved in #336 but we should implement that change in this PR throughout the code.', 'comment_created': datetime.datetime(2020, 8, 21, 18, 2, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474848051, 'comment_body': '```suggestion\r\n        for job in tqdm(jobs, desc=""Collecting aggregate status info for operation {}""\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 18, 2, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474849235, 'comment_body': '```suggestion\r\n    def _fetch_status(self, jobs, distinct_jobs, err, ignore_errors,\r\n```\r\nThe variable ""fetched_jobs"" collects all the distinct jobs from all the jobs or aggregate passed by the user.\r\nIt should be something meaningful.\r\nIn #336 we also use the terms `aggregated_jobs` somewhere.\r\nWe need to prevent that confusion too', 'comment_created': datetime.datetime(2020, 8, 21, 18, 5, 21, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474852549, 'comment_body': '```suggestion\r\n            # Fetch all the distinct jobs from all the jobs or aggregate passed by the user\r\n            distinct_jobs = set()\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 18, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474853986, 'comment_body': '```suggestion\r\n                # In order to group the aggregates in a by-job manner, we need\r\n                # to first sort the aggregates using their aggregate id.\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 18, 16, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474854437, 'comment_body': 'The term `job` is confusing here. We should use aggregates throughout the code-base now', 'comment_created': datetime.datetime(2020, 8, 21, 18, 17, 28, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474856474, 'comment_body': '```suggestion\r\n                raise LookupError(f""Did not find the aggregate {aggregate} having id {aggregate_id} in the project"")\r\n```\r\nWe need to provide the value of the aggregate as users are not going to pass the id in our python API', 'comment_created': datetime.datetime(2020, 8, 21, 18, 21, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474857255, 'comment_body': '```suggestion\r\n        # Convert all the signac jobs passed by a user into a tuple of 1 job.\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 18, 23, 44, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474857959, 'comment_body': '```suggestion\r\n        ""Yield instances of _JobOperation constructed for the specific job-aggregate associated with the group.""\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 18, 25, 17, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474858827, 'comment_body': ""@b-butler @csadorf Should this method expect an aggregate of jobs too?\r\nWe can't return an instance of `_JobOperation` since it's private."", 'comment_created': datetime.datetime(2020, 8, 21, 18, 27, 26, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474859209, 'comment_body': '```suggestion\r\n    def _reregister_default_aggregates(self):\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 18, 28, 16, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474860212, 'comment_body': 'Remove this statement', 'comment_created': datetime.datetime(2020, 8, 21, 18, 30, 21, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474865967, 'comment_body': 'Should be implemented in #335 ', 'comment_created': datetime.datetime(2020, 8, 21, 18, 43, 39, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474896800, 'comment_body': ""This is technically API breaking.\r\nIn order to avoid that, I have added a commented code which I am pasting here\r\n```\r\nif len(distinct_jobs) == 1:  # Doesn't break the current API\r\n    result['labels'] = result['labels'][str(distinct_jobs[0])]\r\n    result['_labels_error'] = result['_labels_error'][str(job)]\r\n```\r\n@csadorf @b-butler please suggest what should be done here"", 'comment_created': datetime.datetime(2020, 8, 21, 19, 34, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 474940014, 'comment_body': ""I agree with @vyasr's assessment."", 'comment_created': datetime.datetime(2020, 8, 21, 20, 27, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474941071, 'comment_body': ""Shouldn't we just check for inclusion of `jobs` in `self.aggregate[group.name]`?"", 'comment_created': datetime.datetime(2020, 8, 21, 20, 28, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474947526, 'comment_body': 'I would uncomment the code for now. With #341 we will likely change the way Python status checking works in the future.', 'comment_created': datetime.datetime(2020, 8, 21, 20, 36, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474948792, 'comment_body': 'The link is the discussion on the ordering of operations in `FlowProject.run` not status checking.', 'comment_created': datetime.datetime(2020, 8, 21, 20, 38, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474951051, 'comment_body': 'Why are we not using `get_aggregate_id` here?', 'comment_created': datetime.datetime(2020, 8, 21, 20, 40, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474951404, 'comment_body': 'Looking at the code it is storing errors for individual aggregates since the for loop is iterating over aggregates.', 'comment_created': datetime.datetime(2020, 8, 21, 20, 41, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474953054, 'comment_body': 'I would still like to see the hard coded names done away with.', 'comment_created': datetime.datetime(2020, 8, 21, 20, 43, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474954755, 'comment_body': ""Couldn't we just put a filter on `jobs`?"", 'comment_created': datetime.datetime(2020, 8, 21, 20, 45, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474959223, 'comment_body': ""What is the difference here from cyclic?\r\n\r\nI don't think we want round robin here. Maybe we want `itertools.chain`?"", 'comment_created': datetime.datetime(2020, 8, 21, 20, 50, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474960477, 'comment_body': '```suggestion\r\n            if not aggregate_id not in self._aggregate_ids:\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 20, 52, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474963169, 'comment_body': ""This is being deprecated. Just keep existing behavior. We don't need to add functionality to it."", 'comment_created': datetime.datetime(2020, 8, 21, 20, 55, 23, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474963705, 'comment_body': 'I think we agreed that operations should own their aggregates.', 'comment_created': datetime.datetime(2020, 8, 21, 20, 55, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474964960, 'comment_body': 'We store a list of job tuples for every operation. We should like have a something akin to a `dict` of operation names to aggregate names which then has the list and `dict` with aggregate ids.', 'comment_created': datetime.datetime(2020, 8, 21, 20, 57, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474965547, 'comment_body': 'What is this for? Why do we need to register them again?', 'comment_created': datetime.datetime(2020, 8, 21, 20, 58, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474967052, 'comment_body': 'We do not want to reiterate through the list of jobs every time we look at the aggregates present. I get we are doing it to ensure we catch job statepoints changing, but I would rather see something that mimics a `dict` or `list` API that lazily loads jobs when required using the project.', 'comment_created': datetime.datetime(2020, 8, 21, 20, 59, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 475051719, 'comment_body': ""This was discussed, but was that feature in the scope of this PR? I wasn't sure about it."", 'comment_created': datetime.datetime(2020, 8, 22, 6, 0, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475051887, 'comment_body': ""I'm not sure why we should do that because then we'd have to iterate over `self._groups` in order to get an aggregate from it's id."", 'comment_created': datetime.datetime(2020, 8, 22, 6, 2, 41, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475052155, 'comment_body': ""If we don't re-register then while using the python API we'd then have to execute `project.generate_aggregates`.\r\nIt'll be very inconsistent otherwise."", 'comment_created': datetime.datetime(2020, 8, 22, 6, 6, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475060814, 'comment_body': 'Good points, @vyasr .', 'comment_created': datetime.datetime(2020, 8, 22, 7, 56, 39, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 475060847, 'comment_body': '@kidrahahjo Please hold off making any changes in that regard.', 'comment_created': datetime.datetime(2020, 8, 22, 7, 57, 6, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 475087702, 'comment_body': ""@b-butler I agree that, but if we don't add submission id the we'll allow users add some other aggregates which may create problems."", 'comment_created': datetime.datetime(2020, 8, 22, 12, 54, 59, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475087880, 'comment_body': 'This is now resolved', 'comment_created': datetime.datetime(2020, 8, 22, 12, 57, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475087977, 'comment_body': 'This is now resolved.', 'comment_created': datetime.datetime(2020, 8, 22, 12, 58, 47, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475118294, 'comment_body': ""We create `distinct_jobs` in `print_status`(because we need it in that method) and then pass it in `_fetch_status`.\r\nI don't think performing that task again would be a nice idea.\r\n\r\n**I'd like to reiterate my comment.** (because I don't think my previous comment was logical) \r\nThe point I was trying to make was users are allowed to pass this in the jobs `jobs=[job1, job2, [job2, job3], [job4]`.\r\nWe could add a filter but that will result in recomputing everything because we need the `distinct_jobs` variable in the `print_status` method too.\r\n\r\n@b-butler please suggest the right approach."", 'comment_created': datetime.datetime(2020, 8, 22, 18, 36, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475118478, 'comment_body': ""This topic is currently being discussed on slack with @b-butler.\r\nI'll post the summary of that discussion after we come to a decision about this"", 'comment_created': datetime.datetime(2020, 8, 22, 18, 38, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475119251, 'comment_body': 'Hmmm, yes I think we should. Good idea, thanks for that @b-butler ', 'comment_created': datetime.datetime(2020, 8, 22, 18, 48, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 475120688, 'comment_body': 'I\'d also like to add that I think we don\'t need to use this method because we technically are creating iterable objects first and then iterating over it which means that we\'re not showing a ""valid"" progress bar here.\r\nI think I should remove this functionality because of this point', 'comment_created': datetime.datetime(2020, 8, 22, 19, 4, 25, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 488817808, 'comment_body': 'This might be clear to other people but it hurt my brain a bit/it was hard for me to see this is an f-string, especially since the line above uses the `.format()` syntax.  ', 'comment_created': datetime.datetime(2020, 9, 15, 16, 54, 42, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 488818557, 'comment_body': 'The github syntax highlighting might be the real issue, but I wonder if it would be more clear to use an f-string one line 904 as well, since its the only example in this function of using the `.format()` syntax', 'comment_created': datetime.datetime(2020, 9, 15, 16, 55, 54, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 492308666, 'comment_body': ""Why is this necessary? We typically don't require an order to our decorators."", 'comment_created': datetime.datetime(2020, 9, 21, 19, 52, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492312268, 'comment_body': 'I would prefer consistency as well.', 'comment_created': datetime.datetime(2020, 9, 21, 19, 59, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492314512, 'comment_body': '`dir` typically stands for directory. Using it for a filename is confusing. `filename` is more clear.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 4, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492315655, 'comment_body': '```suggestion\r\n                        yield tuple(self.open_job(id=job_id) for job_id in job_ids)\r\n```', 'comment_created': datetime.datetime(2020, 9, 21, 20, 6, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492315865, 'comment_body': ""I still don't think we need this. If a user changes a `.aggregates` file that is on them."", 'comment_created': datetime.datetime(2020, 9, 21, 20, 6, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492321397, 'comment_body': '```suggestion\r\n            distinct_jobs = set(jobs)\r\n```', 'comment_created': datetime.datetime(2020, 9, 21, 20, 17, 28, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492326507, 'comment_body': '```suggestion\r\n            errors.setdefault(get_aggregate_id(aggregate), None)\r\n\r\n```', 'comment_created': datetime.datetime(2020, 9, 21, 20, 27, 35, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492327103, 'comment_body': 'I would prefer the name `job_op_id` since we are also using the aggregate id.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 28, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492328537, 'comment_body': 'Maybe a list of job ids would be more appropriate for the dictionary? and we could use `join` later if we need to.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 31, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492330759, 'comment_body': ""This won't grab the singleton groups. It will grab all operations. They each have a singleton group but this is not the way to access them."", 'comment_created': datetime.datetime(2020, 9, 21, 20, 35, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492332456, 'comment_body': 'These variables do not need to be underscored.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 39, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492332589, 'comment_body': 'I would like to see this defined nearer where it is used.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 39, 33, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492334477, 'comment_body': 'Use `job.id` or `job.get_id()` instead. I believe, you still have to use the later for now.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 43, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492335646, 'comment_body': 'This is more status details than aggregate details. It has both, though. It may be worth conceptually splitting these.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 45, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492336400, 'comment_body': ""Internal functions like this don't need to an leading underscore."", 'comment_created': datetime.datetime(2020, 9, 21, 20, 46, 51, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492336523, 'comment_body': 'See comment above.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 47, 9, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492336755, 'comment_body': 'What is the purpose of storing both this and `is_aggregate`?', 'comment_created': datetime.datetime(2020, 9, 21, 20, 47, 35, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492336995, 'comment_body': 'Is this just adding a key value pair for each operation in the project? If so we should just use the `singleton_groups` variable as it will be more clear our intentions.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 48, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492342798, 'comment_body': 'This will return a list not a single id.', 'comment_created': datetime.datetime(2020, 9, 21, 20, 59, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492344181, 'comment_body': 'why are we doing this in its own for loop?', 'comment_created': datetime.datetime(2020, 9, 21, 21, 2, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492346144, 'comment_body': 'this part is the same for `cyclic` besides the `roundrobin`. it may be worth combining into one branch of the conditional with an extra nesting level.', 'comment_created': datetime.datetime(2020, 9, 21, 21, 6, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492347558, 'comment_body': 'This name could be more explicit something like `_is_selected_aggregate`.', 'comment_created': datetime.datetime(2020, 9, 21, 21, 9, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492350228, 'comment_body': 'I would rather not use a try and except block here, checking `id in stored_aggregator` will likely be multiple times faster since we except failures here.', 'comment_created': datetime.datetime(2020, 9, 21, 21, 15, 8, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492351495, 'comment_body': 'I would like to see this function renamed to something like `_aggregate_is_in_project`.', 'comment_created': datetime.datetime(2020, 9, 21, 21, 17, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492352848, 'comment_body': 'It seems this try block is only meant to catch errors in the `tuple` call. If that is the case we should use the `try`, `except`, `else` construct. Or just write the code that would be in the `else` block outside the try block.', 'comment_created': datetime.datetime(2020, 9, 21, 21, 20, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492354699, 'comment_body': ""To prevent an ordering requirement, we should check this for singleton groups at `FlowGroup` construction. Ultimately we decided that aggregates should be associated with operations so we shouldn't limit behavior now that will likely be removed."", 'comment_created': datetime.datetime(2020, 9, 21, 21, 24, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492355256, 'comment_body': ""I don't think we want to give users the ability to add aggregates to groups."", 'comment_created': datetime.datetime(2020, 9, 21, 21, 25, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 492357319, 'comment_body': 'Rather than a `continue` I would like to see an `else` block. Also, this code is used a few times (such as `_main_exec`). It may be worth refactoring into a separate function. (I am referring to the code to get aggregates from ids)', 'comment_created': datetime.datetime(2020, 9, 21, 21, 30, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 499629972, 'comment_body': ""I'm also starting to think that if users change then this should be on them but for now, I'm removing this whole process of storing aggregates in this PR and this will be implemented in the next PR.\r\n"", 'comment_created': datetime.datetime(2020, 10, 5, 14, 13, 59, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499636548, 'comment_body': 'Noted. To be implemented in the next PR.', 'comment_created': datetime.datetime(2020, 10, 5, 14, 22, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499636617, 'comment_body': 'Noted. To be implemented in the next PR.', 'comment_created': datetime.datetime(2020, 10, 5, 14, 23, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499640533, 'comment_body': ""I faced some problems when I was writing the template code. I don't exactly remember what was that.\r\nI'm skipping this for now and have noted this review for a later PR."", 'comment_created': datetime.datetime(2020, 10, 5, 14, 28, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499646900, 'comment_body': ""We previously showed operation based status and not a group based on. Meaning the status for a job operation pair will be shown and not a job group pair.\r\nBut now since aggregates are associated with groups, I thought that it'd be logical to name the variable as `singleton_groups` and stored all the operation names in it. \r\n\r\nI think this variable is poorly named, should I change this to `operation_as_group`?"", 'comment_created': datetime.datetime(2020, 10, 5, 14, 36, 28, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499650676, 'comment_body': ""@b-butler I didn't quite understand what you exactly mean by this. Can you please help me explain?\r\nAlthough this will now be tackled in a later PR."", 'comment_created': datetime.datetime(2020, 10, 5, 14, 41, 26, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499651469, 'comment_body': ""I think this is a misleading variable name. I'll change this in the next PR as this will get removed in this one."", 'comment_created': datetime.datetime(2020, 10, 5, 14, 42, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499652829, 'comment_body': 'Noted, this will be tackled in a later PR', 'comment_created': datetime.datetime(2020, 10, 5, 14, 44, 15, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499653117, 'comment_body': 'Noted, will be tackled in a later PR.', 'comment_created': datetime.datetime(2020, 10, 5, 14, 44, 40, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499656140, 'comment_body': ""the aggregate storing classes are implemented in such a way that if we use `__contains__` method then we'll have to pass an aggregate and not a id. If we use the `__get__` method then we'll be passing an id.\r\nWe could change the functionality if you suggest?"", 'comment_created': datetime.datetime(2020, 10, 5, 14, 48, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499658883, 'comment_body': 'the `aggregate_counter` was used to show how many eligible aggregates are present for an operation. I believe this could be refactored. Although, this will also be tackled in a later PR.\r\n', 'comment_created': datetime.datetime(2020, 10, 5, 14, 52, 7, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 499673786, 'comment_body': ""I read the comment on project.py to understand how we can use aggregation without this. I'll tackle this in a later PR."", 'comment_created': datetime.datetime(2020, 10, 5, 15, 12, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 504227861, 'comment_body': ""As much as I'm personally not a fan of it, the idiomatic Python code for this is: \r\n```suggestion\r\n                return [jobs] if jobs else []\r\n```"", 'comment_created': datetime.datetime(2020, 10, 13, 20, 14, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504237690, 'comment_body': ""You never need to mutate `shown`, so just make it a tuple and save yourself a cast.\r\n```suggestion\r\n            shown = self._jobs[:max_len-2] + ('...', ) + self._jobs[-1:]\r\n```"", 'comment_created': datetime.datetime(2020, 10, 13, 20, 25, 59, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504241761, 'comment_body': ""Making the default value of an argument the class means that you will always get exactly the same object. In this case, I think that is what you want; the aggregator is effectively a generator for AggregateStore classes, but I just want to be sure: there's no state associated with the aggregator that would cause problems here, is there?"", 'comment_created': datetime.datetime(2020, 10, 13, 20, 33, 41, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504243050, 'comment_body': ""In case it's not clear what issues I'm referring to, see this example:\r\n```\r\n>>> def f(x=[1]):\r\n...     x.append(1)\r\n...     return x\r\n...\r\n>>> a = f()\r\n>>> b = f()\r\n>>> a\r\n[1, 1, 1]\r\n>>> b\r\n[1, 1, 1]\r\n```"", 'comment_created': datetime.datetime(2020, 10, 13, 20, 36, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504251967, 'comment_body': ""Why does this need to be called explicitly? Isn't this something that the project should do automatically under the right circumstances? The fact that it's an underscore function means we shouldn't have to call it in our tests."", 'comment_created': datetime.datetime(2020, 10, 13, 20, 53, 34, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504252098, 'comment_body': 'Same question as above.', 'comment_created': datetime.datetime(2020, 10, 13, 20, 53, 48, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504255798, 'comment_body': 'Same question, why is this necessary?', 'comment_created': datetime.datetime(2020, 10, 13, 21, 0, 50, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504256996, 'comment_body': ""I had forgotten how much our tests make use of internal APIs. That's as clear a sign as any that internal refactorings are needed."", 'comment_created': datetime.datetime(2020, 10, 13, 21, 3, 27, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504269452, 'comment_body': 'The names of the various serialized methods don\'t look the same, for example `_serialized_get_job_labels` vs `_execute_serialized_operations` the ""serialized"" is in a different place. More importantly, now that multiple methods are using this, we should try to unify the implementations as much as possible. Is it possible to define a single function that accepts args/kwargs and forwards them along? Would need to standardize the serialization/deserialization of the project as well.', 'comment_created': datetime.datetime(2020, 10, 13, 21, 29, 18, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504271570, 'comment_body': 'These are aggregates, not aggregators, right? Make sure to use the right variable names, the aggregator vs AggregateStore is going to be confusing enough as is.', 'comment_created': datetime.datetime(2020, 10, 13, 21, 33, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504274518, 'comment_body': ""This is a little confusing. Before this function always returned _something_, because there was a concept of an empty JobsCursor. Now it's possible to not only receive a list of aggregates, but also None. Is there a reason not to return an empty list so that at least it's consistently returning an empty iterable rather than None?"", 'comment_created': datetime.datetime(2020, 10, 13, 21, 39, 59, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504277247, 'comment_body': 'If we generalize `select_jobs_from_args` just a little bit (to first verify the existence of `filter` and `doc_filter` in the `args` namespace, this could call that method instead of duplicating the logic.', 'comment_created': datetime.datetime(2020, 10, 13, 21, 46, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504280251, 'comment_body': 'Why did this change from an `in` to an equals? I vaguely remember that this was intentionally supporting this syntax for convenience, but I could be confusing it with something else.', 'comment_created': datetime.datetime(2020, 10, 13, 21, 53, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504653041, 'comment_body': '```suggestion\r\n        # To store the aggregates we need to store the store all the groups associated\r\n        # with each aggregator.\r\n```\r\nAlso maybe move this comment above the for loop instead of here.', 'comment_created': datetime.datetime(2020, 10, 14, 12, 55, 35, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504653605, 'comment_body': '```suggestion\r\n        """"""Return all aggregates associated with the FlowGroup.\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 12, 56, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504656091, 'comment_body': 'No need for a new line here, just make sure the line wraps appropriately.\r\n```suggestion\r\n            The signac job handles. By default all the aggregates are evaluated to get\r\n            the next operation associated.\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 12, 59, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504656868, 'comment_body': 'Why do you specify the initialization here? Aren\'t all aggregates created at initialization?\r\n```suggestion\r\n        """"""Determine the next eligible operations for aggregates.\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 13, 0, 56, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504657088, 'comment_body': '```suggestion\r\n        """"""Yield instances of _JobOperation constructed for the specific aggregate associated\r\n        with the group.""""""\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 13, 1, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504657991, 'comment_body': '```suggestion\r\n        # The jobs parameter in public methods like ``run``, ``submit``, ``status`` may\r\n        # accept either a signac job or an aggregate. We convert that job / aggregate\r\n        # (which may be of any type (eg. list)) to an aggregate of type ``tuple``.\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 13, 2, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504658946, 'comment_body': '```suggestion\r\n            # Aggregates must be a set to prevent duplicate entries\r\n            aggregates = set()  \r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 13, 4, 5, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504659027, 'comment_body': '```suggestion\r\n                # User can still pass signac jobs.\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 13, 4, 11, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504659904, 'comment_body': '```suggestion\r\n        aggregates = self._convert_aggregates_from_jobs(jobs)\r\n```\r\nThe docstring for the function explains this well enough, no need to repeat here.', 'comment_created': datetime.datetime(2020, 10, 14, 13, 5, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504660280, 'comment_body': 'When you say ""regular"", are these checks identical to other places in the code? If so, can we refactor them to all call a single validation function?', 'comment_created': datetime.datetime(2020, 10, 14, 13, 5, 56, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504663343, 'comment_body': ""The fact that `and` has higher precedence than `or` is likely to be very confusing to most readers of this code, and it's good not to depend on such things anyway because they're easy to make mistakes with.\r\n```suggestion\r\n                (requires and set(requires).difference(self.labels(*aggregate)))\r\n```"", 'comment_created': datetime.datetime(2020, 10, 14, 13, 10, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504670182, 'comment_body': 'It\'s not obvious without reading other parts of the code that returning `True if jobs is None` is the expected behavior for this function. I\'ve proposed a docstring that indicates the current behavior, but it is probably worth adding something additional to indicate _why_ this is desirable behavior.\r\n```suggestion\r\n        """"""Verifies whether the aggregate is present in the provided jobs.\r\n        \r\n        Always returns True if jobs is None.\r\n        """"""\r\n        return True if jobs is None else (aggregate in jobs)\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 13, 19, 42, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504673330, 'comment_body': 'The API for `_run_operations` indicates that the input is any sequence, and it internally casts things to lists. We should rely on that and remove all the `list` casts here.', 'comment_created': datetime.datetime(2020, 10, 14, 13, 24, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504673963, 'comment_body': '```suggestion\r\n            Only execute operations for the given jobs or aggregates of jobs,\r\n```', 'comment_created': datetime.datetime(2020, 10, 14, 13, 24, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504676613, 'comment_body': ""```suggestion\r\n        results = []\r\n        index = {}\r\n        for i, job in enumerate(distinct_jobs):\r\n            results_entry = dict()\r\n            results_entry['job_id'] = str(job)\r\n            results_entry['operations'] = dict()\r\n            results_entry['_operations_error'] = None\r\n            results_entry['labels'] = list()\r\n            results_entry['_labels_error'] = None\r\n            results.append(results_entry)\r\n            index[job.get_id()] = i\r\n```"", 'comment_created': datetime.datetime(2020, 10, 14, 13, 28, 34, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504677341, 'comment_body': ""Actually now that I'm reading the block below, I'm confused. Why isn't results just a dict keyed on `job_id`, instead of a list of `dicts` where you have to index by this separate variable `index`?"", 'comment_created': datetime.datetime(2020, 10, 14, 13, 29, 41, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504686874, 'comment_body': ""The tqdm package support [manual updates to a progressbar](https://github.com/tqdm/tqdm#manual). Can you change this to use that instead? The logic shouldn't change much other than using `pbar.update` instead of `print`."", 'comment_created': datetime.datetime(2020, 10, 14, 13, 42, 31, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504689525, 'comment_body': ""The internals of this function feel like they're becoming far too complicated to me. I realize that we're doing two separate loops over jobs and groups, so those are logically distinct, but why is that change part of this PR? `get_job_status` returns a strict superset of the information in `get_job_labels`, in particular it also includes the information on the operations, but why weren't these changes necessary for groups (pre-aggregates)? Also does the fact that we needed to add this new `_get_group_status` method indicate that the `_get_job_status` was in some way broken by groups (not literally broken, but providing incomplete information)? If so, do we need to change it, considering it's part of the public API?\r\n\r\nAlso how big of a performance improvement do we get by separately parallelizing the label and group status updates? The old method was already quite complex, and now there's a ton of extra logic being used simply to construct two separate objects in parallel and then combine them."", 'comment_created': datetime.datetime(2020, 10, 14, 13, 45, 13, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504697769, 'comment_body': ""I would remove line 1832 (which creates the result dict), then just write this line as `result = {'operation_name': group_name}` and move it below the for loop (because it's not modified until the end)."", 'comment_created': datetime.datetime(2020, 10, 14, 13, 55, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504698327, 'comment_body': 'I think this partially answers some of my questions re: `_fetch_status`. I think we would want to fix this method so that we can use it there rather than adding a bunch of new methods (or at least have this method call those methods).', 'comment_created': datetime.datetime(2020, 10, 14, 13, 55, 51, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 504698752, 'comment_body': 'How does this method relate to the new `_get_job_labels` and `_get_group_status`? Do we really need these to all be separate, and if so can we find more clear delineations between them?', 'comment_created': datetime.datetime(2020, 10, 14, 13, 56, 23, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 506448714, 'comment_body': ""I didn't think of this in the way you're referring to. But I believe since the DefaultAggregatesStore class always iterate over a project, I think this is the required behaviour.\r\n\r\nI'm not sure whether it'd be a problem if we use inherited projects. I'll have to test this once."", 'comment_created': datetime.datetime(2020, 10, 16, 13, 53, 51, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506451177, 'comment_body': ""We register jobs after initializing the project. This means that technically, the jobs in the project has changed hence we'll need to re-register aggregates. I think we should make a method called `reregister_aggregates` and use that method instead of using a private method."", 'comment_created': datetime.datetime(2020, 10, 16, 13, 55, 48, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506453417, 'comment_body': 'https://github.com/glotzerlab/signac-flow/pull/335#discussion_r506451177\r\nDiscussed here (for future reference)', 'comment_created': datetime.datetime(2020, 10, 16, 13, 57, 40, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506453443, 'comment_body': 'https://github.com/glotzerlab/signac-flow/pull/335#discussion_r506451177\r\nDiscussed here (for future reference)', 'comment_created': datetime.datetime(2020, 10, 16, 13, 57, 41, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506455510, 'comment_body': 'Can you please help me understand what you mean by this comment? Do you mean that we should avoid using private methods in our tests?', 'comment_created': datetime.datetime(2020, 10, 16, 13, 59, 48, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506477718, 'comment_body': 'The primary reason was to cover an edge case where users pass in an empty list in the `jobs` parameter. `None` here means that allow all the aggregate operation pairs to get executed. But we use an empty list instead of None then the behaviour would be unwanted as the user passed in no jobs. \r\n\r\nPlease suggest what should I do here.', 'comment_created': datetime.datetime(2020, 10, 16, 14, 20, 58, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506478017, 'comment_body': ""That'd be the right approach. Thanks for that."", 'comment_created': datetime.datetime(2020, 10, 16, 14, 21, 18, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506488588, 'comment_body': 'I will revert the change. But if you remember exactly why we used an `in` rather than equals please post it here so that I could add a comment for future reference.', 'comment_created': datetime.datetime(2020, 10, 16, 14, 32, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506495092, 'comment_body': ""Yes that's true, I'll edit the doc."", 'comment_created': datetime.datetime(2020, 10, 16, 14, 38, 32, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506501154, 'comment_body': ""I think this comment is not authored by me. And apart from that, we don't repeat this check anywhere else so I think making a function might add some complexity."", 'comment_created': datetime.datetime(2020, 10, 16, 14, 44, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506502595, 'comment_body': 'This function is removed in the 0.11 release. I will update this branch with master in the next commit.', 'comment_created': datetime.datetime(2020, 10, 16, 14, 46, 33, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506506686, 'comment_body': ""> The None value to jobs indicates that no specific job is provided by the user and hence aggregate is eligible for further evaluation.\r\n\r\nI'm adding this doc as well. Please suggest any further improvement."", 'comment_created': datetime.datetime(2020, 10, 16, 14, 51, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 506722840, 'comment_body': 'As long as using the same aggregator object over and over is fine (to generate many different instances of `DefaultAggregatesStore`) this should be OK.', 'comment_created': datetime.datetime(2020, 10, 16, 21, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 506723449, 'comment_body': ""@b-butler @bdice correct me if I am wrong, but when we had the discussion about when aggregates are created we decided it should be on project construction, right? So that if the user added new jobs after, those wouldn't be in the aggregates and that was expected? I'd be open to adding a public method for re-registering though, I think we just didn't want to try and do that implicitly because it created too many edge cases."", 'comment_created': datetime.datetime(2020, 10, 16, 21, 12, 37, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 506724665, 'comment_body': ""Yes, exactly. Most tests should be validating that the code works as expected from a user's perspective. Since users won't be using internal methods, if our tests require it that suggests something is wrong with our API. This is not _always_ the case; for instance, for packages where a simple API hides some very complicated internals, it could make sense to directly unit test those internals. We do this with `_fetch_status`, for example. However, from skimming our tests we also do this in cases where we're just testing normal usage. I think some of these may be holdovers from deprecations of public methods, so it might not be as bad as I think, but it's something to keep in mind."", 'comment_created': datetime.datetime(2020, 10, 16, 21, 15, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 506731035, 'comment_body': '@vyasr I believe that was the consensus, yes. Create all aggregates on project instantiation, and then (eventually) offer a public method to update the aggregates. Aggregates are not updated implicitly.\r\n\r\n_However,_ it looks like this method is creating a ""mock"" project and adding jobs after the project is instantiated, so the normal workflow is subverted. I think the strategy here is acceptable but perhaps it would be better to:\r\n1. Instantiate project and add jobs (this would normally be done in something like an `init.py` script)\r\n2. Create new instance of project (triggers aggregation registration)\r\n3. Alter the new instance\'s `project._entrypoint` and other ""mocking"" hacks, then return it\r\n\r\nThis way any other ""constructor"" code is called correctly in the future.', 'comment_created': datetime.datetime(2020, 10, 16, 21, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 506732149, 'comment_body': 'I see, so the reason that this is confusing is because `JobsCursor` internally takes advantage of the fact `Project._find_job_ids` correctly handles `None` values for `filter` and `doc_filter`. You can see this because the constructor for `JobsCursor` does not provide default arguments for `filter` and `doc_filter`, so it just stores `None` and then passes it to `_find_job_ids` in the `__iter__` method.\r\n\r\nI think the correct solution here is probably to generalize the `JobsCursor` into an `AggregateCursor` class that is capable of the same types of lazy iteration, but over jobs _or_ aggregates rather than just jobs. @b-butler thoughts?', 'comment_created': datetime.datetime(2020, 10, 16, 21, 37, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 506732519, 'comment_body': 'Will do!', 'comment_created': datetime.datetime(2020, 10, 16, 21, 38, 16, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 506741517, 'comment_body': 'Yes I would prefer that as well.', 'comment_created': datetime.datetime(2020, 10, 16, 22, 6, 56, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507184099, 'comment_body': ""Please correct me if I'm wrong. I believe the strategy that @bdice proposed would result in changing in the way we instantiate projects in the tests. This should be tackled in a separate pull request. If you guys agree then I'm ready to give this a priority right after we merge this pull request."", 'comment_created': datetime.datetime(2020, 10, 18, 16, 36, 24, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507184643, 'comment_body': ""I agree with your POV. But in my opinion (Please correct me if I'm wrong), I think we're on a road where we are really deprecating a lot of public methods and I believe in the near future, not many methods will remain in the public namespace. And if that will be the case, I think testing of private methods might become a necessity."", 'comment_created': datetime.datetime(2020, 10, 18, 16, 41, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507185079, 'comment_body': ""I absolutely agree by this comment. I'll try to normalize as much as I can here."", 'comment_created': datetime.datetime(2020, 10, 18, 16, 45, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507186911, 'comment_body': ""Yes, I'll use the `update` method."", 'comment_created': datetime.datetime(2020, 10, 18, 17, 2, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507187155, 'comment_body': ""We require the results to be a list of dictionaries because of the logic we follow in `print_status` (which was previously implemented).\r\nI think if I change the type of results then I'd have to change the logic in `print_status` as well. If you want, I'll change this logic."", 'comment_created': datetime.datetime(2020, 10, 18, 17, 4, 39, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507190172, 'comment_body': '`_get_operation_status` returns status of a provided aggregate for all the groups whereas `_get_group_status` returns status of all the aggregates of a group only.', 'comment_created': datetime.datetime(2020, 10, 18, 17, 31, 43, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507203372, 'comment_body': ""I think the requested change is relevant enough and small enough that it could be done in this PR. Since all the tests use the `mock_project` method here, isn't it just a matter of adding an extra call to `get_project` or `project_class(...)` before the entrypoint is set? If there's some reason it needs to be more complex, then we can discuss doing it in a follow-up PR."", 'comment_created': datetime.datetime(2020, 10, 18, 19, 33, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507204478, 'comment_body': ""I agree that is possible. However, to your point about testing, if we do end up needing to test more internal methods, we would want to write more of them as proper unit tests, i.e. tests that verify only one thing at a time. Take this test, for instance: it's simultaneously verifying 3 different internal functions, whereas we could verify both `_get_submission_operations` and `create_submission_job_operations` independently without calling `_script`. A big part of why this is happening is that our internal abstractions are not as well-defined as they need to be. I suspect that in the longer run once we have refactored the internals we will want to start exposing more components in the public namespace again; right now it's just necessary to avoid because it's not clear that we're exposing the _right_ intermediates.\r\n\r\nIn any case, this comment was not meant to be actionable in any way within this PR. For now, I think we live with this state of affairs until we can start tackling some of these refactorings."", 'comment_created': datetime.datetime(2020, 10, 18, 19, 43, 47, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507204691, 'comment_body': ""👍 one idea might be to write a function that accepts something like `pickled_kwargs` and `raw_kwargs` (I'm just making up the names, there's probably something better than `raw_kwargs`) and uses that to determine which items need to be unpickled in the `serialized_*` function before passing them back to the project's method."", 'comment_created': datetime.datetime(2020, 10, 18, 19, 45, 37, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507204919, 'comment_body': ""Good point, yes that's fine."", 'comment_created': datetime.datetime(2020, 10, 18, 19, 47, 34, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507204952, 'comment_body': ""OK as long as it's not anywhere else that's fine."", 'comment_created': datetime.datetime(2020, 10, 18, 19, 47, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507205108, 'comment_body': 'That seems like perhaps a more extensive change since it will require modifying our status renderer class etc. Can you make a new issue to track that we want to change this, and then follow up on that in another PR once this is done?', 'comment_created': datetime.datetime(2020, 10, 18, 19, 49, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507205299, 'comment_body': ""Do they behave differently in any other way? Otherwise, can't we just unify them by allowing multiple groups to be passed to `_get_group_status`?"", 'comment_created': datetime.datetime(2020, 10, 18, 19, 51, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 507208331, 'comment_body': 'I agree with @vyas, this should be only slightly different (re-instantiate the project instead of calling the private method) and it fits in the scope of this PR.', 'comment_created': datetime.datetime(2020, 10, 18, 20, 17, 57, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 507494490, 'comment_body': ""@bdice @vyasr \r\nI agree with what you suggest but now when I'm thinking more about this, we won't be having any measure to test the behaviour in this pull request because the default aggregate store just iterates over the project and this will always provide us all the jobs present in the project, no matter when we add the job.\r\n\r\nI agree that it's just a one-liner change but I'd still want to change this in the other PR (where we also use the `AggrgateStore` class) and remove the `_register_aggregates`  call from the tests for now. "", 'comment_created': datetime.datetime(2020, 10, 19, 6, 15, 38, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507501974, 'comment_body': ""actually, we use the length of operations in debugging statements. So I'm not sure if we could simply use any sequence."", 'comment_created': datetime.datetime(2020, 10, 19, 6, 29, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 507504369, 'comment_body': ""Actually, the reason I'm not sure if we should do this is that `get_job_status` was meant to return the status of just a particular job or an aggregate. Previously we could just iterate over jobs and get the labels associated with it as well as fetch status wrt an operation. I'm not sure if we could do this anymore.\r\n\r\nBut I'll try reducing the complexity as much as I can."", 'comment_created': datetime.datetime(2020, 10, 19, 6, 35, 42, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 513915252, 'comment_body': '```suggestion\r\n                eligible = not completed and group._eligible(jobs)\r\n```', 'comment_created': datetime.datetime(2020, 10, 29, 3, 24, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 513917444, 'comment_body': 'This should be equivalent, faster, and a bit more Pythonic.\r\n```suggestion\r\n        yield from sorted(status_dict.items())\r\n```', 'comment_created': datetime.datetime(2020, 10, 29, 3, 27, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 513967480, 'comment_body': '@kidrahahjo Please make an issue (or some means to track work) that documents what still needs to be done in follow-up PRs. Include links to the open discussions like this one that we are punting on for now. It is hard for me to keep all of the context in my head as a reviewer. 😅 ', 'comment_created': datetime.datetime(2020, 10, 29, 4, 51, 52, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 513969517, 'comment_body': ""This comment doesn't make any sense to me. Do you mean:\r\n```suggestion\r\n            The name of the FlowGroup whose aggregate store will be returned.\r\n```"", 'comment_created': datetime.datetime(2020, 10, 29, 4, 56, 46, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 513970033, 'comment_body': '```suggestion\r\n            Aggregate store containing aggregates associated with the provided FlowGroup.\r\n```', 'comment_created': datetime.datetime(2020, 10, 29, 4, 58, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 513971883, 'comment_body': ""I'm very confused, why are there two supported arguments here, `job_id` and `jobid`?"", 'comment_created': datetime.datetime(2020, 10, 29, 5, 2, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 514309094, 'comment_body': ""I understand your reservation, but whether we call `_register_aggregates` manually or not doesn't change that fact. Right now we're also not really testing whether `_register_aggregates` works for non-default aggregates anyway, so I don't think these two changes are related."", 'comment_created': datetime.datetime(2020, 10, 29, 14, 37, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 514310764, 'comment_body': 'Where in debugging statements? For exceptions we raise in the code, in tests, somewhere else? Do we really need the length in those cases? If so, depending on the use case we can always generate the list at that point.', 'comment_created': datetime.datetime(2020, 10, 29, 14, 39, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 514311586, 'comment_body': '@bdice why 🤔 ', 'comment_created': datetime.datetime(2020, 10, 29, 14, 40, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 514312015, 'comment_body': '@kidrahahjo you mentioned you ran into problems with my suggestion here. Could you describe where this approach fails?', 'comment_created': datetime.datetime(2020, 10, 29, 14, 41, 6, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 514329886, 'comment_body': 'I meant to follow up on this with a comment. I had trouble figuring out why the return value should be `None`. Also I was not excited about creating another layer of complexity in aggregation with a Cursor-like class, but could not come up with a better alternative.', 'comment_created': datetime.datetime(2020, 10, 29, 15, 3, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 519260994, 'comment_body': ""`exec` uses `jobid` but every other command uses `job_id`.\r\nWe could, however, deprecate `jobid` and ensure that we're consistent."", 'comment_created': datetime.datetime(2020, 11, 8, 5, 59, 39, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 519574570, 'comment_body': '@kidrahahjo Can you offer your insight on this?', 'comment_created': datetime.datetime(2020, 11, 9, 6, 23, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 519575201, 'comment_body': ""I'm also unsure about this API. There is probably a better way to handle this, but I'm willing to defer any changes here to a later PR if all the refactors are confined to internal/private APIs.  @b-butler Did you have a specific plan in mind?"", 'comment_created': datetime.datetime(2020, 11, 9, 6, 25, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 519576638, 'comment_body': ""Let's rename it. A lot of code is inconsistent with names (groups vs. operations), so I think the choice between `all_groups` and `all_operations` is not important to me. They're actually groups, but the data is from `self.operations`. 🤷\u200d♂️\r\n```suggestion\r\n        all_operations = list(self.operations.keys())\r\n```"", 'comment_created': datetime.datetime(2020, 11, 9, 6, 30, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 519577220, 'comment_body': 'I agree that we should use generators if at all possible, and convert to a list only if strictly necessary. The calling code in the tests can handle that. I also think this is a relatively self-contained change and can be easily deferred to a subsequent PR.', 'comment_created': datetime.datetime(2020, 11, 9, 6, 32, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 519579435, 'comment_body': ""Oh gosh, I see that now. This was almost certainly a mistake. We should decide whether to deprecate `jobid` over the next 2 minor versions, or just break the API. This is a subtle enough change that I would favor breaking the API in the next version, but I'd like to get consensus on that. I believe it might be safe to just break this (and document it in the changelog) because `exec` is almost never directly called by users, and I would guess that most users would provide `-j` and not `--jobid`. The `exec` command is functionally like an internal API because most users only indirectly use it through `run`."", 'comment_created': datetime.datetime(2020, 11, 9, 6, 39, 59, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 519580532, 'comment_body': ""Since every job is acting as an aggregate internally, I believe that the change was necessary for this PR to be consistent with the code. \r\n\r\n`get_job_status` returns the status wrt only a single job/aggregate. Considering the fact that we only use aggregates for fetching per operation status and job for fetching job labels, we may continue facing the problem while parallelization as I am unable to figure out a way which lets us do both at the same time. And this is the main reason why there's a ton of extra logic being used to construct two separate objects in parallel and then combine them."", 'comment_created': datetime.datetime(2020, 11, 9, 6, 43, 52, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 519795649, 'comment_body': 'My question has now changed (given that I have unified the serializer logic). So, along with the serializer functions, do we have to unify the logic for `fetch_something_in_parallel` like methods too?', 'comment_created': datetime.datetime(2020, 11, 9, 13, 7, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 519820640, 'comment_body': 'So basically, `None` here means that no specific preference is made by the user for selecting jobs or aggregates. I believe, if not intuitive, this is one of the least complex approaches to the problem I was trying to solve. ', 'comment_created': datetime.datetime(2020, 11, 9, 13, 39, 24, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 519830899, 'comment_body': 'Just after the generation, we execute this statement.\r\n```\r\nlogger.info(\r\n    ""Executing {} operation(s) (Pass # {:02d})..."".format(len(operations), i_pass))\r\n```\r\nDon\'t know if this log strictly needs the length to be displayed or not.', 'comment_created': datetime.datetime(2020, 11, 9, 13, 55, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 519890035, 'comment_body': ""I think that's a helpful message for users. The refactoring opportunity here would be to compute the number of operations once, and to pass that variable through along with the iterator. An alternate approach that doesn't change the return values of any functions would be to create a helper class that wraps the iterator and has a defined `__len__` method as shown here: https://stackoverflow.com/a/7460929/2505544 This helper class might be useful in several places.\r\n\r\n```python\r\nclass GeneratorLen:\r\n    def __init__(self, gen, length):\r\n        self.gen = gen\r\n        self.length = length\r\n\r\n    def __len__(self): \r\n        return self.length\r\n\r\n    def __iter__(self):\r\n        yield from self.gen\r\n```"", 'comment_created': datetime.datetime(2020, 11, 9, 15, 16, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 520224848, 'comment_body': ""@vyasr @bdice Have we decided if we are just going to allow breaking changes to our API for aggregation? Technically `FlowOperation.__call__` is user facing. I don't mind since I am not sure of an easy way around this that is as clear."", 'comment_created': datetime.datetime(2020, 11, 10, 1, 19, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520226054, 'comment_body': '@vyasr Have we decided that groups will determine the aggregation rather than operations?', 'comment_created': datetime.datetime(2020, 11, 10, 1, 23, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520227478, 'comment_body': 'Just because a `FlowGroup` is eligible does not imply all its operations are.', 'comment_created': datetime.datetime(2020, 11, 10, 1, 27, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520230690, 'comment_body': 'Good catch @b-butler. This can be made non-breaking if we change the argument from `jobs` to `*jobs` and made corresponding changes to the callers of this code:\r\n- Call with `job` instead of `(job,)` for single jobs\r\n- Call with `*jobs` instead of `jobs` for aggregates containing multiple jobs', 'comment_created': datetime.datetime(2020, 11, 10, 1, 37, 41, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 520231437, 'comment_body': '@b-butler If I understand your question correctly, I believe that is what we decided.', 'comment_created': datetime.datetime(2020, 11, 10, 1, 40, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 520231467, 'comment_body': ""I don't know if this second sentence is necessary any more."", 'comment_created': datetime.datetime(2020, 11, 10, 1, 40, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520232030, 'comment_body': ""This comment needs to be removed doesn't it?"", 'comment_created': datetime.datetime(2020, 11, 10, 1, 42, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520232121, 'comment_body': 'Good catch. This should be fixed and we should add a test for the correctness of this behavior.', 'comment_created': datetime.datetime(2020, 11, 10, 1, 42, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 520232996, 'comment_body': 'In general, there is too much code in this try block, but if we are planning refactorings later, than this is fine for now.', 'comment_created': datetime.datetime(2020, 11, 10, 1, 45, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520233315, 'comment_body': ""Shouldn't this be in the `if ignore_errors` block since we don't care about the message otherwise."", 'comment_created': datetime.datetime(2020, 11, 10, 1, 46, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520234099, 'comment_body': 'This belong in an `else` block\r\n```\r\ntry:\r\n    ....\r\nexcept ():\r\n    .....\r\nelse:\r\n    .....\r\n```', 'comment_created': datetime.datetime(2020, 11, 10, 1, 48, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520234746, 'comment_body': 'Lets wait on this for a future refactoring.', 'comment_created': datetime.datetime(2020, 11, 10, 1, 51, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520235723, 'comment_body': 'Disregard my comment, I realize now that we are only storing the names. ', 'comment_created': datetime.datetime(2020, 11, 10, 1, 54, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520238926, 'comment_body': 'Given that this is excepted to error somewhat frequently we will want to change this to an if statement as try blocks are more costly.', 'comment_created': datetime.datetime(2020, 11, 10, 2, 5, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520240901, 'comment_body': 'If this is only used in the deprecated function `next_operations` we can remove this and just put the code there.', 'comment_created': datetime.datetime(2020, 11, 10, 2, 12, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520243439, 'comment_body': '@bdice I am in favor of just fixing this without a deprecation cycle.', 'comment_created': datetime.datetime(2020, 11, 10, 2, 21, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520249420, 'comment_body': 'I just wanted to note that here we validation the aggregates since it is in our public API, but we have already done this in `_select_jobs_from_args` on the command line side. Changing this is out of scope. I just wanted to document it.', 'comment_created': datetime.datetime(2020, 11, 10, 2, 41, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520249818, 'comment_body': ""This is incorrect if any aggregates are defined and `aggregates is None` isn't it? `None` implies all jobs and aggregates correct?"", 'comment_created': datetime.datetime(2020, 11, 10, 2, 42, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520250907, 'comment_body': 'I think a cursor like object that can be iterated over multiple times is what is needed. This can wait for now though.', 'comment_created': datetime.datetime(2020, 11, 10, 2, 45, 51, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520438704, 'comment_body': 'I think to check the eligibility of a `FlowGroup` we iterate on all the operations in that group and then decide whether a group is eligible or not. This means that all the operations have to eligible in order for the group to be eligible.', 'comment_created': datetime.datetime(2020, 11, 10, 10, 5, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 520719152, 'comment_body': '@kidrahahjo you are right that we check the operations within a group to determine if the group itself is eligible, we only require that one operation in a group to be eligible for the entire group to be considered eligible. For multi-operation groups this means that not every operation within a group will be eligible.', 'comment_created': datetime.datetime(2020, 11, 10, 16, 57, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 520722210, 'comment_body': 'This is because a multi-operation group can have eligibility dependencies that are resolved _during_ execution of the group. For example, a group of (`initialize`, `simulate`, `analyze`) can be submitted, where only `initialize` is eligible at first, and `simulate` depends on `initialize` and `analyze` depends on `simulate`.', 'comment_created': datetime.datetime(2020, 11, 10, 17, 1, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 521201145, 'comment_body': ""Interesting point, I didn't realize this.\r\nI will address the changes."", 'comment_created': datetime.datetime(2020, 11, 11, 8, 43, 55, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521204446, 'comment_body': ""This is resolved, so I'm going to resolve the conversation."", 'comment_created': datetime.datetime(2020, 11, 11, 8, 49, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521252253, 'comment_body': ""`status_dict` should be inside the `if` block but I'm not sure about the debugging statement. I'll add all of it inside the `if` block for now."", 'comment_created': datetime.datetime(2020, 11, 11, 10, 12, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521360564, 'comment_body': ""I'm not sure how the last comment on this thread relates to the remainder of it. Adding the submission id is not related to this check being performed... right?"", 'comment_created': datetime.datetime(2020, 11, 11, 13, 33, 47, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521368031, 'comment_body': ""Yes, in general anywhere in this PR where we have to manually construct a tuple of jobs should be inspected to make sure it's not being caused by a missing a tuple unpacking in a function parameter. This is most important for user-facing APIs, but also good to do for internal APIs to ensure consistency and readability going forward."", 'comment_created': datetime.datetime(2020, 11, 11, 13, 45, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521368825, 'comment_body': 'The implication of this choice is that all operations in a group must have the same aggregator. I think that makes sense, yes.', 'comment_created': datetime.datetime(2020, 11, 11, 13, 47, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521370030, 'comment_body': 'Agreed, we can remove it. Any internal change to the ordering will require changing this, but that will be obvious when the test fails.', 'comment_created': datetime.datetime(2020, 11, 11, 13, 49, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521374147, 'comment_body': ""Is there a reason we want the jobs to be a list and not a tuple? I don't recall, and in any case I don't think we have to do anything about it in this PR. @kidrahahjo if there wasn't a good reason to use lists, though, can you add to #362? Otherwise just explain here and close."", 'comment_created': datetime.datetime(2020, 11, 11, 13, 55, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521375574, 'comment_body': ""Add a link to this in #362 and let's move on for now."", 'comment_created': datetime.datetime(2020, 11, 11, 13, 57, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521376131, 'comment_body': 'Add this to #362.', 'comment_created': datetime.datetime(2020, 11, 11, 13, 58, 48, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521382923, 'comment_body': ""Actually, there are two other issues I'd like to address here.\r\n1. The `jobs` argument should probably use argument unpacking (`*jobs`). In order for this to work, `cached_status` would have to be a keyword-only argument `def _get_operations_status(self, *jobs, *, cached_status=None)`. That's a minor change to an internal API, so I would be fine doing that. However, this point might be superseded by point 2:\r\n2. This method is only called once. While I generally think splitting code into modular functions is helpful, I think part of the reason why it's gotten bloated and refactoring has become difficult is that in a lot of cases we have defined single- or double-use functions that we are then hesitant to remove in future iterations. This problem is especially persistent in the functions related to status updates, where these functions _seem_ necessary in order to enable parallelization due to pickling issues. However, I think that the result of this has become that we have too many distributed code paths here. As a result, I propose that as part of addressing #362 one thing we do is completely remove parallelization from status checks and _inline all the functions related to status fetching_. This change may seem drastic (and we could do it incrementally), but I think removing the parallel code paths temporarily will be the only way to clarify the natural data flow pipelines and eliminate redundancies that are currently being heavily obscured by the hoops we jump through to pickle things."", 'comment_created': datetime.datetime(2020, 11, 11, 14, 9, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521386513, 'comment_body': ""No, we still want to log the error in either case. Debug level logger output can be useful to the user to determine what's going wrong even when they choose to ignore errors."", 'comment_created': datetime.datetime(2020, 11, 11, 14, 15, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521386943, 'comment_body': 'Punt to #362', 'comment_created': datetime.datetime(2020, 11, 11, 14, 15, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521396754, 'comment_body': ""I'd say this is out of scope for this PR now. Let's punt to #362."", 'comment_created': datetime.datetime(2020, 11, 11, 14, 29, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521402887, 'comment_body': 'Move to #362.', 'comment_created': datetime.datetime(2020, 11, 11, 14, 38, 43, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521403158, 'comment_body': 'Moved to #362.', 'comment_created': datetime.datetime(2020, 11, 11, 14, 39, 5, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521412555, 'comment_body': ""This doesn't make sense, it'll just throw the same error again. I tried looking back in the history and this code has been here a very long time. It was introduced wayyyy back in [59e2df3cf413261deb999cffebd4c434a7ad2139](https://github.com/glotzerlab/signac-flow/commit/59e2df3cf413261deb999cffebd4c434a7ad2139) back when we still passed scheduler classes around. This block can be removed here."", 'comment_created': datetime.datetime(2020, 11, 11, 14, 52, 37, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521462394, 'comment_body': 'It should be a tuple. I clarified that on #362.', 'comment_created': datetime.datetime(2020, 11, 11, 16, 3, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 521464079, 'comment_body': 'I get a `SyntaxError` when attempting to use `def func(*args, *, some_kwarg):`. You just want `def _get_operations_status(self, *jobs, cached_status=None)`.', 'comment_created': datetime.datetime(2020, 11, 11, 16, 5, 53, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 521469645, 'comment_body': 'I renamed this to `operation_names` to clarify that behavior. I think this can be resolved.', 'comment_created': datetime.datetime(2020, 11, 11, 16, 14, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 521471144, 'comment_body': 'I fixed this.', 'comment_created': datetime.datetime(2020, 11, 11, 16, 16, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 521474513, 'comment_body': 'Good idea. Done.', 'comment_created': datetime.datetime(2020, 11, 11, 16, 21, 22, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 521479660, 'comment_body': ""Clarified on Slack: I knew the `*` would be redundant given `*args`, didn't realize it would be an error.  Good catch."", 'comment_created': datetime.datetime(2020, 11, 11, 16, 28, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 521516503, 'comment_body': 'I also agree that it should be a tuple.', 'comment_created': datetime.datetime(2020, 11, 11, 17, 22, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521577857, 'comment_body': ""@bdice removed this block in a commit, so I'm going to resolve this conversation."", 'comment_created': datetime.datetime(2020, 11, 11, 19, 8, 20, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521581245, 'comment_body': ""Comments are always helpful for future reference, I'll write a valid comment instead."", 'comment_created': datetime.datetime(2020, 11, 11, 19, 14, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521588241, 'comment_body': ""So when someone submits an operation, we stored the information in a hidden folder. If we store submission id then the user won't be able to edit those ids (even willingly, as they're all unique) but if we just store the aggregate ids, then users might be able to add different aggregate ids by themselves which I believed may create some unnecessary errors. But I get @b-butler 's point that it should be on them if they mess up with the hidden file.\r\n\r\nMoreover, this thread is now outdated as this execution is shifted to the next PR because actual aggregation was to be involved for this."", 'comment_created': datetime.datetime(2020, 11, 11, 19, 27, 41, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521590022, 'comment_body': ""@b-butler @bdice I had one question, what if a particular operation was included in multiple groups?\r\nWouldn't the information get overwritten? \r\n\r\nI may be missing some very basic point here but I'm unable to figure out how should we proceed."", 'comment_created': datetime.datetime(2020, 11, 11, 19, 31, 6, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 521594849, 'comment_body': ""I'm going to defer to @b-butler on this, I'm not sure."", 'comment_created': datetime.datetime(2020, 11, 11, 19, 40, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 522254699, 'comment_body': 'The status output we show for jobs doesn\'t include the ""actual"" flow groups.\r\nI believe this problem (if it\'s actually a problem) is already in our code.', 'comment_created': datetime.datetime(2020, 11, 12, 16, 47, 38, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 522321345, 'comment_body': 'Most mappings provide their keys when iterating, not values. Make a separate method for getting the values.\r\n```suggestion\r\n        yield from self._aggregate_per_id\r\n\r\n    def keys(self):\r\n        yield from self._aggregate_per_id.keys()\r\n                \r\n    def values(self):\r\n        yield from self._aggregate_per_id.values()\r\n```', 'comment_created': datetime.datetime(2020, 11, 12, 18, 24, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 522321627, 'comment_body': '```suggestion\r\n        """"""Return whether an aggregate is stored in this\r\n```', 'comment_created': datetime.datetime(2020, 11, 12, 18, 24, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 522325633, 'comment_body': '`open_job` can also raise a LookupError if `id` is a substring that matches the beginning of multiple jobs. Just re-raise that:\r\n```suggestion\r\n        except KeyError:\r\n            return False\r\n        except LookupError:\r\n            raise\r\n```', 'comment_created': datetime.datetime(2020, 11, 12, 18, 31, 7, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 522336521, 'comment_body': ""If it is overwritten, it shouldn't change the correctness. It is sub-optimal though. Ideally we would separate singleton groups from the rest and get the status of those operations."", 'comment_created': datetime.datetime(2020, 11, 12, 18, 48, 51, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 522339056, 'comment_body': ""I'll go with this approach and re-request a review."", 'comment_created': datetime.datetime(2020, 11, 12, 18, 52, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 522534861, 'comment_body': 'This code avoid creating the list needlessly.\r\n```suggestion\r\n                return (jobs,) if jobs else ()\r\n```', 'comment_created': datetime.datetime(2020, 11, 13, 0, 49, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 522549631, 'comment_body': '@bdice and @vyasr are suggesting that `AggregateStore` objects behave like mappings, so this should return ids.\r\n\r\nWe need to change the way `DefaultAggregateStore` works as well to mimic this behavior. To iterate over values we need to implement a values function. These classes should be using `MutableMapping` as their parent class given our current decision.', 'comment_created': datetime.datetime(2020, 11, 13, 1, 22, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 522552436, 'comment_body': '```suggestion\r\n        assert aggregate_instance._aggregator_function(test_list) == (test_list,)\r\n```', 'comment_created': datetime.datetime(2020, 11, 13, 1, 31, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 523460690, 'comment_body': 'The lack of an item setter and item deleter suggests to me that this should be a `Mapping` (an immutable `MutableMapping`).', 'comment_created': datetime.datetime(2020, 11, 14, 20, 38, 13, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 523461871, 'comment_body': 'The lack of an item setter and item deleter suggests to me that this should be a `Mapping` (an immutable `MutableMapping`).', 'comment_created': datetime.datetime(2020, 11, 14, 20, 51, 11, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 523463346, 'comment_body': ""This has been resolved, and my suggestion isn't quite correct."", 'comment_created': datetime.datetime(2020, 11, 14, 21, 7, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 523466411, 'comment_body': 'This has been resolved.', 'comment_created': datetime.datetime(2020, 11, 14, 21, 39, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}]","[{'commit_sha': 'd74b3a0b31a72630c4ba25441006fa565b7b2a94', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bc759003e692a21cb1f4766f7d52b0a90beabb3a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f05cb7097924e26efdad13c41cb9629f0cb5b02e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6c3c21b930fab566b6be3d78f482e1eda13153b1', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '339345fa3c701686acb153e585f773578ec79d6b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4b5856691148888ac545101f4efda91a38a00267', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1481754628ad4b6025c70c59d0cf782c0ffafdd3', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '08991213a9563dc7f46875a79ba20f885c5fc161', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c9c2610d6f03313701c41a29a1fcb1558fc5521b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4a29c6b626dc3029033163009fd59e702ceab182', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '09b599d18dc6760982afd36300af7f10127c5c43', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '03d85900d6cec49cc8782a29905950d1cdec6d7b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3d4e73abfbb4870e117116b39e2e87a518365612', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c22c74d0dca8ce7ab2c17247214fcd4d117b69fb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'faa65714004b67877dc5a003fe6d2823fb5f367f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd73c75c4e61e1675b97b06c571abac5acb8ca4ba', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4126377b90acbc0cbdfdbb508e05ba5dae974a31', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '05c81181e2ae9cfda952fc12f7fa1eceb1ea054d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'beb2804155ea2f4bdea187aef51944bbd5868e0c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4496a4766501bee07c0a975f995170cda0a053e8', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0c6da400e5fb34bd72d33d51cc9ad18b92fa9468', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0d3402d38357f9ecd8ae9e07da49bdd0765a55cb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5493b4ba7da35d45842da0dc503674108509cd91', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a3f9dd1f1ac1d793516bfd8726b1cbdd1917f957', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9ec08f52aedc07859235c479d283ebfcd5e7881', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6eb00cda9e627693c25b205cc630302c4c1139ba', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e0cc5901cbbe26909c0806b23289404528d81762', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '98e61f53e0deac017f0a936d44639ba79e60e9ca', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '43439152e718a63855dfbfa662c7b092843c2d35', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'be961c19dddcde17f18c13f8dd932816e6aa6108', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a5563ac154cddf50096420eca7fce371128db281', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8ef3910308986d593aef83d3f67b6c9af1adbb13', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c803ee537b4fc8ddb5f277a3eea0ab3a98363205', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4f9276fbc4d84c6cbc40258833510785e2a7be8b', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd1c291347b463428261196ff405278707bfa4ef6', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf4efc0205f97c1f82c19f9d8cc8e5347ba99b1e', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ad572a6f56587ca0e58c00d45264bacac77fc6f9', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a673662c45b0ba1a18703129572903eb9af82dae', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5dbf89d042c02849d9f2c3cf0df93bd1cc7e35e3', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '012d110b4fc68f380bd28779094cc08315eba29f', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '86dfd814e4f94339be4ff61df939914081064a2e', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0ad92913836b90c61dd9610439b615e6735e1041', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1c2dcb47d396d81be40bb9603718fb3143efb3a1', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4aa0be213a56b1d7b5abc6d6fee8b45967623371', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '791e0b5b5ef36215dda0e96cc2b5d05eeeb71560', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3932832dcd3d12009cfc8b3cd22b3ec05c1393ca', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '48cbf7ab8b9029817a607e0506368082edb11858', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd6890fe5e0076a5660486f327c8de657e29c71cb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd063e5279b4b3583a72c34325066fe9444ae4f3b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '103bb74fe3cd68c23e16398320df183aa435117b', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4f0fe6f2769e83b882d4e7a1e5ca6f0ea342330', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5a8da4d8074a8b313120d9aafe1548e761ea9f1b', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '702c3f1920def74797371f2ad248d86da549d691', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '43ec9a99ece6c0336b43bc33876b5bf6d69e0332', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd42c1da8d1ea79699c22cb765e3c974c1a1ddf3d', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd4dc18707c7fd952893d1ce658902fc670bd20a7', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'deed3db94babe8c09a8d786fa0fc4670ebe6f933', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '50879810e7672d896062059a44045fc6fed3636b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b540cf24ea3334a89c86553ebd55c8a1512e0c5b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '84091ef426ac5047342255f7dcef6658d2b3cde1', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b70cc8e2825d33fcd48ebee445dc94f45a922ff', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '66baf64b6284e88a08ee9c1f620a4fef036404ad', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '59aae9db3a7c18e841a0ea3ee722e322b7c5a675', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0c60b18d29231fe1bdfdca8fbf1161e5328ec910', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4c8c118025488c2df196b27d9c4d81d03ed0deb0', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a29edc957709467b0aa9f1b3d5cb602ba45edbd3', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '00fd1d2a9d6435b36f2ceb7f34488b2979c7e8d7', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ee66593c80a93e943b7781fc98bde20b112ebba1', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a5bcfa8cb775bcd93261ae961bb33e96a6db3989', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
474066015,Add aggregator classes in flow,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Add aggregator classes to flow.
This pull request introduces a concept of storing the aggregates in an iterable class which will be then stored throughout the `FlowProject`
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
To be merged before #335 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [x] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,348,https://api.github.com/repos/glotzerlab/signac-flow/pulls/348,https://github.com/glotzerlab/signac-flow/pull/348,closed,761,0,2,22,4,187,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-08-26 18:00:18+00:00,2020-09-01 13:55:56+00:00,503738.0,"5 days, 19:55:38","[{'comment_id': 477537468, 'comment_body': 'Is yielding any iterable of jobs okay? or should we require tuples.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 26, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477540138, 'comment_body': 'This will fail with `functool.partial` objects or callable class objects. Also, I would put the cheaper (string and Boolean) comparisons first.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 31, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477542218, 'comment_body': 'I would prefer the class name `Aggregator` as it is not really an aggregate as we have defined it, but rather a definition of aggregation.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 35, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477545603, 'comment_body': 'Needs docstring', 'comment_created': datetime.datetime(2020, 8, 26, 19, 41, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477545676, 'comment_body': 'Needs docstring', 'comment_created': datetime.datetime(2020, 8, 26, 19, 42, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477546248, 'comment_body': 'Can be a docstring.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 43, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477546668, 'comment_body': ""Won't this create a `_StoreAggregates` class for each group/operation. there is no registry that I see."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 44, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477547561, 'comment_body': ""This is not the behavior we want. The aggregate store shouldn't be callable. We need a function to regenerate aggregates, but making an object callable says something about its behavior. Here calling is just to change the state of the object which is not the correct paradigm."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 45, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477547799, 'comment_body': 'Class should be `_AggregateStore` for classes it is typical to use nouns unless the class acts as a functor.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 46, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477548515, 'comment_body': ""When this object is created, I would want to see the aggregates be computed. Otherwise, it isn't really storing anything until after it is called. This would require that it takes an iterable of jobs (typically the project) as a constructor argument as well."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 47, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477548660, 'comment_body': 'Should be a standard method not `__call__`. Also make comment into one line docstring.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 47, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477551425, 'comment_body': 'Currently this class does not provide id indexing (`__getitem__`) or checking for inclusion (`__contains__`). I would like to see both these features. The same for `_StoreAggregatesDefault`.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 53, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477552186, 'comment_body': 'Since we have multiple classes that are serving as aggregate stores, it may be helpful to create a class `_AggregateStoreBase(Mapping)` that uses the `collections.abc.Mapping` class and additionally requires a `recompute_aggregates` method, plus any other functions deemed necessary.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 54, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477556518, 'comment_body': 'To use an object as a key in a dictionary it has to support `__hash__` and `__eq__`', 'comment_created': datetime.datetime(2020, 8, 26, 20, 2, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558152, 'comment_body': 'I would prefer using `hasattr` here.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 5, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558255, 'comment_body': 'Likewise', 'comment_created': datetime.datetime(2020, 8, 26, 20, 5, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558427, 'comment_body': 'hasattr', 'comment_created': datetime.datetime(2020, 8, 26, 20, 6, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558653, 'comment_body': 'Although different in terms of syntax used; this and the previous test are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 6, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477559838, 'comment_body': 'This is also unnecessary.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 9, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477561644, 'comment_body': '```suggestion\r\n        assert [tuple(project)] == list(aggregate_instance)\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 20, 12, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477562621, 'comment_body': ""It may be worth creating a helper function that does the comparison between a function's and an `_StoreAggregate`'s aggregates given a `FlowProject`."", 'comment_created': datetime.datetime(2020, 8, 26, 20, 14, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477563096, 'comment_body': 'We should also test that the size of each aggregate is correct.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 15, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477563438, 'comment_body': 'I would assert that all of the values for `job.sp.even` are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 16, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477564158, 'comment_body': 'I would likewise test that all the values of `job.sp.half` are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 17, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478283283, 'comment_body': ""I think we should be flexible in terms of users point of view.\r\nTo convert those into tuples, we're already converting those iterables into tuples in `_create_nested_aggregate_list`"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 29, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478285406, 'comment_body': ""I thought we'd require an `__eq__` method to put these object as keys in a dictionary but I learnt that we also require the objects to be hashable and it turns out we can uniquely hash these objects (partial functions, lambda functions, or normal functions).\r\nI'll also use `__hash__` here"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 33, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478286069, 'comment_body': 'This is technically breaking the API. Should I post this on slack for further discussion?', 'comment_created': datetime.datetime(2020, 8, 27, 9, 34, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478287693, 'comment_body': ""That is why we'll be using a `__hash__` method to uniquely identify a `_StoreAggregate` instance"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 37, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478288334, 'comment_body': ""I'll use a different method `_generate_aggregates` instead"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 38, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478295728, 'comment_body': 'Hmm, I see what you mean here.\r\nI also agree, will make the necessary changes', 'comment_created': datetime.datetime(2020, 8, 27, 9, 50, 16, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478426607, 'comment_body': 'Why are we mixing two different hash functions? I would prefer to be consistent (although we of course make no promises about this in our API).', 'comment_created': datetime.datetime(2020, 8, 27, 13, 39, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478431171, 'comment_body': 'Does our style have a preference on how import multiple objects from a module/package? If not, I would prefer to either do `from itertools import groupby, zip_longest`, or use fully qualified names everywhere else and just `import itertools` here. Importing `groupby` directly is going to cause cognitive dissonance for readers of the code since we internally define `Aggregate.groupby`.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 46, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478436334, 'comment_body': ""It is breaking an API that doesn't exist yet, so you can ask, but it isn't a breaking change."", 'comment_created': datetime.datetime(2020, 8, 27, 13, 53, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478436807, 'comment_body': 'I guess I am fine then.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 53, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478438579, 'comment_body': ""The API breaking is not a concern since none of this is released yet. Use whatever names you think are appropriate. However, in this case @kidrahahjo @b-butler be mindful of the fact that this class will be used as a decorator by users. For this reason, we may want to follow naming that would not normally be appropriate. For instance, consider that the `pre` and `post` condition classes are lowercased despite being classes, precisely for this reason, and similarly for directives. Decorators should _look like_ functions IMO; while this isn't written in any style guides, it's the rule we've followed in flow because that's more intuitive for users, and it supersedes the typical class naming rule.\r\n\r\nRegarding the actual name of the decorator, consider that the first argument to the constructor of this class is called `aggregator`; it seems awkward for an `Aggregator` to require an `aggregator`. I'm having trouble thinking of a better alternative right now, though; I'll post again if I think of something."", 'comment_created': datetime.datetime(2020, 8, 27, 13, 56, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478440082, 'comment_body': 'Add a comment or two explaining why we need to treat `groupsof(1)` (the default aggregate) differently.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 58, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478440737, 'comment_body': 'I would caution against just using hash for both `__eq__` and `__hash__`. If `hash(obj) == hash(other)` the equality method is used to differentiate between objects. Here if we use it for both we end up with no way to discern the objects.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 59, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478442318, 'comment_body': ""All of this error checking feels rather un-Pythonic to me. However, I can see a good reason for this here since none of these attributes will actually get used until downstream in the aggregation pipeline, at which point the errors would be much harder for users to interpret. @bdice you're usually the style police for EAFP (I'm of the opinion that both LBYL and EAFP have their place in Python, so I'm less opposed to this on principle), what do you think?"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 1, 25, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478443539, 'comment_body': ""I don't know if I've ever said this before, but there's actually too much white space and empty lines in this block (and in various other parts of the code) and it makes it less readable. In particular, there's a newline before every `elif` or `else` clause. Can you tighten some of that up?"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 3, 12, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478445900, 'comment_body': 'Just FYI @kidrahahjo both of these methods have default implementations for any class (e.g. `class A: pass` will have default versions of both methods defined), but I assume @b-butler wants you to define a meaningful equality check here.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 6, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478446662, 'comment_body': 'How will that prevent making a new one? It seems like you will create a new one anyway in `_create_StoreAggregates`.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 7, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478450955, 'comment_body': ""Can we just combine the classes? I'm not seeing much benefit to the separation. Especially if you change the `_StoreAggregates` class to compute the aggregates on construction, then both this and the `*Default` class can just store `self._aggregates` (which would just be the project for the default case) and `yield from` that in `__iter__`. Hashing should also work transparently."", 'comment_created': datetime.datetime(2020, 8, 27, 14, 13, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478451129, 'comment_body': 'This change supports us moving away from the two class model.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 13, 31, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478452293, 'comment_body': ""I would prefer to return `jobs[0].id`, which is strictly correct and doesn't depend on us not changing the string representation of a `Job`."", 'comment_created': datetime.datetime(2020, 8, 27, 14, 15, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478458974, 'comment_body': ""@bdice another instance of type checking up front that is probably justified due to the delayed execution of aggregator.\r\n\r\n@kidrahahjo the sequence here is a little confusing though. The `TypeError` you're catching would be thrown by the first line in the `try` block, so there's no need for the rest to be there. I would move the `if num<=0` check out of the try block. Furthermore, rather than trying to convert to int like this, if we're going to type check I would do it rigorously. Currently, passing `num=3.5` will result in the code silently using `num=3`.\r\n```suggestion\r\n        if num != int(num):\r\n            raise TypeError('The num parameter should be an integer')\r\n        num = int(num)\r\n        if num <= 0:\r\n            raise ValueError('The num parameter should have a value greater than 0')\r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 24, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478460776, 'comment_body': 'Whatever you call the method, make sure it is called in the constructor (and can be called again later if necessary).', 'comment_created': datetime.datetime(2020, 8, 27, 14, 26, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478541622, 'comment_body': ""There's no specific style, but in `project.py` we import them separately."", 'comment_created': datetime.datetime(2020, 8, 27, 16, 21, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478541938, 'comment_body': 'I agree that the first constructor argument would need to change.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 21, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478542153, 'comment_body': 'That is correct.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 22, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478542689, 'comment_body': '`md5` is used to generate the id of an aggregate. No specific preference was there, it was just a suggestion that we could use `md5` for getting aggregate id.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 23, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478543545, 'comment_body': 'We could if this implementation had the complete desired behavior. However, once we add `__getitem__` and `__contains__` are implemented both of which would look different for the classes and the fact that for the default case the regeneration of aggregates is a no-op. I think having separate classes is warranted.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 24, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478544390, 'comment_body': 'Will do', 'comment_created': datetime.datetime(2020, 8, 27, 16, 25, 55, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478544846, 'comment_body': 'Are you referring to having `Aggregate` be the same class as `_AggregateStore`? or the distinction between default aggregation and non-default aggregation.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 26, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478558681, 'comment_body': 'I would like to be consistent if possible as well.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 49, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478560334, 'comment_body': 'It can be `aggregator_function`?', 'comment_created': datetime.datetime(2020, 8, 27, 16, 52, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478562832, 'comment_body': 'This is a statement about possibilities not what the function does (as it is worded).', 'comment_created': datetime.datetime(2020, 8, 27, 16, 56, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478568663, 'comment_body': 'Since only the last aggregate can be a different size. I would say something like the default size of aggregates excluding the final aggregate.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 6, 28, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478569370, 'comment_body': 'See comment about `groupsof` above.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 7, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478570265, 'comment_body': 'the key parameter needs more explanation. Also, you have the key parameter listed twice.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 9, 23, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478571041, 'comment_body': 'This is not necessarily true. A variety of things could have been passed here. I would just mention that we were passed something other than a function.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478571762, 'comment_body': ""The point of `_DefaultAggregateStore` was that we wouldn't want to compute those aggregates as aggregates of 1. We could just yield single jobs.\r\nWe could merge those two classes but the current model is a simple way to differentiate between those two."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 12, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478573408, 'comment_body': 'I would prefer if we used the id to check for inclusion. It would be constant time rather than linear then.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 14, 59, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478574129, 'comment_body': 'There is no need for either of the explicit list calls.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 16, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478576586, 'comment_body': ""We don't need this list conversion."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 20, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478576884, 'comment_body': 'Do worry about the explicit `bool` conversion.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 21, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478579017, 'comment_body': ""Here you are converting to a list again. We don't need to convert to list multiple times. `sorted` always returns a list, and `filter` does not, but if we pass it into `sorted` it will return a list."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478580328, 'comment_body': 'I think it might look cleaner to have a small function `validate_and_filter_jobs` that returns a Boolean or raises an error and just use `nested_aggregate = tuple(filter(validate_and_filter_jobs, aggregate))`', 'comment_created': datetime.datetime(2020, 8, 27, 17, 27, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478580836, 'comment_body': 'Use project id.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 28, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581268, 'comment_body': 'This is internal, should we ever be passed a list of jobs rather than a `FlowProject`? Considering we control this.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 28, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581583, 'comment_body': 'No need for two functions here.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 29, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581894, 'comment_body': '```suggestion\r\nreturn job in self._project\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 17, 29, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478582411, 'comment_body': 'Why would we ever be passed anything other than the project?', 'comment_created': datetime.datetime(2020, 8, 27, 17, 30, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478585901, 'comment_body': ""Don't convert to string here. No need."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 36, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478586175, 'comment_body': 'I would explain what this function is doing as it is not immediately apparent. I understand, but someone fresh coming to the code might not.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 37, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478586904, 'comment_body': 'Using map for these two attributes seems a bit much. Just writing it explicitly would be fine.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 38, 29, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478593082, 'comment_body': '```suggestion\r\n            return self_select == other_select and self_aggregator == other_aggregator\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 17, 49, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478607744, 'comment_body': 'We use md5 for id calculation of Jobs.\r\nI think that was the reason we were using md5 for calculating aggregate id.\r\n@b-butler @vyasr @bdice Please suggest what should be done here.', 'comment_created': datetime.datetime(2020, 8, 27, 18, 15, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478630597, 'comment_body': ""I'm not sure what you exactly mean by this.\r\nI will shift this conversion to `__init__` method of `Aggregate` but what else should I be worried about?"", 'comment_created': datetime.datetime(2020, 8, 27, 18, 58, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478634436, 'comment_body': ""Oh, I'm sorry about that. Thanks for letting me know."", 'comment_created': datetime.datetime(2020, 8, 27, 19, 5, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478687251, 'comment_body': 'I changed the functionality. Please have a look at it once you get time', 'comment_created': datetime.datetime(2020, 8, 27, 20, 49, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478688950, 'comment_body': ""@b-butler The two classes, though does the same thing, are technically not at all similar.\r\nEven if we create `_AggregateStoreBase` we'd then have to override nearly all the methods. (Because even `_register_aggregates` for both the classes registers aggregates differently."", 'comment_created': datetime.datetime(2020, 8, 27, 20, 52, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478699962, 'comment_body': 'Is there a reason to use sha1 anywhere?', 'comment_created': datetime.datetime(2020, 8, 27, 21, 15, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478701018, 'comment_body': ""This is indeed better, but the main purpose it to provide a way to compare arbitrary types that are callable, and that isn't mentioned here."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 17, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478702803, 'comment_body': '```suggestion\r\n        """"""Aggregates jobs according to matching state point key values.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 21, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478703385, 'comment_body': '```suggestion\r\n        """"""Aggregates jobs of a set group size.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 22, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709006, 'comment_body': 'If we have this class which I generally am in favor of. It should not compose an `Aggregate` object but rather take the values from the object and use them itself.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709093, 'comment_body': 'This can be a static method', 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709243, 'comment_body': ""These don't need to be in the try block."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478710118, 'comment_body': 'I may have been confusing here. If we just use `filter` without `sorted` then `jobs` will not be a list when passed to `self._aggregate._aggregator_function`. It will be a `filter` object, so if `sort_by` is `None` then we do need to explicitly cast to a list, if that is an API guarantee to the user for the aggregation function rather than promising to return an iterable of jobs.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 37, 54, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478711087, 'comment_body': 'If we make the change to `_MakeAggregates` I suggest, then we should move the `__eq__` and `__hash__` methods to it.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 39, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478714946, 'comment_body': 'If we are going to use `_MakeAggregates` then we would just want this class to have a `_MakeAggregates` object it can call when it needs to.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478716331, 'comment_body': 'Maybe a comment on how this tests hashing works properly would be helpful (i.e. mentioning that you have 11 unique aggregation definitions).', 'comment_created': datetime.datetime(2020, 8, 27, 21, 52, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478716834, 'comment_body': ""If this is to just test with lambda's versus standard functions, we don't need both tests. If this is to test two different functions then it can be in the same test."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 53, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478717487, 'comment_body': 'This does not test that each aggregate of `aggegrator.groupsof(2)` for instance has two jobs (except the last perhaps).', 'comment_created': datetime.datetime(2020, 8, 27, 21, 54, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478717818, 'comment_body': '```suggestion\r\n            assert all(even == job.sp.even for job in aggregate)\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 55, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718048, 'comment_body': ""```suggestion\r\n            assert all(assert half == job.sp.get('half', -1) for job in aggregate)\r\n                \r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 21, 55, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718457, 'comment_body': ""Thanks for the comment! Could you add how that means we don't need to check whether all the aggregate members are equivalent. Of course this is true for aggregates of size one, but just to be clear for future developers."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 56, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718621, 'comment_body': 'Use all here too.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718671, 'comment_body': 'Use all here.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 57, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478720639, 'comment_body': 'I am saying do not worry about it at all just assume it is something Boolean like.', 'comment_created': datetime.datetime(2020, 8, 27, 22, 2, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478723250, 'comment_body': 'Nope, no specific reason.\r\nIt was used while hashing `_JobOperation`, bundle id in `project.py`', 'comment_created': datetime.datetime(2020, 8, 27, 22, 9, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478724889, 'comment_body': 'the key can also be an arbitrary callable hence, according to me, users may get confused with this doc', 'comment_created': datetime.datetime(2020, 8, 27, 22, 13, 28, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479051633, 'comment_body': ""I'm not sure I see the use case of moving them to `_MakeAggregates` can you please explain?"", 'comment_created': datetime.datetime(2020, 8, 28, 9, 54, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479056580, 'comment_body': 'So, I should probably execute `jobs = list(jobs)` after we filter jobs', 'comment_created': datetime.datetime(2020, 8, 28, 9, 58, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479099813, 'comment_body': ""We'll be eventually storing the instances of `_AggregateStore` and not `_MakeAggregates`. Hence, I think it is not useful to move `__eq__` and `__hash__` method to `_MakeAggregate`"", 'comment_created': datetime.datetime(2020, 8, 28, 10, 34, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479193923, 'comment_body': ""The `_validate_and_filter_job` uses a instance attribute `_project`.\r\nIf we convert this to a static method then we'll have to execute something like this\r\n```\r\nfilter_aggregate = tuple(filter(\r\n    lambda job: _validate_and_filter_job(job, self._project), aggregate))\r\n```\r\nI'm not sure if this is a right approach or not. Please suggest"", 'comment_created': datetime.datetime(2020, 8, 28, 11, 55, 42, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479350825, 'comment_body': 'Nevermind, we do need this at first to be able to discern if an user creates multiple of the same `aggregator` objects... We will likely need a way to hash and equate `_AggregateStores` as well though.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479351768, 'comment_body': ""I don't think we need to internally store the project in this class. We can just expect it to be passed when called. Then we do not need to use `self._project` in fact such an attribute would not even exist. Then `_validate_and_filter-job` could be a closure created within the `_create_nested_aggregates` method. Sorry I missed that we were storing the project before."", 'comment_created': datetime.datetime(2020, 8, 28, 14, 43, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479353635, 'comment_body': ""I don't know why we are storing the project in this class. I know I missed this last review. I believe passing in the project to `_MakeAggregates` is the proper approach. That provides the intuitive behavior of `_MakeAggregates` as a function that takes in a project and returns aggregates."", 'comment_created': datetime.datetime(2020, 8, 28, 14, 46, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479358687, 'comment_body': 'Okay, then I would be consistent here for this file as it is a bit cleaner.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 55, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479359831, 'comment_body': 'This should accept a `FlowProject`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 56, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479360616, 'comment_body': 'This should still be done by the `_AggregateStore` class. I believe the `_MakeAggregate` class should only be responsible for correctly handing the aggregation, not the data structures used by `_AggregateStore`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 58, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479360962, 'comment_body': 'This should be moved back to `_AggregateStore`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 58, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479361333, 'comment_body': 'If we make the change I suggest. I would like to see this yield aggregates. That is just a preference though.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 59, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479370670, 'comment_body': '@b-butler \r\nIn this implementation, we do have an `__eq__` and `__hash__` methods for both `_DefaultAggregateStore` and `_AggregatesStore`', 'comment_created': datetime.datetime(2020, 8, 28, 15, 15, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479447017, 'comment_body': 'We do not need to store the project here.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 40, 8, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479447759, 'comment_body': 'We could use a classmethod for `_MakeAggregates` that takes the `aggregator` and handles this setting internally.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 41, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479448513, 'comment_body': 'We should pass in the project to this function and the `_create_nested_aggregate_list` function, or create the `_validate_and_filter_job` function in this function and pass that to `_create_nested_aggregate_list`. Either is fine with me. It is up to your preference.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 43, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479448898, 'comment_body': 'This list call is unnecessary. If we require that the aggregator function be passed a list, then we should only call list if `self._sort_by is None`.\r\n\r\n````python\r\nif self._sort_by is None:\r\n    jobs = list(jobs)\r\nelse:\r\n    jobs = sorted(...)', 'comment_created': datetime.datetime(2020, 8, 28, 17, 44, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479471676, 'comment_body': ""Why is this after `sort_by` now? With this being before the `sort_by` conditional, we only convert to a list once. Now we would do it twice if `sort_by is not None`. If we put it before, we also don't need the `list` conversion there."", 'comment_created': datetime.datetime(2020, 8, 28, 18, 33, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479472310, 'comment_body': 'I am fine because this makes errors easier for the user to manage.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 35, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479473092, 'comment_body': 'Why are we accepting `kwargs` when they are not used anywhere meaningfully?', 'comment_created': datetime.datetime(2020, 8, 28, 18, 37, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474300, 'comment_body': 'We just need to check that the aggregate ids all all the same.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 39, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474410, 'comment_body': ""We don't need to store the aggregator."", 'comment_created': datetime.datetime(2020, 8, 28, 18, 39, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474518, 'comment_body': '```suggestion\r\n        blob = str(hash(self._aggregates))\r\n```', 'comment_created': datetime.datetime(2020, 8, 28, 18, 40, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479475356, 'comment_body': 'Can we test the `__hash__` and `__eq__` of this class given the typo I found.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 42, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479477989, 'comment_body': 'These are used to check equality between two aggregator objects. I was having difficulty in comparing aggregators hence I thought that these additional parameters would be helpful to test the equality', 'comment_created': datetime.datetime(2020, 8, 28, 18, 47, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479478418, 'comment_body': 'Yes, I think I forgot to write those. Sorry about that. Will do it.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 48, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479634260, 'comment_body': 'We compare and hash the `aggregator` hence I think that we should store the aggregator', 'comment_created': datetime.datetime(2020, 8, 29, 10, 15, 6, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479634335, 'comment_body': 'Do you mean something like this\r\n`self._aggregate_ids.keys() == other._aggregate_ids.keys()` ?', 'comment_created': datetime.datetime(2020, 8, 29, 10, 16, 4, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479636475, 'comment_body': 'This should be `self._aggregator`', 'comment_created': datetime.datetime(2020, 8, 29, 10, 43, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479664323, 'comment_body': 'If this is just for testing equality, please remove it. This feature is not used for any purpose. We should deal directly with the problem of testing equality. What part was giving you difficulty?', 'comment_created': datetime.datetime(2020, 8, 29, 16, 11, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664366, 'comment_body': 'Yep.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 11, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664470, 'comment_body': 'We just need to compare aggregation_ids or hash to determine uniqueness for standard aggregate store object the default is easier with just comparing and using the project directly.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 12, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664707, 'comment_body': 'We should not assert that the length of something passed to `__contains__` here is one. It may be convenient to check for inclusion of an aggregate against all `_AggregateStore` objects default or not. If the length is not 1 then we just return false.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 15, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479665546, 'comment_body': 'The last part is unnecessary. If all the aggregate ids are the same then the store is the same for all intents and purposes, unless you think that multiple forms of aggregation may lead to the same exact aggregates.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 24, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479665574, 'comment_body': ""I would prefer to just use the aggregate ids here too. Even with a million aggregates `int(sha1(','.join(a.keys())))` is fairly fast.\r\n\r\nI think it is cleaner this way, and if we find that users like to make many huge aggregates, we can rethink that decision."", 'comment_created': datetime.datetime(2020, 8, 29, 16, 24, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479666707, 'comment_body': 'Only testing one of these would be fine.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 36, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479666770, 'comment_body': 'Only testing one or two of these would be fine. We should also test that the default aggregate store handles getitem and contains correctly as well.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 37, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479673883, 'comment_body': ""I believe we should be extra sure, there may be a case when we only have a single job in the project and two operations which groups them in groups of 2, groups of 3. Then we won't be differentiating between them. This is completely theoretical and I'll do as you suggest\r\n"", 'comment_created': datetime.datetime(2020, 8, 29, 17, 55, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479680377, 'comment_body': ""As per discussion in slack, we're now only going to compare `_AggregatesStore` object by `aggregator` attributes."", 'comment_created': datetime.datetime(2020, 8, 29, 19, 10, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479681769, 'comment_body': 'We can just set this in the `groupsof` classmethod without needing to set an attribute to the function.', 'comment_created': datetime.datetime(2020, 8, 29, 19, 25, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479682853, 'comment_body': ""I'm not sure if I follow this. The `groupsof` method returns an instance of `aggregator`.\r\nBut since we're going to introduce the tag attribute, hence I think I'll simplify this logic.\r\n\r\nEdit: I got confused and now I understand what you mean."", 'comment_created': datetime.datetime(2020, 8, 29, 19, 38, 3, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479685750, 'comment_body': '```suggestion\r\n        # check the equality based on tags provided by an user or us in a classmethod\r\n```', 'comment_created': datetime.datetime(2020, 8, 29, 20, 12, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685857, 'comment_body': 'What I meant was that we can create the object and if it is the default aggregation, change the `_is_aggregate` flag after instantiation.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 13, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685882, 'comment_body': 'Also I think `groupsof{num}` is sufficient.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 13, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685894, 'comment_body': 'just `groupby{key}-{default}` is fine.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 14, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479687378, 'comment_body': ""I pushed a code, please have a look. I hope that's what you meant."", 'comment_created': datetime.datetime(2020, 8, 29, 20, 30, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479694058, 'comment_body': 'Why do we have both of these? One should suffice.', 'comment_created': datetime.datetime(2020, 8, 29, 21, 59, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479735059, 'comment_body': ""I'm not pretty sure about this.\r\nWhat if `_aggregator` attributes are equal but the `_select` attributes are not and vice versa.\r\nI think we need both of them compared."", 'comment_created': datetime.datetime(2020, 8, 30, 7, 40, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479785142, 'comment_body': '```suggestion\r\n        A callable that performs aggregation of jobs. It takes in a list of\r\n        jobs and can return or yield subsets of jobs as an iterable. The\r\n        default behavior is creating a single aggregate of all jobs.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 47, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785223, 'comment_body': '```suggestion\r\n        Condition for filtering individual jobs. This is passed as the\r\n        callable argument to `filter`. The default behavior is no\r\n        filtering.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 47, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785385, 'comment_body': '```suggestion\r\n        elif (\r\n             self._sort_by != other._sort_by or\r\n             self._reverse_order != other._reverse_order or\r\n             self._tag != other._tag\r\n        ):\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 49, 50, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785420, 'comment_body': '```suggestion\r\n        elif (\r\n             self._select == other._select and\r\n             self._aggregator_function == other._aggregator_function\r\n        ):\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 50, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785686, 'comment_body': ""This whole function seems rather convoluted. Is it all just for optimization (checking cheaper conditions first)? How big a difference is there between the last `elif` clause (which checks identity of `select` and `aggregator_function`) and the comparison of the `__co_code`? Is it really worth doing both? I'm not sure this level of complexity is warranted, but I don't know what the benchmarks look like."", 'comment_created': datetime.datetime(2020, 8, 30, 15, 52, 35, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786151, 'comment_body': ""I would move some of this information to the docstring. If it's meant to be a user-facing feature for the purpose of distinguishing aggregators, the user needs this information so they can decide what to provide as a tag."", 'comment_created': datetime.datetime(2020, 8, 30, 15, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786270, 'comment_body': '```suggestion\r\n        If the number of jobs present in the project is not divisible by the number\r\n        provided by the user, the last aggregate will be smaller and contain all\r\n        remaining jobs.\r\n        For instance, if 10 jobs are present in a project and they are aggregated in\r\n        groups of 3, then the generated aggregates will have lengths 3, 3, 3, and 1.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 58, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786292, 'comment_body': '```suggestion\r\n        The code block below provides an example on how jobs can be aggregated in\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 59, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788500, 'comment_body': ""This solution is pretty hacky... it's abusing the fact that you can store multiple references to the same iterator and then iterate over each reference in sequence to produce chunks of the original. It certainly works, though, and maybe it is the most efficient way to do this without making copies. I assume you found this recipe somewhere, could you add a link to document that, and maybe a comment here as well describing how it works?"", 'comment_created': datetime.datetime(2020, 8, 30, 16, 21, 21, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788586, 'comment_body': '```suggestion\r\n        The below code block provides an example of how to aggregate jobs having a\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 22, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788957, 'comment_body': '```suggestion\r\n            The method by which jobs are grouped. It may be a state point\r\n            or a sequence of state points to group by specific state point\r\n            keys. It may also be an arbitrary callable of :class:`signac.Job`\r\n            when greater flexibility is needed.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 26, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479789585, 'comment_body': ""I think the intention here was to use `md5` everywhere rather than use `sha1` everywhere. We use `md5` for the `id` of jobs, so let's be consistent here. Additionally, `md5` is a faster hash function and it generates shorter hashes, which is good for keeping the directory names shorter for jobs and the strings shorter for aggregate stores. In general we're not concerned with the security implications; if that changes we'll need to change hashes everywhere in signac anyway (and we'd need to use something more secure than sha1)."", 'comment_created': datetime.datetime(2020, 8, 30, 16, 32, 51, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479789621, 'comment_body': 'See comment on import: use md5 instead of sha1.', 'comment_created': datetime.datetime(2020, 8, 30, 16, 33, 9, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479790118, 'comment_body': '```suggestion\r\n        """"""Create the actual collections of jobs to be sent to aggregate operations.\r\n        \r\n        The :class:`aggregate` class is just a decorator that provides a signal for\r\n        operation functions that should be treated as aggregate operations and\r\n        information on how to perform the aggregation. This function generates\r\n        the classes that actually hold sequences of jobs to which aggregate\r\n        operations will be applied.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 38, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479790137, 'comment_body': '```suggestion\r\n    a :class:`aggregator`.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 38, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791193, 'comment_body': ""Should this error be about a job or an aggregate? This is a forward-looking question about how the aggregate's contains method will actually be invoked, @b-butler in future work making use of this class which error would be more appropriate? It seems like we'd want the error to state something about aggregates, but since this class will become the default mode for all aggregation maybe that's not the case since this error could get thrown for operations that act on individual jobs."", 'comment_created': datetime.datetime(2020, 8, 30, 16, 47, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791509, 'comment_body': 'Since this pattern of string[->sequence of strings]->blob->hash is very common, can you define a simple internal function `_hash` that we can call everywhere? That will ensure consistency in our hashing and simplify any future changes (for instance, to which hash function we call).', 'comment_created': datetime.datetime(2020, 8, 30, 16, 51, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791700, 'comment_body': '```suggestion\r\n            even = (i % 2) == 0\r\n```\r\n\r\nRelying on operator precedence when using anything other than pure arithmetic operators always makes me uneasy.', 'comment_created': datetime.datetime(2020, 8, 30, 16, 53, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479795163, 'comment_body': ""This was originally implemented by @csadorf in #52 and that had a link from where it was copied.\r\nI'll add the link into this PR and also mention #52 "", 'comment_created': datetime.datetime(2020, 8, 30, 17, 29, 33, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479797989, 'comment_body': ""That is true.\r\nIn #335 I have added support for these classes and I believe that it should be about an aggregate because everything will become an aggregate internally.\r\nI'm curious to know what @b-butler thinks about this"", 'comment_created': datetime.datetime(2020, 8, 30, 17, 57, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479799143, 'comment_body': ""A user could do something like this\r\n```\r\n@aggregator.groupsof(2)\r\n@FlowProject.operation\r\ndef op_1(*jobs):\r\n    pass\r\n\r\n@aggregator.groupsof(2)\r\n@FlowProject.operation\r\ndef op_2(*jobs):\r\n    pass\r\n```\r\nWe won't be able to differentiate between these two if we don't use `__code__.co_code` along with `tag` attribute"", 'comment_created': datetime.datetime(2020, 8, 30, 18, 8, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479812095, 'comment_body': ""Putting #52 doesn't help very much, it requires somebody to know that it refers to a pull request (and in the event that we ever switched off of Github we could lose PRs entirely). I would include the link and mention the `grouper` recipe (that's the function at that link that implements this technique)."", 'comment_created': datetime.datetime(2020, 8, 30, 20, 27, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813348, 'comment_body': ""I can't seem to access the original thread of discussion here, so I'll just make a new comment. The point that I was trying to make about this function (the whole `__eq__` method) being complicated was not about why we need the `tag`. I get that the tag might be necessary to distinguish between two. I was asking whether this `elif` clause is worth having at all. The remainder of this method basically tries to compare either the `co_code` or the hash of the `select`s and `aggregator_function`s to determine their equality, and either of those will be basically the same speed as the equality check in this `elif` (the `co_code` is just cached in the object on creation AFAIK). So I don't see any reason not to change this `elif` to an `else` clause, remove the equality checks that are currently here, and move the code with `self_select`, `other_select`, etc into this `else` clause."", 'comment_created': datetime.datetime(2020, 8, 30, 20, 41, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813430, 'comment_body': 'Have these tests been written?', 'comment_created': datetime.datetime(2020, 8, 30, 20, 42, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813520, 'comment_body': 'Now that the information is in the docstring, you can remove this comment entirely.', 'comment_created': datetime.datetime(2020, 8, 30, 20, 43, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479814256, 'comment_body': ""Does setting tags affect correctness, or is it just a performance optimization? Now I'm actually a little confused what the goal of the tags are. Are there cases where a user would have to provide tags, otherwise we might think that two aggregates are equivalent and therefore reuse the same set of job aggregates for them even though they should actually be using different ones? That seems _highly_ problematic to me. If the worst case scenario is just that we regenerate too many aggregates, then providing tags as a way for users to speed that up is fine, but we should never be in a situation where we silently use the wrong aggregates.\r\n\r\nIt should be possible to avoid any false positives with equality, it's just not possible to avoid getting false negatives (which is where the optimization comes in). Can you give an example where the current test fails to distinguish functions without the use of tags? Does that issue get fixed if you also check `co_consts` in addition to `co_code`?"", 'comment_created': datetime.datetime(2020, 8, 30, 20, 51, 6, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479817454, 'comment_body': ""@vyasr, @b-butler asked me to check this first in order to reduce the complexity.\r\nFor example, if we're able to compare the `aggregator_function` and `select` directly then there's no need to compare the binary code. But if we fail, then we end up comparing the binary code."", 'comment_created': datetime.datetime(2020, 8, 30, 21, 25, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479817652, 'comment_body': '@vyasr yes, I have written the tests.\r\nYou can have a look at them (They are the last 4 tests of this class)', 'comment_created': datetime.datetime(2020, 8, 30, 21, 28, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479821374, 'comment_body': ""I understand, but I'm saying that I don't expect this to lead to any real performance improvement. In practice I expect users to use the provided `groupsof` and `groupby` options the vast majority of the time, and those will never pass this check because those decorators create new internal functions each time they are called. When users do bother to create custom aggregation functions, I expect them to use lambdas or something most of the time, in which case again this equality check will fail. While checking the type and then checking the sort/reverse/tag are probably useful, this branch adds complexity without any evidence that it will improve performance. That is the hallmark of premature optimization, so I'm recommending not doing this unless we see that the `__eq__` method is actually a performance bottleneck that could benefit from this extra check."", 'comment_created': datetime.datetime(2020, 8, 30, 22, 2, 38, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480117103, 'comment_body': ""I understand what you say.\r\n@b-butler It'd be really helpful to know your views on this. If you agree, then I'll go ahead and remove the block."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 7, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480117864, 'comment_body': 'I did not try `co_consts`. I will try to make that work and let you know', 'comment_created': datetime.datetime(2020, 8, 31, 13, 8, 34, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480138481, 'comment_body': ""Well first, can you give an example where the tag is _necessary_, i.e. we would think two aggregators are identical when they really aren't? I have no idea if `co_consts` would fix the problem because I don't know what it is, I just suggested that because there is more information available than `co_code` if that is insufficient to distinguish.\r\n\r\nFor a feature like this we _cannot_ rely on the user to provide tags to prevent incorrectly identifying two distinct aggregates as the same. If we really can't distinguish them for some reason, I think we would have to eat the performance cost and just copy all aggregates and not reuse any of them. Optimizations cannot result in incorrect behavior, and we can't push that responsibility onto the user."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 41, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480144754, 'comment_body': ""When we use `co_code`, we are not able to differentiate between `groupsof(2)` and `groupsof(3)`.\r\nI believe this is because the function doesn't itself store any information about the number provided.\r\nIt just references to the value stored for num.\r\nThis is where `tag` comes handy. `co_consts` will not work here because it will just provide the constants declared in the function (which we don't do).\r\n```\r\na = 1\r\ndef x():\r\n    c = a\r\n    return c\r\n```\r\nThe output of `x.__code__.co_consts` would be (None,).\r\nThis is, kind of, the similar problem we're facing currently."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 51, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480165179, 'comment_body': ""Yes that's what I would expect. In this particular case you can get around the problem by instead looking at `x.__closure__`. However, I'm not sure if this would work in *all* cases. I think if you traversed all members of `x.__code__` and `x.__closure__` and checked them each for equality with the same members of another function you could guarantee that you don't get false positive, but I'm not 100% sure about that. For this particular use case, I think guaranteeing 0 false positives is far more important than preventing false negatives; the latter is just a performance hit, whereas the former leads to incorrect behavior. Reiterating what I said in my previous comment, it's much better to store some extra aggregates than to use the wrong aggregates for operations.\r\n\r\n@b-butler what are your thoughts here?"", 'comment_created': datetime.datetime(2020, 8, 31, 14, 23, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480208372, 'comment_body': 'I agree with @vyasr here generally, hence the comment I made before.', 'comment_created': datetime.datetime(2020, 8, 31, 15, 30, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 480210882, 'comment_body': ""I was not aware of `__closure__`, but that would likely be sufficient then. I don't care about false negatives, but yes we need to be sure of no false positives. We should also be fairly sure that `groupsof` and `groupby` are not giving false negatives."", 'comment_created': datetime.datetime(2020, 8, 31, 15, 34, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 481554288, 'comment_body': 'I also prefer fully qualified names (`import itertools` and `itertools.groupby`) to avoid confusion about the similarly-named aggregate functions.', 'comment_created': datetime.datetime(2020, 9, 2, 2, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}]","[{'commit_sha': '3af7e0e7454f1a4a4d46faf5f62a7bfb6b131414', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '48e503c2eb7b3adb988756868da4833fe9013128', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd5b19bd07c901cf4d25fcaf6f9efa777462d4659', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a7712f6d50731e9bd185571cefca3e122b09080e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3d4c6af2113ab1e8a84f465b4a8499f3fbb7b3bc', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8017bc31f131cae5b16a64b896d6fe88ce3c76ac', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a8a9df2e5a42eba61db2fecd14facb3790822b4', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '749c3b2a770740487946b4f81d54dd3f17f1fd99', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63e3c0720240b9687a6d53cd1398fa51181607a6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd8dab6f27c2fc650e7164c7427b0982a9d4ad19b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e74e03d68ea347917ebf49939782c85cc4c350c0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '014e1f42f1305363049e424d39e6e8b9b63e7860', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '908d92092bbca3f1b3b4b7e96c06a9befebd01ec', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2bb9f4519afad64cb65b881b161a8ed55f507405', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf54e1723d541ea02913e903f5274d064a77ec40', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dfdaff832461783e58120b48111745a4a38d12b2', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5426b9516e6f58e175a82acc6c72a66cf479794f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9e3d4e038952a4e794b9ca3244e8048d9c9f1242', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f5db9b8b8eff07801185ab96b26e09c31eca3c81', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f2edcfdf46985bc43ce66dff52f2d161eee5b121', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ed0ae4c7e57ca55e290a66b484d2b0c4ed785768', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a578a495969c99e1c58777ebb36a5e3548020a41', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
462623014,Add Aggregation Feature to Flow,"<!-- Provide a general summary of your changes in the Title above -->

## Description
Introducing the use of  `Aggregate` class in flow.
This class includes features like:
1.  _Aggregating by numbers_
2. _Aggregating by a condition/statepoint-param_ 
3. _Sorting by a statepoint-parameter_
4. _Filtering jobs using the `select` parameter_
<!-- Describe your changes in detail -->

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
The current [PR](https://github.com/glotzerlab/signac-flow/pull/289) for aggregation is too big. Now that PR will track my project and I'll be splitting the work into several small PRs.

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [ ] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",False,336,https://api.github.com/repos/glotzerlab/signac-flow/pulls/336,https://github.com/glotzerlab/signac-flow/pull/336,closed,1612,334,14,96,4,15,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-08-04 08:47:17+00:00,2021-02-11 12:23:22+00:00,16515365.0,"191 days, 3:36:05","[{'comment_id': 475747612, 'comment_body': 'Use f-strings, here and below.', 'comment_created': datetime.datetime(2020, 8, 24, 16, 37, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475748235, 'comment_body': 'We use American spellings, not British. Fewer keystrokes. 😉\r\n```suggestion\r\n        The default behavior is no filtering.\r\n```', 'comment_created': datetime.datetime(2020, 8, 24, 16, 38, 53, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475748347, 'comment_body': '```suggestion\r\n        The default behavior is no sorting.\r\n```', 'comment_created': datetime.datetime(2020, 8, 24, 16, 39, 5, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475751656, 'comment_body': ""I think this is equivalent - please check it.\r\n```suggestion\r\n        self._is_aggregate = getattr(aggregator, '_num', 0) != 1\r\n```"", 'comment_created': datetime.datetime(2020, 8, 24, 16, 44, 45, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475752868, 'comment_body': ""~We're shadowing built-in functions `sort` and `reverse` here. We'll want to avoid that. I recommend renaming the parameters to `sort_function` or `sorter` and `reverse_order` or something like that.~\r\n\r\nedit: Sorry, this comment was inaccurate. The built-in functions are `sorted` and `reversed`. This naming is fine, I think."", 'comment_created': datetime.datetime(2020, 8, 24, 16, 46, 46, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475757109, 'comment_body': ""~Don't shadow `sort` and `reverse` functions.~\r\nedit: This is fine. See above."", 'comment_created': datetime.datetime(2020, 8, 24, 16, 54, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475757193, 'comment_body': ""~Don't shadow `sort` and `reverse` functions.~\r\nedit: This is fine. See above."", 'comment_created': datetime.datetime(2020, 8, 24, 16, 54, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475757660, 'comment_body': 'Use f-strings here and below.', 'comment_created': datetime.datetime(2020, 8, 24, 16, 54, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475758950, 'comment_body': ""I'd rewrite this to use `zip` instead of `enumerate`. This might work:\r\n```suggestion\r\n                    return [job.sp.get(key, default_value) for key, default_value in zip(keys, default)]\r\n```"", 'comment_created': datetime.datetime(2020, 8, 24, 16, 56, 53, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475761678, 'comment_body': 'This class should be private, according to this comment.', 'comment_created': datetime.datetime(2020, 8, 24, 17, 1, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475761794, 'comment_body': '```suggestion\r\n        ""Return aggregated jobs.""\r\n```', 'comment_created': datetime.datetime(2020, 8, 24, 17, 1, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475762829, 'comment_body': 'I\'d prefer to separate the job ids with a comma for conceptual clarity. I know this isn\'t really ""meaningful"" since it\'s hashed, but I think it makes the purpose clearer.\r\n```suggestion\r\n    blob = \',\'.join((job.get_id() for job in jobs))\r\n```', 'comment_created': datetime.datetime(2020, 8, 24, 17, 3, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 475762910, 'comment_body': '```suggestion\r\n    """"""Generate hashed id for an aggregate of jobs.\r\n```', 'comment_created': datetime.datetime(2020, 8, 24, 17, 3, 31, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}]","[{'commit_sha': '4eb97a0aa25bb1b6369496af2bee6f67994a8489', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '07c5e16afdf4517ce4da4ebb833984be1f75ea90', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5cc7912fb4592e95eed90c91e70e7d3ae7f58613', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b9c465566ea6fa26e4e62504999a89744c392153', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a7ca7e18bfb338f96298cc1f6f78c08232be79f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '15b79cfe961a2d57665c48a5e497ae1acd4bef35', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'df99e5046a204f52ed38bface0de8b5a8c8727e7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5f1e0607da1063f03f6d7232e32729afc089d471', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0a33a273b73c972dc944addbb220a3a7286d4d92', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6a379207b0a2f44ba6ccc5f8b2cc411bff428df6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '39b4a3c6cf32fe56eaa80cffe9b62cd084276c7a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7478f4dd3ba19250cbb99dcbfae03886b7563b18', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b5ba89fcc826d1267181b465ea9c44102f5a8197', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b07f7b1ac8bffdc0cfc1e80cab9bb0670e10cc8', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6da1cf1a5b39455485b1d9225792370df0c09a79', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eadb0319a7a685a9be8a1fd2eed161b3ec02cb6d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a2446e54cdf2fff1d1d027d4344e1ac1dc9c0838', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b937d46c7777566664645b3844f974092b6014a0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'be56b51ed6e537328c5170f5d0660a7c8769d7f6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f266987b1ceb0c75bad48c099bf6df248bbc6f6c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4f51e2979660e104a577b8a67a2b9d67a45034c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '729dca01c12e9691f6a6add85f6acae8fec68275', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0fd78b54775bfe56b3ec16e25811cc96d77d4180', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fab2f68b758f29856df59cdef1e7038b7dabdadc', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fcb29de2b4f83319559e91d8001604c4b9cfbe9b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'abbd6d16dfbf4ef8f6318bf8fe7469d8e8903572', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '26928dcefbd25974f5b7361c1f79ce9695873114', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14f9fa98dbd848e170fdc82480b9284ebcdad451', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c11f40b21e27f9520c42a7aa327f5c88476df99b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8dc5a9551970f2103b75c014d765089965b25d1d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4efa4808f6b09d6c4dca5aeffa2f5384fc69f763', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd26aa802ad36a6b9dd381f7790cad90612df6f9', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '39ec72bd83f9b108d4a0dba277f5ddac5479b58d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '702ae4edf57deeec424eab489077e503a954bda3', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '05855afc201b4c401bd31dba1c90eda43b108cf6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fd2aaee45a07eaf70576cd22d0393d67eff5bd2f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '857b54c2460f78a24c6e3e24039462c647051070', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c3154f134ebc688e065c9b4d516f09f8ddaf5a98', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2cca72a54b660411d35cf1008a2c267f371f50e9', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7e664633f4582f731f0f6867cb066aa8cce682b8', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '355a9bf5b4051338d1f1187a160170fc02d81603', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '35e8295dc9d7713104cbfe71e01e9a44797757fe', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b41151a75355173f5028934693b60b5621ba8ec', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c1e69ccb676738a2ac8b361b892e8dd5c34c299e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '760de94dbfed24bc3f8966e7a34c7eb0bdd5ba88', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a7f63092f2ed9e9d78635573afd5cf5c127754b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '417ff18e37dc693e6b048531f8d378ebe88f6eec', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b72036303699a9fdb884a433531bdcaa774c3069', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e460b7074098e138de41fed28a3897d67d2c2ea1', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '441db268435c9203af0eeb80bfb089726a7e4d59', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c300013f636dc3c865681d1034ac55ee4e9b8d93', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '810850a547303370900822c3639d11ef7ef95d5f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2ff36c019a3d99e61d09de0cd3a8451af65aea8a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cc3d42aa83664bea7e47102a0caa20cc44d30ee3', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe178539088c92de6f3fafee5975dfc943091733', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1f3c2683bd6a40f4148cc13a7748bb68b0aeea24', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '024921a709f9e791589d11fcc247925f3560eccb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '86d784f179b2328068472e72a716754f449e70bf', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e64c09c71563b6f8fdb0724a1e020fcd1e665cf7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b2e21b785868ecdac8d6786e55661b6efc56a791', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '432232374609977cc8915883e9fc1dedfe0c9196', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1d5f6cc8596c66976b072d23407be49860b5d6d5', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a9d5b1a38702729b392e4b30aceb5be95e3aede7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd74b3a0b31a72630c4ba25441006fa565b7b2a94', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bc759003e692a21cb1f4766f7d52b0a90beabb3a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f05cb7097924e26efdad13c41cb9629f0cb5b02e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6c3c21b930fab566b6be3d78f482e1eda13153b1', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '339345fa3c701686acb153e585f773578ec79d6b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9bbbcfce75954d14fd327a66e421d53e365ee898', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd5e558cb771de2254c261a18c385d41e03fcb54a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '65980049af5c16a00c7746a6a45bd24ecc2432bb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '49007b69638dc892fca9c4b9ad71fd0274308f9d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '66d78ebb3c04f63a1965b42533e1ddf973182dd3', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f196cdd54a9b65d46acc57d9c4fc361fde59b594', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e0d1483d651ab8150427a3d6138eed270daeea1f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cfbc133efad2b37bcc1270359e31d1b8d3bedf4f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5881a69b3a714240ecfe15c0eee5db0a0418d652', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '07dd725cc12ab0e9d45b39f1c77df6dd0e55477e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e1f815ae3a19ddc56e27cac6a82e91affd9cf059', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4cbe754cccf2318cdc163404abf14b0992db2f9b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5f4f09d462518288d760768e02aab587be517739', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63d6810faa0d390e80c9af4245ccb07bf5e50d2f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cd3def4e011c38efe4274389e6ff4afc374dcdd3', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ec8a04b803a382ac2243a83d62c0f31125f84079', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd16edeba786d02531876db99b7b8e6fa04f4223d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ef70af78611bf2f448214930b284117fb0eda690', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ea4bccb5bc3c3152534ae34c154c69de49e6496b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a76c5b2da5f5eab1cfcf92a9397675aab56d02d2', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8925ad49bd16ade31ce741052c5757bd0c326dfd', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8d4313b50a9b4ec7c994b2cd02aec45748f91d31', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '35b8bda05f74f22a717c5f1a3d3258acd00ce72f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '97714c9ef6a717940401129b7c9d8f818fbec35f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fbb9e151046761dc9505a3426f124e293046c4ab', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '92b425b2503412d3a17082c89d26646d4bbac8fb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ad2da196f623bdda182228d2808080460664e979', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7e463d95f90695823c45e037abd1cda921251c9', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
474066015,Add aggregator classes in flow,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Add aggregator classes to flow.
This pull request introduces a concept of storing the aggregates in an iterable class which will be then stored throughout the `FlowProject`
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
To be merged before #335 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [x] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,348,https://api.github.com/repos/glotzerlab/signac-flow/pulls/348,https://github.com/glotzerlab/signac-flow/pull/348,closed,761,0,2,22,4,187,2,1,"[{'name': 'GSoC'}, {'name': 'aggregation'}]",2020-08-26 18:00:18+00:00,2020-09-01 13:55:56+00:00,503738.0,"5 days, 19:55:38","[{'comment_id': 477537468, 'comment_body': 'Is yielding any iterable of jobs okay? or should we require tuples.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 26, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477540138, 'comment_body': 'This will fail with `functool.partial` objects or callable class objects. Also, I would put the cheaper (string and Boolean) comparisons first.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 31, 44, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477542218, 'comment_body': 'I would prefer the class name `Aggregator` as it is not really an aggregate as we have defined it, but rather a definition of aggregation.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 35, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477545603, 'comment_body': 'Needs docstring', 'comment_created': datetime.datetime(2020, 8, 26, 19, 41, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477545676, 'comment_body': 'Needs docstring', 'comment_created': datetime.datetime(2020, 8, 26, 19, 42, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477546248, 'comment_body': 'Can be a docstring.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 43, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477546668, 'comment_body': ""Won't this create a `_StoreAggregates` class for each group/operation. there is no registry that I see."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 44, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477547561, 'comment_body': ""This is not the behavior we want. The aggregate store shouldn't be callable. We need a function to regenerate aggregates, but making an object callable says something about its behavior. Here calling is just to change the state of the object which is not the correct paradigm."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 45, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477547799, 'comment_body': 'Class should be `_AggregateStore` for classes it is typical to use nouns unless the class acts as a functor.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 46, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477548515, 'comment_body': ""When this object is created, I would want to see the aggregates be computed. Otherwise, it isn't really storing anything until after it is called. This would require that it takes an iterable of jobs (typically the project) as a constructor argument as well."", 'comment_created': datetime.datetime(2020, 8, 26, 19, 47, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477548660, 'comment_body': 'Should be a standard method not `__call__`. Also make comment into one line docstring.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 47, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477551425, 'comment_body': 'Currently this class does not provide id indexing (`__getitem__`) or checking for inclusion (`__contains__`). I would like to see both these features. The same for `_StoreAggregatesDefault`.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 53, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477552186, 'comment_body': 'Since we have multiple classes that are serving as aggregate stores, it may be helpful to create a class `_AggregateStoreBase(Mapping)` that uses the `collections.abc.Mapping` class and additionally requires a `recompute_aggregates` method, plus any other functions deemed necessary.', 'comment_created': datetime.datetime(2020, 8, 26, 19, 54, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477556518, 'comment_body': 'To use an object as a key in a dictionary it has to support `__hash__` and `__eq__`', 'comment_created': datetime.datetime(2020, 8, 26, 20, 2, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558152, 'comment_body': 'I would prefer using `hasattr` here.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 5, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558255, 'comment_body': 'Likewise', 'comment_created': datetime.datetime(2020, 8, 26, 20, 5, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558427, 'comment_body': 'hasattr', 'comment_created': datetime.datetime(2020, 8, 26, 20, 6, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477558653, 'comment_body': 'Although different in terms of syntax used; this and the previous test are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 6, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477559838, 'comment_body': 'This is also unnecessary.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 9, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477561644, 'comment_body': '```suggestion\r\n        assert [tuple(project)] == list(aggregate_instance)\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 20, 12, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477562621, 'comment_body': ""It may be worth creating a helper function that does the comparison between a function's and an `_StoreAggregate`'s aggregates given a `FlowProject`."", 'comment_created': datetime.datetime(2020, 8, 26, 20, 14, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477563096, 'comment_body': 'We should also test that the size of each aggregate is correct.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 15, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477563438, 'comment_body': 'I would assert that all of the values for `job.sp.even` are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 16, 24, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 477564158, 'comment_body': 'I would likewise test that all the values of `job.sp.half` are identical.', 'comment_created': datetime.datetime(2020, 8, 26, 20, 17, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478283283, 'comment_body': ""I think we should be flexible in terms of users point of view.\r\nTo convert those into tuples, we're already converting those iterables into tuples in `_create_nested_aggregate_list`"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 29, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478285406, 'comment_body': ""I thought we'd require an `__eq__` method to put these object as keys in a dictionary but I learnt that we also require the objects to be hashable and it turns out we can uniquely hash these objects (partial functions, lambda functions, or normal functions).\r\nI'll also use `__hash__` here"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 33, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478286069, 'comment_body': 'This is technically breaking the API. Should I post this on slack for further discussion?', 'comment_created': datetime.datetime(2020, 8, 27, 9, 34, 14, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478287693, 'comment_body': ""That is why we'll be using a `__hash__` method to uniquely identify a `_StoreAggregate` instance"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 37, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478288334, 'comment_body': ""I'll use a different method `_generate_aggregates` instead"", 'comment_created': datetime.datetime(2020, 8, 27, 9, 38, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478295728, 'comment_body': 'Hmm, I see what you mean here.\r\nI also agree, will make the necessary changes', 'comment_created': datetime.datetime(2020, 8, 27, 9, 50, 16, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478426607, 'comment_body': 'Why are we mixing two different hash functions? I would prefer to be consistent (although we of course make no promises about this in our API).', 'comment_created': datetime.datetime(2020, 8, 27, 13, 39, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478431171, 'comment_body': 'Does our style have a preference on how import multiple objects from a module/package? If not, I would prefer to either do `from itertools import groupby, zip_longest`, or use fully qualified names everywhere else and just `import itertools` here. Importing `groupby` directly is going to cause cognitive dissonance for readers of the code since we internally define `Aggregate.groupby`.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 46, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478436334, 'comment_body': ""It is breaking an API that doesn't exist yet, so you can ask, but it isn't a breaking change."", 'comment_created': datetime.datetime(2020, 8, 27, 13, 53, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478436807, 'comment_body': 'I guess I am fine then.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 53, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478438579, 'comment_body': ""The API breaking is not a concern since none of this is released yet. Use whatever names you think are appropriate. However, in this case @kidrahahjo @b-butler be mindful of the fact that this class will be used as a decorator by users. For this reason, we may want to follow naming that would not normally be appropriate. For instance, consider that the `pre` and `post` condition classes are lowercased despite being classes, precisely for this reason, and similarly for directives. Decorators should _look like_ functions IMO; while this isn't written in any style guides, it's the rule we've followed in flow because that's more intuitive for users, and it supersedes the typical class naming rule.\r\n\r\nRegarding the actual name of the decorator, consider that the first argument to the constructor of this class is called `aggregator`; it seems awkward for an `Aggregator` to require an `aggregator`. I'm having trouble thinking of a better alternative right now, though; I'll post again if I think of something."", 'comment_created': datetime.datetime(2020, 8, 27, 13, 56, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478440082, 'comment_body': 'Add a comment or two explaining why we need to treat `groupsof(1)` (the default aggregate) differently.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 58, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478440737, 'comment_body': 'I would caution against just using hash for both `__eq__` and `__hash__`. If `hash(obj) == hash(other)` the equality method is used to differentiate between objects. Here if we use it for both we end up with no way to discern the objects.', 'comment_created': datetime.datetime(2020, 8, 27, 13, 59, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478442318, 'comment_body': ""All of this error checking feels rather un-Pythonic to me. However, I can see a good reason for this here since none of these attributes will actually get used until downstream in the aggregation pipeline, at which point the errors would be much harder for users to interpret. @bdice you're usually the style police for EAFP (I'm of the opinion that both LBYL and EAFP have their place in Python, so I'm less opposed to this on principle), what do you think?"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 1, 25, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478443539, 'comment_body': ""I don't know if I've ever said this before, but there's actually too much white space and empty lines in this block (and in various other parts of the code) and it makes it less readable. In particular, there's a newline before every `elif` or `else` clause. Can you tighten some of that up?"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 3, 12, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478445900, 'comment_body': 'Just FYI @kidrahahjo both of these methods have default implementations for any class (e.g. `class A: pass` will have default versions of both methods defined), but I assume @b-butler wants you to define a meaningful equality check here.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 6, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478446662, 'comment_body': 'How will that prevent making a new one? It seems like you will create a new one anyway in `_create_StoreAggregates`.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 7, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478450955, 'comment_body': ""Can we just combine the classes? I'm not seeing much benefit to the separation. Especially if you change the `_StoreAggregates` class to compute the aggregates on construction, then both this and the `*Default` class can just store `self._aggregates` (which would just be the project for the default case) and `yield from` that in `__iter__`. Hashing should also work transparently."", 'comment_created': datetime.datetime(2020, 8, 27, 14, 13, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478451129, 'comment_body': 'This change supports us moving away from the two class model.', 'comment_created': datetime.datetime(2020, 8, 27, 14, 13, 31, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478452293, 'comment_body': ""I would prefer to return `jobs[0].id`, which is strictly correct and doesn't depend on us not changing the string representation of a `Job`."", 'comment_created': datetime.datetime(2020, 8, 27, 14, 15, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478458974, 'comment_body': ""@bdice another instance of type checking up front that is probably justified due to the delayed execution of aggregator.\r\n\r\n@kidrahahjo the sequence here is a little confusing though. The `TypeError` you're catching would be thrown by the first line in the `try` block, so there's no need for the rest to be there. I would move the `if num<=0` check out of the try block. Furthermore, rather than trying to convert to int like this, if we're going to type check I would do it rigorously. Currently, passing `num=3.5` will result in the code silently using `num=3`.\r\n```suggestion\r\n        if num != int(num):\r\n            raise TypeError('The num parameter should be an integer')\r\n        num = int(num)\r\n        if num <= 0:\r\n            raise ValueError('The num parameter should have a value greater than 0')\r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 14, 24, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478460776, 'comment_body': 'Whatever you call the method, make sure it is called in the constructor (and can be called again later if necessary).', 'comment_created': datetime.datetime(2020, 8, 27, 14, 26, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478541622, 'comment_body': ""There's no specific style, but in `project.py` we import them separately."", 'comment_created': datetime.datetime(2020, 8, 27, 16, 21, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478541938, 'comment_body': 'I agree that the first constructor argument would need to change.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 21, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478542153, 'comment_body': 'That is correct.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 22, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478542689, 'comment_body': '`md5` is used to generate the id of an aggregate. No specific preference was there, it was just a suggestion that we could use `md5` for getting aggregate id.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 23, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478543545, 'comment_body': 'We could if this implementation had the complete desired behavior. However, once we add `__getitem__` and `__contains__` are implemented both of which would look different for the classes and the fact that for the default case the regeneration of aggregates is a no-op. I think having separate classes is warranted.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 24, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478544390, 'comment_body': 'Will do', 'comment_created': datetime.datetime(2020, 8, 27, 16, 25, 55, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478544846, 'comment_body': 'Are you referring to having `Aggregate` be the same class as `_AggregateStore`? or the distinction between default aggregation and non-default aggregation.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 26, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478558681, 'comment_body': 'I would like to be consistent if possible as well.', 'comment_created': datetime.datetime(2020, 8, 27, 16, 49, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478560334, 'comment_body': 'It can be `aggregator_function`?', 'comment_created': datetime.datetime(2020, 8, 27, 16, 52, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478562832, 'comment_body': 'This is a statement about possibilities not what the function does (as it is worded).', 'comment_created': datetime.datetime(2020, 8, 27, 16, 56, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478568663, 'comment_body': 'Since only the last aggregate can be a different size. I would say something like the default size of aggregates excluding the final aggregate.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 6, 28, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478569370, 'comment_body': 'See comment about `groupsof` above.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 7, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478570265, 'comment_body': 'the key parameter needs more explanation. Also, you have the key parameter listed twice.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 9, 23, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478571041, 'comment_body': 'This is not necessarily true. A variety of things could have been passed here. I would just mention that we were passed something other than a function.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478571762, 'comment_body': ""The point of `_DefaultAggregateStore` was that we wouldn't want to compute those aggregates as aggregates of 1. We could just yield single jobs.\r\nWe could merge those two classes but the current model is a simple way to differentiate between those two."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 12, 1, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478573408, 'comment_body': 'I would prefer if we used the id to check for inclusion. It would be constant time rather than linear then.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 14, 59, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478574129, 'comment_body': 'There is no need for either of the explicit list calls.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 16, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478576586, 'comment_body': ""We don't need this list conversion."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 20, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478576884, 'comment_body': 'Do worry about the explicit `bool` conversion.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 21, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478579017, 'comment_body': ""Here you are converting to a list again. We don't need to convert to list multiple times. `sorted` always returns a list, and `filter` does not, but if we pass it into `sorted` it will return a list."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478580328, 'comment_body': 'I think it might look cleaner to have a small function `validate_and_filter_jobs` that returns a Boolean or raises an error and just use `nested_aggregate = tuple(filter(validate_and_filter_jobs, aggregate))`', 'comment_created': datetime.datetime(2020, 8, 27, 17, 27, 16, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478580836, 'comment_body': 'Use project id.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 28, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581268, 'comment_body': 'This is internal, should we ever be passed a list of jobs rather than a `FlowProject`? Considering we control this.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 28, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581583, 'comment_body': 'No need for two functions here.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 29, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478581894, 'comment_body': '```suggestion\r\nreturn job in self._project\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 17, 29, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478582411, 'comment_body': 'Why would we ever be passed anything other than the project?', 'comment_created': datetime.datetime(2020, 8, 27, 17, 30, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478585901, 'comment_body': ""Don't convert to string here. No need."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 36, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478586175, 'comment_body': 'I would explain what this function is doing as it is not immediately apparent. I understand, but someone fresh coming to the code might not.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 37, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478586904, 'comment_body': 'Using map for these two attributes seems a bit much. Just writing it explicitly would be fine.', 'comment_created': datetime.datetime(2020, 8, 27, 17, 38, 29, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478593082, 'comment_body': '```suggestion\r\n            return self_select == other_select and self_aggregator == other_aggregator\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 17, 49, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478607744, 'comment_body': 'We use md5 for id calculation of Jobs.\r\nI think that was the reason we were using md5 for calculating aggregate id.\r\n@b-butler @vyasr @bdice Please suggest what should be done here.', 'comment_created': datetime.datetime(2020, 8, 27, 18, 15, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478630597, 'comment_body': ""I'm not sure what you exactly mean by this.\r\nI will shift this conversion to `__init__` method of `Aggregate` but what else should I be worried about?"", 'comment_created': datetime.datetime(2020, 8, 27, 18, 58, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478634436, 'comment_body': ""Oh, I'm sorry about that. Thanks for letting me know."", 'comment_created': datetime.datetime(2020, 8, 27, 19, 5, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478687251, 'comment_body': 'I changed the functionality. Please have a look at it once you get time', 'comment_created': datetime.datetime(2020, 8, 27, 20, 49, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478688950, 'comment_body': ""@b-butler The two classes, though does the same thing, are technically not at all similar.\r\nEven if we create `_AggregateStoreBase` we'd then have to override nearly all the methods. (Because even `_register_aggregates` for both the classes registers aggregates differently."", 'comment_created': datetime.datetime(2020, 8, 27, 20, 52, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478699962, 'comment_body': 'Is there a reason to use sha1 anywhere?', 'comment_created': datetime.datetime(2020, 8, 27, 21, 15, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478701018, 'comment_body': ""This is indeed better, but the main purpose it to provide a way to compare arbitrary types that are callable, and that isn't mentioned here."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 17, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478702803, 'comment_body': '```suggestion\r\n        """"""Aggregates jobs according to matching state point key values.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 21, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478703385, 'comment_body': '```suggestion\r\n        """"""Aggregates jobs of a set group size.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 22, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709006, 'comment_body': 'If we have this class which I generally am in favor of. It should not compose an `Aggregate` object but rather take the values from the object and use them itself.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709093, 'comment_body': 'This can be a static method', 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478709243, 'comment_body': ""These don't need to be in the try block."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 35, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478710118, 'comment_body': 'I may have been confusing here. If we just use `filter` without `sorted` then `jobs` will not be a list when passed to `self._aggregate._aggregator_function`. It will be a `filter` object, so if `sort_by` is `None` then we do need to explicitly cast to a list, if that is an API guarantee to the user for the aggregation function rather than promising to return an iterable of jobs.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 37, 54, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478711087, 'comment_body': 'If we make the change to `_MakeAggregates` I suggest, then we should move the `__eq__` and `__hash__` methods to it.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 39, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478714946, 'comment_body': 'If we are going to use `_MakeAggregates` then we would just want this class to have a `_MakeAggregates` object it can call when it needs to.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478716331, 'comment_body': 'Maybe a comment on how this tests hashing works properly would be helpful (i.e. mentioning that you have 11 unique aggregation definitions).', 'comment_created': datetime.datetime(2020, 8, 27, 21, 52, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478716834, 'comment_body': ""If this is to just test with lambda's versus standard functions, we don't need both tests. If this is to test two different functions then it can be in the same test."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 53, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478717487, 'comment_body': 'This does not test that each aggregate of `aggegrator.groupsof(2)` for instance has two jobs (except the last perhaps).', 'comment_created': datetime.datetime(2020, 8, 27, 21, 54, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478717818, 'comment_body': '```suggestion\r\n            assert all(even == job.sp.even for job in aggregate)\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 21, 55, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718048, 'comment_body': ""```suggestion\r\n            assert all(assert half == job.sp.get('half', -1) for job in aggregate)\r\n                \r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 21, 55, 57, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718457, 'comment_body': ""Thanks for the comment! Could you add how that means we don't need to check whether all the aggregate members are equivalent. Of course this is true for aggregates of size one, but just to be clear for future developers."", 'comment_created': datetime.datetime(2020, 8, 27, 21, 56, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718621, 'comment_body': 'Use all here too.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478718671, 'comment_body': 'Use all here.', 'comment_created': datetime.datetime(2020, 8, 27, 21, 57, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478720639, 'comment_body': 'I am saying do not worry about it at all just assume it is something Boolean like.', 'comment_created': datetime.datetime(2020, 8, 27, 22, 2, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 478723250, 'comment_body': 'Nope, no specific reason.\r\nIt was used while hashing `_JobOperation`, bundle id in `project.py`', 'comment_created': datetime.datetime(2020, 8, 27, 22, 9, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 478724889, 'comment_body': 'the key can also be an arbitrary callable hence, according to me, users may get confused with this doc', 'comment_created': datetime.datetime(2020, 8, 27, 22, 13, 28, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479051633, 'comment_body': ""I'm not sure I see the use case of moving them to `_MakeAggregates` can you please explain?"", 'comment_created': datetime.datetime(2020, 8, 28, 9, 54, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479056580, 'comment_body': 'So, I should probably execute `jobs = list(jobs)` after we filter jobs', 'comment_created': datetime.datetime(2020, 8, 28, 9, 58, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479099813, 'comment_body': ""We'll be eventually storing the instances of `_AggregateStore` and not `_MakeAggregates`. Hence, I think it is not useful to move `__eq__` and `__hash__` method to `_MakeAggregate`"", 'comment_created': datetime.datetime(2020, 8, 28, 10, 34, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479193923, 'comment_body': ""The `_validate_and_filter_job` uses a instance attribute `_project`.\r\nIf we convert this to a static method then we'll have to execute something like this\r\n```\r\nfilter_aggregate = tuple(filter(\r\n    lambda job: _validate_and_filter_job(job, self._project), aggregate))\r\n```\r\nI'm not sure if this is a right approach or not. Please suggest"", 'comment_created': datetime.datetime(2020, 8, 28, 11, 55, 42, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479350825, 'comment_body': 'Nevermind, we do need this at first to be able to discern if an user creates multiple of the same `aggregator` objects... We will likely need a way to hash and equate `_AggregateStores` as well though.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479351768, 'comment_body': ""I don't think we need to internally store the project in this class. We can just expect it to be passed when called. Then we do not need to use `self._project` in fact such an attribute would not even exist. Then `_validate_and_filter-job` could be a closure created within the `_create_nested_aggregates` method. Sorry I missed that we were storing the project before."", 'comment_created': datetime.datetime(2020, 8, 28, 14, 43, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479353635, 'comment_body': ""I don't know why we are storing the project in this class. I know I missed this last review. I believe passing in the project to `_MakeAggregates` is the proper approach. That provides the intuitive behavior of `_MakeAggregates` as a function that takes in a project and returns aggregates."", 'comment_created': datetime.datetime(2020, 8, 28, 14, 46, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479358687, 'comment_body': 'Okay, then I would be consistent here for this file as it is a bit cleaner.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 55, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479359831, 'comment_body': 'This should accept a `FlowProject`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 56, 52, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479360616, 'comment_body': 'This should still be done by the `_AggregateStore` class. I believe the `_MakeAggregate` class should only be responsible for correctly handing the aggregation, not the data structures used by `_AggregateStore`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 58, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479360962, 'comment_body': 'This should be moved back to `_AggregateStore`.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 58, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479361333, 'comment_body': 'If we make the change I suggest. I would like to see this yield aggregates. That is just a preference though.', 'comment_created': datetime.datetime(2020, 8, 28, 14, 59, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479370670, 'comment_body': '@b-butler \r\nIn this implementation, we do have an `__eq__` and `__hash__` methods for both `_DefaultAggregateStore` and `_AggregatesStore`', 'comment_created': datetime.datetime(2020, 8, 28, 15, 15, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479447017, 'comment_body': 'We do not need to store the project here.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 40, 8, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479447759, 'comment_body': 'We could use a classmethod for `_MakeAggregates` that takes the `aggregator` and handles this setting internally.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 41, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479448513, 'comment_body': 'We should pass in the project to this function and the `_create_nested_aggregate_list` function, or create the `_validate_and_filter_job` function in this function and pass that to `_create_nested_aggregate_list`. Either is fine with me. It is up to your preference.', 'comment_created': datetime.datetime(2020, 8, 28, 17, 43, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479448898, 'comment_body': 'This list call is unnecessary. If we require that the aggregator function be passed a list, then we should only call list if `self._sort_by is None`.\r\n\r\n````python\r\nif self._sort_by is None:\r\n    jobs = list(jobs)\r\nelse:\r\n    jobs = sorted(...)', 'comment_created': datetime.datetime(2020, 8, 28, 17, 44, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479471676, 'comment_body': ""Why is this after `sort_by` now? With this being before the `sort_by` conditional, we only convert to a list once. Now we would do it twice if `sort_by is not None`. If we put it before, we also don't need the `list` conversion there."", 'comment_created': datetime.datetime(2020, 8, 28, 18, 33, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479472310, 'comment_body': 'I am fine because this makes errors easier for the user to manage.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 35, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479473092, 'comment_body': 'Why are we accepting `kwargs` when they are not used anywhere meaningfully?', 'comment_created': datetime.datetime(2020, 8, 28, 18, 37, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474300, 'comment_body': 'We just need to check that the aggregate ids all all the same.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 39, 40, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474410, 'comment_body': ""We don't need to store the aggregator."", 'comment_created': datetime.datetime(2020, 8, 28, 18, 39, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479474518, 'comment_body': '```suggestion\r\n        blob = str(hash(self._aggregates))\r\n```', 'comment_created': datetime.datetime(2020, 8, 28, 18, 40, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479475356, 'comment_body': 'Can we test the `__hash__` and `__eq__` of this class given the typo I found.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 42, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479477989, 'comment_body': 'These are used to check equality between two aggregator objects. I was having difficulty in comparing aggregators hence I thought that these additional parameters would be helpful to test the equality', 'comment_created': datetime.datetime(2020, 8, 28, 18, 47, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479478418, 'comment_body': 'Yes, I think I forgot to write those. Sorry about that. Will do it.', 'comment_created': datetime.datetime(2020, 8, 28, 18, 48, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479634260, 'comment_body': 'We compare and hash the `aggregator` hence I think that we should store the aggregator', 'comment_created': datetime.datetime(2020, 8, 29, 10, 15, 6, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479634335, 'comment_body': 'Do you mean something like this\r\n`self._aggregate_ids.keys() == other._aggregate_ids.keys()` ?', 'comment_created': datetime.datetime(2020, 8, 29, 10, 16, 4, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479636475, 'comment_body': 'This should be `self._aggregator`', 'comment_created': datetime.datetime(2020, 8, 29, 10, 43, 49, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479664323, 'comment_body': 'If this is just for testing equality, please remove it. This feature is not used for any purpose. We should deal directly with the problem of testing equality. What part was giving you difficulty?', 'comment_created': datetime.datetime(2020, 8, 29, 16, 11, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664366, 'comment_body': 'Yep.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 11, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664470, 'comment_body': 'We just need to compare aggregation_ids or hash to determine uniqueness for standard aggregate store object the default is easier with just comparing and using the project directly.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 12, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479664707, 'comment_body': 'We should not assert that the length of something passed to `__contains__` here is one. It may be convenient to check for inclusion of an aggregate against all `_AggregateStore` objects default or not. If the length is not 1 then we just return false.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 15, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479665546, 'comment_body': 'The last part is unnecessary. If all the aggregate ids are the same then the store is the same for all intents and purposes, unless you think that multiple forms of aggregation may lead to the same exact aggregates.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 24, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479665574, 'comment_body': ""I would prefer to just use the aggregate ids here too. Even with a million aggregates `int(sha1(','.join(a.keys())))` is fairly fast.\r\n\r\nI think it is cleaner this way, and if we find that users like to make many huge aggregates, we can rethink that decision."", 'comment_created': datetime.datetime(2020, 8, 29, 16, 24, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479666707, 'comment_body': 'Only testing one of these would be fine.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 36, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479666770, 'comment_body': 'Only testing one or two of these would be fine. We should also test that the default aggregate store handles getitem and contains correctly as well.', 'comment_created': datetime.datetime(2020, 8, 29, 16, 37, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479673883, 'comment_body': ""I believe we should be extra sure, there may be a case when we only have a single job in the project and two operations which groups them in groups of 2, groups of 3. Then we won't be differentiating between them. This is completely theoretical and I'll do as you suggest\r\n"", 'comment_created': datetime.datetime(2020, 8, 29, 17, 55, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479680377, 'comment_body': ""As per discussion in slack, we're now only going to compare `_AggregatesStore` object by `aggregator` attributes."", 'comment_created': datetime.datetime(2020, 8, 29, 19, 10, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479681769, 'comment_body': 'We can just set this in the `groupsof` classmethod without needing to set an attribute to the function.', 'comment_created': datetime.datetime(2020, 8, 29, 19, 25, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479682853, 'comment_body': ""I'm not sure if I follow this. The `groupsof` method returns an instance of `aggregator`.\r\nBut since we're going to introduce the tag attribute, hence I think I'll simplify this logic.\r\n\r\nEdit: I got confused and now I understand what you mean."", 'comment_created': datetime.datetime(2020, 8, 29, 19, 38, 3, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479685750, 'comment_body': '```suggestion\r\n        # check the equality based on tags provided by an user or us in a classmethod\r\n```', 'comment_created': datetime.datetime(2020, 8, 29, 20, 12, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685857, 'comment_body': 'What I meant was that we can create the object and if it is the default aggregation, change the `_is_aggregate` flag after instantiation.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 13, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685882, 'comment_body': 'Also I think `groupsof{num}` is sufficient.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 13, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479685894, 'comment_body': 'just `groupby{key}-{default}` is fine.', 'comment_created': datetime.datetime(2020, 8, 29, 20, 14, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479687378, 'comment_body': ""I pushed a code, please have a look. I hope that's what you meant."", 'comment_created': datetime.datetime(2020, 8, 29, 20, 30, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479694058, 'comment_body': 'Why do we have both of these? One should suffice.', 'comment_created': datetime.datetime(2020, 8, 29, 21, 59, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 479735059, 'comment_body': ""I'm not pretty sure about this.\r\nWhat if `_aggregator` attributes are equal but the `_select` attributes are not and vice versa.\r\nI think we need both of them compared."", 'comment_created': datetime.datetime(2020, 8, 30, 7, 40, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479785142, 'comment_body': '```suggestion\r\n        A callable that performs aggregation of jobs. It takes in a list of\r\n        jobs and can return or yield subsets of jobs as an iterable. The\r\n        default behavior is creating a single aggregate of all jobs.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 47, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785223, 'comment_body': '```suggestion\r\n        Condition for filtering individual jobs. This is passed as the\r\n        callable argument to `filter`. The default behavior is no\r\n        filtering.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 47, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785385, 'comment_body': '```suggestion\r\n        elif (\r\n             self._sort_by != other._sort_by or\r\n             self._reverse_order != other._reverse_order or\r\n             self._tag != other._tag\r\n        ):\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 49, 50, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785420, 'comment_body': '```suggestion\r\n        elif (\r\n             self._select == other._select and\r\n             self._aggregator_function == other._aggregator_function\r\n        ):\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 50, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479785686, 'comment_body': ""This whole function seems rather convoluted. Is it all just for optimization (checking cheaper conditions first)? How big a difference is there between the last `elif` clause (which checks identity of `select` and `aggregator_function`) and the comparison of the `__co_code`? Is it really worth doing both? I'm not sure this level of complexity is warranted, but I don't know what the benchmarks look like."", 'comment_created': datetime.datetime(2020, 8, 30, 15, 52, 35, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786151, 'comment_body': ""I would move some of this information to the docstring. If it's meant to be a user-facing feature for the purpose of distinguishing aggregators, the user needs this information so they can decide what to provide as a tag."", 'comment_created': datetime.datetime(2020, 8, 30, 15, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786270, 'comment_body': '```suggestion\r\n        If the number of jobs present in the project is not divisible by the number\r\n        provided by the user, the last aggregate will be smaller and contain all\r\n        remaining jobs.\r\n        For instance, if 10 jobs are present in a project and they are aggregated in\r\n        groups of 3, then the generated aggregates will have lengths 3, 3, 3, and 1.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 58, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479786292, 'comment_body': '```suggestion\r\n        The code block below provides an example on how jobs can be aggregated in\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 15, 59, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788500, 'comment_body': ""This solution is pretty hacky... it's abusing the fact that you can store multiple references to the same iterator and then iterate over each reference in sequence to produce chunks of the original. It certainly works, though, and maybe it is the most efficient way to do this without making copies. I assume you found this recipe somewhere, could you add a link to document that, and maybe a comment here as well describing how it works?"", 'comment_created': datetime.datetime(2020, 8, 30, 16, 21, 21, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788586, 'comment_body': '```suggestion\r\n        The below code block provides an example of how to aggregate jobs having a\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 22, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479788957, 'comment_body': '```suggestion\r\n            The method by which jobs are grouped. It may be a state point\r\n            or a sequence of state points to group by specific state point\r\n            keys. It may also be an arbitrary callable of :class:`signac.Job`\r\n            when greater flexibility is needed.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 26, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479789585, 'comment_body': ""I think the intention here was to use `md5` everywhere rather than use `sha1` everywhere. We use `md5` for the `id` of jobs, so let's be consistent here. Additionally, `md5` is a faster hash function and it generates shorter hashes, which is good for keeping the directory names shorter for jobs and the strings shorter for aggregate stores. In general we're not concerned with the security implications; if that changes we'll need to change hashes everywhere in signac anyway (and we'd need to use something more secure than sha1)."", 'comment_created': datetime.datetime(2020, 8, 30, 16, 32, 51, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479789621, 'comment_body': 'See comment on import: use md5 instead of sha1.', 'comment_created': datetime.datetime(2020, 8, 30, 16, 33, 9, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479790118, 'comment_body': '```suggestion\r\n        """"""Create the actual collections of jobs to be sent to aggregate operations.\r\n        \r\n        The :class:`aggregate` class is just a decorator that provides a signal for\r\n        operation functions that should be treated as aggregate operations and\r\n        information on how to perform the aggregation. This function generates\r\n        the classes that actually hold sequences of jobs to which aggregate\r\n        operations will be applied.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 38, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479790137, 'comment_body': '```suggestion\r\n    a :class:`aggregator`.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 16, 38, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791193, 'comment_body': ""Should this error be about a job or an aggregate? This is a forward-looking question about how the aggregate's contains method will actually be invoked, @b-butler in future work making use of this class which error would be more appropriate? It seems like we'd want the error to state something about aggregates, but since this class will become the default mode for all aggregation maybe that's not the case since this error could get thrown for operations that act on individual jobs."", 'comment_created': datetime.datetime(2020, 8, 30, 16, 47, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791509, 'comment_body': 'Since this pattern of string[->sequence of strings]->blob->hash is very common, can you define a simple internal function `_hash` that we can call everywhere? That will ensure consistency in our hashing and simplify any future changes (for instance, to which hash function we call).', 'comment_created': datetime.datetime(2020, 8, 30, 16, 51, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479791700, 'comment_body': '```suggestion\r\n            even = (i % 2) == 0\r\n```\r\n\r\nRelying on operator precedence when using anything other than pure arithmetic operators always makes me uneasy.', 'comment_created': datetime.datetime(2020, 8, 30, 16, 53, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479795163, 'comment_body': ""This was originally implemented by @csadorf in #52 and that had a link from where it was copied.\r\nI'll add the link into this PR and also mention #52 "", 'comment_created': datetime.datetime(2020, 8, 30, 17, 29, 33, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479797989, 'comment_body': ""That is true.\r\nIn #335 I have added support for these classes and I believe that it should be about an aggregate because everything will become an aggregate internally.\r\nI'm curious to know what @b-butler thinks about this"", 'comment_created': datetime.datetime(2020, 8, 30, 17, 57, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479799143, 'comment_body': ""A user could do something like this\r\n```\r\n@aggregator.groupsof(2)\r\n@FlowProject.operation\r\ndef op_1(*jobs):\r\n    pass\r\n\r\n@aggregator.groupsof(2)\r\n@FlowProject.operation\r\ndef op_2(*jobs):\r\n    pass\r\n```\r\nWe won't be able to differentiate between these two if we don't use `__code__.co_code` along with `tag` attribute"", 'comment_created': datetime.datetime(2020, 8, 30, 18, 8, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479812095, 'comment_body': ""Putting #52 doesn't help very much, it requires somebody to know that it refers to a pull request (and in the event that we ever switched off of Github we could lose PRs entirely). I would include the link and mention the `grouper` recipe (that's the function at that link that implements this technique)."", 'comment_created': datetime.datetime(2020, 8, 30, 20, 27, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813348, 'comment_body': ""I can't seem to access the original thread of discussion here, so I'll just make a new comment. The point that I was trying to make about this function (the whole `__eq__` method) being complicated was not about why we need the `tag`. I get that the tag might be necessary to distinguish between two. I was asking whether this `elif` clause is worth having at all. The remainder of this method basically tries to compare either the `co_code` or the hash of the `select`s and `aggregator_function`s to determine their equality, and either of those will be basically the same speed as the equality check in this `elif` (the `co_code` is just cached in the object on creation AFAIK). So I don't see any reason not to change this `elif` to an `else` clause, remove the equality checks that are currently here, and move the code with `self_select`, `other_select`, etc into this `else` clause."", 'comment_created': datetime.datetime(2020, 8, 30, 20, 41, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813430, 'comment_body': 'Have these tests been written?', 'comment_created': datetime.datetime(2020, 8, 30, 20, 42, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479813520, 'comment_body': 'Now that the information is in the docstring, you can remove this comment entirely.', 'comment_created': datetime.datetime(2020, 8, 30, 20, 43, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479814256, 'comment_body': ""Does setting tags affect correctness, or is it just a performance optimization? Now I'm actually a little confused what the goal of the tags are. Are there cases where a user would have to provide tags, otherwise we might think that two aggregates are equivalent and therefore reuse the same set of job aggregates for them even though they should actually be using different ones? That seems _highly_ problematic to me. If the worst case scenario is just that we regenerate too many aggregates, then providing tags as a way for users to speed that up is fine, but we should never be in a situation where we silently use the wrong aggregates.\r\n\r\nIt should be possible to avoid any false positives with equality, it's just not possible to avoid getting false negatives (which is where the optimization comes in). Can you give an example where the current test fails to distinguish functions without the use of tags? Does that issue get fixed if you also check `co_consts` in addition to `co_code`?"", 'comment_created': datetime.datetime(2020, 8, 30, 20, 51, 6, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479817454, 'comment_body': ""@vyasr, @b-butler asked me to check this first in order to reduce the complexity.\r\nFor example, if we're able to compare the `aggregator_function` and `select` directly then there's no need to compare the binary code. But if we fail, then we end up comparing the binary code."", 'comment_created': datetime.datetime(2020, 8, 30, 21, 25, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479817652, 'comment_body': '@vyasr yes, I have written the tests.\r\nYou can have a look at them (They are the last 4 tests of this class)', 'comment_created': datetime.datetime(2020, 8, 30, 21, 28, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 479821374, 'comment_body': ""I understand, but I'm saying that I don't expect this to lead to any real performance improvement. In practice I expect users to use the provided `groupsof` and `groupby` options the vast majority of the time, and those will never pass this check because those decorators create new internal functions each time they are called. When users do bother to create custom aggregation functions, I expect them to use lambdas or something most of the time, in which case again this equality check will fail. While checking the type and then checking the sort/reverse/tag are probably useful, this branch adds complexity without any evidence that it will improve performance. That is the hallmark of premature optimization, so I'm recommending not doing this unless we see that the `__eq__` method is actually a performance bottleneck that could benefit from this extra check."", 'comment_created': datetime.datetime(2020, 8, 30, 22, 2, 38, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480117103, 'comment_body': ""I understand what you say.\r\n@b-butler It'd be really helpful to know your views on this. If you agree, then I'll go ahead and remove the block."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 7, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480117864, 'comment_body': 'I did not try `co_consts`. I will try to make that work and let you know', 'comment_created': datetime.datetime(2020, 8, 31, 13, 8, 34, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480138481, 'comment_body': ""Well first, can you give an example where the tag is _necessary_, i.e. we would think two aggregators are identical when they really aren't? I have no idea if `co_consts` would fix the problem because I don't know what it is, I just suggested that because there is more information available than `co_code` if that is insufficient to distinguish.\r\n\r\nFor a feature like this we _cannot_ rely on the user to provide tags to prevent incorrectly identifying two distinct aggregates as the same. If we really can't distinguish them for some reason, I think we would have to eat the performance cost and just copy all aggregates and not reuse any of them. Optimizations cannot result in incorrect behavior, and we can't push that responsibility onto the user."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 41, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480144754, 'comment_body': ""When we use `co_code`, we are not able to differentiate between `groupsof(2)` and `groupsof(3)`.\r\nI believe this is because the function doesn't itself store any information about the number provided.\r\nIt just references to the value stored for num.\r\nThis is where `tag` comes handy. `co_consts` will not work here because it will just provide the constants declared in the function (which we don't do).\r\n```\r\na = 1\r\ndef x():\r\n    c = a\r\n    return c\r\n```\r\nThe output of `x.__code__.co_consts` would be (None,).\r\nThis is, kind of, the similar problem we're facing currently."", 'comment_created': datetime.datetime(2020, 8, 31, 13, 51, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 480165179, 'comment_body': ""Yes that's what I would expect. In this particular case you can get around the problem by instead looking at `x.__closure__`. However, I'm not sure if this would work in *all* cases. I think if you traversed all members of `x.__code__` and `x.__closure__` and checked them each for equality with the same members of another function you could guarantee that you don't get false positive, but I'm not 100% sure about that. For this particular use case, I think guaranteeing 0 false positives is far more important than preventing false negatives; the latter is just a performance hit, whereas the former leads to incorrect behavior. Reiterating what I said in my previous comment, it's much better to store some extra aggregates than to use the wrong aggregates for operations.\r\n\r\n@b-butler what are your thoughts here?"", 'comment_created': datetime.datetime(2020, 8, 31, 14, 23, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480208372, 'comment_body': 'I agree with @vyasr here generally, hence the comment I made before.', 'comment_created': datetime.datetime(2020, 8, 31, 15, 30, 42, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 480210882, 'comment_body': ""I was not aware of `__closure__`, but that would likely be sufficient then. I don't care about false negatives, but yes we need to be sure of no false positives. We should also be fairly sure that `groupsof` and `groupby` are not giving false negatives."", 'comment_created': datetime.datetime(2020, 8, 31, 15, 34, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 481554288, 'comment_body': 'I also prefer fully qualified names (`import itertools` and `itertools.groupby`) to avoid confusion about the similarly-named aggregate functions.', 'comment_created': datetime.datetime(2020, 9, 2, 2, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}]","[{'commit_sha': '3af7e0e7454f1a4a4d46faf5f62a7bfb6b131414', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '48e503c2eb7b3adb988756868da4833fe9013128', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd5b19bd07c901cf4d25fcaf6f9efa777462d4659', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a7712f6d50731e9bd185571cefca3e122b09080e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3d4c6af2113ab1e8a84f465b4a8499f3fbb7b3bc', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8017bc31f131cae5b16a64b896d6fe88ce3c76ac', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a8a9df2e5a42eba61db2fecd14facb3790822b4', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '749c3b2a770740487946b4f81d54dd3f17f1fd99', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63e3c0720240b9687a6d53cd1398fa51181607a6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd8dab6f27c2fc650e7164c7427b0982a9d4ad19b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e74e03d68ea347917ebf49939782c85cc4c350c0', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '014e1f42f1305363049e424d39e6e8b9b63e7860', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '908d92092bbca3f1b3b4b7e96c06a9befebd01ec', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2bb9f4519afad64cb65b881b161a8ed55f507405', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf54e1723d541ea02913e903f5274d064a77ec40', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dfdaff832461783e58120b48111745a4a38d12b2', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5426b9516e6f58e175a82acc6c72a66cf479794f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9e3d4e038952a4e794b9ca3244e8048d9c9f1242', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f5db9b8b8eff07801185ab96b26e09c31eca3c81', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f2edcfdf46985bc43ce66dff52f2d161eee5b121', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ed0ae4c7e57ca55e290a66b484d2b0c4ed785768', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a578a495969c99e1c58777ebb36a5e3548020a41', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
402756945,Add a class for Directives,"<!-- Provide a general summary of your changes in the Title above -->
By - @b-butler 

Adds two classes `Directives` and `DirectivesItem` that serve as a smart mapping for the environment and user-specified directives and a specification for environmental directives respectively. `FlowProject` and `FlowGroup` have been changed accordingly.
## Description
<!-- Describe your changes in detail -->

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
This resolves #265 and helps to centralize logic for directives.
This pull request is a necessary follow-up for #282.
Also resolves #240.

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Tasks to accomplish:
- [x] Test the individual DirectivesItems.
- [x] Test the Directives class.
- [x] Determine and add environment specific DirectivesItem and correct their get_default_directives function (this at least at the decision level will likely involve a discussion between multiple people).
- [x] Some probably large degree of code refactoring (I was just initially trying to get the outline working and there).
- [ ] Opening a PR in signac-docs to update documentation.
- [x] Going through docstrings and ensuring they are complete, grammatically correct, and helpful. Multiple methods will need these as well.
- [x] Add tracking of user specified directives. Previously TrackGetItemDict found in flow/util/misc.py was used. We can use this internally or create our own fix.
- [x] Fix code so tests pass

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [ ] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [x] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,283,https://api.github.com/repos/glotzerlab/signac-flow/pulls/283,https://github.com/glotzerlab/signac-flow/pull/283,closed,669,64,8,76,17,273,3,2,"[{'name': 'enhancement'}, {'name': 'GSoC'}, {'name': 'directives'}]",2020-04-13 17:46:05+00:00,2020-09-29 21:01:07+00:00,14613302.0,"169 days, 3:15:02","[{'comment_id': 408212029, 'comment_body': 'I believe you asked @bdice a question regarding this, but why are `raise_if_too_small`, `_evaluate`,  `finalize_np`,  `is_fraction`, and `no_aggregation` copied ?', 'comment_created': datetime.datetime(2020, 4, 14, 15, 7, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408213474, 'comment_body': 'There must have been a miscommunication. There is no need to have a `mock_project` for these tests. The name is confusing since what we are dealing with here is a `_DirectivesItem` not a `FlowProject`.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 8, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408216066, 'comment_body': ""No need for parenthesis in Python conditionals. Also, a space between the if and condition is expected style wise, i.e.\r\n````python\r\nif project_class == _DirectivesItem:\r\n````\r\nBut don't use that, since we don't need the `mock_project` function."", 'comment_created': datetime.datetime(2020, 4, 14, 15, 12, 9, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408216375, 'comment_body': 'What is this testing?', 'comment_created': datetime.datetime(2020, 4, 14, 15, 12, 32, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408216611, 'comment_body': 'What is this testing?', 'comment_created': datetime.datetime(2020, 4, 14, 15, 12, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408218416, 'comment_body': 'The default validation is the `identity` function. No need to create the function externally. What we do need to test is custom validation functions, and that the default validation function just returns the given value.\r\n\r\nAlso, the identity function here modifies integer values which is a bit strange. This does test that the validation is working, but I would want a less confusing name for the function like `square_ints`. Also, we should test error raising with the validation too, just to make sure we raise errors correctly although that could be a different test.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 15, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408222815, 'comment_body': 'Okay then I will create instances directly without a `mock_project`.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 20, 52, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408224952, 'comment_body': 'It is more Pythonic to use `if isinstance(v, int):` or if you just want all numbers,\r\n````python\r\nfrom numbers import Number\r\nif isinstance(v, Number):\r\n````\r\nor even just integers\r\n````python\r\nfrom numbers import Integral\r\nif isinstance(v, Integral):\r\n````', 'comment_created': datetime.datetime(2020, 4, 14, 15, 23, 43, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408225252, 'comment_body': 'Why are these copied?', 'comment_created': datetime.datetime(2020, 4, 14, 15, 24, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408226065, 'comment_body': 'No need for `mock_project`. You could define a fixture that creates a basic `Directives` object if you like.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 25, 7, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408226416, 'comment_body': 'No need for validation here. We just want to check that all directives have been set to their default values.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 25, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408226629, 'comment_body': 'name `project` is confusing.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 25, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408227866, 'comment_body': 'This is just checking that the name is used for the dictionary key. While that is useful, we need more tests for the functioning of the class.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 27, 23, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408232165, 'comment_body': 'These do not need to be in `__all__`.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 33, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408232976, 'comment_body': 'This was done in order to prevent a lot of importing in `flow/__init__.py`. This was a temporary solution as `from . import directives as directives_module` was referring to the `directives` class in `operations.py` module', 'comment_created': datetime.datetime(2020, 4, 14, 15, 34, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408237220, 'comment_body': 'Oops. Sorry about that. ', 'comment_created': datetime.datetime(2020, 4, 14, 15, 39, 57, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408238717, 'comment_body': 'I thought testing the calling nature of the class should also be tested. That if we call the instance directly and the parameters are callable then it should return the callable itself\r\n', 'comment_created': datetime.datetime(2020, 4, 14, 15, 42, 4, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408238972, 'comment_body': 'Answered [here](https://github.com/glotzerlab/signac-flow/pull/283#discussion_r408238717)', 'comment_created': datetime.datetime(2020, 4, 14, 15, 42, 25, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408249197, 'comment_body': 'Yes, I get your point. I will change the name and test error.', 'comment_created': datetime.datetime(2020, 4, 14, 15, 55, 59, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408253894, 'comment_body': 'Okay, that seems a good way!', 'comment_created': datetime.datetime(2020, 4, 14, 16, 2, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408256902, 'comment_body': 'I should probably name it as `test_instance`', 'comment_created': datetime.datetime(2020, 4, 14, 16, 6, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408257578, 'comment_body': ""I was unable to import the `directives` class and a lot of importing would have been there in `flow/__init__.py` so I chose to copy them. If you want I'll just import them."", 'comment_created': datetime.datetime(2020, 4, 14, 16, 7, 36, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408258198, 'comment_body': ""Seems fair, I'll make use of `pytest.fixture` annotation"", 'comment_created': datetime.datetime(2020, 4, 14, 16, 8, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408260047, 'comment_body': ""I just pushed the tests so that I can get a rough idea on what am supposed to do. Now that I have it, I'll proceed with my work."", 'comment_created': datetime.datetime(2020, 4, 14, 16, 11, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408261061, 'comment_body': 'I will remove them.', 'comment_created': datetime.datetime(2020, 4, 14, 16, 12, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 408289077, 'comment_body': 'Or just `directives` would be fine and clear.', 'comment_created': datetime.datetime(2020, 4, 14, 16, 54, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408290044, 'comment_body': ""We need to import them, otherwise we won't know if they get broken in the `flow/directives.py` file. I much prefer the `from module import name as new name` approach."", 'comment_created': datetime.datetime(2020, 4, 14, 16, 55, 25, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408292500, 'comment_body': ""What we want to test is more akin to if we call it with a value does it do what we expect. For instance, if we expect an integer do we raise an error on a string, and the like. Calling it with its own functions is not something that we or a user should do, so we don't need to test it.  For serial and parallel, I am more looking to see that if passed two values it computes the expected value (e.g. `NP.serial(4, 2) == 4`, `NP.parallel(4, 2) == 6`)."", 'comment_created': datetime.datetime(2020, 4, 14, 16, 59, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408292819, 'comment_body': 'It is fine. Nothing to be sorry about, just trying to improve the code.', 'comment_created': datetime.datetime(2020, 4, 14, 16, 59, 33, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 408293379, 'comment_body': ""We need to import them, otherwise we won't know if they get broken in the flow/directives.py file. I much prefer the from module import name as new name approach."", 'comment_created': datetime.datetime(2020, 4, 14, 17, 0, 19, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414161316, 'comment_body': 'I like this test. However, we need it for all all caps `_DirectiveItems`.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 18, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414161698, 'comment_body': 'No need for the strings here (for testing NP).', 'comment_created': datetime.datetime(2020, 4, 23, 22, 19, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414161893, 'comment_body': 'See above comment for `test_serial`.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 19, 38, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414163387, 'comment_body': 'This tests that the default is a valid value. This may not be the case (if the default is `None`).', 'comment_created': datetime.datetime(2020, 4, 23, 22, 23, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414163816, 'comment_body': 'Why do we need to set the default to 0 we can just directly test the validation.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 24, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414164786, 'comment_body': 'This likely will be subject to rounding error.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 26, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414167220, 'comment_body': ""To test this you need a `_DirectivesItem` and a dictionary like object. The idea of finalize is to allow the `_DirectivesItem` to be able to use the information of the dictionary to decide what value to return.\r\n\r\nImagine that you always earn 10 units a hour except if it is Tuesday. With finalize a function like,\r\n````python\r\ndef hourly_pay_finalize(normal_pay, mapping):\r\n    if mapping['day'] == 'Tuesday':\r\n        return 15\r\n    else:\r\n        return normal_pay\r\n````"", 'comment_created': datetime.datetime(2020, 4, 23, 22, 31, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414168909, 'comment_body': 'We need two kinds of testing: the functionality of all the pre-defined `_DirectivesItem` and testing of the functionality directly with a custom `_DirectivesItem` object (this will involve instantiating your own objects, testing default parameters, and the general object behavior).', 'comment_created': datetime.datetime(2020, 4, 23, 22, 35, 23, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414170272, 'comment_body': 'I am trying to understand the need for this instead of just `Directives(**kwargs)` or `Directives(available_directives_list)`.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 38, 32, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414172522, 'comment_body': ""This doesn't actually test the setting because the initial value is the default."", 'comment_created': datetime.datetime(2020, 4, 23, 22, 43, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414173903, 'comment_body': 'This would make a good fixture.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 47, 4, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414174083, 'comment_body': 'Why not just include the last value `OMP_NUM_THREADS`?', 'comment_created': datetime.datetime(2020, 4, 23, 22, 47, 35, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414175091, 'comment_body': ""This is on the right track, but I would rather not use a `_DirectivesItem` for the purposes of a user-directive. A simple name: value mapping is fine `['test'] = True` is fine."", 'comment_created': datetime.datetime(2020, 4, 23, 22, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414175899, 'comment_body': 'Why not include the last directive.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 51, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 414176172, 'comment_body': 'There are no tests for the update or aggregate method.', 'comment_created': datetime.datetime(2020, 4, 23, 22, 52, 32, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417204961, 'comment_body': ""I thought that we may also wanna add tests for manual `_DirectiveItem` and we'll need to pass different arguments."", 'comment_created': datetime.datetime(2020, 4, 29, 10, 9, 4, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417205158, 'comment_body': 'Noted', 'comment_created': datetime.datetime(2020, 4, 29, 10, 9, 25, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417205430, 'comment_body': 'Okay, noted.', 'comment_created': datetime.datetime(2020, 4, 29, 10, 9, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417206392, 'comment_body': 'Will update you by tomorrow on this.', 'comment_created': datetime.datetime(2020, 4, 29, 10, 11, 46, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417207702, 'comment_body': ""It may be accidentally done by me, I'll correct it."", 'comment_created': datetime.datetime(2020, 4, 29, 10, 14, 17, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417208409, 'comment_body': ""To check the setting behaviour. \r\n`directives[OMP_NUM_THREADS.name] = OMP_NUM_THREADS.default`\r\nThe above code checks whether we're able to add `OMP_NUM_THREADS` manually or not."", 'comment_created': datetime.datetime(2020, 4, 29, 10, 15, 44, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417209187, 'comment_body': ""But after seeing [this comment](https://github.com/glotzerlab/signac-flow/pull/283#discussion_r414172522), I'll edit the code"", 'comment_created': datetime.datetime(2020, 4, 29, 10, 17, 19, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417209243, 'comment_body': 'Noted', 'comment_created': datetime.datetime(2020, 4, 29, 10, 17, 27, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417209573, 'comment_body': 'I have done this locally, will push the changes and update you.', 'comment_created': datetime.datetime(2020, 4, 29, 10, 18, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417210365, 'comment_body': 'Checked for `None` type', 'comment_created': datetime.datetime(2020, 4, 29, 10, 19, 52, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417210738, 'comment_body': 'Inserted tests for every directive', 'comment_created': datetime.datetime(2020, 4, 29, 10, 20, 37, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417211260, 'comment_body': 'Resolved', 'comment_created': datetime.datetime(2020, 4, 29, 10, 21, 34, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417414226, 'comment_body': ""That's a great example. Now I can successfully test it."", 'comment_created': datetime.datetime(2020, 4, 29, 15, 39, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417442612, 'comment_body': 'This was sorted by changing the validation function.', 'comment_created': datetime.datetime(2020, 4, 29, 16, 19, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417495277, 'comment_body': ""If we do need to pass different arguments to `_DirectivesItem` can't we do that with `_DirectivesItem(**kwargs)` directly?"", 'comment_created': datetime.datetime(2020, 4, 29, 17, 41, 33, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417496076, 'comment_body': 'This is marked as resolve, but there is still no fixture.', 'comment_created': datetime.datetime(2020, 4, 29, 17, 42, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417496307, 'comment_body': 'I do not see any new tests here.', 'comment_created': datetime.datetime(2020, 4, 29, 17, 43, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417496480, 'comment_body': ""The code is still here, so I don't see how this is resolved?"", 'comment_created': datetime.datetime(2020, 4, 29, 17, 43, 33, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417496942, 'comment_body': 'I do not see the change. Did you forget to push your changes?', 'comment_created': datetime.datetime(2020, 4, 29, 17, 44, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417497440, 'comment_body': 'Anyways for this test, I would prefer to see not that the default works, but that the validation functions work (i.e. that given appropriate values they set and given inappropriate values they error).', 'comment_created': datetime.datetime(2020, 4, 29, 17, 45, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417497744, 'comment_body': 'Code has not change. Is not resolved.', 'comment_created': datetime.datetime(2020, 4, 29, 17, 45, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417502884, 'comment_body': 'About your latest comment, I think this should be addressed internally itself rather than manually. What I mean to say is, while setting a default value, we should check whether the validation returns a proper value or not.', 'comment_created': datetime.datetime(2020, 4, 29, 17, 53, 29, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417532558, 'comment_body': 'I am not sure as to why we should test that behavior though? If you are wanting to test that the defaults are valid to set to the directive, then we should name this `test_defaults_are_valid` or something similar.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 43, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417532986, 'comment_body': 'Why is this commented function here.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 44, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417533413, 'comment_body': 'technically this is mod not divide. If you mean divisible then use that instead of `div`.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 45, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417534208, 'comment_body': 'It is more clear to future developers if we don\'t just `deepcopy` an existing `_DirectivesItem` but create our own ""dummy"" `_DirectivesItem`.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 46, 20, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417536301, 'comment_body': 'Also, this does test the functionality; however, the conversion from a number to whether it is divisible by ten may be confusing since the purpose is to return a validated value or raise an error.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 49, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417536705, 'comment_body': 'Values here should be between 0 and 1.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 50, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417536875, 'comment_body': 'Values should be between 0 and 1.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 50, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417537914, 'comment_body': 'I would prefer to see a custom created `_DirectivesItem` here.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 52, 30, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417538334, 'comment_body': '```suggestion\r\n        assert directive_copy.parallel(3, 2) == 6\r\n```', 'comment_created': datetime.datetime(2020, 4, 29, 18, 53, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417538662, 'comment_body': 'This line is unnecessary\r\n```suggestion\r\n```', 'comment_created': datetime.datetime(2020, 4, 29, 18, 53, 41, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417539140, 'comment_body': ""This isn't really testing the functionality of `parallel`. This error is raised by the lambda function.\r\n```suggestion\r\n```"", 'comment_created': datetime.datetime(2020, 4, 29, 18, 54, 32, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417540742, 'comment_body': 'We should not set to a `_DirectivesItem`. ', 'comment_created': datetime.datetime(2020, 4, 29, 18, 57, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417541184, 'comment_body': 'This tests `np_finalize` well, but I would like to see an example with a ""dummy"" `_DirectivesItem` as well.', 'comment_created': datetime.datetime(2020, 4, 29, 18, 57, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417541490, 'comment_body': 'Do we need to rewrite this function instead of using this existing function?', 'comment_created': datetime.datetime(2020, 4, 29, 18, 58, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417541989, 'comment_body': ""We don't need the `setUp` here. It doesn't gain us anything."", 'comment_created': datetime.datetime(2020, 4, 29, 18, 59, 9, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417542209, 'comment_body': 'Not really necessary.\r\n```suggestion\r\n```', 'comment_created': datetime.datetime(2020, 4, 29, 18, 59, 34, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417543348, 'comment_body': 'This should not be the case right. `PRODUCT.default` should be 10 right?', 'comment_created': datetime.datetime(2020, 4, 29, 19, 1, 46, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417544579, 'comment_body': 'This test a bunch of the functionality I wanted; however, it test them in one test. It would be nicer to have individual tests for the individual functionality. Also, `PRODUCT` does not need to be capitalized.', 'comment_created': datetime.datetime(2020, 4, 29, 19, 3, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417546421, 'comment_body': ""```suggestion\r\n        directives['test_directive'] = 'test'\r\n        assert directives['test_directive'] == 'test'\r\n\r\n```"", 'comment_created': datetime.datetime(2020, 4, 29, 19, 7, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417548823, 'comment_body': 'No reason not to include the last directive in the list since `PROCESS_FRACTION` is the last in the list.', 'comment_created': datetime.datetime(2020, 4, 29, 19, 11, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417549866, 'comment_body': ""This shouldn't work any more since `PROCESS_FRACTION` is last in the list. This should be tested using a random key not a `_DirectivesItem` used as a user directive."", 'comment_created': datetime.datetime(2020, 4, 29, 19, 13, 18, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 417972029, 'comment_body': 'Will import the existing function', 'comment_created': datetime.datetime(2020, 4, 30, 12, 27, 57, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417972432, 'comment_body': ""Included in `test_manual_item` method, however, I'll split the manual tests as you suggested."", 'comment_created': datetime.datetime(2020, 4, 30, 12, 28, 42, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417974798, 'comment_body': ""This means we need to test the error only when we're raising an error manually. Right?"", 'comment_created': datetime.datetime(2020, 4, 30, 12, 33, 9, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417974883, 'comment_body': 'Removed', 'comment_created': datetime.datetime(2020, 4, 30, 12, 33, 20, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417975354, 'comment_body': ""This was done in order to validate parallel. As suggested by you that it's not necessary then I'll remove it."", 'comment_created': datetime.datetime(2020, 4, 30, 12, 34, 10, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417975482, 'comment_body': 'Noted', 'comment_created': datetime.datetime(2020, 4, 30, 12, 34, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417975551, 'comment_body': 'Noted', 'comment_created': datetime.datetime(2020, 4, 30, 12, 34, 30, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417975792, 'comment_body': ""Yes, that's a valid point. I'll make the changes."", 'comment_created': datetime.datetime(2020, 4, 30, 12, 34, 55, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417976080, 'comment_body': 'Resolved it locally, by returning `v` itself if we is divisible by 10 else we raise an error.', 'comment_created': datetime.datetime(2020, 4, 30, 12, 35, 32, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417976743, 'comment_body': 'I will test the validation when the value is set to `None`.', 'comment_created': datetime.datetime(2020, 4, 30, 12, 36, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417980064, 'comment_body': ""I did it in order to maintain consistency, I'll use the class directly if you want."", 'comment_created': datetime.datetime(2020, 4, 30, 12, 42, 26, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417981114, 'comment_body': 'Currently, there is no way to check whether the default value is valid or not. I think this functionality will be tested best by using try and except.', 'comment_created': datetime.datetime(2020, 4, 30, 12, 44, 16, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417981717, 'comment_body': ""Yes, this was a typographical error. I'll correct this."", 'comment_created': datetime.datetime(2020, 4, 30, 12, 45, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417981859, 'comment_body': 'Noted', 'comment_created': datetime.datetime(2020, 4, 30, 12, 45, 39, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 417988125, 'comment_body': 'In the method `finalize_np` there is a conditional statement that whether `nranks` or `omp_num_threads` are callable or not. This confused me and hence I set the value to a `_DirectivesItem`. Can you please help me understand this with a use case?', 'comment_created': datetime.datetime(2020, 4, 30, 12, 56, 13, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 418004224, 'comment_body': 'Also, I think this is valid in this case. This will raise an error if default value is not valid.', 'comment_created': datetime.datetime(2020, 4, 30, 13, 21, 31, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 418042072, 'comment_body': ""I figured out that we need to initialize with `_DirectivesItem` only one time. So I've made the changes accordingly"", 'comment_created': datetime.datetime(2020, 4, 30, 14, 14, 10, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 418044022, 'comment_body': ""Here I've now used the `product_directive` which I made manually, and I don't think this will matter as the `Directives` class doesn't know that the `product_directive` exist."", 'comment_created': datetime.datetime(2020, 4, 30, 14, 16, 52, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 418081939, 'comment_body': ""I am not sure if my point is getting across adequately. I don't believe there to be a reduction in complexity between `setup(_DirectivesItems, parallel=foo, serial=bar, name='example', ...)` and `_DirectivesItems(parallel=foo, serial=bar, name='example', ...)`, the second is shorter and more explicit. This is true for any class you would pass it.\r\n\r\nAbstractions should only be employed when they reduce complexity (or code duplication) when used. Given that every abstraction has its own intrinsic complexity that means abstractions can be more complicated to use than the plain solution."", 'comment_created': datetime.datetime(2020, 4, 30, 15, 8, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 418083951, 'comment_body': ""Historically, flow allows all directives to be a callable with one positional parameter (a job). This means we have to support that use case. To do that we need to allow the setting of any directive with a callable and currently trust that it will return to us a valid value when called with a specific job (we don't check this in the current code). "", 'comment_created': datetime.datetime(2020, 4, 30, 15, 10, 45, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 418101762, 'comment_body': ""Ohh okay, that's true. Then I don't think we should use the `setUp` fixture anywhere. Right?"", 'comment_created': datetime.datetime(2020, 4, 30, 15, 36, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 418104535, 'comment_body': ""Okay. Then how am I supposed to check the callable behaviour? Passing some function won't be logical here (I guess)."", 'comment_created': datetime.datetime(2020, 4, 30, 15, 40, 8, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 418156391, 'comment_body': 'Actually that is the exact expected behavior (passing in a function), and yes we should test that using functions as values works.', 'comment_created': datetime.datetime(2020, 4, 30, 17, 1, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 418673175, 'comment_body': 'I believe this should raise an error.', 'comment_created': datetime.datetime(2020, 5, 1, 18, 27, 5, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 418674205, 'comment_body': ""```suggestion\r\n        directives['test'] = True\r\n        assert directives['test']\r\n```\r\n\r\nWhat we are testing here has nothing to do with `_DirectivesItem`s."", 'comment_created': datetime.datetime(2020, 5, 1, 18, 29, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 418674611, 'comment_body': 'See changes suggested in `test_set_directives_item`.', 'comment_created': datetime.datetime(2020, 5, 1, 18, 30, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 418675429, 'comment_body': 'This is used multiple times, would make a good fixture.', 'comment_created': datetime.datetime(2020, 5, 1, 18, 31, 56, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 418676316, 'comment_body': ""You don't need another `Directives` class here. You could just use `directives1.update(valid_values)` and `assert directives1[key] == valid_values[key]`."", 'comment_created': datetime.datetime(2020, 5, 1, 18, 34, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419116791, 'comment_body': ""An unexpected error occurs here. \r\nWhile updating I set \r\n```\r\nvalid_values = {'np': 4, 'ngpu': 1, 'nranks': 0,\r\n                        'omp_num_threads': 10, 'executable': 'PathFinder',\r\n                        'walltime': 20., 'memory': 16, 'processor_fraction': 0.5}\r\n```\r\nThe `np` directive is updated to 4 while it updates every other directive properly. I checked that this functionality arrises due to the finalize attribute of `NP`. Am I correct? If yes then how did it work when I used another `Directives` class"", 'comment_created': datetime.datetime(2020, 5, 3, 15, 10, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 419117887, 'comment_body': ""Also after digging into the code, I realized that when we set any directive then it calls the directive. For instance, if we set the value for NP = 4, then it'll eventually result in this statement NP(4) which, after validation, returns some value and that value is set to that particular directive in the `Directives` class. I check the validation function of NP, the post-process here is the `raise_if_too_small` method. \r\n\r\nI am not able to see any involvement of the finalize attribute here. Can you please help me?"", 'comment_created': datetime.datetime(2020, 5, 3, 15, 18, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 419492314, 'comment_body': 'Still no need for this code.', 'comment_created': datetime.datetime(2020, 5, 4, 14, 46, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419493101, 'comment_body': 'Either some developer documentation as to the purpose of this fixture, or a more descriptive name or both would be helpful.', 'comment_created': datetime.datetime(2020, 5, 4, 14, 47, 53, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419494400, 'comment_body': 'I get that it is mostly miscommunication from me that you wrote this test, but instead of just testing None, testing a larger swath of invalid values should be done.', 'comment_created': datetime.datetime(2020, 5, 4, 14, 49, 38, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419495123, 'comment_body': 'This tests one case, see comment above on `test_none_default_value`. A test that looks to see if many different invalid values raise Errors would be good.', 'comment_created': datetime.datetime(2020, 5, 4, 14, 50, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419495679, 'comment_body': '```suggestion\r\n    def test_del_directive(self, setUp, available_directives_list):\r\n```\r\n\r\nNo need for that fixture now.', 'comment_created': datetime.datetime(2020, 5, 4, 14, 51, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419497370, 'comment_body': '```suggestion\r\n        directives1.update(valid_values_0)\r\n```\r\nThat functionality is already tested so you can just use it here.', 'comment_created': datetime.datetime(2020, 5, 4, 14, 53, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419497559, 'comment_body': 'Can use update here too.', 'comment_created': datetime.datetime(2020, 5, 4, 14, 54, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419499105, 'comment_body': '```suggestion\r\n            directives1 = Directives(available_directives_list)\r\n```', 'comment_created': datetime.datetime(2020, 5, 4, 14, 56, 6, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 419505530, 'comment_body': 'Would `non_default_directive_values` be good?', 'comment_created': datetime.datetime(2020, 5, 4, 15, 4, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 419573703, 'comment_body': 'I have tested this is the `TestItems` class. If you want, I can write here too.', 'comment_created': datetime.datetime(2020, 5, 4, 16, 43, 11, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 425937982, 'comment_body': ""This is a good test, I would potentially add more invalid_values (e.g. `'np': [0, -1, 'foo', {}]`). To make it easier for you in this case, I would just test that the invalid values raise and not worry about the exception type."", 'comment_created': datetime.datetime(2020, 5, 15, 17, 12, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 425939422, 'comment_body': ""No need for the try and except blocks here. We are raising regardless. pytest's will show us the line which the exception is raised.\r\n```suggestion\r\n        val = product_directive.validation(product_directive.default)\r\n        assert product_directive.default == val\r\n```"", 'comment_created': datetime.datetime(2020, 5, 15, 17, 15, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 425939801, 'comment_body': 'This tests the same thing as above.\r\n```suggestion\r\n```', 'comment_created': datetime.datetime(2020, 5, 15, 17, 15, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 425940267, 'comment_body': 'I would test these flipped as well (20, 10).', 'comment_created': datetime.datetime(2020, 5, 15, 17, 16, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 425941178, 'comment_body': ""You could make this directives object a fixture, if you want since it is used in multiple places. I don't feel strongly either way."", 'comment_created': datetime.datetime(2020, 5, 15, 17, 18, 33, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 425941794, 'comment_body': 'No need to invoke the `product_directive` here. Just testing against some random string is fine.', 'comment_created': datetime.datetime(2020, 5, 15, 17, 19, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 425943436, 'comment_body': ""I would use `directives1.update(valid_values_0)` here too, and just test the assert. Also with this update, you shouldn't have to created an `expected_values` `dict` right? The expected values are just the values in the `valid_values_{0,1}`."", 'comment_created': datetime.datetime(2020, 5, 15, 17, 23, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 425944614, 'comment_body': ""We don't need to test all directives here just `processor_fraction`."", 'comment_created': datetime.datetime(2020, 5, 15, 17, 25, 34, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 428749227, 'comment_body': 'I too don\'t feel strongly either way. I think declaring the class inside a method is a good option here because of the ""pass by reference"" nature of the classes in python.', 'comment_created': datetime.datetime(2020, 5, 21, 15, 57, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 428752678, 'comment_body': 'Noted.', 'comment_created': datetime.datetime(2020, 5, 21, 16, 2, 52, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 428752918, 'comment_body': 'Okay, will update', 'comment_created': datetime.datetime(2020, 5, 21, 16, 3, 17, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 428753105, 'comment_body': ""That'd be great, I'll do it."", 'comment_created': datetime.datetime(2020, 5, 21, 16, 3, 35, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 428753178, 'comment_body': 'Noted', 'comment_created': datetime.datetime(2020, 5, 21, 16, 3, 43, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 428753354, 'comment_body': 'Noted.', 'comment_created': datetime.datetime(2020, 5, 21, 16, 4, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 428847438, 'comment_body': ""Actually the `__getitem__` function will use the environment directives' `finalize` methods, so the returned values will not be identical. However, the is no real reason to set `directives1` to the values in `non_default_directives_values[0]` and then update it to one."", 'comment_created': datetime.datetime(2020, 5, 21, 18, 52, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 428867379, 'comment_body': 'Oh okay, now I get your point', 'comment_created': datetime.datetime(2020, 5, 21, 19, 31, 42, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 447131044, 'comment_body': 'Is there a benefit to doing this rather than having a list of two dictionaries?', 'comment_created': datetime.datetime(2020, 6, 29, 17, 21, 26, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447132094, 'comment_body': ""Can we be more specific on the type of exception? If we can't that is okay, but if we can that would be helpful. It may be worth ensuring we raise a `ValueError` for these."", 'comment_created': datetime.datetime(2020, 6, 29, 17, 23, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447133833, 'comment_body': 'Can we be more specific on the type of exception?', 'comment_created': datetime.datetime(2020, 6, 29, 17, 26, 17, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447134966, 'comment_body': ""We are only testing `processor_fraction` we don't need the other non-default values."", 'comment_created': datetime.datetime(2020, 6, 29, 17, 28, 21, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447137297, 'comment_body': 'Why is this here if we update with `valid_values_1`?', 'comment_created': datetime.datetime(2020, 6, 29, 17, 32, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447137862, 'comment_body': ""Having seen how often this pattern arises, I have changed my mind. I like the idea of a `directives` fixture so we don't have to pass `available_directives_list` everywhere."", 'comment_created': datetime.datetime(2020, 6, 29, 17, 33, 12, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447189527, 'comment_body': 'Not really.\r\nMaking a list will be more logical, I guess', 'comment_created': datetime.datetime(2020, 6, 29, 19, 4, 34, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 447224976, 'comment_body': 'We can but since `ValueError` is not the only error which will get thrown. Hence I would have to define all the errors manually.', 'comment_created': datetime.datetime(2020, 6, 29, 20, 11, 27, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 447229182, 'comment_body': 'In Python except blocks allow for you to pass a tuple like `except (ValueError, TypeError)`. `pytest.raises` allows a similar API for catching one of a number of exceptions.', 'comment_created': datetime.datetime(2020, 6, 29, 20, 19, 31, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447238037, 'comment_body': '@b-butler  If we pass in decimal when the required value is a validation, it converts that decimal into an integer. (This is not the expected behaviour, right?)\r\nIf not then we should raise error straightaway.', 'comment_created': datetime.datetime(2020, 6, 29, 20, 36, 2, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 447246057, 'comment_body': 'When I pass in `None` which is of type `NoneType` to `Executable` then it creates string `None` and raises no error.', 'comment_created': datetime.datetime(2020, 6, 29, 20, 50, 56, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 447251204, 'comment_body': ""Some of these decisions are difficult. In a way, we don't want a user to do something like `value = 4 / 2` and raise an error (the output of division is always a float in Python. In this case, I think we allow it. We can be more strict by checking how close it is to an integer, but I do not feel that is necessary for now."", 'comment_created': datetime.datetime(2020, 6, 29, 21, 0, 48, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447254119, 'comment_body': 'Regarding the `None`, conversion. We should have an allow none flag in the class which just returns `None` if the value passed in is `None`.', 'comment_created': datetime.datetime(2020, 6, 29, 21, 6, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 447255073, 'comment_body': 'Noted, will make the changes.', 'comment_created': datetime.datetime(2020, 6, 29, 21, 8, 32, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 447258572, 'comment_body': 'okay, noted', 'comment_created': datetime.datetime(2020, 6, 29, 21, 15, 32, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 447261458, 'comment_body': ""Oh alright, that's interesting"", 'comment_created': datetime.datetime(2020, 6, 29, 21, 21, 50, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 451572489, 'comment_body': 'Why are we skipping `executable` now?', 'comment_created': datetime.datetime(2020, 7, 8, 14, 6, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451573901, 'comment_body': 'Given how we use `directives_fixture` I think it makes sense just to return the directives item. I would then just manually create it here, since it is the only place we put in a value into the fixture function.', 'comment_created': datetime.datetime(2020, 7, 8, 14, 8, 49, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451574206, 'comment_body': '```suggestion\r\n    def test_set_defined_directive(self, directives_fixture):\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 9, 13, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451574452, 'comment_body': '```suggestion\r\n    def test_set_defined_directive_invalid(self, directives_fixture):\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 9, 33, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451575158, 'comment_body': '```suggestion\r\n    def test_set_undefined_directive(self, directives_fixture):\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 10, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451575525, 'comment_body': '```suggestion\r\n    def test_set_directives_item(self, directives_fixture):\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 10, 50, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451575846, 'comment_body': '```suggestion\r\n    def test_del_directive(self, directives_fixture):\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 11, 15, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451576446, 'comment_body': '```suggestion\r\n        self, directives_fixture\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 12, 2, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451577315, 'comment_body': '```suggestion\r\n        self, directives_fixture, non_default_directive_values\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 13, 10, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451577641, 'comment_body': '```suggestion\r\n        self, directives_fixture, non_default_directive_values\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 13, 37, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451577932, 'comment_body': '```suggestion\r\n        self, directives_fixture, non_default_directive_values\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451578660, 'comment_body': '```suggestion\r\n        self, directives_fixture, non_default_directive_values\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 14, 14, 58, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 451579776, 'comment_body': 'There really is no need for the internal function. We can just return a `Directives` object.', 'comment_created': datetime.datetime(2020, 7, 8, 14, 16, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 453003123, 'comment_body': ""`__str__` methods are there for almost all data structures.\r\n`Executable` expect a string, if not found, then it tries to convert it into a string and becomes successful almost every time.\r\nHence I thought that it'd be best to skip it for now "", 'comment_created': datetime.datetime(2020, 7, 10, 18, 23, 38, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 453005323, 'comment_body': ""I think returning `Directives(available_directives_list)` will be a good choice here. But since in some methods we're using more than one instance of `Directives` class, I think this fixture is also good due to the pass by reference behavior of python class."", 'comment_created': datetime.datetime(2020, 7, 10, 18, 28, 22, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 453027936, 'comment_body': 'In the mentioned case, I now have initialized the instance manually.', 'comment_created': datetime.datetime(2020, 7, 10, 19, 4, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 456187057, 'comment_body': '""ability for directives to interspect"": I\'m not sure what is meant by this. Perhaps you mean ""introspect"" or ""inspect"" but that requires something else in the sentence (a direct object, I believe) to be introspected / inspected.', 'comment_created': datetime.datetime(2020, 7, 17, 2, 42, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456187370, 'comment_body': 'The last sentence doesn\'t make sense to me. Perhaps:\r\n\r\n""A directive\'s value may also be a callable accepting a job as the parameter and returning a valid value for that directive.""', 'comment_created': datetime.datetime(2020, 7, 17, 2, 43, 52, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456187514, 'comment_body': 'I\'m not familiar with the ""T"" and ""S"" here. Also this doesn\'t look like valid NumPy docstring formatting. I think the parentheses are not needed.', 'comment_created': datetime.datetime(2020, 7, 17, 2, 44, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456188137, 'comment_body': 'We need to determine how to document parameters that accept any type. I think ""any"" might be right but we should find references on this.\r\n```suggestion\r\n    default : any, optional\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 2, 46, 53, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456188223, 'comment_body': 'Likewise, apply the docstring formatting changes to other parts of this PR.', 'comment_created': datetime.datetime(2020, 7, 17, 2, 47, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456188482, 'comment_body': 'We should `import operator` and use `operator.add` here.\r\n```suggestion\r\n                 serial=max, parallel=operator.add, finalize=None):\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 2, 48, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456188892, 'comment_body': 'What does dft mean? ...default? Spell that out if so.', 'comment_created': datetime.datetime(2020, 7, 17, 2, 50, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456190685, 'comment_body': '```suggestion\r\n        The sequence of all environment-specified directives. All other\r\n        directives are user-specified and not validated. There is no way to\r\n        include environment directives not specified at initialization without\r\n        using the object\'s private API.\r\n```\r\nThe last sentence sounds like a double-negative. I would try to rewrite it. Perhaps:\r\n\r\n""Including environment directives after initialization requires the use of this object\'s private API.""\r\n\r\nBut even then, why are we advertising the private API? This doesn\'t sound like it goes in a docstring. We shouldn\'t invite the user to make a hacky solution.', 'comment_created': datetime.datetime(2020, 7, 17, 2, 57, 7, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456191198, 'comment_body': '```suggestion\r\n            default_value = self._directive_definitions[name].default\r\n            other_directive = other.get(name, default_value)\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 2, 59, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456191280, 'comment_body': '```suggestion\r\n            raise RuntimeError(""job must be specified when evaluating a callable directive."")\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 2, 59, 41, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456191717, 'comment_body': 'This seems like a typo.\r\n```suggestion\r\n                raise TypeError(""Expected an object of type {}. Received {} ""\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 1, 16, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456192087, 'comment_body': '```suggestion\r\n    """"""Return the actual number of processes/threads to use.\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 2, 48, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456192496, 'comment_body': ""We _multiply_ the number of ranks and threads, right? Also I don't understand the purpose of this function as a whole. Where does `value` come from?"", 'comment_created': datetime.datetime(2020, 7, 17, 3, 4, 45, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456192754, 'comment_body': '```suggestion\r\nThe number of GPUs to use for this operation.\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 5, 45, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456194736, 'comment_body': ""Everything after `name` could become [keyword-only arguments](https://www.python.org/dev/peps/pep-3102/). I couldn't understand the code later in this PR where the parameters are provided without their corresponding keywords. This feature has been around for all of Python 3, though I've never used keyword-only arguments. Forcing keywords also ensures that you can re-order or add new parameters after the `*` in the API without breaking downstream callers' code.\r\n```suggestion\r\n    def __init__(self, name, *, validation=None, default=None,\r\n```"", 'comment_created': datetime.datetime(2020, 7, 17, 3, 14, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456194943, 'comment_body': '```suggestion\r\nThe path to the executable to be used for this operation.\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 15, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456195186, 'comment_body': '```suggestion\r\nBy default this should point to a Python executable (interpreter); however, if\r\nthe :py:class:`FlowProject` path is an empty string, the executable can be a\r\npath to an executable Python script.\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 16, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456195655, 'comment_body': '```suggestion\r\nThis directive expects a float representing the walltime in hours. Fractional\r\nvalues are supported. For example, a value of 0.5 will request 30 minutes of\r\nwalltime.\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 18, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456195829, 'comment_body': '```suggestion\r\nThe number of gigabytes of memory to request for this operation.\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 19, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456196009, 'comment_body': 'Where does the requirement for an integer value come from? I am pretty sure fractional values are allowed by most schedulers.', 'comment_created': datetime.datetime(2020, 7, 17, 3, 20, 7, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456196218, 'comment_body': 'We need to be consistent about whether we say the resource is ""requested"" or ""used"" for each of these directives. I don\'t have a strong preference, just needs to match.', 'comment_created': datetime.datetime(2020, 7, 17, 3, 20, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456196302, 'comment_body': 'beweeeeeeen 💯 \r\n```suggestion\r\n        raise ValueError(""Value must be between 0 and 1."")\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 21, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456196531, 'comment_body': ""This looks like a TODO item. I don't know what this directive does..."", 'comment_created': datetime.datetime(2020, 7, 17, 3, 22, 16, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456197237, 'comment_body': '```suggestion\r\n# Copyright (c) 2020 The Regents of the University of Michigan\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 25, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456197579, 'comment_body': 'Group these imports together. I understand you might want the `Directives` class and `no_aggregation` separately, for semantic reasons. But all the directives should be combined.\r\n```suggestion\r\nfrom flow.directives import (NP, NRANKS, NGPU, EXECUTABLE, OMP_NUM_THREADS,\r\n                             WALLTIME, MEMORY, PROCESS_FRACTION)\r\n```', 'comment_created': datetime.datetime(2020, 7, 17, 3, 26, 47, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456197943, 'comment_body': 'Leave a comment about why `executable` is skipped.', 'comment_created': datetime.datetime(2020, 7, 17, 3, 28, 33, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 456198465, 'comment_body': ""I don't see what this is testing. What's being squared here? (Maybe this needs additional comments in the tests.)"", 'comment_created': datetime.datetime(2020, 7, 17, 3, 30, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 460236026, 'comment_body': ""I don't either honestly. I have never used it, but it is already in the code base, so I added the directive as well as I could."", 'comment_created': datetime.datetime(2020, 7, 24, 19, 3, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460239527, 'comment_body': ""The parenthesis was me combining Google and NumPy accidentally. As for the style, that is following the Python type hinting style. I haven't seen it for docs, but I find it more descriptive, but it makes more sense to use what more people are familiar with."", 'comment_created': datetime.datetime(2020, 7, 24, 19, 11, 27, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460247023, 'comment_body': 'When querying a `Directives` object for a directive like `np`, the `finalize` method of the `_DirectivesItem` is used to ensure that if the directive can be dependent on other directives (as `np` can), we have a way to examine the rest of the directives.', 'comment_created': datetime.datetime(2020, 7, 24, 19, 28, 3, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460248630, 'comment_body': ""It doesn't come from anywhere, my mistake."", 'comment_created': datetime.datetime(2020, 7, 24, 19, 31, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460249289, 'comment_body': 'This is testing that the `finalize` attribute of `NP` works as expected. This is the method that allows looking at `nranks` and `omp_num_threads` for calculating `np`.', 'comment_created': datetime.datetime(2020, 7, 24, 19, 33, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460555246, 'comment_body': 'This directive exists to improve launcher support on stampede. Specifically, this variable controls how much cpu needs to be allocated to a single job op when using stampede. For instance, if the value is 0.5 and you bundle 20, it will request 10 cpus. ', 'comment_created': datetime.datetime(2020, 7, 26, 17, 53, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 460910785, 'comment_body': '@vyasr thanks. In that case, if this is only for Stampede we should move this to only be in the Stampede environment.', 'comment_created': datetime.datetime(2020, 7, 27, 13, 59, 51, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 460921369, 'comment_body': ""I don't think that's necessary. The launcher on stampede is basically identical to a process pool (e.g. `multiprocessing.Pool` in python) except that it transparently supports things like multi-node with MPI on stampede. I'm not sure how well Python handles such use cases (although it might be fine if you bind all cores to one task), but since Stampede2 provides a specific solution it made sense to take advantage.  The functionality is general, though (I believe it's just used as a prefactor in the resource calculation template filter), and could conceivably be used by someone running a process pool directly with python, for instance, where they anticipate being able to run a large number of job-ops through a small number of cores if each job-op is small. So I think it makes sense to leave it here, but simply add documentation indicating this."", 'comment_created': datetime.datetime(2020, 7, 27, 14, 14, 57, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 463168723, 'comment_body': 'The `lambda` function here which is taking x as an argument will take a `job` instead. This function here is just an arbitrary function. ', 'comment_created': datetime.datetime(2020, 7, 30, 17, 49, 52, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 463796740, 'comment_body': 'The fact we have to use this hack to make template tests pass is unfortunately. Could you make a comment explaining why we do this for future developers.', 'comment_created': datetime.datetime(2020, 7, 31, 19, 38, 36, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 464096296, 'comment_body': '- Would it be possible to return a *wrapped callable* where the wrapper function validates the result of the callable? That way we don\'t have to give up on validation.\r\n- The description of how `finalize` can be ""abused"" (unnecessarily negative word choice) is not clear to me. I would prefer a sentence like:\r\n> ""The results of a directive are validated before the call to `finalize`. It is the caller\'s responsibility to ensure that finalized values are still valid.""', 'comment_created': datetime.datetime(2020, 8, 2, 16, 20, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464096349, 'comment_body': 'NumPy docstyle requires a space here.\r\n```suggestion\r\n    name : str\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 21, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464096369, 'comment_body': '```suggestion\r\n        The name of the directive.\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 21, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464096532, 'comment_body': '```suggestion\r\n        appropriate error. If not provided or ``None``, the validation\r\n        function directly returns the passed value. Defaults to ``None``.\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 23, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464096585, 'comment_body': 'Two backticks are needed to trigger code font in rST.\r\n```suggestion\r\n        Sets the default for the directive, defaults to ``None``.\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 24, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464096807, 'comment_body': '""Defaults to the maximum of the two"" is unclear. You mean the default function is `max`? Use a sentence like I suggested above (not making a code suggestion because it\'s hard to wrap the lines appropriately).\r\n```\r\nIf ``None`` or not provided, the ``max`` function is used. Defaults to ``None``.\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 26, 45, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464096866, 'comment_body': '```\r\nIf ``None`` or not provided, the ``operator.add`` function is used. Defaults to ``None``.\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 27, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464097554, 'comment_body': 'Does the word ""current"" make sense here? Directives have no ""past"" values (they\'re immutable if I understand correctly).\r\n```\r\nIf ``None`` or not provided, the current value is returned. Defaults to ``None``.\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 34, 26, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464097729, 'comment_body': '""directives"" should be a reference to the `Directives` class, right? (My suggested Sphinx syntax may be incorrect here. Please verify, perhaps by testing with another class whose docs are actually rendered.)\r\n```suggestion\r\n        :class:`~.Directives` object it is a child of and outputs the finalized value for\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 35, 58, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464097859, 'comment_body': 'Replace docstring references to a user-provided ""function"" with ""callable."" It\'s a more general term (one could provide callable objects or static methods of a class, which aren\'t plain functions). That applies to all these inputs that are accepting callables.', 'comment_created': datetime.datetime(2020, 8, 2, 16, 37, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464098311, 'comment_body': ""This really isn't how private APIs are supposed to work. A public class should not require a sequence of instances of a private class for initialization. We need to be consistent by making both public or both private."", 'comment_created': datetime.datetime(2020, 8, 2, 16, 42, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464098476, 'comment_body': 'As a matter of style, we support Python 3.6+ and format strings are allowable if you prefer them.\r\n```suggestion\r\n            raise TypeError(f""Expected a _DirectivesItem object. Received {type(directive)}."")\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 16, 44, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464098571, 'comment_body': 'If you make this change, please try to make the same change everywhere in this file.', 'comment_created': datetime.datetime(2020, 8, 2, 16, 44, 58, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464100282, 'comment_body': ""I would prefer to use `raise from` with a custom DirectivesError error class. Follow this example: https://stackoverflow.com/a/29442282\r\n\r\nSearch in the code base for an example error class (ideally one with a docstring), but something like this should work:\r\n```python\r\nclass DirectivesError(Exception):\r\n    pass\r\n\r\n# Then raise from:\r\nraise DirectivesError('Error...') from err\r\n```"", 'comment_created': datetime.datetime(2020, 8, 2, 17, 3, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464100362, 'comment_body': ""And if you _do_ want to forward the exception type, use `type(err)('Error...')` instead of `err.__class__('Error...')`."", 'comment_created': datetime.datetime(2020, 8, 2, 17, 4, 33, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464101156, 'comment_body': 'The logic here indicates that the name should be `is_greater_or_equal`.', 'comment_created': datetime.datetime(2020, 8, 2, 17, 13, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464101178, 'comment_body': '```suggestion\r\n    We check the default np because when aggregation occurs we multiply the\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 17, 13, 48, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464101494, 'comment_body': ""I'm not sure how you got `r1 * r2 * t1 * t2` in the original expression... is this supposed to say:\r\n```suggestion\r\n    number of processors needed as (r1 * t1) + (r2 * t2) <= (r1 + r2) * (t1 + t2)\r\n```\r\nBut also my suggested expression isn't always true."", 'comment_created': datetime.datetime(2020, 8, 2, 17, 17, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464101672, 'comment_body': '```suggestion\r\n""""""\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 17, 19, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 468010152, 'comment_body': ""Good catch on language. I didn't think of the connotation when writing it, and yes it is possible to wrap the function which is a great idea."", 'comment_created': datetime.datetime(2020, 8, 10, 15, 56, 39, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468132414, 'comment_body': '`DirectiveItem` instances provide the logic and definition for a directive like `np`. The `Directives` class uses the definitions to set and get directives. For directives like `np` when `np == NP._default` and `nranks` and `omp_num_threads` are set, we need to update `np` accordingly. We do this by taking the currently set value and the `Directives` instance and using `NP._finalize` return the correct `np`.\r\n\r\nSo there are current values just as in a dictionary, but they are not found in the `DirectivesItem` instance', 'comment_created': datetime.datetime(2020, 8, 10, 19, 28, 47, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468141129, 'comment_body': 'I think it makes sense to have `Directives` private. I originally intended to have `Directives` public to allow validation before creating `_JobOperation` objects, but given that the valid directives are environment dependent, and `FlowGroup` has to store a `dict` of operation directives, validating and keeping the `dict` of directives updated is likely not worth it.\r\n\r\n`_DirectivesItem` may need to be public as I think it makes sense to keep the instances public as they serve as good documentation of standard directives.', 'comment_created': datetime.datetime(2020, 8, 10, 19, 46, 1, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 468172942, 'comment_body': 'Actually I changed my mind. We already document directives elsewhere in the documentation, so I will make everything private.', 'comment_created': datetime.datetime(2020, 8, 10, 20, 40, 11, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 481252949, 'comment_body': ""Perhaps better to name this `validator`. We're using that term in a similar way in signac: https://github.com/glotzerlab/signac/pull/378\r\n```suggestion\r\n    validator : callable, optional\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 15, 59, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481266115, 'comment_body': '```suggestion\r\n    finalize : callable, optional\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 16, 12, 39, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481270033, 'comment_body': ""I'd remove the suffix `_list` from the variable name. Also, I think `environment` might be more descriptive than `available`.\r\n```suggestion\r\n    environment_directives : sequence of _DirectivesItem\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 16, 15, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481271733, 'comment_body': ""Phrase this the opposite way and don't reference private APIs in docstrings:\r\n```suggestion\r\n        directives are user-specified and not validated. All environment\r\n        directives must be specified at initialization.\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 16, 18, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481272769, 'comment_body': '```suggestion\r\n            raise ValueError(f""Cannot re-define directive name {directive._name}."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 16, 20, 28, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481275201, 'comment_body': ""`Exception` is too broad, and will catch almost everything including keyboard interrupts and memory errors. The suggestion below is just an example -- I just made up a set of common errors, and this is not necessarily the correct set. It may make sense to document the errors that directives/validators/etc. can raise, if that's not already documented.\r\n```suggestion\r\n        except (KeyError, ValueError, TypeError) as err:\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 16, 24, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481281576, 'comment_body': 'The style of this block is EAFP (try accessing a key), while the others (`__setitem__` and `__delitem__`) are LBYL (`if key in ...`). In this case, I believe the EAFP style is not desirable because exceptions are _expected_, and catching them can be expensive. It also introduces a slightly confusing second layer of indentation.\r\n```suggestion\r\n        if key in self._defined_directives and key in self._directive_definitions:\r\n            value = self._defined_directives[key]\r\n            return self._directive_definitions[key]._finalize(value, self)\r\n        elif key in self._user_directives:\r\n            return self._user_directives[key]\r\n        else:\r\n            raise KeyError(f""{key} not in directives."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 16, 35, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481283466, 'comment_body': ""I prefer to only define `__repr__` when it's possible to make `obj == eval(repr(obj))`. I don't think that invariant holds here, but I don't have strong opinions on this and the current `repr` might be helpful enough."", 'comment_created': datetime.datetime(2020, 9, 1, 16, 38, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481284806, 'comment_body': 'Unnecessary `continue` at the end of the loop body, and unnecessary wrapping (our line length limit is more than this).\r\n```suggestion\r\n            if other_directive is not None:\r\n                self._defined_directives[name] = agg_func(directive, other_directive)\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 16, 40, 31, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481285713, 'comment_body': ""I don't think this should be its own function, it appears to be used one time. Also, it's unclear to me how `jobs` could ever be `None`?"", 'comment_created': datetime.datetime(2020, 9, 1, 16, 42, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481288174, 'comment_body': 'Define all the helpers like `_nonnegative_int`, `_natural_number`, and `_no_aggregation` before defining any directives.', 'comment_created': datetime.datetime(2020, 9, 1, 16, 46, 6, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481289682, 'comment_body': 'Docstrings for all variables should go _below_ the variable definition, and should use the first line (don\'t put a blank line immediately after the opening `""""""`).\r\n\r\nWhile variable docstrings are fairly uncommon, the convention of putting the docstrings below is recommended by [Napoleon](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html) for both NumPy and Google-style docstrings, and it also agrees with another tool, [Epydoc](http://epydoc.sourceforge.net/manual-docstring.html).', 'comment_created': datetime.datetime(2020, 9, 1, 16, 48, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481291213, 'comment_body': '```suggestion\r\nThe number of tasks to launch for a given operation.\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 16, 51, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481292394, 'comment_body': 'It would be good to clarify that this value is the number of CPU cores to be requested. The official docs for SLURM use the ""tasks to launch"" terminology but I want to make sure the purpose is clear to all users.', 'comment_created': datetime.datetime(2020, 9, 1, 16, 52, 52, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481293145, 'comment_body': '4 hours? The default below is 12 hours. I would use 12.\r\n```suggestion\r\nwalltime. Defaults to 12 hours.\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 16, 54, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481294933, 'comment_body': 'This feels hacky. The smallest permitted value here is 1/1000th of a byte of memory. 😮', 'comment_created': datetime.datetime(2020, 9, 1, 16, 57, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481300292, 'comment_body': ""This looks like it's performing `base_directives.update(None)`? `dict.update(None)` doesn't even work in Python...?\r\n```suggestion\r\n            directives = job._project._environment._get_default_directives()\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 17, 6, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481303027, 'comment_body': 'I don\'t like the name `base_directives` because it\'s being updated and returned (and is no longer just the ""base"" directives). A name like `directives` or `all_directives` might be better. (I can\'t make a code suggestion to help here because of how the diff is structured.)', 'comment_created': datetime.datetime(2020, 9, 1, 17, 11, 6, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481303289, 'comment_body': '```suggestion\r\n        # Assuming all the jobs belong to the same FlowProject\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 17, 11, 31, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481304082, 'comment_body': 'Makes the structure of `self.operations` more explicit.\r\n```suggestion\r\n        op_names = list(self.operations.keys())\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 17, 12, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481304436, 'comment_body': 'Same as before - is `base_directives` the right name for something that is updated?', 'comment_created': datetime.datetime(2020, 9, 1, 17, 13, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481307823, 'comment_body': ""I don't think my question was answered. I ran `test_finalize` locally with this line commented out and it still passed. What is this line trying to do? Does it have any effect on the execution? Does this test actually depend on that lambda function being assigned?"", 'comment_created': datetime.datetime(2020, 9, 1, 17, 19, 26, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481308696, 'comment_body': '```suggestion\r\n    """"""Tests for _Directives class.""""""\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 17, 20, 54, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481308941, 'comment_body': '```suggestion\r\n    """"""Tests for _DirectivesItem class.""""""\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 17, 21, 22, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 489518606, 'comment_body': ""Shouldn't this just be called `_Directive`? A singular directive?"", 'comment_created': datetime.datetime(2020, 9, 16, 15, 15, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 496566826, 'comment_body': 'The logic can be merged within the evaluate method.\r\n@b-butler can you comment on the `None` type of the jobs?', 'comment_created': datetime.datetime(2020, 9, 29, 9, 18, 33, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 496615805, 'comment_body': '@b-butler can you please comment on this?', 'comment_created': datetime.datetime(2020, 9, 29, 10, 38, 53, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 496652321, 'comment_body': ""Technically this was testing if anyone among `nranks` or `opm_num_threads` is callable then return the np passed. But now I think that this test is not necessary hence I'll remove this test."", 'comment_created': datetime.datetime(2020, 9, 29, 11, 47, 33, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 496694484, 'comment_body': 'I would also like to see this name changed to `_Directive`.', 'comment_created': datetime.datetime(2020, 9, 29, 12, 57, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496696590, 'comment_body': '```suggestion\r\n            given callable with a validator.\r\n```', 'comment_created': datetime.datetime(2020, 9, 29, 13, 0, 46, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496697215, 'comment_body': '```suggestion\r\n            raise ValueError(f""Cannot redefine directive name {directive._name}."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 29, 13, 1, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496698277, 'comment_body': ""We don't use quotes around the name/key in other error messages so I dropped the quotes here.\r\n```suggestion\r\n            raise DirectivesError(f'Error setting directive {key}') from err\r\n```"", 'comment_created': datetime.datetime(2020, 9, 29, 13, 3, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496699640, 'comment_body': '```suggestion\r\n                                f""Received {v} of type {type(v)}."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 29, 13, 5, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496699709, 'comment_body': '```suggestion\r\n                             f""Received {v}."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 29, 13, 5, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496700075, 'comment_body': 'This should probably be a `ValueError`.\r\n```suggestion\r\n            raise ValueError(""jobs must be specified when evaluating a callable directive."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 29, 13, 6, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496731158, 'comment_body': '```suggestion\r\n- Added classes ``_Directives`` and ``_Directive`` that serve as a smart mapping for directives specified by the environment or user (#265, #283).\r\n```', 'comment_created': datetime.datetime(2020, 9, 29, 13, 47, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 496851779, 'comment_body': 'We can move it into a helper function of `_aggregate`. `jobs` could be `None` when combining directives without a job such as `directives.update(other_directives, aggregate=True)`. In practice this may not be used often, but it makes sense to allow.', 'comment_created': datetime.datetime(2020, 9, 29, 16, 3, 14, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}]","[{'commit_sha': '8c235a344be1fca52ac4b53b55a2242fd506005d', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a338c7719bd0527c36cb5088f40d9f4eb36799f4', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5e559522429f711bd9bd0273d65cd922e1fc6cf9', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c04ff3faa89db40ae9309eb01fa3c1c90176273e', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '24d7c73164d281c56ac60b7f2295dabbb4e2c4dc', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7913f86233ce608ec60472ce7c319a5aa8965795', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4e7423d4e4c78f5e3a607511f9dc588c8dce4c32', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '85c4a56cf700371ce6cd242fce599bf85cc8093f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ded660ca35345841041eb4923762dd7b44d966eb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8878e123298ed89b0e5e55a110c96e8c77f1de46', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '69ce38ed39080d7f17154aac8a48aad154338c6a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0222d1ca7ad59f754b5f6413bd627cd96ca5921e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '03c28fda0aa7cbec3439bb4873e042c72b7e34a1', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1ddc75f24af5719075620bef1292ed07d3012ac3', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7a6e0ff95cecd2d4ef3b2d54c04d2c608b1a989d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe0a10952d9777606f03655a88184213994dd3fd', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dadf3ce26cce987cb29edd1e4ca1493ce231ad8c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3f78039a11acc77fd31f5f47df9ba5829569952c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e93c8bd1b8e6c084e3dbdf0e99b2315fd4c14389', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b4e16f1d100e75feae3834c94fe30d716cfa043b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2287b20df5a6a46ca3b7feafcfd17c785045646e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fdde63a44158017cbe37b8a148c02e8d4b751c36', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e9c275eaa3e2d3d435c2ac3c461af5aa18c5aa8', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '774e52572dd515adcdbf45f992068bee71a4540b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '873ba6430cd535f3c836000e55f169d18bf5e7e8', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8f5f6801b069674728492287e4a4c81975a38c74', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c0676118973a561fc73e711f969d681a2230f2e6', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0ba7d66503a144fbc3cb1dac559cabba243ee839', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6f0df77c41e28f1c82b344bda64b74780075b5e4', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd3915c8fcc929182ee823d813a04ffa181c1042d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ed55884b2a0e20760a7461840d64dcc8167cc20b', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5cbb70c8d53f1570f561ab6ac52183371cb7b880', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bfe328e48ff0411e0218e41682bb27f406683833', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd09bcc47580a448d0e1ec3f6ac2cdb85765ea0bf', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fc5d74800f15321353d572907a3c8651ce6e91da', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '92e30dd0f44a8bb447d1462157f2f880d91ca391', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'becdb14c0ee73fe672b685b66bd9acbcb6a8ebb3', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '954977de20c03bbe2b010795c3f0b6904544428b', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a460a6cbf0acaf558b79369d7bc6231972ec39a', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'be47a25aee563f6c421c84b4527cbddf9e07ca56', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'db48d8e406dfb037390c14d9469a391fb263af61', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4e3700ee81495490992bd48085f4f305fa11e2fe', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '45ed886b11c0da7d64f269c8778b238966c8c0d8', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '84117867a055da826354f5e4c104d383e0e63aeb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '89c202f75346cd3c9dbc06743d48c95b2234abdb', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ad31590a566aa8930ad6c9b13b623911493ee9ae', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a8e2f8ead655f601d33d3363346d7c187dd3c5a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dfc0e9509a0a693da05358e7e84dfe01a69f2b69', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c57ee0366b107a63dafea3d2e47e4d18155197d8', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe82798a0829c7dc10b79a5d225d0edf7e3069cd', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0babaefbea49d1e6feed82fbcedbe0079c5ddd7a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '80af0742f85f799a4679ff3fd114c78c0785e3fe', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9fbb7ddfadd776a780aa74764ee3ea38848d03b3', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b5c8e19ce0156845c7f69f56a13486686beba7c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6c88ac7c3d4974c2af26ec75901835e00cf26125', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '97cc1c17c4b7ccf4cc38a99e9cf967e6a6b02e67', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '51adfce004c1f5b52125b7392915b6a3ec7ed9f8', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3c2b57cd7e87d216b213fc01cb84b3c578c215e2', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '73fc6b3250861063466c3dae40bd6e9f180030cf', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b0842f31ef634e9ec03de7fc985bdd9f6c9f56b', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3bf80089105168b6eaaf5bc066bf6547c16d6d82', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7de952221cc6ef077f65923b0e6204670622132e', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3718402f092623604b3f86b633c1bfe31cdd1358', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1abe8bbdc2157689e32ec7c7a38407b998e89cc7', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '72d93dddc359342e828e274b652d4827dd676098', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8d9bab57086e77b29d90675ee694b354cc0f7f56', 'committer_username': 'b-butler', 'committer_name': 'Brandon Butler', 'committer_email': 'butlerbr@umich.edu', 'commit_date': datetime.datetime(2019, 1, 16, 19, 30, 21, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63940d31dbdf699fb2bc55b9c7189453c9b062af', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3c09d315e4bf7edea19860728a7e8b44bf894d27', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4e6f5770c154bf60664e4646500f9f2a4250fa1c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1717353a007ebc244fc050979fa841c4fded678a', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ddff799c9e9611025f6a7782b6c30b5641e5904f', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f08e41acf7d1a9a31da4435cb3ead91f900f8790', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '27af0add06558facd3d4ec768db3ad6b9c560bd1', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9d6ced68fe2213752b364e751dbd7329d645abc6', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '20d43b6cfb1c2e69365e718d2fbb1f7060424c80', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ff589a3a4cb5d63db8cd015f310cb5185bcfa948', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
452562220,Support for pre-commit hook using `pre-commit`.,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Enabling the support of [pre-commit](https://pre-commit.com/) for pre-commit hook.
Developers will now have to perform these steps in order to enable the pre-commit hook.
```
pip install -r requirements-precommit.txt
pre-commit install
```
This will add the hook to `git`.

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Resolves #355 

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md#code-style) of this project.
- [ ] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [x] I have updated the [changelog](https://github.com/glotzerlab/signac/blob/master/changelog.txt) and added all related issue and pull request numbers for future reference (if applicable). See example below.


Example for a changelog entry: `Fix issue with launching rockets to the moon (#101, #212).`
",True,358,https://api.github.com/repos/glotzerlab/signac/pulls/358,https://github.com/glotzerlab/signac/pull/358,closed,143,104,17,28,13,17,2,1,"[{'name': 'enhancement'}, {'name': 'GSoC'}]",2020-07-19 13:23:26+00:00,2020-08-02 22:52:27+00:00,1243741.0,"14 days, 9:29:01","[{'comment_id': 456908925, 'comment_body': 'This repo provides lots of hooks.\r\nI think we should adopt the hooks like `requirements-txt-fixer`, `file-contents-sorter`, `double-quote-string-fixer`. `check-yaml`, `pretty-format-json`, and `check-json`.\r\nThere are more of them but I think these were relatively more relevant.', 'comment_created': datetime.datetime(2020, 7, 19, 13, 27, 34, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 457390233, 'comment_body': ""I like your list and the hooks you've already added. I think a couple more hooks of potential interest are `name-tests-test` and `debug-statements`"", 'comment_created': datetime.datetime(2020, 7, 20, 13, 36, 48, tzinfo=datetime.timezone.utc), 'commenter': 'tommy-waltmann', 'type': 'User'}, {'comment_id': 457500487, 'comment_body': ""@tommy-waltmann Thanks for the review.\r\nI'll try to add them locally and check whether it catches any error or not. "", 'comment_created': datetime.datetime(2020, 7, 20, 15, 34, 54, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 458707749, 'comment_body': '@tommy-waltmann, the `name-tests-test` hook checks whether the name of all the files in the folder `tests/` starts with `test_` or not.\r\nGiven this I think it may restrict the development as in signac-flow, we have python modules named `define_test_project.py`, `extract_templates.py` in the `tests/` folder.', 'comment_created': datetime.datetime(2020, 7, 22, 10, 55, 38, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 458756694, 'comment_body': 'Yeah, on second thought this one may not be the best idea. The unit testing frameworks also enforce this by themselves to some extent by requiring the files be named a certain way to be run as tests.', 'comment_created': datetime.datetime(2020, 7, 22, 12, 32, 48, tzinfo=datetime.timezone.utc), 'commenter': 'tommy-waltmann', 'type': 'User'}, {'comment_id': 459122596, 'comment_body': ""This is fixed in a different PR, but swapping `l` for `i` to get the tool to be happy isn't a great reason to change it. I'm guessing it allows `i` due to the prolific use of that variable name (and most of the time it is clear what it means). Instead, use `_` to indicate that we have a temp variable that we don't care about. "", 'comment_created': datetime.datetime(2020, 7, 22, 22, 37, 5, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 459122681, 'comment_body': '```suggestion\r\n        return (json.loads(_) for _ in fd)\r\n```', 'comment_created': datetime.datetime(2020, 7, 22, 22, 37, 16, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 459122782, 'comment_body': '```suggestion\r\n        return (json.loads(_) for _ in fd)\r\n```', 'comment_created': datetime.datetime(2020, 7, 22, 22, 37, 35, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 459124865, 'comment_body': 'I know these are just tests, but IMHO going from `l` to `m` here is confusing since we are going `i, j, k, l`. My preference would be to add some sort of #noqa to make flake8 happy.', 'comment_created': datetime.datetime(2020, 7, 22, 22, 43, 31, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 459138098, 'comment_body': 'Or even better, a descriptive name like `line`.\r\n```suggestion\r\n        return (json.loads(line) for line in fd)\r\n```', 'comment_created': datetime.datetime(2020, 7, 22, 23, 23, 4, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 459138225, 'comment_body': 'Or `line`, see previous comment.\r\n```suggestion\r\n        return (json.loads(line) for line in fd)\r\n```', 'comment_created': datetime.datetime(2020, 7, 22, 23, 23, 32, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 459138459, 'comment_body': 'Or descriptive names like `a_value`, `b_value`, `c_value`, `d_value` that correspond to the state point.', 'comment_created': datetime.datetime(2020, 7, 22, 23, 24, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 459405039, 'comment_body': '@mikemhenry Since, for a similar method in `__main__.py`, we have used `line`. Hence, I think I should use `line` here too.', 'comment_created': datetime.datetime(2020, 7, 23, 12, 17, 5, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 459405634, 'comment_body': 'There are several places where this is repeated. Hence, instead of using #noqa everywhere, I think I should go with changing all the names.', 'comment_created': datetime.datetime(2020, 7, 23, 12, 18, 16, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 460254110, 'comment_body': 'Yes `line` is great! My suggestion for `_` was to use it as a throw away variable instead of something like `i` or `l` BUT always always use something descriptive if it makes sense! ', 'comment_created': datetime.datetime(2020, 7, 24, 19, 44, 2, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 460429611, 'comment_body': '😊 I distinguish ""temporary"" variables like `line` that are re-used by name at least once from ""throwaway"" variables that are never used by name. I use `_` when dealing with functions like [NumPy histograms](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html) that return a tuple like `histogram, bin_edges`. If I don\'t plan to use bin edges, then I call it like\n```python\nhistogram, _ = np.histogram(...)\n```', 'comment_created': datetime.datetime(2020, 7, 25, 18, 9, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464007826, 'comment_body': 'This needs to have a type annotation for it to be recognized as a `dataclass` field. The correct type annotation should be `Optional[str]`, in my understanding. I will add this line at the top:\r\n```python\r\nfrom typing import Optional\r\n```\r\nand then edit this line to say:\r\n```suggestion\r\n    orcid: Optional[str]\r\n```', 'comment_created': datetime.datetime(2020, 8, 1, 22, 48, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}]","[{'commit_sha': 'c10bc726375ef65cd61192936cbad2e6dcb00f1c', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b53b563049dd87e8a685fc3baa704aabc360a434', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '25173f28705aeb62304d27a49df2f5059ab77291', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9b5438c48d860df8b0bb5d308e6d53863081a4d9', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7d7295d3e5214e63213a9bf4b01af485b9b0b9fd', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '712dab75e5738f1f44b7b7b18d15843f51109e81', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '43e0acce8fbd411165553db423d8e839b800be81', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'feb1d4e3c809672275a1931dd00b575ea64ec50d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ada926e9f810f68ec1762b65c1c7173045c4bcce', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '362767b7391e19ee6824f6e88e2dc197c14ce2b7', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5a4e1d37d3989c8ace4c1ae7a9ae1b4901d08f11', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'accb4f61571df18a8c74ece3a36aba9db5aa9a28', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '29860bd272a6eac13710ed41227d870f02bd9415', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '96331e34d425f343b48e07dad00bc3d96245ff6b', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cda4e71f6671c9018603b9b8a19214c2ebd88adf', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7a23c41b11a65de93e570eb9f74b072961a5349d', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e209defad8fe3b6731edddcd5a03bafde0bbc186', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4d81b262cb44fd84a78fe59b2a83c62de058bde0', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5c1c923ca78da0af6aa32c6af663245cde9e7ae2', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '927d05c707baff83461ccf697c7b5c6e4be3f8dc', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '29bb5524be843a8cedffe6faa48963ed424cb5df', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '771f1dd2e3674bfa832160819de48c0120cdef82', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '51e2dad56dd7040a09b157bba568e52acdd50046', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23ea5eee40a55b21522c88725065200bc05102a8', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '61fc28228ea3c9424a47d076c9a94cc5d17652e2', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0edf1477ff67be13874fc273bb53008fd442d266', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b4e1ef61cdc09c0886911f8cf8747e844c622be0', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '05e4903639032ae1cbdac6de1303fcc9846bde40', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
462292927,Add pre-commit hook,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Enabling the support of [pre-commit](https://pre-commit.com/) for pre-commit hook.
Developers will now have to perform these steps in order to enable the pre-commit hook.
```
pip install -r requirements-precommit.txt
pre-commit install
```
This will add the hook to `git`.

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-flow/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac-flow/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-flow/blob/master/CONTRIBUTING.md#code-style) of this project.
- [ ] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [x] I have updated the [changelog](https://github.com/glotzerlab/signac-flow/blob/master/changelog.txt).
",True,333,https://api.github.com/repos/glotzerlab/signac-flow/pulls/333,https://github.com/glotzerlab/signac-flow/pull/333,closed,32,13,9,4,3,2,1,1,[{'name': 'GSoC'}],2020-08-03 17:04:40+00:00,2020-08-12 15:27:27+00:00,771767.0,"8 days, 22:22:47","[{'comment_id': 465215462, 'comment_body': 'Why do we pin two different flake8 versions in requirements-precommit and requirements-dev?', 'comment_created': datetime.datetime(2020, 8, 4, 17, 32, 55, tzinfo=datetime.timezone.utc), 'commenter': 'jennyfothergill', 'type': 'User'}, {'comment_id': 465216421, 'comment_body': ""This is not meant to be in this file.\r\nI'll remove this."", 'comment_created': datetime.datetime(2020, 8, 4, 17, 34, 44, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}]","[{'commit_sha': '57d35d650f64d751cb9e86a649f13438f2f7f19e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '85c04b862c3a232882055b2d70d1bdfd5a08a85d', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'afaec3e50c50adf4d821cc09222cf4a61b2e1898', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4699ee75c362f97311bbdba997cb22b4da3a5d23', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14
454949661,Add docs for pre-commit,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Added user guide to set up a pre-commit hook using [pre-commit](https://pre-commit.com/)

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Should be merged after [signac/#358](https://github.com/glotzerlab/signac/pull/358) gets merged

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac-docs/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac-docs/blob/master/ContributorAgreement.md).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac-docs/blob/master/CONTRIBUTING.md#code-style) of this project.
",True,92,https://api.github.com/repos/glotzerlab/signac-docs/pulls/92,https://github.com/glotzerlab/signac-docs/pull/92,closed,13,4,1,8,2,5,0,1,[],2020-07-22 08:00:35+00:00,2020-08-26 16:57:49+00:00,3056234.0,"35 days, 8:57:14","[{'comment_id': 464537023, 'comment_body': ""Is this something that you run on each commit or you run once on the project and it's always in place? This point could be more clear here."", 'comment_created': datetime.datetime(2020, 8, 3, 16, 53, 4, tzinfo=datetime.timezone.utc), 'commenter': 'tcmoore3', 'type': 'User'}, {'comment_id': 464549914, 'comment_body': 'I addressed your comment. Please review the changes.', 'comment_created': datetime.datetime(2020, 8, 3, 17, 17, 23, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 464551215, 'comment_body': '```suggestion\r\n    To install and run `Pre-commit`_ for all the files present in the repository, run the following command:\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 17, 19, 50, tzinfo=datetime.timezone.utc), 'commenter': 'kidrahahjo', 'type': 'User'}, {'comment_id': 471634941, 'comment_body': '```suggestion\r\n    During continuous integration, the code and the documentation is checked automatically using `Flake8`_, `Pydocstyle`_, and `Mypy`_.\r\n```', 'comment_created': datetime.datetime(2020, 8, 17, 17, 18, 55, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}, {'comment_id': 474052380, 'comment_body': ""This needs to use the same name as above. Otherwise the link won't work correctly.\r\n```suggestion\r\n.. Pydocstyle: http://pydocstyle.org/en/4.0.0/index.html\r\n```"", 'comment_created': datetime.datetime(2020, 8, 20, 15, 3, 22, tzinfo=datetime.timezone.utc), 'commenter': 'b-butler', 'type': 'User'}]","[{'commit_sha': 'f41110bb06feb1e23b981492d79a574e41355894', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '62a5780a1b625b7e8c7b58ee796b547317ee4141', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cb730bae8d5c86decf2cf80e7ba37b04978ca15e', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23b94a36925a14f26d5f452527320cb877a0cd27', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8f7e356bb583ef243057aef93b9388a6b2160831', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4751243a5872c540918f159bed638820f1eafb4', 'committer_username': 'csadorf', 'committer_name': 'Simon Adorf', 'committer_email': None, 'commit_date': datetime.datetime(2012, 2, 15, 21, 1, 17, tzinfo=datetime.timezone.utc)}, {'commit_sha': '442d82e8d098185d770e61e87a5f3f509931ba37', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ce51ad33bfbde9387867b66bd1c4071cc618d52f', 'committer_username': 'kidrahahjo', 'committer_name': 'Hardik Ojha', 'committer_email': None, 'commit_date': datetime.datetime(2018, 11, 4, 13, 33, 23, tzinfo=datetime.timezone.utc)}]",Hardik Ojha,44747868,,User,,40,,22,14

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
168428410,signac-examples,glotzerlab/signac-examples,Jupyter Notebook,8,15,10,15,546,8,18,1,"[{'id': 463969021, 'number': 15, 'closed': datetime.datetime(2021, 10, 9, 16, 42, 55, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 6, 11, 33, 25, tzinfo=datetime.timezone.utc), 'time_taken': 37084170.0, 'time_delta': '429 days, 5:09:30', 'additions': 376, 'deletions': 8, 'state': 'closed'}, {'id': 387275866, 'number': 10, 'closed': datetime.datetime(2020, 3, 18, 1, 47, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 12, 14, 27, 25, tzinfo=datetime.timezone.utc), 'time_taken': 472815.0, 'time_delta': '5 days, 11:20:15', 'additions': 9, 'deletions': 17, 'state': 'closed'}]"
168431310,signac-flow,glotzerlab/signac-flow,Python,37,48,14,44,1442,53,33,2,"[{'id': 1038564407, 'number': 671, 'closed': datetime.datetime(2022, 10, 7, 1, 34, 5, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 8, 27, 5, 46, 10, tzinfo=datetime.timezone.utc), 'time_taken': 3527275.0, 'time_delta': '40 days, 19:47:55', 'additions': 220, 'deletions': 17, 'state': 'closed'}, {'id': 1036857563, 'number': 670, 'closed': datetime.datetime(2022, 8, 25, 15, 9, 19, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 8, 25, 14, 39, 8, tzinfo=datetime.timezone.utc), 'time_taken': 1811.0, 'time_delta': '0:30:11', 'additions': 1, 'deletions': 2, 'state': 'closed'}, {'id': 1036701122, 'number': 668, 'closed': datetime.datetime(2022, 8, 25, 13, 19, 36, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 8, 25, 12, 38, 34, tzinfo=datetime.timezone.utc), 'time_taken': 2462.0, 'time_delta': '0:41:02', 'additions': 1, 'deletions': 0, 'state': 'closed'}, {'id': 1031743565, 'number': 666, 'closed': datetime.datetime(2022, 10, 13, 16, 8, 37, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 8, 20, 10, 9, 12, tzinfo=datetime.timezone.utc), 'time_taken': 4687165.0, 'time_delta': '54 days, 5:59:25', 'additions': 191, 'deletions': 112, 'state': 'closed'}, {'id': 953418625, 'number': 645, 'closed': datetime.datetime(2022, 8, 31, 18, 2, 14, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 6, 1, 9, 26, tzinfo=datetime.timezone.utc), 'time_taken': 7893374.0, 'time_delta': '91 days, 8:36:14', 'additions': 366, 'deletions': 362, 'state': 'closed'}, {'id': 953073150, 'number': 644, 'closed': datetime.datetime(2022, 6, 4, 2, 59, 29, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 6, 1, 6, 32, 16, tzinfo=datetime.timezone.utc), 'time_taken': 246433.0, 'time_delta': '2 days, 20:27:13', 'additions': 44, 'deletions': 5, 'state': 'closed'}, {'id': 852261934, 'number': 610, 'closed': datetime.datetime(2022, 2, 14, 16, 42, 11, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 2, 14, 16, 27, 41, tzinfo=datetime.timezone.utc), 'time_taken': 870.0, 'time_delta': '0:14:30', 'additions': 8, 'deletions': 8, 'state': 'closed'}, {'id': 817532790, 'number': 601, 'closed': datetime.datetime(2022, 1, 30, 1, 6, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 1, 10, 11, 42, 42, tzinfo=datetime.timezone.utc), 'time_taken': 1689857.0, 'time_delta': '19 days, 13:24:17', 'additions': 47, 'deletions': 11, 'state': 'closed'}, {'id': 716884456, 'number': 564, 'closed': datetime.datetime(2021, 8, 20, 17, 15, 11, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 8, 20, 17, 12, 11, tzinfo=datetime.timezone.utc), 'time_taken': 180.0, 'time_delta': '0:03:00', 'additions': 9, 'deletions': 9, 'state': 'closed'}, {'id': 696301517, 'number': 556, 'closed': datetime.datetime(2021, 7, 24, 16, 42, 39, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 7, 24, 6, 11, 24, tzinfo=datetime.timezone.utc), 'time_taken': 37875.0, 'time_delta': '10:31:15', 'additions': 5, 'deletions': 80, 'state': 'closed'}, {'id': 679200538, 'number': 549, 'closed': datetime.datetime(2021, 8, 10, 17, 23, 20, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 28, 16, 40, 47, tzinfo=datetime.timezone.utc), 'time_taken': 3717753.0, 'time_delta': '43 days, 0:42:33', 'additions': 102, 'deletions': 38, 'state': 'closed'}, {'id': 676474420, 'number': 546, 'closed': datetime.datetime(2021, 6, 24, 17, 17, 1, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 23, 17, 14, 45, tzinfo=datetime.timezone.utc), 'time_taken': 86536.0, 'time_delta': '1 day, 0:02:16', 'additions': 23, 'deletions': 12, 'state': 'closed'}, {'id': 673903291, 'number': 544, 'closed': datetime.datetime(2021, 11, 23, 22, 8, 55, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 19, 16, 29, 36, tzinfo=datetime.timezone.utc), 'time_taken': 13585159.0, 'time_delta': '157 days, 5:39:19', 'additions': 104, 'deletions': 43, 'state': 'closed'}, {'id': 650272221, 'number': 521, 'closed': datetime.datetime(2021, 5, 21, 19, 56, 5, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 5, 21, 19, 45, 10, tzinfo=datetime.timezone.utc), 'time_taken': 655.0, 'time_delta': '0:10:55', 'additions': 1, 'deletions': 0, 'state': 'closed'}, {'id': 573139851, 'number': 466, 'closed': datetime.datetime(2021, 3, 9, 17, 18, 50, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 2, 14, 19, 24, 12, tzinfo=datetime.timezone.utc), 'time_taken': 1979678.0, 'time_delta': '22 days, 21:54:38', 'additions': 257, 'deletions': 40, 'state': 'closed'}, {'id': 571772490, 'number': 464, 'closed': datetime.datetime(2021, 5, 17, 19, 0, 7, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 2, 11, 12, 10, 39, tzinfo=datetime.timezone.utc), 'time_taken': 8232568.0, 'time_delta': '95 days, 6:49:28', 'additions': 530, 'deletions': 192, 'state': 'closed'}, {'id': 562036619, 'number': 443, 'closed': datetime.datetime(2021, 1, 30, 20, 0, 31, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 1, 26, 20, 27, 17, tzinfo=datetime.timezone.utc), 'time_taken': 343994.0, 'time_delta': '3 days, 23:33:14', 'additions': 49, 'deletions': 51, 'state': 'closed'}, {'id': 562016732, 'number': 442, 'closed': datetime.datetime(2021, 2, 25, 18, 22, 41, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 1, 26, 19, 49, 5, tzinfo=datetime.timezone.utc), 'time_taken': 2586816.0, 'time_delta': '29 days, 22:33:36', 'additions': 65, 'deletions': 7, 'state': 'closed'}, {'id': 561185582, 'number': 439, 'closed': datetime.datetime(2021, 1, 27, 22, 2, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 1, 25, 16, 4, 36, tzinfo=datetime.timezone.utc), 'time_taken': 194290.0, 'time_delta': '2 days, 5:58:10', 'additions': 2, 'deletions': 22, 'state': 'closed'}, {'id': 560004901, 'number': 436, 'closed': datetime.datetime(2021, 1, 24, 1, 37, 43, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 1, 22, 14, 36, 56, tzinfo=datetime.timezone.utc), 'time_taken': 126047.0, 'time_delta': '1 day, 11:00:47', 'additions': 47, 'deletions': 30, 'state': 'closed'}, {'id': 558342767, 'number': 432, 'closed': datetime.datetime(2021, 1, 20, 18, 48, 16, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 1, 20, 15, 51, 45, tzinfo=datetime.timezone.utc), 'time_taken': 10591.0, 'time_delta': '2:56:31', 'additions': 116, 'deletions': 97, 'state': 'closed'}, {'id': 558333752, 'number': 431, 'closed': datetime.datetime(2021, 1, 20, 15, 44, 52, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 1, 20, 15, 39, 5, tzinfo=datetime.timezone.utc), 'time_taken': 347.0, 'time_delta': '0:05:47', 'additions': 2, 'deletions': 2, 'state': 'closed'}, {'id': 554215469, 'number': 424, 'closed': datetime.datetime(2021, 1, 16, 1, 21, 36, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 1, 13, 14, 13, 56, tzinfo=datetime.timezone.utc), 'time_taken': 212860.0, 'time_delta': '2 days, 11:07:40', 'additions': 17, 'deletions': 77, 'state': 'closed'}, {'id': 541627034, 'number': 403, 'closed': datetime.datetime(2020, 12, 19, 5, 15, 33, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 12, 17, 6, 4, 31, tzinfo=datetime.timezone.utc), 'time_taken': 169862.0, 'time_delta': '1 day, 23:11:02', 'additions': 8, 'deletions': 0, 'state': 'closed'}, {'id': 541614083, 'number': 402, 'closed': datetime.datetime(2020, 12, 28, 4, 11, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 12, 17, 5, 32, 15, tzinfo=datetime.timezone.utc), 'time_taken': 945571.0, 'time_delta': '10 days, 22:39:31', 'additions': 28, 'deletions': 24, 'state': 'closed'}, {'id': 534233349, 'number': 390, 'closed': datetime.datetime(2020, 12, 30, 1, 0, 52, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 12, 8, 8, 0, 27, tzinfo=datetime.timezone.utc), 'time_taken': 1875625.0, 'time_delta': '21 days, 17:00:25', 'additions': 123, 'deletions': 66, 'state': 'closed'}, {'id': 529144618, 'number': 383, 'closed': datetime.datetime(2020, 12, 28, 4, 12, 53, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 11, 29, 17, 40, 53, tzinfo=datetime.timezone.utc), 'time_taken': 2457120.0, 'time_delta': '28 days, 10:32:00', 'additions': 50, 'deletions': 115, 'state': 'closed'}, {'id': 474066015, 'number': 348, 'closed': datetime.datetime(2020, 9, 1, 13, 55, 56, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 26, 18, 0, 18, tzinfo=datetime.timezone.utc), 'time_taken': 503738.0, 'time_delta': '5 days, 19:55:38', 'additions': 761, 'deletions': 0, 'state': 'closed'}, {'id': 465562071, 'number': 337, 'closed': datetime.datetime(2020, 8, 10, 15, 51, 44, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 10, 15, 11, 28, tzinfo=datetime.timezone.utc), 'time_taken': 2416.0, 'time_delta': '0:40:16', 'additions': 76, 'deletions': 18, 'state': 'closed'}, {'id': 462623014, 'number': 336, 'closed': datetime.datetime(2021, 2, 11, 12, 23, 22, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 4, 8, 47, 17, tzinfo=datetime.timezone.utc), 'time_taken': 16515365.0, 'time_delta': '191 days, 3:36:05', 'additions': 1612, 'deletions': 334, 'state': 'closed'}, {'id': 462619895, 'number': 335, 'closed': datetime.datetime(2020, 11, 16, 15, 39, 39, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 4, 8, 41, 31, tzinfo=datetime.timezone.utc), 'time_taken': 9010688.0, 'time_delta': '104 days, 6:58:08', 'additions': 588, 'deletions': 277, 'state': 'closed'}, {'id': 462611191, 'number': 334, 'closed': datetime.datetime(2020, 8, 13, 15, 30, 34, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 4, 8, 24, 49, tzinfo=datetime.timezone.utc), 'time_taken': 803145.0, 'time_delta': '9 days, 7:05:45', 'additions': 12, 'deletions': 8, 'state': 'closed'}, {'id': 462292927, 'number': 333, 'closed': datetime.datetime(2020, 8, 12, 15, 27, 27, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 3, 17, 4, 40, tzinfo=datetime.timezone.utc), 'time_taken': 771767.0, 'time_delta': '8 days, 22:22:47', 'additions': 32, 'deletions': 13, 'state': 'closed'}, {'id': 457667825, 'number': 329, 'closed': datetime.datetime(2020, 7, 28, 12, 41, 25, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 28, 9, 3, 20, tzinfo=datetime.timezone.utc), 'time_taken': 13085.0, 'time_delta': '3:38:05', 'additions': 9, 'deletions': 1, 'state': 'closed'}, {'id': 457330304, 'number': 328, 'closed': datetime.datetime(2020, 7, 27, 21, 56, 50, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 27, 18, 30, 26, tzinfo=datetime.timezone.utc), 'time_taken': 12384.0, 'time_delta': '3:26:24', 'additions': 5, 'deletions': 0, 'state': 'closed'}, {'id': 456765196, 'number': 327, 'closed': datetime.datetime(2020, 7, 26, 16, 8, 22, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 26, 15, 27, 7, tzinfo=datetime.timezone.utc), 'time_taken': 2475.0, 'time_delta': '0:41:15', 'additions': 0, 'deletions': 4, 'state': 'closed'}, {'id': 452200957, 'number': 326, 'closed': datetime.datetime(2020, 7, 22, 20, 29, 50, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 18, 23, 22, 51, tzinfo=datetime.timezone.utc), 'time_taken': 335219.0, 'time_delta': '3 days, 21:06:59', 'additions': 18, 'deletions': 17, 'state': 'closed'}, {'id': 452170276, 'number': 325, 'closed': datetime.datetime(2020, 7, 27, 20, 31, 31, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 18, 22, 9, 52, tzinfo=datetime.timezone.utc), 'time_taken': 771699.0, 'time_delta': '8 days, 22:21:39', 'additions': 201, 'deletions': 72, 'state': 'closed'}, {'id': 450158537, 'number': 324, 'closed': datetime.datetime(2020, 8, 12, 15, 43, 35, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 16, 12, 31, 10, tzinfo=datetime.timezone.utc), 'time_taken': 2344345.0, 'time_delta': '27 days, 3:12:25', 'additions': 316, 'deletions': 194, 'state': 'closed'}, {'id': 442300907, 'number': 315, 'closed': datetime.datetime(2020, 7, 9, 20, 57, 8, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 30, 21, 19, 45, tzinfo=datetime.timezone.utc), 'time_taken': 776243.0, 'time_delta': '8 days, 23:37:23', 'additions': 10, 'deletions': 7, 'state': 'closed'}, {'id': 442226480, 'number': 312, 'closed': datetime.datetime(2020, 7, 28, 21, 15, 3, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 30, 18, 43, 51, tzinfo=datetime.timezone.utc), 'time_taken': 2428272.0, 'time_delta': '28 days, 2:31:12', 'additions': 46, 'deletions': 85, 'state': 'closed'}, {'id': 442073779, 'number': 306, 'closed': datetime.datetime(2020, 8, 4, 8, 48, 6, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 30, 14, 33, 40, tzinfo=datetime.timezone.utc), 'time_taken': 3003266.0, 'time_delta': '34 days, 18:14:26', 'additions': 1163, 'deletions': 276, 'state': 'closed'}, {'id': 424607074, 'number': 290, 'closed': datetime.datetime(2020, 6, 15, 15, 9, 11, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 28, 16, 43, 30, tzinfo=datetime.timezone.utc), 'time_taken': 1549541.0, 'time_delta': '17 days, 22:25:41', 'additions': 10, 'deletions': 10, 'state': 'closed'}, {'id': 415757694, 'number': 289, 'closed': datetime.datetime(2020, 8, 14, 18, 7, 33, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 10, 18, 2, 53, tzinfo=datetime.timezone.utc), 'time_taken': 8294680.0, 'time_delta': '96 days, 0:04:40', 'additions': 1017, 'deletions': 293, 'state': 'closed'}, {'id': 413757410, 'number': 288, 'closed': datetime.datetime(2020, 5, 5, 21, 22, 51, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 5, 21, 16, 13, tzinfo=datetime.timezone.utc), 'time_taken': 398.0, 'time_delta': '0:06:38', 'additions': 1, 'deletions': 1, 'state': 'closed'}, {'id': 402756945, 'number': 283, 'closed': datetime.datetime(2020, 9, 29, 21, 1, 7, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 13, 17, 46, 5, tzinfo=datetime.timezone.utc), 'time_taken': 14613302.0, 'time_delta': '169 days, 3:15:02', 'additions': 669, 'deletions': 64, 'state': 'closed'}, {'id': 397073393, 'number': 280, 'closed': datetime.datetime(2020, 4, 4, 16, 47, 26, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 1, 15, 37, 17, tzinfo=datetime.timezone.utc), 'time_taken': 263409.0, 'time_delta': '3 days, 1:10:09', 'additions': 8, 'deletions': 0, 'state': 'closed'}, {'id': 387155495, 'number': 272, 'closed': datetime.datetime(2020, 3, 12, 13, 37, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 12, 10, 18, 36, tzinfo=datetime.timezone.utc), 'time_taken': 11914.0, 'time_delta': '3:18:34', 'additions': 1, 'deletions': 0, 'state': 'closed'}, {'id': 387148790, 'number': 271, 'closed': datetime.datetime(2020, 5, 5, 15, 16, 29, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 12, 10, 5, 19, tzinfo=datetime.timezone.utc), 'time_taken': 4684270.0, 'time_delta': '54 days, 5:11:10', 'additions': 147, 'deletions': 19, 'state': 'closed'}, {'id': 385974775, 'number': 269, 'closed': datetime.datetime(2020, 3, 12, 9, 38, 39, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 10, 7, 22, 51, tzinfo=datetime.timezone.utc), 'time_taken': 180948.0, 'time_delta': '2 days, 2:15:48', 'additions': 0, 'deletions': 0, 'state': 'closed'}, {'id': 374417309, 'number': 246, 'closed': datetime.datetime(2020, 2, 14, 11, 2, 24, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 2, 12, 16, 53, 9, tzinfo=datetime.timezone.utc), 'time_taken': 151755.0, 'time_delta': '1 day, 18:09:15', 'additions': 76, 'deletions': 55, 'state': 'closed'}, {'id': 369480564, 'number': 232, 'closed': datetime.datetime(2020, 2, 9, 18, 54, 24, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 1, 31, 9, 9, 33, tzinfo=datetime.timezone.utc), 'time_taken': 812691.0, 'time_delta': '9 days, 9:44:51', 'additions': 259, 'deletions': 274, 'state': 'closed'}, {'id': 369473429, 'number': 231, 'closed': datetime.datetime(2020, 1, 31, 8, 53, 7, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 1, 31, 8, 49, 14, tzinfo=datetime.timezone.utc), 'time_taken': 233.0, 'time_delta': '0:03:53', 'additions': 155, 'deletions': 157, 'state': 'closed'}]"
168432220,signac,glotzerlab/signac,Python,36,129,13,41,2564,10,55,1,"[{'id': 1216965355, 'number': 886, 'closed': datetime.datetime(2023, 1, 28, 3, 1, 17, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 1, 25, 18, 27, 49, tzinfo=datetime.timezone.utc), 'time_taken': 203608.0, 'time_delta': '2 days, 8:33:28', 'additions': 1, 'deletions': 1, 'state': 'closed'}, {'id': 1023113484, 'number': 807, 'closed': datetime.datetime(2022, 9, 18, 15, 41, 57, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 8, 10, 19, 26, 43, tzinfo=datetime.timezone.utc), 'time_taken': 3356114.0, 'time_delta': '38 days, 20:15:14', 'additions': 42, 'deletions': 148, 'state': 'closed'}, {'id': 452562220, 'number': 358, 'closed': datetime.datetime(2020, 8, 2, 22, 52, 27, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 19, 13, 23, 26, tzinfo=datetime.timezone.utc), 'time_taken': 1243741.0, 'time_delta': '14 days, 9:29:01', 'additions': 143, 'deletions': 104, 'state': 'closed'}, {'id': 391104732, 'number': 308, 'closed': datetime.datetime(2020, 4, 3, 18, 27, 36, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 19, 16, 24, 59, tzinfo=datetime.timezone.utc), 'time_taken': 1303357.0, 'time_delta': '15 days, 2:02:37', 'additions': 39, 'deletions': 5, 'state': 'closed'}, {'id': 373153392, 'number': 286, 'closed': datetime.datetime(2020, 2, 10, 16, 14, 58, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 2, 10, 14, 6, 47, tzinfo=datetime.timezone.utc), 'time_taken': 7691.0, 'time_delta': '2:08:11', 'additions': 6, 'deletions': 6, 'state': 'closed'}]"
168426142,signac-docs,glotzerlab/signac-docs,,18,8,10,31,245,30,17,0,"[{'id': 650680008, 'number': 134, 'closed': datetime.datetime(2021, 6, 9, 17, 21, 20, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 5, 22, 20, 8, 48, tzinfo=datetime.timezone.utc), 'time_taken': 1545152.0, 'time_delta': '17 days, 21:12:32', 'additions': 16, 'deletions': 2, 'state': 'closed'}, {'id': 579513962, 'number': 122, 'closed': datetime.datetime(2021, 6, 26, 19, 9, 4, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 2, 24, 18, 24, 49, tzinfo=datetime.timezone.utc), 'time_taken': 10543455.0, 'time_delta': '122 days, 0:44:15', 'additions': 193, 'deletions': 1, 'state': 'closed'}, {'id': 544585274, 'number': 107, 'closed': datetime.datetime(2021, 2, 4, 18, 35, 22, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 12, 23, 5, 51, 30, tzinfo=datetime.timezone.utc), 'time_taken': 3761032.0, 'time_delta': '43 days, 12:43:52', 'additions': 3, 'deletions': 0, 'state': 'closed'}, {'id': 531710168, 'number': 105, 'closed': datetime.datetime(2021, 1, 7, 15, 41, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 12, 3, 11, 29, 30, tzinfo=datetime.timezone.utc), 'time_taken': 3039090.0, 'time_delta': '35 days, 4:11:30', 'additions': 19, 'deletions': 10, 'state': 'closed'}, {'id': 454949661, 'number': 92, 'closed': datetime.datetime(2020, 8, 26, 16, 57, 49, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 22, 8, 0, 35, tzinfo=datetime.timezone.utc), 'time_taken': 3056234.0, 'time_delta': '35 days, 8:57:14', 'additions': 13, 'deletions': 4, 'state': 'closed'}, {'id': 413749643, 'number': 87, 'closed': datetime.datetime(2020, 5, 7, 5, 39, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 5, 20, 58, 10, tzinfo=datetime.timezone.utc), 'time_taken': 117690.0, 'time_delta': '1 day, 8:41:30', 'additions': 9, 'deletions': 0, 'state': 'closed'}]"

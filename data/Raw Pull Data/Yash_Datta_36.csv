pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
422431811,Add the Basic project framework,"This is the first PR in a series of PRs to address #1 
It adds the basic project framework, together with some plugins and basic README.

@JulienPeloton  request you to please review, in particular, the [document](https://github.com/saucam/grafink/blob/feature/BaseFw/docs/Schema-Model.md) on ```Schema Modelling``` and the questions in that document.",True,2,https://api.github.com/repos/astrolabsoftware/grafink/pulls/2,https://github.com/astrolabsoftware/grafink/pull/2,closed,1029,1,20,17,5,36,1,0,[{'name': 'framework'}],2020-05-24 15:47:37+00:00,2020-05-26 09:34:47+00:00,150430.0,"1 day, 17:47:10","[{'comment_id': 429809261, 'comment_body': '""The above creates a deployable zip file `target/universal/grafink-<version>.zip`...""', 'comment_created': datetime.datetime(2020, 5, 25, 8, 40, 19, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429810225, 'comment_body': 'Could we add support for Scala 2.11 as well? While 2.11 is deprecated in Spark 2.4.x, it is still widely used (it will be dropped only in Spark 3.0 which is not yet released).', 'comment_created': datetime.datetime(2020, 5, 25, 8, 42, 23, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429810847, 'comment_body': 'I had trouble with deduplication errors. We could had the following in the `build.sbt` to avoid such errors:\r\n```scala\r\nassemblyMergeStrategy in assembly := {\r\n  case PathList(""META-INF"", xs @ _*) => MergeStrategy.discard\r\n  case x => MergeStrategy.first\r\n }\r\n```\r\n', 'comment_created': datetime.datetime(2020, 5, 25, 8, 43, 31, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429811230, 'comment_body': 'I think it would be more informative to have the type of rows rather than example values. I will send you an updated version.', 'comment_created': datetime.datetime(2020, 5, 25, 8, 44, 22, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429811925, 'comment_body': 'You could add as a comment that the schema is subject to evolution. I need to add a schema version for HBase (I will let you know when it is available).', 'comment_created': datetime.datetime(2020, 5, 25, 8, 45, 45, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429812369, 'comment_body': '""Following alert properties will be **primarily** modelled as vertex labels""\r\n\r\nIdeally, there should be more.', 'comment_created': datetime.datetime(2020, 5, 25, 8, 46, 29, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429814790, 'comment_body': 'In the cluster, we are using the N-1 version (i.e. Spark 2.4.4 currently).', 'comment_created': datetime.datetime(2020, 5, 25, 8, 51, 11, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429815453, 'comment_body': 'Missing short documentation /* ... */', 'comment_created': datetime.datetime(2020, 5, 25, 8, 52, 29, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429815508, 'comment_body': 'Missing short documentation /* ... */', 'comment_created': datetime.datetime(2020, 5, 25, 8, 52, 36, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429819677, 'comment_body': 'If I unzip it, I have only:\r\n\r\n```bash\r\ngrafink julien$ ls target/universal/grafink-0.1.0-SNAPSHOT/\r\ntotal 0\r\ndrwxr-xr-x    4 julien  staff   128 25 May 10:54 bin\r\ndrwxr-xr-x  172 julien  staff  5504 25 May 10:54 lib\r\n\r\ngrafink julien$ ls target/universal/grafink-0.1.0-SNAPSHOT/bin/\r\ntotal 56\r\n-rwxr-xr-x  1 julien  staff  10693 25 May 10:36 grafink\r\n-rw-r--r--  1 julien  staff  14780 25 May 10:36 grafink.bat\r\n```\r\ni.e. the files above are missing', 'comment_created': datetime.datetime(2020, 5, 25, 9, 0, 42, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429823293, 'comment_body': 'For string-type property, we should match values.\r\nFor ML score (between 0 and 1), we should put a threshold (say naively 0.5). Alerts below 0.5 are of the same kind, and vice-versa. It could be more subtle later of course.\r\n', 'comment_created': datetime.datetime(2020, 5, 25, 9, 7, 47, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429824068, 'comment_body': 'This mainly concerns speed. User usually will just need a few of properties (object ID, time, ...). You can with object ID for example, and we will re-discuss that later.', 'comment_created': datetime.datetime(2020, 5, 25, 9, 9, 17, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429824482, 'comment_body': 'we want to connect the new alerts (add edges) with the existing alerts (vertices) in Janusgraph.', 'comment_created': datetime.datetime(2020, 5, 25, 9, 10, 5, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429826250, 'comment_body': 'We could also have a \'similarity\' edge that summarizes all edges between two vertices. To be more clear, if two vertices are connected by 4 edges (4 properties ""in common""), the \'similarity\' edge would be strength 4.', 'comment_created': datetime.datetime(2020, 5, 25, 9, 13, 45, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 429833501, 'comment_body': 'Oops extremely sorry for missing this. Let me fix this quickly.', 'comment_created': datetime.datetime(2020, 5, 25, 9, 27, 53, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 429833629, 'comment_body': 'Ok will add support for cross compiling', 'comment_created': datetime.datetime(2020, 5, 25, 9, 28, 8, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 429833799, 'comment_body': 'ok\r\n', 'comment_created': datetime.datetime(2020, 5, 25, 9, 28, 31, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 429879342, 'comment_body': 'Now while adding support for 2.11 I see that we would have to use older versions of common libraries should we chose to use them, since most are dropping this support.', 'comment_created': datetime.datetime(2020, 5, 25, 11, 15, 40, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430000416, 'comment_body': 'fixed now', 'comment_created': datetime.datetime(2020, 5, 25, 15, 55, 3, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430000480, 'comment_body': 'fixed', 'comment_created': datetime.datetime(2020, 5, 25, 15, 55, 10, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430118727, 'comment_body': 'Done', 'comment_created': datetime.datetime(2020, 5, 26, 1, 51, 11, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430119039, 'comment_body': 'Done', 'comment_created': datetime.datetime(2020, 5, 26, 1, 52, 46, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430172458, 'comment_body': 'According to the README, one should run `./bin/start.sh --config conf/application.conf`, hence `lib_dir` must be:\r\n\r\n```bash\r\nlib_dir=$(cd ""$(dirname ${BASH_SOURCE[0]})""/../lib; pwd)\r\n```\r\n\r\n(otherwise I have path mismatch).', 'comment_created': datetime.datetime(2020, 5, 26, 6, 0, 31, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430173239, 'comment_body': '`SPARK_MASTER` needs to be defined as env variable prior to run the job. It might not be the case - hence it would be good to test its value and send an error message if empty (or have a default value).', 'comment_created': datetime.datetime(2020, 5, 26, 6, 2, 55, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430173755, 'comment_body': 'All those options above are rather specific. Could it be adapted depending on the environment we deploy? A minima, we should have a local[*] case to allow testing. Otherwise on production, we currently use mesos. ', 'comment_created': datetime.datetime(2020, 5, 26, 6, 4, 44, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430181029, 'comment_body': ""This option has been deprecated;\r\n```\r\n20/05/26 08:24:41 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been\r\ndeprecated as of Spark 2.3 and may be removed in the future. Please use the new key \r\n'spark.executor.memoryOverhead' instead.\r\n```"", 'comment_created': datetime.datetime(2020, 5, 26, 6, 25, 30, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430182004, 'comment_body': 'If I test the script locally with `SPARK_MASTER=local[*]`, i get:\r\n\r\n```\r\ngrafink-0.1.0-SNAPSHOT julien$ ./bin/start.sh --config ""conf/application.conf""\r\nRunning spark-submit...\r\n20/05/26 08:24:41 WARN SparkConf: The configuration key \'spark.yarn.executor.memoryOverhead\' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key \'spark.executor.memoryOverhead\' instead.\r\n20/05/26 08:24:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\nError: Option --config must be a valid file path\r\njanusloader 0.13.0\r\nUsage: janusloader [options]\r\n\r\n  -c, --config <value>  config accepts path to a configuration file\r\nlog4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).\r\nlog4j:WARN Please initialize the log4j system properly.\r\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\r\n```\r\n\r\nwhat do I miss?', 'comment_created': datetime.datetime(2020, 5, 26, 6, 28, 5, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430185825, 'comment_body': 'Yes but then we have to specify the environment while creating the package.\r\nHmm, let me think what can be done', 'comment_created': datetime.datetime(2020, 5, 26, 6, 37, 42, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430185908, 'comment_body': 'Ok will change', 'comment_created': datetime.datetime(2020, 5, 26, 6, 37, 54, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430207172, 'comment_body': 'As discussed, there should be only one package, with different run commands (or scripts, like `start_prod.sh`, `start_local.sh`, ...)', 'comment_created': datetime.datetime(2020, 5, 26, 7, 25, 37, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430215827, 'comment_body': 'This `basename` causes the failure when I run `./bin/start.sh --config conf/application.conf`. Why do you need it?', 'comment_created': datetime.datetime(2020, 5, 26, 7, 42, 24, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430216550, 'comment_body': 'This clashes with the default `spark.network.timeout` value:\r\n```\r\nException in thread ""main"" java.lang.IllegalArgumentException: requirement failed: The value of \r\nspark.network.timeout=120000ms must be no less than the value of spark.executor.heartbeatInterval=120000ms.\r\n```\r\n\r\nI would remove `--conf spark.executor.heartbeatInterval=120s` unless you have a good reason to keep it.', 'comment_created': datetime.datetime(2020, 5, 26, 7, 43, 48, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 430254678, 'comment_body': 'thanks for pointing this out, i forgot to push changes to the start script since it is generated from the bash template', 'comment_created': datetime.datetime(2020, 5, 26, 8, 49, 15, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430254867, 'comment_body': 'yes defaulted to local', 'comment_created': datetime.datetime(2020, 5, 26, 8, 49, 35, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430255577, 'comment_body': 'this is needed when running in cluster mode, because at that time, spark uploads the files as well. Just changed it to overwrite it when using local mode.', 'comment_created': datetime.datetime(2020, 5, 26, 8, 50, 43, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 430255805, 'comment_body': 'removed', 'comment_created': datetime.datetime(2020, 5, 26, 8, 51, 4, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}]","[{'commit_sha': '664a4cd3f0ee9261ba6fee1726b4aaad56ba48f9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'aef36969e61594606f7f65d2e2fbe2c8dcfc482c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3d374c28cafa16d7e2ed0695fc0d69792fcd1c8c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '850adf4568808e3a51dbf43188367a6a6a7790eb', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2d4701c9b78a3c9052b4195baa78a78e8d714f06', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '051d1740234eb8c8bd2b3ccd6cb9bfcf0170d930', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '81548d6f6e4c022115a73201600b5d32c17261f4', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '0b39fa4cd57927782a5e5c2eb7b1f4be3817e03d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2602a3a4aec486f13bfb219d1b73e02eb00be4e6', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'd2587590c58b508f01a74ee13ce158d4766a25ae', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '848849d347ceaf45657074d2d809f0c08464abe8', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8ecd1cdbeb01536c266ef197abd2ef1edc893f18', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '95c1c571bba9d7f90ef363080bea053fa6211ec4', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '6beb58ea42e7081a6920ad208b0c005e4285116a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c92afa9c1a2898e191759b5ce387fb95d70c39ad', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9e8ec630f2603e4dcb2369e2be9861ab59d3c1ba', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2ccabdbd9780b284be382ef0b2e3374cf64f575d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
423785022,Propose Data loading approaches,"This PR proposes the data loading approaches based on the Schema Model, further addressing the next steps of #1 

It also adds a design for how to load data from parquet files into hbase

@JulienPeloton
@hrivnac 
kindly review and share your thoughts on the same.",True,3,https://api.github.com/repos/astrolabsoftware/grafink/pulls/3,https://github.com/astrolabsoftware/grafink/pull/3,closed,245,0,4,8,1,10,0,0,[],2020-05-27 11:24:47+00:00,2020-06-04 08:26:47+00:00,680520.0,"7 days, 21:02:00","[{'comment_id': 431669075, 'comment_body': 'JanusGraph 0.5.1 is currently installed (N-1)', 'comment_created': datetime.datetime(2020, 5, 28, 8, 30, 44, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 431669426, 'comment_body': 'I am not sure if we have changed anything yet. @hrivnac should know.', 'comment_created': datetime.datetime(2020, 5, 28, 8, 31, 17, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 431669886, 'comment_body': 'Yes, the parquet data is partitioned by year/month/day/hour - so it should be easy to target a particular day to ingest.', 'comment_created': datetime.datetime(2020, 5, 28, 8, 32, 4, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 431685330, 'comment_body': 'Yes, we should have this capability. It can happen if we reprocess historical data, and push reprocessed data to JanusGraph. It should not happen frequently though.', 'comment_created': datetime.datetime(2020, 5, 28, 8, 57, 46, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 431688378, 'comment_body': ""For the proof of concept, let's use a very simple edge label:\r\n- two vertices would be linked if they share the same vertex property value.\r\n- there would be one single edge label, called 'similarity', and its value would be the sum of all links between two vertices.\r\n\r\nExample\r\nvertex 1: prop1='foo', prop2='bar', prop3='foobar'\r\nvertex 2: prop1='foo', prop2='toto', prop3='foobar'\r\n\r\nvertex1 -> similarity(=2) -> vertex2 (and vice-versa: vertex2 -> similarity(=2) -> vertex1).\r\n\r\nIt would evolve over time, but let's start with this simple graph first to build the architecture."", 'comment_created': datetime.datetime(2020, 5, 28, 9, 2, 56, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 431691276, 'comment_body': 'hm, the ticket has not received attention in a year. Not sure there will be an implementation soon.', 'comment_created': datetime.datetime(2020, 5, 28, 9, 7, 56, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 431692073, 'comment_body': 'This sounds a no-go, as we will have to add edges to existing vertices while writing data each time. So the associated I/O cost would be overwhelming...', 'comment_created': datetime.datetime(2020, 5, 28, 9, 9, 19, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 433797197, 'comment_body': 'JanusGraph is installed on 134.158.74.85:/opt/janusgraph.\r\nYou can run it locally via:\r\n/opt/janusgraph/bin/gremlin.sh\r\nand connecting:\r\ngraph = JanusGraphFactory.build().set(""storage.backend"", ""hbase"").set(""storage.hostname"", ""134.158.74.54"").set(""storage.hbase.table"", ""janusgraph"").open()\r\ng = graph.traversal()\r\n\r\nYou probably should create your own HBase table (not ""janusgraph"") for development.\r\n\r\nServer is started/stopped via:\r\nJANUSGRAPH_YAML=${janusgraph_dir}/conf/gremlin-server/jhtools.yaml ${janusgraph_dir}/bin/gremlin-server.sh start\r\nJANUSGRAPH_YAML=${janusgraph_dir}/conf/gremlin-server/jhtools.yaml ${janusgraph_dir}/bin/gremlin-server.sh stop\r\n\r\nIf you want to run it remotely, you should get conf/IJCLab.yaml file and use in germlin:\r\n\r\n:remote connect tinkerpop.server conf/IJCLab.yaml session\r\n:remote console\r\n\r\nOtherwise, nothing has been modified.', 'comment_created': datetime.datetime(2020, 6, 2, 11, 11, 2, tzinfo=datetime.timezone.utc), 'commenter': 'hrivnac', 'type': 'User'}, {'comment_id': 433811319, 'comment_body': 'thanks !', 'comment_created': datetime.datetime(2020, 6, 2, 11, 39, 41, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 434003728, 'comment_body': ""That could be an example. But I think, we should be a bit more generic. I.e. just to offer a possibility (API) to create Edges based on a certain characteristics. In this particular case:\r\n1) The way to express 'similarity' in code.\r\n2) The API to allow to apply 1) to the data (and to do updates later).  "", 'comment_created': datetime.datetime(2020, 6, 2, 16, 14, 26, tzinfo=datetime.timezone.utc), 'commenter': 'hrivnac', 'type': 'User'}]","[{'commit_sha': 'bcd1a2e4e1121910b3950739fcfc449938bd99df', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '490de4e5f8630db272763e3fee6c34bbcdd76706', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8db5289c2f13a6256c381b37cdf4dbde352e1070', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'a8be93887939307957fe3ba3e39b23d232962395', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c6494904769325c64bc154d617f7ccc84e082542', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '1c8f43f7b368015fa52837bd6c33d2009fcd13c1', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'd599336a5fdab1412f805276b9af7490d209518d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'bafdb9ddda7db05a9ab3b3e7b81e08cc8d8f8913', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
425621853,"Move to zio framework, add startdate and duration params","This PR continues to further consolidate the base framework for the project as part of #1 
Here we move to [Zio](https://github.com/zio/zio) to make the code purely functional.
Some immediate benefits include
- Ability to test every module
- Some essential constructs like ```ensuring``` or ```brackets``` that make it easier to further develop the spark job

Have also added 2 more command line params ```startdate``` and ```duration```
Moved the spark parameters to the bash script so we can trigger spark-submit based on target envrionment",True,4,https://api.github.com/repos/astrolabsoftware/grafink/pulls/4,https://github.com/astrolabsoftware/grafink/pull/4,closed,764,121,22,8,2,5,0,0,[],2020-05-31 14:44:33+00:00,2020-06-04 12:41:26+00:00,338213.0,"3 days, 21:56:53","[{'comment_id': 434317890, 'comment_body': 'What is driving the max value for `duration`? ', 'comment_created': datetime.datetime(2020, 6, 3, 5, 34, 55, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 434328154, 'comment_body': 'Just the maximum amount of data that we want to process at a given time ?', 'comment_created': datetime.datetime(2020, 6, 3, 6, 8, 48, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 434329160, 'comment_body': 'OK - so probably a week is more than enough (for LSST, we would have about a TB per night).', 'comment_created': datetime.datetime(2020, 6, 3, 6, 11, 47, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 434535121, 'comment_body': 'ok , let me change this\r\n', 'comment_created': datetime.datetime(2020, 6, 3, 12, 39, 46, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 435177985, 'comment_body': '> Thanks, it looks good to me! I did not know ZIO yet, so it took me some time to explore it - nice!\r\n\r\nI am exploring it properly myself :)', 'comment_created': datetime.datetime(2020, 6, 4, 11, 17, 53, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}]","[{'commit_sha': '4b40b519e53dc3af5e988aba89d7f623a25d8d6a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3ab2e8d587978a8e4a9dcdfedbd70ea5a6b1fe07', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'bdd3714d6a4bcbdc3eb743915779285289dc6559', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '393532c130802a968c9604008db5f55595b30e34', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '0e09619573cc21795672cb965363dbe57044e4e9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9ef9e7ede635c3b9a96f6b27226d77df21426f19', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7b1f1e9e69f4fd7e2a4852c87e1c4e574edf8841', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'da143779f8ff598c9ef27b752c03c84247f10eb8', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
443923744,Decouple EdgeProcessor from data to be loaded,"This PR addresses #12 , where we strive to generalize grafink, so that the data model and schema (data specific changes) are limited to the VertexClassifier rules.
This is a step in the direction of making grafink more general for loading any data into JanusGraph",True,14,https://api.github.com/repos/astrolabsoftware/grafink/pulls/14,https://github.com/astrolabsoftware/grafink/pull/14,closed,110,40,7,2,3,0,0,0,[],2020-07-03 08:23:41+00:00,2020-07-03 10:09:40+00:00,6359.0,1:45:59,[],"[{'commit_sha': 'ffd28f4b8c9089e196bff3bb28e7290cf6b34a6a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3f4ca154e72cf5e68fc90b8a222a21b8e511ab3b', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
443990881,Fix sbt-buildInfo error,"This PR fixes #9 and adds codecov config file, updates name of start script as well",True,15,https://api.github.com/repos/astrolabsoftware/grafink/pulls/15,https://github.com/astrolabsoftware/grafink/pull/15,closed,20,10,7,1,1,0,0,0,[],2020-07-03 10:46:01+00:00,2020-07-03 11:22:56+00:00,2215.0,0:36:55,[],"[{'commit_sha': '2cd0b343fdd582de5eca3ab4021b5afe7685f8b9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
444269614,Update the grafink architecture,,True,17,https://api.github.com/repos/astrolabsoftware/grafink/pulls/17,https://github.com/astrolabsoftware/grafink/pull/17,closed,18,12,1,1,1,0,0,0,[],2020-07-04 10:48:29+00:00,2020-07-04 15:30:12+00:00,16903.0,4:41:43,[],"[{'commit_sha': 'ae4c5daabb7ee55382b6ccdbc61a8ddcac896f17', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
444421776,Add support for data deletion,This PR addresses #11  by adding a CL parameter ```--delete``` that runs Grafink in delete mode and deletes the data for the  startDate and duration. Also there is a configurable option to remove IDManager data on successful data deletion from the graph.,False,18,https://api.github.com/repos/astrolabsoftware/grafink/pulls/18,https://github.com/astrolabsoftware/grafink/pull/18,closed,403,125,20,4,2,0,0,0,[],2020-07-05 15:22:57+00:00,2020-07-11 15:06:13+00:00,517396.0,"5 days, 23:43:16",[],"[{'commit_sha': 'd71e378619e09fd41139ff18aa6e82ea194ccd05', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'abdc991cefa42a82007e03b346a82a49195fbe8e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7f05e2ed10d8ef008d20d148a12566268ebda71c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'eeb523b2a06858a9b969e797cd9e5bd97d842d06', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
448252281,Introduce grafink-shell,"This PR adds a grafink-shell to address requirement #21 of a CLI tool to query the loaded data in JnausGraph (backed by HBase)
",True,22,https://api.github.com/repos/astrolabsoftware/grafink/pulls/22,https://github.com/astrolabsoftware/grafink/pull/22,closed,317,44,18,7,3,6,1,0,[{'name': 'shell'}],2020-07-13 13:21:33+00:00,2020-07-24 11:58:45+00:00,945432.0,"10 days, 22:37:12","[{'comment_id': 459226906, 'comment_body': 'It would be probably good to mention the default in the README as well', 'comment_created': datetime.datetime(2020, 7, 23, 5, 51, 16, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 459366130, 'comment_body': '`asScala` needs JavaConverters loaded - could you add `import scala.collection.JavaConverters._` in the example?', 'comment_created': datetime.datetime(2020, 7, 23, 10, 52, 47, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 459387642, 'comment_body': 'ok', 'comment_created': datetime.datetime(2020, 7, 23, 11, 41, 2, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 459944090, 'comment_body': 'Let me add this to default imports when starting the shell instead', 'comment_created': datetime.datetime(2020, 7, 24, 9, 20, 35, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 459945057, 'comment_body': 'sounds good to me!', 'comment_created': datetime.datetime(2020, 7, 24, 9, 22, 46, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 459967961, 'comment_body': 'updated readme', 'comment_created': datetime.datetime(2020, 7, 24, 10, 14, 50, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}]","[{'commit_sha': '0a6232586a8e1737a89982aaeebeac755a55a92e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'f383b8938b6875484f51bb13e97bf6fbcb2c5988', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c4257e1bb7d9bad7e40c21bf46bc8472c3633d27', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9827ccb00aebc3218e1760fa87767357c5fc785f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '60da5f86c4b9eac4a7c732ad05ea87e5e0e7d9ff', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '294f1bc8d515794832d077d205000f05f2d18e46', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2faea95f5d7c0a6d46ff31b7719d40d442277be3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
461825272,Introduce REST interface to grafink loaded data,"This PR addresses #23.  We restructure the grafink code into 3 separate submodules

```common``` which is common code for both data loading job and the api. This is cross-compiled for both scala 2.11 and 2.12

```core``` which is the grafink spark job code to bulk load data into ```Janusgraph```. This is cross-compiled for both scala 2.11 and 2.12

```api``` which forms the module for REST api to Janusgraph data. Currently I have added only 1 API ```info``` to retrieve Vertex and Edge labels of the graph backed by supplied ```tableName```. This code is only compiled for scala 2.12

This PR also address #26  and #27 by adding ability to add new columns into the read data from existing columns using arbitrary sql expressions
",True,28,https://api.github.com/repos/astrolabsoftware/grafink/pulls/28,https://github.com/astrolabsoftware/grafink/pull/28,closed,1554,309,77,18,3,12,0,0,[],2020-08-02 15:59:31+00:00,2020-08-10 06:29:10+00:00,656979.0,"7 days, 14:29:39","[{'comment_id': 464946686, 'comment_body': 'Minor: After creating the distribution, if I unzip the file I get all subfolders (`lib`, `conf`, `bin`) inside the root of the project:\r\n```\r\n$ unzip api/...\r\n$ ls\r\ndrwxr-xr-x  180 julien  staff   5760  4 Aug 11:29 lib\r\ndrwxr-xr-x    3 julien  staff     96  4 Aug 11:29 conf\r\ndrwxr-xr-x    3 julien  staff     96  4 Aug 11:29 bin\r\ndrwxr-xr-x    4 julien  staff    128  4 Aug 11:21 target\r\ndrwxr-xr-x    6 julien  staff    192  4 Aug 08:56 api\r\n-rw-r--r--    1 julien  staff   1731  3 Aug 08:50 build.sbt\r\ndrwxr-xr-x    4 julien  staff    128  3 Aug 08:41 common\r\ndrwxr-xr-x    6 julien  staff    192  3 Aug 08:41 core\r\ndrwxr-xr-x    8 julien  staff    256  3 Aug 08:40 project\r\ndrwxr-xr-x    7 julien  staff    224  3 Aug 08:37 docs\r\n-rw-r--r--    1 julien  staff    284  3 Aug 08:37 codecov.yaml\r\n-rw-r--r--    1 julien  staff  18606  3 Aug 08:37 README.md\r\n-rwxr-xr-x    1 julien  staff  12738  3 Aug 08:37 scalastyle-config.xml\r\n-rw-r--r--    1 julien  staff  11357  3 Aug 08:37 LICENSE\r\n```\r\nIt would be cleaner to put them inside a folder named `grafink-api-<version>` as it is done for `core`.', 'comment_created': datetime.datetime(2020, 8, 4, 10, 13, 7, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 465004977, 'comment_body': 'The header of the file is missing', 'comment_created': datetime.datetime(2020, 8, 4, 12, 13, 29, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 465005181, 'comment_body': 'The header of the file is missing', 'comment_created': datetime.datetime(2020, 8, 4, 12, 13, 53, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 465005256, 'comment_body': 'The header of the file is missing', 'comment_created': datetime.datetime(2020, 8, 4, 12, 14, 3, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 465005329, 'comment_body': 'The header of the file is missing', 'comment_created': datetime.datetime(2020, 8, 4, 12, 14, 13, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 465008106, 'comment_body': 'The file header is missing.', 'comment_created': datetime.datetime(2020, 8, 4, 12, 19, 30, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 465008248, 'comment_body': 'The file header is missing.', 'comment_created': datetime.datetime(2020, 8, 4, 12, 19, 47, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 467542028, 'comment_body': 'This is fixed now', 'comment_created': datetime.datetime(2020, 8, 9, 6, 12, 5, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 467542042, 'comment_body': 'added', 'comment_created': datetime.datetime(2020, 8, 9, 6, 12, 11, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 467542048, 'comment_body': 'added', 'comment_created': datetime.datetime(2020, 8, 9, 6, 12, 15, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 467542051, 'comment_body': 'added', 'comment_created': datetime.datetime(2020, 8, 9, 6, 12, 19, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 467542055, 'comment_body': 'added', 'comment_created': datetime.datetime(2020, 8, 9, 6, 12, 23, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}]","[{'commit_sha': 'bef6d704424d83d1c560995ac0d9c88a67545284', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'fa155eaf4e8ac99289ee38bbd26a153f2aecaae4', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '0c848ff7863206d47c4e5cc97faa6fd10a1f7b21', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '256ac20232ef0a66b29b0843d58692f17aa6362d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9a592c953dc87af4c4eb784c540ef38ffe87aa77', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '71e4c5336069c89528c03912a6333c1f9b7bc10c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '169ad1ea9f122af6cfbfc6924c7a1e7e3062c3f8', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'b2de2c3c2a911441e0b32fc08f0370a8234ac1c6', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '1b432d3cabde1240c0b11baeb39d24b63c33afbe', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '07d7c95039384d3366ec325eef0ab89b63a2ee07', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'e302eb6ffbc53f253cd76d3af7a465af837a099d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'f00174425ffdb7a3502ae74662ea44e8f7fc685b', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '94e59872765242890bfdb947520b4380fd0a9728', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '108de9b8b80d92cf1639c4d1933f2d4a0ec8fbe3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '1f4a990094792ac5d22d09c0d42c48ccf4ecf230', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'e7d0640c03ee1e3bb3daac824f066efd2ecb5857', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '82394ba81b9e18525a197c0b733289cdcb64f7f1', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '88a1a9792227ec6f34ea03745167d32d9fc6ce27', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
466689554,Add the TwoMode graph representation VertexClassiferRule,"This PR address #29 by adding a ```TwoModeClassifier``` rule for two mode graph representation. Attempt has been made to make this feature as generic as possible, by driving the fixed ```similarity``` vertices via a csv file. Also, recipes are configurable and can be applied by changing the config.
Currently supported recipes are:

```
- supernova
- microlensing
- catalog
- asteroids
```

This PR also addresses #30 by adding a ```SameValueClassifier``` to link alerts having same vertex property values for eg: ```objectId```. Note that computing this requires an inner join between data to be loaded and existing data, so need to be careful which column to configure for this rule",True,31,https://api.github.com/repos/astrolabsoftware/grafink/pulls/31,https://github.com/astrolabsoftware/grafink/pull/31,closed,1880,273,40,15,1,0,0,0,[],2020-08-12 10:59:57+00:00,2020-08-24 06:24:41+00:00,1020284.0,"11 days, 19:24:44",[],"[{'commit_sha': '70425a6758c52a3701cc5da9aa3f9a342cc55413', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '5c2036d1e9e68f4859574212f90d33ff8cf674e6', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '1577cb4525162b3ce7965fc9e989e5455107b011', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'b42486602955427a57b487216815b38d355a77d3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7836605a819b72e782a27d0ebd2a94e7ca4a6c4e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8b115b1cf35a7685ee196074377d3e1b10504143', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9a8fb403f8eb44d1f038424b036109882798427f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '1d3093df74b7ffd25d2a1ba45575e589cf633a0f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'b90f8a533e2fb9a8f8adfc29fe4cf769cb8f3eee', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'd2730388af6bdafd9da060a140830e3dd3bc2437', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'e632e00997b173985e6d93291ec71fe708c73780', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3088e7a4544383db579d33493b40524cb62bdb93', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '5048b117491a64017958a40bb043fb9efea7ec4a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '4ed88a619e839b0f9dab19bbc75b63faadc78353', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'f24c6668fd28f1a5e69ed4b3bfba675e42960aac', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
473144691,Make changes for new vertex properties and change supernova recipe,This PR addresses #35 ,True,38,https://api.github.com/repos/astrolabsoftware/grafink/pulls/38,https://github.com/astrolabsoftware/grafink/pull/38,closed,105,45,10,2,1,0,0,0,[],2020-08-25 11:42:03+00:00,2020-08-26 08:45:59+00:00,75836.0,21:03:56,[],"[{'commit_sha': 'd57138042be7f294b604457704bc2e347e492794', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'bd1958c1f4655628c9b75bb5335c1ed3503fe0d9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
472345860,Udpdate the schema documentation,"This PR brings updates in the Schema model due to recent change (#36). Note that this PR only focuses on the change for `Janusgraph Schema Model`, but we need to revisit also other sections (vertices, edges, Data Insertion Algorithm, ...). The other changes will be done in another PR.",True,37,https://api.github.com/repos/astrolabsoftware/grafink/pulls/37,https://github.com/astrolabsoftware/grafink/pull/37,closed,133,138,1,3,1,6,2,0,"[{'name': 'documentation'}, {'name': 'schema'}]",2020-08-24 08:12:19+00:00,2020-08-27 08:58:15+00:00,261956.0,"3 days, 0:45:56","[{'comment_id': 475473700, 'comment_body': 'probaBly remove these', 'comment_created': datetime.datetime(2020, 8, 24, 9, 38, 22, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 475474882, 'comment_body': 'These are described here: \r\n\r\nhttps://github.com/astrolabsoftware/grafink/blob/master/docs/classifiers/VertexClassifiers.md\r\n\r\nwe probably need to update this file now', 'comment_created': datetime.datetime(2020, 8, 24, 9, 40, 26, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 476394924, 'comment_body': 'Do you mean all the code block?', 'comment_created': datetime.datetime(2020, 8, 25, 12, 3, 13, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 476465998, 'comment_body': 'No i meant 1 row(s)', 'comment_created': datetime.datetime(2020, 8, 25, 13, 53, 13, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 477135751, 'comment_body': 'OK, done.', 'comment_created': datetime.datetime(2020, 8, 26, 8, 42, 56, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 477136003, 'comment_body': 'Updated. Do you want to further update?', 'comment_created': datetime.datetime(2020, 8, 26, 8, 43, 20, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}]","[{'commit_sha': '64ca23278468bc4743f3a5ed859421c90f947faa', 'committer_username': 'JulienPeloton', 'committer_name': 'Julien', 'committer_email': None, 'commit_date': datetime.datetime(2016, 7, 12, 20, 17, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '26cdf94e16010c7997f25f7476692fd6710b118a', 'committer_username': 'JulienPeloton', 'committer_name': 'Julien', 'committer_email': None, 'commit_date': datetime.datetime(2016, 7, 12, 20, 17, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b4984363c9605149ba93263507df18b842b00f53', 'committer_username': 'JulienPeloton', 'committer_name': 'Julien', 'committer_email': None, 'commit_date': datetime.datetime(2016, 7, 12, 20, 17, 20, tzinfo=datetime.timezone.utc)}]",Julien,20426972,,User,,60,,29,50
474395260,Fix VertexClassifier documentation,"The image links were pointing to my own repo, fixing that in this PR",True,39,https://api.github.com/repos/astrolabsoftware/grafink/pulls/39,https://github.com/astrolabsoftware/grafink/pull/39,closed,15,6,3,4,2,0,0,0,[],2020-08-27 01:51:33+00:00,2020-08-27 08:57:51+00:00,25578.0,7:06:18,[],"[{'commit_sha': 'c050aea91b2921616635329b0b1508aa9d11b32b', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '80b2f6089c154c2d17423d1db939b478aef4a1ae', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'aefd624f0474ee40b73317deafd9031825dd3359', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '746e76d3773cc3eda7ffa6f2d79a5f26933786cc', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
474633646,"Add API documentation, add benchmark for TwoModeClassifier","This PR adds API documentation
It also changes the default parallelism when loading edges that are less than 25K to 50",True,40,https://api.github.com/repos/astrolabsoftware/grafink/pulls/40,https://github.com/astrolabsoftware/grafink/pull/40,closed,169,4,4,2,1,0,0,0,[],2020-08-27 11:24:29+00:00,2020-08-27 14:04:49+00:00,9620.0,2:40:20,[],"[{'commit_sha': '93d0610c7ad1e2730d73eb403863c0854efd213e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ac896da8f01fe5d693f031146947c47e6376fd1a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102
474789711,Fix Edge Loading,"This PR adds another fix to the data bug that was encountered previously, as we need to commit the transaction between adding the edge and its reverse edge",True,41,https://api.github.com/repos/astrolabsoftware/grafink/pulls/41,https://github.com/astrolabsoftware/grafink/pull/41,closed,3,2,2,2,1,5,0,0,[],2020-08-27 15:42:59+00:00,2020-08-28 09:24:05+00:00,63666.0,17:41:06,"[{'comment_id': 478877568, 'comment_body': 'Interesting - between the previous run and this one, there were only 0.04% more edge loaded (from 980989 to 981364) but the edge load time is almost doubled. Any ideas?', 'comment_created': datetime.datetime(2020, 8, 28, 7, 18, 26, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 478878102, 'comment_body': 'Or this is because it has to perform a full scan anyway for reverse edge (even if there are a few)?', 'comment_created': datetime.datetime(2020, 8, 28, 7, 19, 40, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}, {'comment_id': 478946925, 'comment_body': 'Actually it has to do a commit of the transaction between the two edge additions now. Previously, it was only committing at the end, for both the 2 additions, so this is an increase in time per edge creation and hence a jump in time taken.\r\nOn the other hand, the API itself is not very reliable in committing the transactions, so it seems it was working most of the times but only skipping adding the edges on a few occasions (which could be due to multiple commits happening in parallel due to spark)', 'comment_created': datetime.datetime(2020, 8, 28, 8, 36, 14, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 478948952, 'comment_body': 'So basically the number of missed edges is random, and depends on each job run', 'comment_created': datetime.datetime(2020, 8, 28, 8, 38, 20, tzinfo=datetime.timezone.utc), 'commenter': 'saucam', 'type': 'User'}, {'comment_id': 479012863, 'comment_body': 'OK, that makes sense - thanks!', 'comment_created': datetime.datetime(2020, 8, 28, 9, 23, 29, tzinfo=datetime.timezone.utc), 'commenter': 'JulienPeloton', 'type': 'User'}]","[{'commit_sha': '9e8f45210a0af46e02ee9f0a4faf6a1a57a83366', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'b0e254bb301251f449b423fe9bdcde4151d20cb0', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Yash Datta,1253893,yd2590@columbia.edu,User,,146,,256,102

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
263824953,grafink,astrolabsoftware/grafink,Scala,5,6,5,2,40,4,4,0,"[{'id': 528912054, 'number': 44, 'closed': datetime.datetime(2020, 12, 2, 21, 13, 8, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 11, 28, 8, 34, 25, tzinfo=datetime.timezone.utc), 'time_taken': 391123.0, 'time_delta': '4 days, 12:38:43', 'additions': 69, 'deletions': 0, 'state': 'closed'}, {'id': 497245367, 'number': 43, 'closed': datetime.datetime(2020, 10, 5, 4, 29, 26, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 10, 3, 9, 18, 31, tzinfo=datetime.timezone.utc), 'time_taken': 155455.0, 'time_delta': '1 day, 19:10:55', 'additions': 16, 'deletions': 1, 'state': 'closed'}, {'id': 476147193, 'number': 42, 'closed': datetime.datetime(2020, 9, 2, 19, 20, 7, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 31, 8, 27, 2, tzinfo=datetime.timezone.utc), 'time_taken': 211985.0, 'time_delta': '2 days, 10:53:05', 'additions': 34, 'deletions': 0, 'state': 'closed'}, {'id': 474789711, 'number': 41, 'closed': datetime.datetime(2020, 8, 28, 9, 24, 5, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 27, 15, 42, 59, tzinfo=datetime.timezone.utc), 'time_taken': 63666.0, 'time_delta': '17:41:06', 'additions': 3, 'deletions': 2, 'state': 'closed'}, {'id': 474633646, 'number': 40, 'closed': datetime.datetime(2020, 8, 27, 14, 4, 49, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 27, 11, 24, 29, tzinfo=datetime.timezone.utc), 'time_taken': 9620.0, 'time_delta': '2:40:20', 'additions': 169, 'deletions': 4, 'state': 'closed'}, {'id': 474395260, 'number': 39, 'closed': datetime.datetime(2020, 8, 27, 8, 57, 51, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 27, 1, 51, 33, tzinfo=datetime.timezone.utc), 'time_taken': 25578.0, 'time_delta': '7:06:18', 'additions': 15, 'deletions': 6, 'state': 'closed'}, {'id': 473144691, 'number': 38, 'closed': datetime.datetime(2020, 8, 26, 8, 45, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 25, 11, 42, 3, tzinfo=datetime.timezone.utc), 'time_taken': 75836.0, 'time_delta': '21:03:56', 'additions': 105, 'deletions': 45, 'state': 'closed'}, {'id': 466689554, 'number': 31, 'closed': datetime.datetime(2020, 8, 24, 6, 24, 41, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 12, 10, 59, 57, tzinfo=datetime.timezone.utc), 'time_taken': 1020284.0, 'time_delta': '11 days, 19:24:44', 'additions': 1880, 'deletions': 273, 'state': 'closed'}, {'id': 461825272, 'number': 28, 'closed': datetime.datetime(2020, 8, 10, 6, 29, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 2, 15, 59, 31, tzinfo=datetime.timezone.utc), 'time_taken': 656979.0, 'time_delta': '7 days, 14:29:39', 'additions': 1554, 'deletions': 309, 'state': 'closed'}, {'id': 448252281, 'number': 22, 'closed': datetime.datetime(2020, 7, 24, 11, 58, 45, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 13, 13, 21, 33, tzinfo=datetime.timezone.utc), 'time_taken': 945432.0, 'time_delta': '10 days, 22:37:12', 'additions': 317, 'deletions': 44, 'state': 'closed'}, {'id': 447778944, 'number': 20, 'closed': datetime.datetime(2020, 7, 17, 8, 10, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 11, 15, 5, 40, tzinfo=datetime.timezone.utc), 'time_taken': 493506.0, 'time_delta': '5 days, 17:05:06', 'additions': 763, 'deletions': 195, 'state': 'closed'}, {'id': 444421776, 'number': 18, 'closed': datetime.datetime(2020, 7, 11, 15, 6, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 5, 15, 22, 57, tzinfo=datetime.timezone.utc), 'time_taken': 517396.0, 'time_delta': '5 days, 23:43:16', 'additions': 403, 'deletions': 125, 'state': 'closed'}, {'id': 444269614, 'number': 17, 'closed': datetime.datetime(2020, 7, 4, 15, 30, 12, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 4, 10, 48, 29, tzinfo=datetime.timezone.utc), 'time_taken': 16903.0, 'time_delta': '4:41:43', 'additions': 18, 'deletions': 12, 'state': 'closed'}, {'id': 443990881, 'number': 15, 'closed': datetime.datetime(2020, 7, 3, 11, 22, 56, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 3, 10, 46, 1, tzinfo=datetime.timezone.utc), 'time_taken': 2215.0, 'time_delta': '0:36:55', 'additions': 20, 'deletions': 10, 'state': 'closed'}, {'id': 443923744, 'number': 14, 'closed': datetime.datetime(2020, 7, 3, 10, 9, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 3, 8, 23, 41, tzinfo=datetime.timezone.utc), 'time_taken': 6359.0, 'time_delta': '1:45:59', 'additions': 110, 'deletions': 40, 'state': 'closed'}, {'id': 434270202, 'number': 7, 'closed': datetime.datetime(2020, 7, 1, 6, 41, 6, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 15, 3, 53, 12, tzinfo=datetime.timezone.utc), 'time_taken': 1392474.0, 'time_delta': '16 days, 2:47:54', 'additions': 2840, 'deletions': 99, 'state': 'closed'}, {'id': 425621853, 'number': 4, 'closed': datetime.datetime(2020, 6, 4, 12, 41, 26, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 31, 14, 44, 33, tzinfo=datetime.timezone.utc), 'time_taken': 338213.0, 'time_delta': '3 days, 21:56:53', 'additions': 764, 'deletions': 121, 'state': 'closed'}, {'id': 423785022, 'number': 3, 'closed': datetime.datetime(2020, 6, 4, 8, 26, 47, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 27, 11, 24, 47, tzinfo=datetime.timezone.utc), 'time_taken': 680520.0, 'time_delta': '7 days, 21:02:00', 'additions': 245, 'deletions': 0, 'state': 'closed'}, {'id': 422431811, 'number': 2, 'closed': datetime.datetime(2020, 5, 26, 9, 34, 47, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 24, 15, 47, 37, tzinfo=datetime.timezone.utc), 'time_taken': 150430.0, 'time_delta': '1 day, 17:47:10', 'additions': 1029, 'deletions': 1, 'state': 'closed'}]"

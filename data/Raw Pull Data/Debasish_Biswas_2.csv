pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
1366246232,Adding modules that will have the Vert.x implementations of the kafka communication,"Module setup for #2928 

## Proposed Changes

- empty modules `Receiver-vertx` & `Producer-vertx` added.


",True,3106,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3106,https://github.com/knative-extensions/eventing-kafka-broker/pull/3106,closed,136,0,5,5,5,2,5,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/L'}, {'name': 'ok-to-test'}, {'name': 'area/data-plane'}]",2023-05-26 12:09:59+00:00,2023-05-31 08:51:36+00:00,420097.0,"4 days, 20:41:37","[{'comment_id': 1209887596, 'comment_body': ""Can we do this when we need to enable preview features?\r\n\r\nI'd also add this flag only on the modules that need preview features instead of being on the top-level pom file."", 'comment_created': datetime.datetime(2023, 5, 30, 8, 11, 3, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1210051163, 'comment_body': 'Done ☺️', 'comment_created': datetime.datetime(2023, 5, 30, 10, 10, 19, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}]","[{'commit_sha': '26ee8955acb15cda96cc883fd67718b21662ac42', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '6711f5e6bc0af9ad95757b973b46d64d8a732226', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'a5651828be77754aed41b508efc8bbd55c167c9b', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7095b2f78b75a8012d4a9aa8d5d3eade06b349a3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7aae1d017e61a011a658e1f32b8bf59e052718b7', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1375557871,ReactiveKafkaProducer Interface and it's Vert.x Implementation,"Progress for #2928 

## Proposed Changes

- Identified what Kafka Producer Functions are used in Base Reciever Module
- Implemented those Methods in receiver Vert.x Module
",True,3131,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3131,https://github.com/knative-extensions/eventing-kafka-broker/pull/3131,closed,180,3,4,4,6,2,4,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/L'}, {'name': 'area/data-plane'}]",2023-06-02 10:48:39+00:00,2023-06-06 10:36:27+00:00,344868.0,"3 days, 23:47:48","[{'comment_id': 1217677796, 'comment_body': 'Can we use `map` instead of the additional promise here?\r\n\r\nhttps://vertx.io/docs/apidocs/io/vertx/core/Future.html#map-java.util.function.Function-\r\n\r\nSomething like this:\r\n```java\r\n    public Future<RecordMetadata> send(ProducerRecord<K,V> record) {\r\n        return this.producer.send(KafkaProducerRecord.create(record.topic(), record.value()))\r\n          .map(record -> new RecordMetadata(\r\n                new TopicPartition(record.topic(), vertxRecordMetadata.getPartition()),\r\n                    vertxRecordMetadata.getOffset(), 0, vertxRecordMetadata.getTimestamp(), -1, -1\r\n        ));\r\n    }\r\n```', 'comment_created': datetime.datetime(2023, 6, 5, 7, 58, 49, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1217679365, 'comment_body': 'Can we add Javadocs on the interfaces `ReactiveProducerFactory` and `ReactiveKafkaProducer` at least?', 'comment_created': datetime.datetime(2023, 6, 5, 8, 0, 7, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}]","[{'commit_sha': 'c72007f02bcea2d0ec6b6c5bfc2e365a1fba3f5a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'e04dde7f04148d30695991117b5a0f5995b8b064', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ea95745cf008579aa80a5fbe639df0f908fc8f24', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '823b059fa213fe6834445aaff4726a5331604536', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1384687722,Migrate base receiver module to use `ReactiveKafkaProducer` instead of `KafkaProducer`,"Progress on #2928 

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Replace Vert.x `KafkaProducer` with `ReactiveKafkaProducer` and `ReactiveProducerFactory`
- Use `vertxreceiver` modules `main()` method as an entry point and call the `receiver` module `start()`[old main method] with the `VertxProducerFactory` object as an argument.
- Create `MockReactiveKafkaProducer` and `MockReactiveProducerFactory` for test case implementation.
- Replacing all the Vert.x KafkaProducer in tests.

",True,3142,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3142,https://github.com/knative-extensions/eventing-kafka-broker/pull/3142,closed,384,149,25,17,15,25,4,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/XL'}, {'name': 'area/data-plane'}]",2023-06-08 15:26:44+00:00,2023-06-19 10:06:53+00:00,931209.0,"10 days, 18:40:09","[{'comment_id': 1226511623, 'comment_body': 'The issue of `ReceiverVerticleTest` failing is due to not using the `producer` parameter\r\n\r\nI did this:\r\n\r\n`MockReactiveProducerFactory`\r\n```java\r\npackage dev.knative.eventing.kafka.broker.receiver;\r\n\r\nimport java.util.Properties;\r\n\r\nimport org.apache.kafka.clients.producer.MockProducer;\r\nimport org.apache.kafka.clients.producer.Producer;\r\n\r\nimport io.cloudevents.CloudEvent;\r\nimport io.vertx.core.Vertx;\r\n\r\npublic class MockReactiveProducerFactory implements ReactiveProducerFactory<String, CloudEvent> {\r\n\r\n  @Override\r\n  public ReactiveKafkaProducer<String, CloudEvent> create(Vertx v, Properties config) {\r\n    return new MockReactiveKafkaProducer<String, CloudEvent>(new MockProducer<>());\r\n  }\r\n\r\n  public static ReactiveKafkaProducer<String, CloudEvent> createStatic(Vertx v,\r\n                                                                       Producer<String, CloudEvent> producer) {\r\n    return new MockReactiveKafkaProducer<String, CloudEvent>(producer);\r\n  }\r\n\r\n}\r\n```\r\n`MockReactiveKafkaProducer`\r\n```java\r\npackage dev.knative.eventing.kafka.broker.receiver;\r\n\r\nimport io.vertx.core.Promise;\r\nimport org.apache.kafka.clients.producer.Callback;\r\nimport org.apache.kafka.clients.producer.Producer;\r\nimport org.apache.kafka.clients.producer.ProducerRecord;\r\nimport org.apache.kafka.clients.producer.RecordMetadata;\r\n\r\nimport io.cloudevents.CloudEvent;\r\nimport io.vertx.core.Future;\r\n\r\npublic class MockReactiveKafkaProducer<K, V> implements ReactiveKafkaProducer<String, CloudEvent> {\r\n\r\n  private final Producer<String, CloudEvent> producer;\r\n\r\n  public MockReactiveKafkaProducer(Producer<String, CloudEvent> producer) {\r\n    this.producer = producer;\r\n  }\r\n\r\n  @Override\r\n  public Future<Void> close() {\r\n    producer.close();\r\n    return Future.succeededFuture();\r\n  }\r\n\r\n  @Override\r\n  public Future<Void> flush() {\r\n    producer.flush();\r\n    return Future.succeededFuture();\r\n  }\r\n\r\n  @Override\r\n  public Future<RecordMetadata> send(ProducerRecord<String, CloudEvent> record) {\r\n    final Promise<RecordMetadata> p = Promise.promise();\r\n    producer.send(record, (metadata, exception) -> {\r\n      if (exception != null) {\r\n        p.fail(exception);\r\n      } else {\r\n        p.complete(metadata);\r\n      }\r\n    });\r\n    return p.future();\r\n  }\r\n\r\n  @Override\r\n  public org.apache.kafka.clients.producer.Producer<String, CloudEvent> unwrap() {\r\n    return producer;\r\n  }\r\n}\r\n```', 'comment_created': datetime.datetime(2023, 6, 12, 11, 29, 21, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1229794189, 'comment_body': '```suggestion\r\n      <version>${project.version}</version>\r\n      <classifier>tests</classifier>\r\n```', 'comment_created': datetime.datetime(2023, 6, 14, 15, 16, 25, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1229836933, 'comment_body': ""I think we're missing this in the receiver module?\r\n\r\nhttps://github.com/knative-sandbox/eventing-kafka-broker/blob/898e479be20128819351ca341aff9d4e6f8ba50e/data-plane/core/pom.xml#L207-L219"", 'comment_created': datetime.datetime(2023, 6, 14, 15, 46, 19, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1231845657, 'comment_body': '```suggestion\r\n</project>\r\n\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 6, 47, 51, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1231846858, 'comment_body': '```suggestion\r\n                          final ReactiveProducerFactory<String, CloudEvent> kafkaProducerFactory) {\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 6, 48, 45, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232115254, 'comment_body': 'Can you describe why do we need 2 methods instead of only 1?', 'comment_created': datetime.datetime(2023, 6, 16, 11, 16, 10, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232116660, 'comment_body': '```suggestion\r\n    ReactiveKafkaProducer<K, V> create(Vertx v, Properties config);\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 11, 17, 44, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232116813, 'comment_body': '```suggestion\r\n    ReactiveKafkaProducer<K, V> create(Vertx v, Producer<K, V> producer);\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 11, 17, 57, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232125505, 'comment_body': 'Do we need the static methods or we can use the instance methods? with like:\r\n\r\n```\r\nnew MockReactiveProducerFactory().create(...)\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 11, 27, 38, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232142459, 'comment_body': 'public is unnecessary on interface methods', 'comment_created': datetime.datetime(2023, 6, 16, 11, 47, 7, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232144682, 'comment_body': '```suggestion\r\npublic class IngressRequestHandlerImpl implements IngressRequestHandler {\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 11, 48, 44, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232145479, 'comment_body': '```suggestion\r\n  public static void start(final String[] args, final ReactiveProducerFactory kafkaProducerFactory) throws IOException {\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 11, 49, 11, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232150954, 'comment_body': ""If we don't remove this from here, we can remove the method\r\n```\r\n    @Test\r\n    public void traceIsPropagated() throws ExecutionException, InterruptedException, TimeoutException {\r\n        super.traceIsPropagated();\r\n    }\r\n```\r\nin the subclass"", 'comment_created': datetime.datetime(2023, 6, 16, 11, 54, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232151350, 'comment_body': '```suggestion\r\n        return new VertxProducerFactory<>();\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 11, 54, 29, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232152057, 'comment_body': '```suggestion\r\n        return new VertxKafkaProducer<>(v, config);\r\n    }\r\n    \r\n    public ReactiveKafkaProducer<K, V> create(Vertx v, Producer<K, V> producer) {\r\n        return new VertxKafkaProducer<>(v, producer);\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 11, 55, 16, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232157951, 'comment_body': 'I think we might only need the one with the producer in input and we can remove the other one, and replace the usage in `ReceiverVerticleFactory` with something like this?\r\n\r\n```java\r\nproperties -> kafkaProducerFactory.create(v, new KafkaProducer<>(properties))\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 12, 1, 53, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232206348, 'comment_body': 'I have provided two methods to create producer\r\none for\r\nhttps://github.com/knative-sandbox/eventing-kafka-broker/blob/898e479be20128819351ca341aff9d4e6f8ba50e/data-plane/receiver/src/main/java/dev/knative/eventing/kafka/broker/receiver/main/ReceiverVerticleFactory.java#L66\r\n\r\nand another one for \r\nhttps://github.com/knative-sandbox/eventing-kafka-broker/blob/898e479be20128819351ca341aff9d4e6f8ba50e/data-plane/receiver/src/test/java/dev/knative/eventing/kafka/broker/receiver/impl/ReceiverVerticleTracingTest.java#L111\r\n\r\nYes we can have ` kafkaProducerFactory.create(v, new KafkaProducer<>(properties))` and wrap it up in the vertex module using vertx `kafkaProducer.create(vertx v, Producer p)`', 'comment_created': datetime.datetime(2023, 6, 16, 12, 46, 53, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1232234423, 'comment_body': 'This class is `abstract` now, so need to run the tests from the subclass. Or this test not showing In the IDE to run.\r\nI think we need to have the method of subclass.', 'comment_created': datetime.datetime(2023, 6, 16, 13, 11, 25, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1232236418, 'comment_body': 'It works for me by:\r\n- Adding `@Test` back here\r\n- removing traceIsPropagated in the subclass\r\n\r\na similar example is `UnorderedConsumerVerticleTest` with `AbstractConsumerVerticleTest`', 'comment_created': datetime.datetime(2023, 6, 16, 13, 13, 20, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1232270547, 'comment_body': 'Yes `UnorderedConsumerVerticleTest` with `AbstractConsumerVerticleTest` have the same approach and in my VS-Code IDE they are also not showing as tests that I can run.\r\nI think I should switch to IntelliJ for Java development at least. But my laptop does not allow it, it became so laggy with browser, slack and JetBrains IDE. 😅😅', 'comment_created': datetime.datetime(2023, 6, 16, 13, 41, 34, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1232272887, 'comment_body': 'I have removed the `staticCreate` and use `new MockReactiveProducerFactory().create(...)` instead.', 'comment_created': datetime.datetime(2023, 6, 16, 13, 43, 44, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1232273967, 'comment_body': 'done', 'comment_created': datetime.datetime(2023, 6, 16, 13, 44, 8, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1232282668, 'comment_body': '```suggestion\r\n        return DataPlaneContract.Reference.newBuilder().build();\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 13, 51, 17, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1232558755, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2023, 6, 16, 17, 51, 6, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1233837398, 'comment_body': 'Which VS-code plugin for Java are you using?', 'comment_created': datetime.datetime(2023, 6, 19, 10, 10, 6, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}]","[{'commit_sha': '6b5a72ca9e4c8f5208b6fa8bc48b68bc59addee4', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2dca1436b003a7a6458668f826d5f8a5eeae07e6', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'aa5d33d7aa41f7256968a82cb207a5e105b11a32', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '80b66559c00803cf73b1757ff0ed264344912032', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '71a18a437d574313443ced2d0cc90a65b5890b86', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'a0cf7f1ac493af0ac83110875f44c28766a75445', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'bdbb11987c036b729765c31487b425322a69a822', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ba14c8678061c1e54e1f237feb7ae2baca6bf007', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'a066a898c5c9652706e7e036a1eb663d08f170ba', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '4ac3218673371b631a9f34688c9c91e13b3a8be3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '0f11c41f76893bda2373c325a8422b389abce6ab', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '730bce7e576f5fb7a3638a05f280d63907280326', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '300823c7e43d267b0277bdd1168f4970a46893ef', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ffd6aa40a06622246f6962f10fb2a18e94c13d88', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '47874dae8b8d49417bcb5c43cea018542236ccca', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '52528d93360d6dfe69936a88aff4587b470bead3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8fcba1614f761f62dfacb230dd32ec5a4cfbfadf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1400366570,`ReactiveKafkaConsumer` Interface and it's Vert.x Implementation,"Progress on #2928 


<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Identifies all the Consumer functions used and needs to be implemented in specialised modules.
- Implement all of these methods in the dispatcher vertx module with vertx implementation.

It may require some additional changes while migrating the base dispatcher to use `ReactiveKafkaConsumer`

",True,3159,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3159,https://github.com/knative-extensions/eventing-kafka-broker/pull/3159,closed,256,3,4,8,7,6,5,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/L'}, {'name': 'ok-to-test'}, {'name': 'area/data-plane'}]",2023-06-20 18:57:15+00:00,2023-06-26 15:51:53+00:00,507278.0,"5 days, 20:54:38","[{'comment_id': 1241744193, 'comment_body': 'Do we need the assign method? If `assign` is used only for testing, I think we should find a different solution for testing', 'comment_created': datetime.datetime(2023, 6, 26, 7, 27, 28, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1241757811, 'comment_body': 'Yes, It is used only for testing. okay we can implement `assign` method on the mockConsumer, we need for testing.', 'comment_created': datetime.datetime(2023, 6, 26, 7, 37, 52, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1241819535, 'comment_body': '```suggestion\r\n    Future<Map<TopicPartition, OffsetAndMetadata>> commit(Map<TopicPartition, OffsetAndMetadata> offset);\r\n```', 'comment_created': datetime.datetime(2023, 6, 26, 8, 29, 46, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1241822460, 'comment_body': '```suggestion\r\n    public Future<Map<TopicPartition, OffsetAndMetadata>> commit(Map<TopicPartition, OffsetAndMetadata> offset){\r\n\r\n        Map<io.vertx.kafka.client.common.TopicPartition, io.vertx.kafka.client.consumer.OffsetAndMetadata> vertxOffset = new HashMap<>();\r\n\r\n        for(Map.Entry<TopicPartition, OffsetAndMetadata> entry: offset.entrySet()){\r\n            vertxOffset.put(\r\n                new io.vertx.kafka.client.common.TopicPartition(entry.getKey().topic(), entry.getKey().partition()),\r\n                new io.vertx.kafka.client.consumer.OffsetAndMetadata(entry.getValue().offset(), entry.getValue().metadata())\r\n            );\r\n        }\r\n        \r\n        return consumer.commit(vertxOffset).map( v -> {\r\n            Map<TopicPartition, OffsetAndMetadata> result = new HashMap<>();\r\n            for(Map.Entry<io.vertx.kafka.client.common.TopicPartition,io.vertx.kafka.client.consumer.OffsetAndMetadata> entry: v.entrySet()){\r\n                result.put(\r\n                    new TopicPartition(entry.getKey().getTopic(), entry.getKey().getPartition()),\r\n                    new OffsetAndMetadata(entry.getValue().getOffset(), entry.getValue().getMetadata())\r\n                );\r\n            }\r\n            return result;\r\n        });\r\n    }\r\n```', 'comment_created': datetime.datetime(2023, 6, 26, 8, 31, 52, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1241828345, 'comment_body': 'For both `for loop`s before commit and inside `map`, can we use the Stream API?\r\n\r\nFor example:\r\n```java\r\nfinal var vertxOffset = offset.entrySet().stream()\r\n  .map(entry -> new SimpleImmutableEntry<>(\r\n      new io.vertx.kafka.client.common.TopicPartition(entry.getKey().topic(), entry.getKey().partition()),\r\n      new io.vertx.kafka.client.consumer.OffsetAndMetadata(entry.getValue().offset(), entry.getValue().metadata())\r\n  ))\r\n  .collect(Collectors.toMap(Entry::getKey, Entry::getValue))\r\n```', 'comment_created': datetime.datetime(2023, 6, 26, 8, 36, 48, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1241832065, 'comment_body': 'If we use the stream API (see comment below), this commit can be resolved', 'comment_created': datetime.datetime(2023, 6, 26, 8, 39, 55, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}]","[{'commit_sha': 'ff2ce9d855a439ab8da8adcbf3cf051ceb234da2', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'd595c9d36bb0539ae50a0154f0b9fe4faf25f6d0', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7f7730b11163b1ee7e1adb2e63d4a19b44a602bd', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7de947f79becf5d842ba5182baca7586fb5fad05', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '68efcf0208c5fa3757e2586068ec3fd3b3a6d35f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '416d81db24723d1975ba0a3727d846aa40404272', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '51092a881d6e3ae18c736fc8b7148218a1ce0823', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'cfef09065bbb0459bd5f349e7ef2a45078d76e76', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1410473469,Migrate current dispatcher to use `ReactiveKafkaConsumer` instead of Vertx KafkaConsumer.,"progress #2928 
The new dispatcher-vertx module is the one that uses Vertx implementation.

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Remove all the Vertx Kafka client dependencies from the base dispatcher module.
- Change the current `main()` to `start(..)` and call from the other module with specialised Consumer implementation as args.
- migrate all the tests from Direct KafkaConsumer to use ReactiveKafkaConsumer Interface.

## Aditional Info

- The implementation of passing handler function to `ConsumerRebalanceListener` has gotten complex. I will simplify that further in the future.
- Tests for the dispatcher-vertx module are not there as vertx implementations are already well tested.",True,3177,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3177,https://github.com/knative-extensions/eventing-kafka-broker/pull/3177,closed,526,763,42,19,9,2,4,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/XXL'}, {'name': 'area/data-plane'}]",2023-06-27 19:18:53+00:00,2023-07-04 07:21:38+00:00,561765.0,"6 days, 12:02:45","[{'comment_id': 1247722193, 'comment_body': 'We can use a for loop here:\r\n```suggestion\r\n    for (final var record : records) {\r\n```', 'comment_created': datetime.datetime(2023, 6, 30, 10, 39, 1, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1251124881, 'comment_body': ""It's Done."", 'comment_created': datetime.datetime(2023, 7, 3, 17, 2, 11, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}]","[{'commit_sha': '98540aa5370942f3e54b4c98489a03e85a642e8b', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8c2ee6f024fe81a8d5dfe046bd72616aa55de381', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c177c6e270fe6a90045edfc1e161ed3955caf78a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8ded997ab07db3c97d4b323ae5835594acb5c528', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'de96bb4c80996aeddebd8a17c45850a668fd2e1f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '1985f9b2450298a18e4626e206a37e44d8f47018', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c92064c855e2f4994f5f7fbefe3312a0f8359c23', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c981de6be56e3d4acf86ebb106aff7a74c0de08f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '93c5ec242e1132f01c57366a613e44bf5b185a36', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'a9c994acb74762501d598166ece5c9f44b09df17', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '318813aff0007b030d45141243456a6176e801af', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '27f70d756dc06f7ae57fa769e96f39af24c9d2b7', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ce8cf428db84ccb107e0eb425101466899e19f25', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '6149102049c4aef984d450423b0dbe659bf2f708', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2c076582282e95888e438a57922a1c76eab8425f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '0fe0d11dd1f10132d5ad15ad36762a8c4470209f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'be13474aebf9fb977b45e833040c5129c4f49dd3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ca1dadee3bc77a685396f31ad1616825b4837717', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ebff3831256a54adbc56ae2f18f0e4e815c02757', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1414564092,Upgrade workflow's java version to 20,"As we are planning to build the receiver and dispatcher with loom virtual thread through #2928  the workflow needs to upgrade to 20+ JAVA version.

## Proposed Changes

- Update the `knative-java-test` and `knative-profile-data-plane` to use JAVA 20. 
- Update the `dependent-bot` java version to 17 the current LTS.
",True,3186,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3186,https://github.com/knative-extensions/eventing-kafka-broker/pull/3186,closed,3,3,3,2,6,0,4,1,"[{'name': 'approved'}, {'name': 'size/XS'}, {'name': 'lgtm'}, {'name': 'area/test'}]",2023-06-30 09:29:18+00:00,2023-07-06 10:26:40+00:00,521842.0,"6 days, 0:57:22",[],"[{'commit_sha': 'e5352f06f1d9e6e4d26f37d7870e80ed45fbab85', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '4215c65f169ca56c68e2ba858f91ea4770e3535e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1429806609,Remove the use of `KafkaProducer` from the dispatcher and use `ReactiveKafkaProducer` instead,"Fixes #3191 and progress in #2928

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

A clean, without-conflict clone PR of #3192",True,3206,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3206,https://github.com/knative-extensions/eventing-kafka-broker/pull/3206,closed,166,178,44,9,7,7,4,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/L'}, {'name': 'area/data-plane'}]",2023-07-11 16:31:44+00:00,2023-07-13 15:06:14+00:00,167670.0,"1 day, 22:34:30","[{'comment_id': 1260845739, 'comment_body': 'Why this CE SDK version change?', 'comment_created': datetime.datetime(2023, 7, 12, 8, 55, 48, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1260847207, 'comment_body': ""Can't we reuse the existing mock and factory?"", 'comment_created': datetime.datetime(2023, 7, 12, 8, 56, 50, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1260911306, 'comment_body': ""There was a merger conflict and the CE SDK versions were changed in #3183. \r\nfrom My end, I have just added\r\n```\r\n(Unknown license) receiver-vertx (dev.knative.eventing.kafka.broker:receiver-vertx:1.0-SNAPSHOT - no url defined)\r\n```\r\n\r\nWhile resolving the merge conflict all of these are showing, I don't know why."", 'comment_created': datetime.datetime(2023, 7, 12, 9, 42, 24, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1260933034, 'comment_body': 'Okay I have changed to use the existing receiver Mock into dispatcher module', 'comment_created': datetime.datetime(2023, 7, 12, 9, 59, 40, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1260954697, 'comment_body': 'You might need to rebase the latest main branch', 'comment_created': datetime.datetime(2023, 7, 12, 10, 18, 14, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1260958877, 'comment_body': 'Oh, wait. I mistakenly removed the upgrades version. while resolving conflict.', 'comment_created': datetime.datetime(2023, 7, 12, 10, 21, 49, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1260960968, 'comment_body': 'Done.', 'comment_created': datetime.datetime(2023, 7, 12, 10, 23, 29, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}]","[{'commit_sha': '8d622a74ddb77d0cd67a6fea7737dec32bdea415', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '73cc567d23455664043814c8ecdf19979addd4cf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '303fe5e561e9b3e853556822a8456b5fd11daacd', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '6a204eb6ee3f0b14bbf1b79ebac52e1bd88abbe5', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'd9b84a9175b843411b597ff89777ccf5c3542dc0', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '175cd6d293b565154d6f8b12c2fec2a1df3d3a39', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'db8f22d21f2b3294a3179439877fc1a8a710224c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ad98ad491b5ae6bfa1677d50ca78d0371634c3dd', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7b05f36f33612f38e4c7bd541f3e16a46e8f56b9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1429900097,Remove `ConsumerRebalanceListener` from `ConsumerVerticleContext`,"A clean conflict-free PR of #3195

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Put the `ConsumerRebalanceListener` into `ConsumerVerticle`
",True,3207,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3207,https://github.com/knative-extensions/eventing-kafka-broker/pull/3207,closed,45,39,8,3,9,0,4,1,"[{'name': 'approved'}, {'name': 'size/M'}, {'name': 'lgtm'}, {'name': 'area/data-plane'}]",2023-07-11 17:32:07+00:00,2023-07-13 15:06:22+00:00,164055.0,"1 day, 21:34:15",[],"[{'commit_sha': 'c4d8cbb1ab095d3ae4c6ef40f6fd6ef6008f0ded', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8b2d531759eed68e2188cfa6d09598f3af669f3c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7ace30ccf84b8fbac3fe0a290422d26e9d0ad6eb', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1432617991,Adding the Loom base modules with empty files.,"Progress in #2928 

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Added both loom-based modules with Java 19 as the latest Maven shade plugin does not support Java20 till now.
- Lower the Java version to 19 in tests as Every version has its exact preview feature and does not work in other versions.
Updates in latter comment
",True,3211,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3211,https://github.com/knative-extensions/eventing-kafka-broker/pull/3211,closed,302,0,9,8,6,0,5,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/L'}, {'name': 'area/data-plane'}, {'name': 'area/test'}]",2023-07-13 08:16:13+00:00,2023-07-14 03:12:15+00:00,68162.0,18:56:02,[],"[{'commit_sha': '247d8868cecd02c1592942198338f6532bc55734', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '06fe46a923150727d7e2e90e0853be5435208f6b', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '28d025eedfaef710d2a2d7c1dc05b3b4ceb115bf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '0545b96a4df32a156c658928920b72fe00c68061', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9c9d4b086a76403a94e458dc56fe7e703ededdc7', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3ead7188a6fadb92686a2859ae3918c610f1bbc0', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '96edabea34fcb121e82df76bc81cf473d57900f5', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'dbdd532d5c484a38eef042e19c020aff0b748005', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1435950205,Add Receiver loom based module Implementation,"Progress in #2928 

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Loom-based module implementation
- KafkaProducer unit Test
- modify the tests module DataPlaneTest to be runnable  for both vertx and loom modules

<!--
If this change has user-visible impact, follow the instructions below.
Examples include:

- :gift: Add new feature
- :bug: Fix bug
- :broom: Update or clean up current behavior
- :wastebasket: Remove feature or internal logic

Otherwise delete the rest of this template.
-->

**Release Note**

<!--
:page_facing_up: If this change has user-visible impact, write a release note in the block
below. Include the string ""action required"" if additional action is required of
users switching to the new release, for example in case of a breaking change.

Write as if you are speaking to users, not other Knative contributors. If this
change has no user-visible impact, no release-note is needed.
-->

```release-note

```

**Docs**

<!--
:book: If this change has user-visible impact, link to an issue or PR in
https://github.com/knative/docs.
-->
",True,3215,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3215,https://github.com/knative-extensions/eventing-kafka-broker/pull/3215,closed,831,28,17,36,10,42,4,2,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/XL'}, {'name': 'area/data-plane'}]",2023-07-15 15:55:59+00:00,2023-08-01 15:47:47+00:00,1468308.0,"16 days, 23:51:48","[{'comment_id': 1276302963, 'comment_body': 'This will hard loop, we can maybe `Thread.sleep(2000L)`?', 'comment_created': datetime.datetime(2023, 7, 27, 13, 43, 29, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1278840580, 'comment_body': 'Did after close() sendFromQueue VThread will get end or it will get preempted in the background as it is in an infinite loop, May need to change the condition.', 'comment_created': datetime.datetime(2023, 7, 31, 6, 28, 11, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1278912709, 'comment_body': 'In addition, we need to interrupt the thread on close because it might be waiting on `take()` and it will never exit', 'comment_created': datetime.datetime(2023, 7, 31, 7, 51, 17, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1278945952, 'comment_body': 'Yes, we can do that. \r\n\r\nand for interrupting the sendFromQueue thread on close I am using `while (!isClosed.get() || !eventQueue.isEmpty())`', 'comment_created': datetime.datetime(2023, 7, 31, 8, 20, 51, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1278951163, 'comment_body': '> In addition, we need to interrupt the thread on close because it might be waiting on take() and it will never exit\r\n\r\nOh I see, it might not work when the producer is not closed and we are waiting on queue.take() and without any incoming event we are closing.', 'comment_created': datetime.datetime(2023, 7, 31, 8, 25, 32, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1278964553, 'comment_body': ""Both conditions must be true, the reason being:\r\n- when close, we want to process the queue before closing, and\r\n- we don't want to stop processing before close is called\r\n\r\notherwise when there are elements and the caller calls close the condition is never true:\r\n```java\r\n while (!eventQueue.isEmpty())\r\n```\r\n\r\n```suggestion\r\n        while (!isClosed.get() && !eventQueue.isEmpty()) {\r\n```"", 'comment_created': datetime.datetime(2023, 7, 31, 8, 37, 10, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1278995296, 'comment_body': ""> - when close, we want to process the queue before closing, and\r\n> - we don't want to stop processing before close is called\r\n\r\nYes, that is why I have used `||` as when `isClosed` is `true` and `!isClosed.get()` is false but there are elements in the eventQueue we want to continue the loop.\r\n\r\n---\r\nBut still it might not work for the same reason\r\n> when the producer is not closed and we are waiting on `queue.take()` and without any incoming event we are calling close. so the execution is never going to `while(condition..)` \r\n\r\n- I have changed the condition to use `Thread.interrupt()` which we are calling from the `close` method.\r\nI think it will work and also simple."", 'comment_created': datetime.datetime(2023, 7, 31, 9, 2, 52, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1279021895, 'comment_body': 'this sleep should be in the loop `while (!eventQueue.isEmpty())`', 'comment_created': datetime.datetime(2023, 7, 31, 9, 15, 33, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1279023697, 'comment_body': 'when is `v` null? I think `v` being non null should be a prerequisite', 'comment_created': datetime.datetime(2023, 7, 31, 9, 16, 57, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1279024011, 'comment_body': 'There are many annotations saying missing coverage, can we add more tests?', 'comment_created': datetime.datetime(2023, 7, 31, 9, 17, 12, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1279024807, 'comment_body': 'Can we use a logger at debug level here?', 'comment_created': datetime.datetime(2023, 7, 31, 9, 17, 56, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1279068973, 'comment_body': 'Oh, I thought we will consume all the remaining events in 2 sec.😅', 'comment_created': datetime.datetime(2023, 7, 31, 9, 55, 47, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1279069008, 'comment_body': 'Yes, I can do that, Just need to change the Test I have written for there I was passing null and not a Vertx obj.', 'comment_created': datetime.datetime(2023, 7, 31, 9, 55, 48, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1279070802, 'comment_body': 'Yes, there are so many annotations saying missing coverage. But I am not sure what type of test I should add. Okay let me try', 'comment_created': datetime.datetime(2023, 7, 31, 9, 57, 16, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1279088132, 'comment_body': 'I believe tests testing send + close with a non empty queue is super interesting to make sure that the concurrency and coordination works', 'comment_created': datetime.datetime(2023, 7, 31, 10, 13, 26, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1279174006, 'comment_body': 'I have added a bunch of Tests. Taking new test ideas from ChatGPT😌.', 'comment_created': datetime.datetime(2023, 7, 31, 11, 39, 53, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1279198957, 'comment_body': 'Hm, interesting this test is passing locally. Should I increase the wait time? Maybe it need some more time to get interrupted as it was a blocked thread. ', 'comment_created': datetime.datetime(2023, 7, 31, 12, 5, 58, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1279424220, 'comment_body': '```suggestion\r\n        }\r\n        \r\n        logger.debug(""Background thread finished."");\r\n```', 'comment_created': datetime.datetime(2023, 7, 31, 14, 51, 3, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1279475038, 'comment_body': 'I have just changed the `sendFromQueue` function to use the callback and it is stopping now. ', 'comment_created': datetime.datetime(2023, 7, 31, 15, 21, 32, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1279478995, 'comment_body': 'We need to complete the promise when no exception is raised\r\n```suggestion\r\n                    if (exception != null) {\r\n                        recordPromise.getPromise().fail(exception);\r\n                        if (startedSpan != null) {\r\n                            startedSpan.fail(ctx, exception);\r\n                        }\r\n                        return;\r\n                    }\r\n                    recordPromise.getPromise().complete(metadata);\r\n```', 'comment_created': datetime.datetime(2023, 7, 31, 15, 23, 45, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1279632518, 'comment_body': 'yup, I missed it in hurry.😅', 'comment_created': datetime.datetime(2023, 7, 31, 17, 5, 1, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1280327308, 'comment_body': 'Can we use the shorter form with the import?', 'comment_created': datetime.datetime(2023, 8, 1, 9, 7, 42, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280331320, 'comment_body': 'Calling `completeNow` multiple times doesn\'t do what we want here, we expect to have `numRecords + 1 (for close)` ""future completions"", for that we can use checkpoints:\r\n\r\n```java\r\n\r\n        final var checkpoints = testContext.checkpoint(numRecords + 1);\r\n        \r\n        testContext.verify(() -> {\r\n                assertTrue(ar.succeeded());\r\n                // other assertions\r\n\r\n                checkpoints.flag(); // complete checkpoint\r\n            });\r\n       \r\n', 'comment_created': datetime.datetime(2023, 8, 1, 9, 11, 21, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280331952, 'comment_body': '```suggestion\r\n                assertFalse(producer.isSendFromQueueThreadAlive());\r\n```', 'comment_created': datetime.datetime(2023, 8, 1, 9, 11, 54, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280338772, 'comment_body': ""Can't we set those assertions at line 110 instead of looping and aggregating futures?\r\n`producer.send(record)` at line 110"", 'comment_created': datetime.datetime(2023, 8, 1, 9, 17, 34, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280339985, 'comment_body': 'We need to set what happens on failure with `.onFailure(testContext::failNow)` so that we get a more descriptive error message', 'comment_created': datetime.datetime(2023, 8, 1, 9, 18, 38, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280340118, 'comment_body': 'We need to set what happens on failure with `.onFailure(testContext::failNow)` so that we get a more descriptive error message', 'comment_created': datetime.datetime(2023, 8, 1, 9, 18, 45, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280341575, 'comment_body': '```suggestion\r\n                assertFalse(producer.isSendFromQueueThreadAlive());\r\n```', 'comment_created': datetime.datetime(2023, 8, 1, 9, 19, 58, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280342208, 'comment_body': 'Same comment above related to multiple `completeNow` calls and setting up the `onFailure` handling for  a more descriptive error message.', 'comment_created': datetime.datetime(2023, 8, 1, 9, 20, 25, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280342502, 'comment_body': 'Same comment above related to multiple `completeNow` calls and setting up the `onFailure` handling for  a more descriptive error message.', 'comment_created': datetime.datetime(2023, 8, 1, 9, 20, 37, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280355013, 'comment_body': 'I would rework this class to be static and defined on generic `<K, V>`\r\n\r\n```suggestion\r\n    private static class RecordPromise<K, V> {\r\n        private final ProducerRecord<K, V> record;\r\n        private final Promise<RecordMetadata> promise;\r\n\r\n        private RecordPromise(ProducerRecord<K, V> record, Promise<RecordMetadata> promise) {\r\n            this.record = record;\r\n            this.promise = promise;\r\n        }\r\n\r\n        public ProducerRecord<K, V> getRecord() {\r\n            return record;\r\n        }\r\n\r\n        public Promise<RecordMetadata> getPromise() {\r\n            return promise;\r\n        }\r\n    }\r\n```\r\n\r\nTo reduce the risk of the introduction (now and in the future) of any form of memory leak https://www.infoworld.com/article/3526554/avoid-memory-leaks-in-inner-classes.html', 'comment_created': datetime.datetime(2023, 8, 1, 9, 31, 10, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280373029, 'comment_body': 'should we make this `final`?', 'comment_created': datetime.datetime(2023, 8, 1, 9, 41, 36, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1280374317, 'comment_body': ""I'd choose a different name vor the constant instead of just `fn` "", 'comment_created': datetime.datetime(2023, 8, 1, 9, 42, 43, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1280374993, 'comment_body': ""that's a good call. I am also in fav. of this"", 'comment_created': datetime.datetime(2023, 8, 1, 9, 43, 18, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1280378100, 'comment_body': 'and `static` as well', 'comment_created': datetime.datetime(2023, 8, 1, 9, 45, 59, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280393395, 'comment_body': 'Send can throw an exception and we need to handle it accordingly \r\n\r\nI would rework the method with something like this so that we handle tracing in a single place only as well:\r\n```java\r\n  private void sendFromQueue() {\r\n    while (!Thread.currentThread().isInterrupted()) {\r\n      try {\r\n        RecordPromise<K, V> recordPromise = eventQueue.take();\r\n\r\n        ProducerTracer.StartedSpan startedSpan =\r\n          this.tracer == null ? null : this.tracer.prepareSendMessage(ctx, recordPromise.getRecord());\r\n\r\n        recordPromise.getPromise().future()\r\n          .onComplete(v -> {\r\n            if (startedSpan != null) {\r\n              startedSpan.finish(ctx);\r\n            }\r\n          })\r\n          .onFailure(cause -> {\r\n            if (startedSpan != null) {\r\n              startedSpan.fail(ctx, cause);\r\n            }\r\n          });\r\n\r\n\r\n        try {\r\n          producer.send(recordPromise.getRecord(), (metadata, exception) -> {\r\n            if (exception != null) {\r\n              recordPromise.getPromise().fail(exception);\r\n            }\r\n            recordPromise.getPromise().complete(metadata);\r\n          });\r\n        } catch (final KafkaException ex) {\r\n          recordPromise.getPromise().fail(ex);\r\n        }\r\n\r\n      } catch (InterruptedException e) {\r\n        logger.debug(""Interrupted while waiting for event queue to be populated."");\r\n      }\r\n    }\r\n  }\r\n```', 'comment_created': datetime.datetime(2023, 8, 1, 9, 59, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280447998, 'comment_body': 'So for all of the suggestion we will have the test something like\r\n```java\r\n    @Test\r\n    public void testCloseIsWaitingForEmptyQueue(VertxTestContext testContext) {\r\n        // Send multiple records\r\n        int numRecords = 100000;\r\n        final var checkpoints = testContext.checkpoint(numRecords + 1);\r\n\r\n        for (int i = 0; i < numRecords; i++) {\r\n            ProducerRecord<String, Integer> record = new ProducerRecord<>(""test"", ""sequence number"", i);\r\n            producer.send(record)\r\n                    .onSuccess(ar -> {\r\n                        checkpoints.flag();\r\n                    })\r\n                    .onFailure(testContext::failNow);\r\n        }\r\n\r\n        // Close the producer and wait for the event queue to be empty\r\n        producer.close()\r\n                .onComplete(ar -> {\r\n                    testContext.verify(() -> {\r\n                        assertTrue(ar.succeeded());\r\n                        assertEquals(0, producer.getEventQueueSize());\r\n                        assertFalse(producer.isSendFromQueueThreadAlive());\r\n\r\n                        checkpoints.flag();\r\n                    });\r\n                })\r\n                .onFailure(testContext::failNow);\r\n    }\r\n```', 'comment_created': datetime.datetime(2023, 8, 1, 10, 44, 15, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1280467792, 'comment_body': 'Yes!\r\n', 'comment_created': datetime.datetime(2023, 8, 1, 11, 3, 53, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280561593, 'comment_body': ""I have taken this class as it is from the Vert.x tracing implementation, so I haven't changed anything. \r\nhttps://github.com/vert-x3/vertx-kafka-client/blob/master/src/main/java/io/vertx/kafka/client/common/tracing/TraceTags.java\r\n\r\n"", 'comment_created': datetime.datetime(2023, 8, 1, 12, 31, 42, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1280562008, 'comment_body': 'Done.', 'comment_created': datetime.datetime(2023, 8, 1, 12, 32, 1, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1280584434, 'comment_body': 'It seems more natural to interrupt and wait for it to terminate, what is the reason for the different order?\r\n\r\n```suggestion\r\n                sendFromQueueThread.join();\r\n                producer.close();\r\n```', 'comment_created': datetime.datetime(2023, 8, 1, 12, 48, 5, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1280592833, 'comment_body': 'No, particular reason. okay I will change it.', 'comment_created': datetime.datetime(2023, 8, 1, 12, 53, 16, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}]","[{'commit_sha': '47aaa7a78bef4fdb50fd50e35ea63d74e1ee7b9f', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '09db442321e11196b19f625629dd72369df961d7', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '4995d875118d32c9e9deafedb295de34d4bd607e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9835ce8aaf703f70aefed0e4bc8325a9ec838029', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'b35d7fa81d176284295a9a0be5dab1c748b4584e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '5dbc5fb8f23a02532e9bc3261a95c314561301b8', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '10ef6c67184f22966fd56549e2f8fb986e8f3e43', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '40c039cce213df921be9e4e201433340a8383a0a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'd80422821aa3c2ab55cfa2fecf8b9c3b1f14d0fb', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7d3181d44ec8becf435e6d9cfac251430e5aafdf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'efdce4a9faea9c40c5bbba172ce8a4ba575671bd', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3760489af3d2eef09f0ea68aa395183d0fca258d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '9ce362c5a8f87356976f76aebadbe428051ee59c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '6e4ff628082c83bc23a866d5bab04a50b7b45eca', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '893e4ee5aabca0f3fda8212f45ecf7859f1ffe63', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '7e8c26f2a8a28d922e76b3a76176a21104a45416', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '64c1dcd235a7b6fc1177a0f0f47d17b5e4e0fd9d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c767c506fdca0e43b2c0a3d74f444f473a66a874', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'a2693216a6e07344d920ab7843ee18afba755148', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '15e73e6168010a646bae50fe348e755ba3247632', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '1d2d1661d1c7d5fecc871952db2ff5d53972e9c7', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'c59d60c75b7f8c17f4f87db691a80c93c604c493', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '78172b896fd72f626422ead871487045d1c77627', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'f874986d6e4f42dde017fd3201c9695c6c2e4e0e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'd9eb5dc4180981596840d2755fe00ef478b21ff6', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'bb5219aedd9db3f36a7d83a692ca9bb590069198', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '6c24beec4da89a8759544f9729a48f397449e49a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '6c77c833df6d9b70b687ad687dcf7ee06bf19621', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ac6792dad5bbae2ddda54249ee6b406d97c7e666', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '27e95fd133d2e909ec9db9c0e14fa223f3680257', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '221b5123ed72a715394a82d14bb885e35d1ae5e5', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8192ddb034f2e3a448a1ff8f1a2fe5e555de3e7a', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2be5c02d93cae479c09041962a4d3a7afc5a2400', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'dbb47e3f75817041dfb288d73e17b55fe0e92c18', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '4aa9d86680711cb6a8ca9661a62cadc3700aff14', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'eab64fae0f824b3504ba0f1be1b458d7f070bd11', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1458472401,Add Dispatcher loom based module Implementation,"Progress in #2928

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Loom-based dispatcher module implementation
- Unit Test for them
",True,3257,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3257,https://github.com/knative-extensions/eventing-kafka-broker/pull/3257,closed,495,13,9,11,8,23,4,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/XL'}, {'name': 'area/data-plane'}]",2023-08-01 17:00:58+00:00,2023-08-14 13:03:44+00:00,1108966.0,"12 days, 20:02:46","[{'comment_id': 1280919850, 'comment_body': 'Definitely need suggestions here. ', 'comment_created': datetime.datetime(2023, 8, 1, 17, 2, 45, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1281650618, 'comment_body': 'Yes, we cannot do that, we need to queue the ""close task"" and then on a separate thread we can wait for the queue to become empty\r\n```\r\n        // add close task to queue ...\r\n\r\n        // mark as closed\r\n       isClosed.set(true);\r\n        // wait for tasks to complete\r\n        Thread.ofVirtual().start(() -> {\r\n            try {\r\n                while(!taskQueue.isEmpty()) {\r\n                    Thread.sleep(2000);\r\n                }\r\n                taskRunnerThread.interrupt();\r\n                taskRunnerThread.join();\r\n                promise.complete();\r\n            } catch (Exception e) {\r\n                promise.fail(e);\r\n            }\r\n        });```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 30, 5, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281661062, 'comment_body': ""This is normal and expected to happen, I'd not call the exception handler\r\n```suggestion\r\n```"", 'comment_created': datetime.datetime(2023, 8, 2, 9, 38, 52, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281662946, 'comment_body': '```suggestion\r\n        final Promise<Map<TopicPartition, OffsetAndMetadata>> promise = Promise.promise();\r\n```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 40, 35, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281663176, 'comment_body': '```suggestion\r\n        final Promise<Void> promise = Promise.promise();\r\n```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 40, 45, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281663352, 'comment_body': '```suggestion\r\n        final Promise<Void> promise = Promise.promise();\r\n```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 40, 55, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281663449, 'comment_body': '```suggestion\r\n        final Promise<ConsumerRecords<K, V>> promise = Promise.promise();\r\n```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 41, 1, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281663575, 'comment_body': '```suggestion\r\n        final Promise<Void> promise = Promise.promise();\r\n```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 41, 8, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281663767, 'comment_body': '```suggestion\r\n        final Promise<Void> promise = Promise.promise();\r\n```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 41, 18, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1281663895, 'comment_body': '```suggestion\r\n        final Promise<Void> promise = Promise.promise();\r\n```', 'comment_created': datetime.datetime(2023, 8, 2, 9, 41, 25, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1283358411, 'comment_body': 'I would place this inside the `consumer.close().onComplete( <here> )` without the `thread.sleep`\r\n', 'comment_created': datetime.datetime(2023, 8, 3, 15, 17, 54, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1283359665, 'comment_body': 'Isn\'t ""after close"" rather than ""before close"" ?', 'comment_created': datetime.datetime(2023, 8, 3, 15, 18, 54, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1283363074, 'comment_body': 'This promise should complete when the new virtual thread below is finished', 'comment_created': datetime.datetime(2023, 8, 3, 15, 21, 36, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1283367273, 'comment_body': 'Something like this?\r\n```\r\n        final Promise<Void> promise = Promise.promise();\r\n        isClosed.set(true);\r\n        taskQueue.add(() -> {\r\n            try {\r\n                consumer.close();\r\n            } catch (Exception e) {\r\n                promise.tryFail(e);\r\n            }\r\n        });\r\n\r\n\r\n        Thread.ofVirtual().start(() -> {\r\n            try {\r\n                while (!taskQueue.isEmpty()) {\r\n                    Thread.sleep(100);\r\n                }\r\n                taskRunnerThread.interrupt();\r\n                taskRunnerThread.join();\r\n                promise.tryComplete();\r\n            } catch (InterruptedException e) {\r\n                logger.debug(""Interrupted while waiting for taskRunnerThread to finish"", e);\r\n                promise.tryFail(e);\r\n            }\r\n        });\r\n```', 'comment_created': datetime.datetime(2023, 8, 3, 15, 24, 44, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1283370431, 'comment_body': 'In addition, can we increase the sleep time to be the same as the producer one? \r\n\r\nhttps://github.com/knative-extensions/eventing-kafka-broker/blob/24ef5f8a68370ecc504db45177bf1f09d3c76490/data-plane/receiver-loom/src/main/java/dev/knative/eventing/kafka/broker/receiverloom/LoomKafkaProducer.java#L118', 'comment_created': datetime.datetime(2023, 8, 3, 15, 27, 14, tzinfo=datetime.timezone.utc), 'commenter': 'pierDipi', 'type': 'User'}, {'comment_id': 1283426758, 'comment_body': 'Ohh 😅 yes. ', 'comment_created': datetime.datetime(2023, 8, 3, 16, 11, 26, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1283453251, 'comment_body': '> I would place this inside the consumer.close().onComplete( <here> ) without the thread.sleep\r\n\r\nI have changed them accordingly.', 'comment_created': datetime.datetime(2023, 8, 3, 16, 34, 36, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1285777962, 'comment_body': 'why is this needed?', 'comment_created': datetime.datetime(2023, 8, 7, 12, 9, 9, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1285799790, 'comment_body': 'why that switch?', 'comment_created': datetime.datetime(2023, 8, 7, 12, 31, 36, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1285862286, 'comment_body': 'As we are using the Java Project Loom virtual threads. which is still a preview feature in JDK20.\r\nIt will be stable in JDK21 which will release this sep I believe.', 'comment_created': datetime.datetime(2023, 8, 7, 13, 22, 57, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1285871427, 'comment_body': 'in the last PR #3215 we do not have the dispatcher so I directly add the dependency of receiver-loom but we have the dispatcher now so I just switch it. \r\n\r\nDispatcher has a dependency on receiver also so instead of adding both here i just have added the dispatcher-loom. Same as the vertx one\r\nhttps://github.com/knative-extensions/eventing-kafka-broker/blob/69db9c4e8000467e249b8af9f89c9f5409c728a4/data-plane/tests/pom.xml#L54-L58', 'comment_created': datetime.datetime(2023, 8, 7, 13, 30, 16, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}, {'comment_id': 1286880655, 'comment_body': 'can you add that as a comment above? I was imagine this, but it should be explicit, IMO', 'comment_created': datetime.datetime(2023, 8, 8, 9, 47, 22, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1286935427, 'comment_body': 'Sure', 'comment_created': datetime.datetime(2023, 8, 8, 10, 38, 58, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}]","[{'commit_sha': '91f42c8e2abb0ae3c296db373f9b84e9251e7613', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd843bbb7f6945e456dc762d8990c0de0f4df06a1', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '949b6b66259dbc9456e918b62be66d4a0d6e8dfb', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bc159ed66ead97876189026e4abe8a026f9f56fc', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f7e6a96455b7cc69af5a21b3f7f2ede14b73efc9', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3311168b288666f9fe0253873ed7f79a05b08876', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5218d800a884e061f57c74606f9cb005181839b2', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '57d6c0377df74c7de11637afdadf8cba8e5ad520', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8f734d8a914cb65e53434a62931465f81186ea73', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '366439c9cfc839b74188bd9b9ca26fefad526dd1', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '073de91218918d5bc732c004bcd079d06fe698e8', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1419016318,Java Version to 20,"Knative-Kafka-Broker needs to update the prow tests Java version to 20. 
/cc @pierDipi @lance  ",True,119,https://api.github.com/repos/knative/infra/pulls/119,https://github.com/knative/infra/pull/119,closed,1,1,1,1,1,0,3,1,"[{'name': 'lgtm'}, {'name': 'approved'}, {'name': 'size/XS'}]",2023-07-04 06:00:11+00:00,2023-07-04 07:00:38+00:00,3627.0,1:00:27,[],"[{'commit_sha': 'a2b3548d93a2b18ffd44f0eba9e922d99ae529ed', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1462482022,Consumer tracer to replace the use of Vert.x Kafka lib in base dispatcher module.,"Progress #2928 

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Added the ConsumerTracer referencing https://github.com/vert-x3/vertx-kafka-client
- Change the current Impl to use it.
- Some additional changed
  - Made the promises of the Loom-Producer `final`
  - Format `ExactFilterBenchmark` and `FilterBenchmark` via spotless. that might have been missed in the last PR #3247 

",True,3269,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3269,https://github.com/knative-extensions/eventing-kafka-broker/pull/3269,closed,128,14,7,8,13,8,4,1,"[{'name': 'approved'}, {'name': 'lgtm'}, {'name': 'size/L'}, {'name': 'area/data-plane'}]",2023-08-04 07:41:47+00:00,2023-08-21 12:49:21+00:00,1487254.0,"17 days, 5:07:34","[{'comment_id': 1293363350, 'comment_body': 'can we not do these formatting changes? ', 'comment_created': datetime.datetime(2023, 8, 14, 11, 51, 49, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1293366462, 'comment_body': 'do you have a link handy to that matching code? ', 'comment_created': datetime.datetime(2023, 8, 14, 11, 55, 24, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1293369634, 'comment_body': 'have it: https://github.com/vert-x3/vertx-kafka-client/blob/a0e349fca33d3bb4f003ac53e6e0def42a76e8ab/src/main/java/io/vertx/kafka/client/common/tracing/ConsumerTracer.java#L37\r\n\r\n', 'comment_created': datetime.datetime(2023, 8, 14, 11, 59, 8, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}, {'comment_id': 1293494336, 'comment_body': ""perhaps me, but I'd add this on the comment of the `clazz`, and also point a link of the `sha` in GIT, that matches this file, at the time of copying.\r\n\r\n"", 'comment_created': datetime.datetime(2023, 8, 14, 13, 57, 8, tzinfo=datetime.timezone.utc), 'commenter': 'matzew', 'type': 'User'}]","[{'commit_sha': '10595c4faf6bb60c53d38ba5446acdf915bdba1d', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '870e4bba04a18222a93e4e037766fcec1c83786a', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'aaa305c779ac471a6267f574722e772ee0e25c60', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '37b068680f3e374d45a983b8dc4e938a0902ffa4', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '31b59c64219e4fcab997ee3c09161e4eb1be050e', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b5410eeb1c1f5a7957278e9d16823e936e8b65e2', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2fba8b07f5cd86d8e851a8514d2137821da43233', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7a0cd4320930fc938844cdef2b9b5e2653472b0b', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1478409947,Added Scripts to deploy the Loom modules,"Progress #2928 

<!-- Please include the 'why' behind your changes if no issue exists -->

## Proposed Changes

- Added a new command in run.sh `./hack/run.sh deploy-loom`
- Change the data-plane.sh to deploy the loom modules whenever mentioned",True,3290,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3290,https://github.com/knative-extensions/eventing-kafka-broker/pull/3290,closed,35,8,2,2,6,0,4,1,"[{'name': 'approved'}, {'name': 'size/M'}, {'name': 'lgtm'}, {'name': 'area/test'}]",2023-08-17 05:46:21+00:00,2023-08-22 12:02:55+00:00,454594.0,"5 days, 6:16:34",[],"[{'commit_sha': '52a2ea909a8bf94ae3068e67a915826c0969377c', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd52f8e70853b271053fd387ec47ee430842494b4', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1485150061,Fixing: `NullPointerException` occurring and it's discarding the records while tracing for Loom deployment,"<!-- Please include the 'why' behind your changes if no issue exists -->
### Problem

Current Loom Dispatcher was not working properly and there is no events retrieving on that side.

The Problem we find is that when we are using loom modules the ConsumerTracer (which is using vertx opentelemetry), is a `NullPointerException` occurring and it's discarding the records.
```sh
""stack_trace"":""java.lang.NullPointerException"": 
Cannot invoke ""io.vertx.core.Context.getLocal(Object)"" because ""vertxCtx"" is null
   at io.vertx.tracing.opentelemetry.VertxContextStorageProvider$VertxContextStorage.attach(VertxContextStorageProvider.java:27)
   at io.vertx.tracing.opentelemetry.OpenTelemetryTracer.receiveRequest(OpenTelemetryTracer.java:70)
   at io.vertx.tracing.opentelemetry.OpenTelemetryTracer.receiveRequest(OpenTelemetryTracer.java:31)
   at dev.knative.eventing.kafka.broker.core.tracing.kafka.ConsumerTracer.prepareMessageReceived(ConsumerTracer.java:88)
   at dev.knative.eventing.kafka.broker.dispatcher.impl.RecordDispatcherImpl.getStartedSpan(RecordDispatcherImpl.java:485)
```


## Proposed Changes

As for the Solution we have here is we handle the records inside the current Vertx Context. So that when for the tracing we try to get the currentContext we get the context instead of `null` https://github.com/knative-extensions/eventing-kafka-broker/blob/c6e8f3c4c5c74917f36b3d30fc8bc3ffbccce8e2/data-plane/dispatcher/src/main/java/dev/knative/eventing/kafka/broker/dispatcher/impl/RecordDispatcherImpl.java#L203-L205


/cc @pierDipi @matzew 
<!--
If this change has user-visible impact, follow the instructions below.
Examples include:

- :gift: Add new feature
- :bug: Fix bug
- :broom: Update or clean up current behavior
- :wastebasket: Remove feature or internal logic

Otherwise delete the rest of this template.
-->

**Release Note**

<!--
:page_facing_up: If this change has user-visible impact, write a release note in the block
below. Include the string ""action required"" if additional action is required of
users switching to the new release, for example in case of a breaking change.

Write as if you are speaking to users, not other Knative contributors. If this
change has no user-visible impact, no release-note is needed.
-->
<!--
:book: If this change has user-visible impact, link to an issue or PR in
https://github.com/knative/docs.
-->
",True,3300,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3300,https://github.com/knative-extensions/eventing-kafka-broker/pull/3300,closed,23,17,2,2,3,0,4,2,"[{'name': 'approved'}, {'name': 'size/M'}, {'name': 'lgtm'}, {'name': 'area/data-plane'}]",2023-08-22 17:22:57+00:00,2023-08-23 05:52:56+00:00,44999.0,12:29:59,[],"[{'commit_sha': '0bf6b9bf42492ce630566ce7313cf763f25ff339', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b92a3b9b46c6978e0ca3f04fd96d8becd7d2b80', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133
1489117055,Added Installation Docs for Loom Dispatcher and Receiver Implementations,"## Proposed Changes

- Added a Note in DEVELOPMENT.md to install loom impls.
- Update the data-plane/README.md according to current folder structure
- Added a new Docs Loom-Modules.md as installation guide.

Please let me know if I should add anything more. 

/cc @pierDipi @matzew @Cali0707 @Leo6Leo ",True,3308,https://api.github.com/repos/knative-extensions/eventing-kafka-broker/pulls/3308,https://github.com/knative-extensions/eventing-kafka-broker/pull/3308,closed,40,4,3,7,6,4,4,2,"[{'name': 'approved'}, {'name': 'size/M'}, {'name': 'lgtm'}, {'name': 'area/data-plane'}]",2023-08-25 05:58:12+00:00,2023-08-25 17:04:58+00:00,40006.0,11:06:46,"[{'comment_id': 1305816814, 'comment_body': 'The links here seems like not correct @debasishbsws ', 'comment_created': datetime.datetime(2023, 8, 25, 15, 34, 46, tzinfo=datetime.timezone.utc), 'commenter': 'Leo6Leo', 'type': 'User'}, {'comment_id': 1305820363, 'comment_body': '```suggestion\r\n**Pre-requisites:** You have followed the [CONTRIBUTING](https://github.com/knative-extensions/eventing-kafka-broker/blob/main/CONTRIBUTING.md) & [DEVELOPMENT](https://github.com/knative-extensions/eventing-kafka-broker/blob/main/DEVELOPMENT.md) guides and have a Kubernetes cluster up and running and reachable.\r\n```', 'comment_created': datetime.datetime(2023, 8, 25, 15, 38, 5, tzinfo=datetime.timezone.utc), 'commenter': 'Leo6Leo', 'type': 'User'}, {'comment_id': 1305820427, 'comment_body': '```suggestion\r\nLoom implemantation of Dispatcher and Receiver are located in [`dispatcher-loom`](https://github.com/knative-extensions/eventing-kafka-broker/tree/main/data-plane/dispatcher-loom) and [`receiver-loom`](https://github.com/knative-extensions/eventing-kafka-broker/tree/main/data-plane/receiver-loom) directories respectively.  \r\n```', 'comment_created': datetime.datetime(2023, 8, 25, 15, 38, 8, tzinfo=datetime.timezone.utc), 'commenter': 'Leo6Leo', 'type': 'User'}, {'comment_id': 1305826831, 'comment_body': 'Ohh yes, I have used relative path it should be fully qualified. Thanks', 'comment_created': datetime.datetime(2023, 8, 25, 15, 44, 20, tzinfo=datetime.timezone.utc), 'commenter': 'debasishbsws', 'type': 'User'}]","[{'commit_sha': 'ab46411cd0f88a86da5e1db1331cacfe3e6a2549', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6071731b7cac623c7cbcd27feed85e1b06e06d5b', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '01df1a9782b104e473ea9403d93c3f890eef609d', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2f3386226c739db7dce22ffcb2cfa70586766c66', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c53550c48abeca125c16ed6ae6a87d0f2dbeb88a', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9f044904d7585ef1a3144247400ef1a52da50503', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5c91e4d37b71234c545d51548335936ae486fd95', 'committer_username': 'debasishbsws', 'committer_name': 'Debasish Biswas', 'committer_email': 'debasishbsws.dev@gmail.com', 'commit_date': datetime.datetime(2020, 5, 15, 3, 10, 58, tzinfo=datetime.timezone.utc)}]",Debasish Biswas,65381620,debasishbsws.dev@gmail.com,User,,71,,40,133

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
273315692,eventing-kafka-broker,knative-extensions/eventing-kafka-broker,Go,115,168,14,69,2240,99,34,26,"[{'id': 1508908025, 'number': 3326, 'closed': datetime.datetime(2023, 9, 12, 14, 37, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 9, 9, 18, 35, 34, tzinfo=datetime.timezone.utc), 'time_taken': 244896.0, 'time_delta': '2 days, 20:01:36', 'additions': 4, 'deletions': 2, 'state': 'closed'}, {'id': 1489117055, 'number': 3308, 'closed': datetime.datetime(2023, 8, 25, 17, 4, 58, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 8, 25, 5, 58, 12, tzinfo=datetime.timezone.utc), 'time_taken': 40006.0, 'time_delta': '11:06:46', 'additions': 40, 'deletions': 4, 'state': 'closed'}, {'id': 1485150061, 'number': 3300, 'closed': datetime.datetime(2023, 8, 23, 5, 52, 56, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 8, 22, 17, 22, 57, tzinfo=datetime.timezone.utc), 'time_taken': 44999.0, 'time_delta': '12:29:59', 'additions': 23, 'deletions': 17, 'state': 'closed'}, {'id': 1481524675, 'number': 3292, 'closed': datetime.datetime(2023, 8, 28, 17, 20, 51, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 8, 19, 16, 59, 12, tzinfo=datetime.timezone.utc), 'time_taken': 778899.0, 'time_delta': '9 days, 0:21:39', 'additions': 19, 'deletions': 0, 'state': 'closed'}, {'id': 1478409947, 'number': 3290, 'closed': datetime.datetime(2023, 8, 22, 12, 2, 55, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 8, 17, 5, 46, 21, tzinfo=datetime.timezone.utc), 'time_taken': 454594.0, 'time_delta': '5 days, 6:16:34', 'additions': 35, 'deletions': 8, 'state': 'closed'}, {'id': 1462482022, 'number': 3269, 'closed': datetime.datetime(2023, 8, 21, 12, 49, 21, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 8, 4, 7, 41, 47, tzinfo=datetime.timezone.utc), 'time_taken': 1487254.0, 'time_delta': '17 days, 5:07:34', 'additions': 128, 'deletions': 14, 'state': 'closed'}, {'id': 1458472401, 'number': 3257, 'closed': datetime.datetime(2023, 8, 14, 13, 3, 44, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 8, 1, 17, 0, 58, tzinfo=datetime.timezone.utc), 'time_taken': 1108966.0, 'time_delta': '12 days, 20:02:46', 'additions': 495, 'deletions': 13, 'state': 'closed'}, {'id': 1435950205, 'number': 3215, 'closed': datetime.datetime(2023, 8, 1, 15, 47, 47, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 15, 15, 55, 59, tzinfo=datetime.timezone.utc), 'time_taken': 1468308.0, 'time_delta': '16 days, 23:51:48', 'additions': 831, 'deletions': 28, 'state': 'closed'}, {'id': 1432617991, 'number': 3211, 'closed': datetime.datetime(2023, 7, 14, 3, 12, 15, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 13, 8, 16, 13, tzinfo=datetime.timezone.utc), 'time_taken': 68162.0, 'time_delta': '18:56:02', 'additions': 302, 'deletions': 0, 'state': 'closed'}, {'id': 1429900097, 'number': 3207, 'closed': datetime.datetime(2023, 7, 13, 15, 6, 22, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 11, 17, 32, 7, tzinfo=datetime.timezone.utc), 'time_taken': 164055.0, 'time_delta': '1 day, 21:34:15', 'additions': 45, 'deletions': 39, 'state': 'closed'}, {'id': 1429806609, 'number': 3206, 'closed': datetime.datetime(2023, 7, 13, 15, 6, 14, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 11, 16, 31, 44, tzinfo=datetime.timezone.utc), 'time_taken': 167670.0, 'time_delta': '1 day, 22:34:30', 'additions': 166, 'deletions': 178, 'state': 'closed'}, {'id': 1425000292, 'number': 3195, 'closed': datetime.datetime(2023, 7, 11, 17, 33, 6, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 7, 17, 35, 25, tzinfo=datetime.timezone.utc), 'time_taken': 345461.0, 'time_delta': '3 days, 23:57:41', 'additions': 62, 'deletions': 88, 'state': 'closed'}, {'id': 1419499689, 'number': 3192, 'closed': datetime.datetime(2023, 7, 11, 16, 32, 39, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 4, 11, 33, 56, tzinfo=datetime.timezone.utc), 'time_taken': 622723.0, 'time_delta': '7 days, 4:58:43', 'additions': 227, 'deletions': 163, 'state': 'closed'}, {'id': 1414564092, 'number': 3186, 'closed': datetime.datetime(2023, 7, 6, 10, 26, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 30, 9, 29, 18, tzinfo=datetime.timezone.utc), 'time_taken': 521842.0, 'time_delta': '6 days, 0:57:22', 'additions': 3, 'deletions': 3, 'state': 'closed'}, {'id': 1410473469, 'number': 3177, 'closed': datetime.datetime(2023, 7, 4, 7, 21, 38, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 27, 19, 18, 53, tzinfo=datetime.timezone.utc), 'time_taken': 561765.0, 'time_delta': '6 days, 12:02:45', 'additions': 526, 'deletions': 763, 'state': 'closed'}, {'id': 1400366570, 'number': 3159, 'closed': datetime.datetime(2023, 6, 26, 15, 51, 53, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 20, 18, 57, 15, tzinfo=datetime.timezone.utc), 'time_taken': 507278.0, 'time_delta': '5 days, 20:54:38', 'additions': 256, 'deletions': 3, 'state': 'closed'}, {'id': 1384687722, 'number': 3142, 'closed': datetime.datetime(2023, 6, 19, 10, 6, 53, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 8, 15, 26, 44, tzinfo=datetime.timezone.utc), 'time_taken': 931209.0, 'time_delta': '10 days, 18:40:09', 'additions': 384, 'deletions': 149, 'state': 'closed'}, {'id': 1383225267, 'number': 3137, 'closed': datetime.datetime(2023, 6, 9, 11, 40, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 7, 19, 9, 41, tzinfo=datetime.timezone.utc), 'time_taken': 145878.0, 'time_delta': '1 day, 16:31:18', 'additions': 1, 'deletions': 1, 'state': 'closed'}, {'id': 1375557871, 'number': 3131, 'closed': datetime.datetime(2023, 6, 6, 10, 36, 27, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 6, 2, 10, 48, 39, tzinfo=datetime.timezone.utc), 'time_taken': 344868.0, 'time_delta': '3 days, 23:47:48', 'additions': 180, 'deletions': 3, 'state': 'closed'}, {'id': 1366246232, 'number': 3106, 'closed': datetime.datetime(2023, 5, 31, 8, 51, 36, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 5, 26, 12, 9, 59, tzinfo=datetime.timezone.utc), 'time_taken': 420097.0, 'time_delta': '4 days, 20:41:37', 'additions': 136, 'deletions': 0, 'state': 'closed'}, {'id': 1281287689, 'number': 3016, 'closed': datetime.datetime(2024, 2, 3, 4, 3, 56, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 3, 18, 19, 58, 26, tzinfo=datetime.timezone.utc), 'time_taken': 27763530.0, 'time_delta': '321 days, 8:05:30', 'additions': 43, 'deletions': 16, 'state': 'closed'}, {'id': 1273850303, 'number': 3007, 'closed': datetime.datetime(2023, 6, 27, 5, 45, 56, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 3, 13, 19, 32, 13, tzinfo=datetime.timezone.utc), 'time_taken': 9108823.0, 'time_delta': '105 days, 10:13:43', 'additions': 29, 'deletions': 6, 'state': 'closed'}, {'id': 1272026413, 'number': 3006, 'closed': datetime.datetime(2023, 3, 14, 14, 35, 58, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 3, 11, 11, 47, 45, tzinfo=datetime.timezone.utc), 'time_taken': 269293.0, 'time_delta': '3 days, 2:48:13', 'additions': 25, 'deletions': 3, 'state': 'closed'}, {'id': 1261152658, 'number': 2998, 'closed': datetime.datetime(2023, 3, 18, 20, 0, 36, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 3, 2, 22, 10, 6, tzinfo=datetime.timezone.utc), 'time_taken': 1374630.0, 'time_delta': '15 days, 21:50:30', 'additions': 82, 'deletions': 93, 'state': 'closed'}, {'id': 1255622052, 'number': 2985, 'closed': datetime.datetime(2023, 8, 1, 6, 15, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 2, 27, 14, 57, 51, tzinfo=datetime.timezone.utc), 'time_taken': 13360675.0, 'time_delta': '154 days, 15:17:55', 'additions': 2, 'deletions': 2, 'state': 'closed'}]"
465895809,infra,knative/infra,Jsonnet,27,8,7,128,3164,10,1,0,"[{'id': 1481559257, 'number': 169, 'closed': datetime.datetime(2023, 8, 25, 12, 19, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 8, 19, 19, 24, 46, tzinfo=datetime.timezone.utc), 'time_taken': 492913.0, 'time_delta': '5 days, 16:55:13', 'additions': 150, 'deletions': 0, 'state': 'closed'}, {'id': 1419016318, 'number': 119, 'closed': datetime.datetime(2023, 7, 4, 7, 0, 38, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 4, 6, 0, 11, tzinfo=datetime.timezone.utc), 'time_taken': 3627.0, 'time_delta': '1:00:27', 'additions': 1, 'deletions': 1, 'state': 'closed'}]"

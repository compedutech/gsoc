pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
1620399588,Add two consumer benchmark,"This PR contains:
1. Moved utilities from KafkaTests to Kafka with `@_spi` annotation
2. Fix for some `.finished` state and `waitForNewMessages()` call 
3. Two consumer tests with automatic and manual commits (""SwiftKafkaConsumer..."")
4. 2 tests with pure librdkafka with same automatic and manual commits for comparsion (""librdkafka..."")

The following results are for this baseline (1000 messages):
```
Host 'xxx-MacBook-Pro.local' with 12 'arm64' processors with 96 GB memory, running:
Darwin Kernel Version 23.1.0: Mon Oct  9 21:28:45 PDT 2023; root:xnu-10002.41.9~6/RELEASE_ARM64_T6020

============================
SwiftKafkaConsumerBenchmarks
============================

SwiftKafkaConsumer - basic consumer (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │    2056 │    2057 │    2061 │    2063 │    2063 │    2063 │    2063 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │     168 │     168 │     170 │     174 │     174 │     174 │     174 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      21 │      21 │      21 │      22 │      22 │      22 │      22 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │    4109 │    4111 │    4115 │    4117 │    4117 │    4117 │    4117 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases (K)                     │      24 │      24 │      24 │      24 │      24 │      24 │      24 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains (K)                      │      18 │      18 │      18 │      18 │      18 │      18 │      18 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       1 │       1 │       1 │       1 │       1 │       1 │       1 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │      19 │      19 │      19 │      20 │      20 │      20 │      20 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │    1564 │    1564 │    1574 │    1677 │    1677 │    1677 │    1677 │       3 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

SwiftKafkaConsumer - with offset commit (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │    5039 │    5039 │    5039 │    5039 │    5039 │    5039 │    5039 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches (K)             │      10 │      10 │      10 │      10 │      10 │      10 │      10 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      22 │      22 │      22 │      22 │      22 │      22 │      22 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs (K)                │      13 │      13 │      13 │      13 │      13 │      13 │      13 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases (K)                     │      47 │      47 │      47 │      47 │      47 │      47 │      47 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains (K)                      │      29 │      29 │      29 │      29 │      29 │      29 │      29 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │     662 │     662 │     662 │     662 │     662 │     662 │     662 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (s)            │     104 │     104 │     104 │     104 │     104 │     104 │     104 │       1 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

librdkafka - basic consumer (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │     118 │     127 │     133 │     135 │     149 │     149 │     149 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      21 │      32 │      44 │      55 │      64 │      64 │      64 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases                         │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains                          │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       2 │       2 │       2 │       2 │       2 │       2 │       2 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (μs)            │    4571 │    6066 │    6684 │    7806 │    8607 │    8607 │    8607 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │     611 │     614 │     619 │     624 │     626 │     626 │     626 │       9 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

librdkafka - with offset commit (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │    5118 │    5123 │    5127 │    5139 │    5147 │    5147 │    5147 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      20 │      26 │      32 │      43 │      47 │      47 │      47 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases                         │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains                          │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       1 │       1 │       1 │       1 │       1 │       1 │       1 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │      73 │      74 │      76 │      77 │      80 │      80 │      80 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │     980 │     983 │     987 │     995 │    1012 │    1012 │    1012 │       6 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛
```",True,149,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/149,https://github.com/swift-server/swift-kafka-client/pull/149,closed,782,216,16,27,5,0,0,0,[],2023-11-28 17:44:59+00:00,2024-03-11 08:56:53+00:00,8953914.0,"103 days, 15:11:54",[],"[{'commit_sha': '98f17fae5cb602437672c0d0248480433d6a4636', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '57a349ef67161c14f7ac5e7b172d3011f957a575', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0123cafd9337daa1cf452666cd2c5160987e6e45', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '61b7aa573150650db2b0371cb2ed8d7aa7970977', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '376b30cb8cca623239eaecdfb20be789f44207f1', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '01a94481595c5c5b7f5e0e2a2b6c82d4a214bd16', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '274e4d987899fcb4c00ba8ace3fee7eff406e776', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1811752714ebb5797b05360b8ea39fb5a6e11fdf', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '632b6b71b52c1e0f1b6c7bb5aaa5b483cf4af2dc', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a617092d332da14e3c16da49278ffbe33fd94cb5', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e0c7ae783040bcb7c0bf2f409c4359899100fee9', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f9b1d5555398f7ae2294da4569f8b274dfcc8c73', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7de0be798d1a7817c7fe57bda037cca80a94ce5e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6a2a1b78d0bf71041ba3408ad870ab666743cbfe', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '34e7b4d1b91d62a91b15391476ab63358d83318c', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7f4c8e250ea9ec2e7665a3101dc3b6234ddb074c', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '01779edae1b2d58ac2574a4caebcae6823cc15d7', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'df17518b5c33e634f5cdf9d2093b5604d2bc6947', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3255efcd6e1253343e47315ab0ea5eba6d17346d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd316aacb28148516e120a0ea6f61d304b4cedd35', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4b7bbdd8ead3a1c14ffa0777b0191cc8868e3c05', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '860e1d5c0f7e5bd2769d0b31c7ce07eb7fa92306', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e328b68f3f3ca5b48e8116f74bee559ee05abc1d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4702bbbef7fe414d463619277c14d825f5ef920e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7d2828bd61d346e79637f8048bd59597900246a6', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fedbeff1d281dd8800b6551d619f39b0de7febcb', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2799c02056accb77e5501b9bc1789fec38ed983f', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}]",,127803250,,User,,4,,0,0
1620399588,Add two consumer benchmark,"This PR contains:
1. Moved utilities from KafkaTests to Kafka with `@_spi` annotation
2. Fix for some `.finished` state and `waitForNewMessages()` call 
3. Two consumer tests with automatic and manual commits (""SwiftKafkaConsumer..."")
4. 2 tests with pure librdkafka with same automatic and manual commits for comparsion (""librdkafka..."")

The following results are for this baseline (1000 messages):
```
Host 'xxx-MacBook-Pro.local' with 12 'arm64' processors with 96 GB memory, running:
Darwin Kernel Version 23.1.0: Mon Oct  9 21:28:45 PDT 2023; root:xnu-10002.41.9~6/RELEASE_ARM64_T6020

============================
SwiftKafkaConsumerBenchmarks
============================

SwiftKafkaConsumer - basic consumer (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │    2056 │    2057 │    2061 │    2063 │    2063 │    2063 │    2063 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │     168 │     168 │     170 │     174 │     174 │     174 │     174 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      21 │      21 │      21 │      22 │      22 │      22 │      22 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │    4109 │    4111 │    4115 │    4117 │    4117 │    4117 │    4117 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases (K)                     │      24 │      24 │      24 │      24 │      24 │      24 │      24 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains (K)                      │      18 │      18 │      18 │      18 │      18 │      18 │      18 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       1 │       1 │       1 │       1 │       1 │       1 │       1 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │      19 │      19 │      19 │      20 │      20 │      20 │      20 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │    1564 │    1564 │    1574 │    1677 │    1677 │    1677 │    1677 │       3 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

SwiftKafkaConsumer - with offset commit (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │    5039 │    5039 │    5039 │    5039 │    5039 │    5039 │    5039 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches (K)             │      10 │      10 │      10 │      10 │      10 │      10 │      10 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      22 │      22 │      22 │      22 │      22 │      22 │      22 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs (K)                │      13 │      13 │      13 │      13 │      13 │      13 │      13 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases (K)                     │      47 │      47 │      47 │      47 │      47 │      47 │      47 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains (K)                      │      29 │      29 │      29 │      29 │      29 │      29 │      29 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │     662 │     662 │     662 │     662 │     662 │     662 │     662 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (s)            │     104 │     104 │     104 │     104 │     104 │     104 │     104 │       1 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

librdkafka - basic consumer (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │     118 │     127 │     133 │     135 │     149 │     149 │     149 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      21 │      32 │      44 │      55 │      64 │      64 │      64 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases                         │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains                          │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       2 │       2 │       2 │       2 │       2 │       2 │       2 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (μs)            │    4571 │    6066 │    6684 │    7806 │    8607 │    8607 │    8607 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │     611 │     614 │     619 │     624 │     626 │     626 │     626 │       9 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

librdkafka - with offset commit (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │    5118 │    5123 │    5127 │    5139 │    5147 │    5147 │    5147 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      20 │      26 │      32 │      43 │      47 │      47 │      47 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases                         │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains                          │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       1 │       1 │       1 │       1 │       1 │       1 │       1 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │      73 │      74 │      76 │      77 │      80 │      80 │      80 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │     980 │     983 │     987 │     995 │    1012 │    1012 │    1012 │       6 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛
```",True,149,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/149,https://github.com/swift-server/swift-kafka-client/pull/149,closed,782,216,16,27,5,0,0,0,[],2023-11-28 17:44:59+00:00,2024-03-11 08:56:53+00:00,8953914.0,"103 days, 15:11:54",[],"[{'commit_sha': '98f17fae5cb602437672c0d0248480433d6a4636', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '57a349ef67161c14f7ac5e7b172d3011f957a575', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0123cafd9337daa1cf452666cd2c5160987e6e45', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '61b7aa573150650db2b0371cb2ed8d7aa7970977', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '376b30cb8cca623239eaecdfb20be789f44207f1', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '01a94481595c5c5b7f5e0e2a2b6c82d4a214bd16', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '274e4d987899fcb4c00ba8ace3fee7eff406e776', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1811752714ebb5797b05360b8ea39fb5a6e11fdf', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '632b6b71b52c1e0f1b6c7bb5aaa5b483cf4af2dc', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a617092d332da14e3c16da49278ffbe33fd94cb5', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e0c7ae783040bcb7c0bf2f409c4359899100fee9', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f9b1d5555398f7ae2294da4569f8b274dfcc8c73', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7de0be798d1a7817c7fe57bda037cca80a94ce5e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6a2a1b78d0bf71041ba3408ad870ab666743cbfe', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '34e7b4d1b91d62a91b15391476ab63358d83318c', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7f4c8e250ea9ec2e7665a3101dc3b6234ddb074c', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '01779edae1b2d58ac2574a4caebcae6823cc15d7', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'df17518b5c33e634f5cdf9d2093b5604d2bc6947', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3255efcd6e1253343e47315ab0ea5eba6d17346d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd316aacb28148516e120a0ea6f61d304b4cedd35', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4b7bbdd8ead3a1c14ffa0777b0191cc8868e3c05', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '860e1d5c0f7e5bd2769d0b31c7ce07eb7fa92306', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e328b68f3f3ca5b48e8116f74bee559ee05abc1d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4702bbbef7fe414d463619277c14d825f5ef920e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7d2828bd61d346e79637f8048bd59597900246a6', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fedbeff1d281dd8800b6551d619f39b0de7febcb', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2799c02056accb77e5501b9bc1789fec38ed983f', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}]",,127803250,,User,,4,,0,0
1620399588,Add two consumer benchmark,"This PR contains:
1. Moved utilities from KafkaTests to Kafka with `@_spi` annotation
2. Fix for some `.finished` state and `waitForNewMessages()` call 
3. Two consumer tests with automatic and manual commits (""SwiftKafkaConsumer..."")
4. 2 tests with pure librdkafka with same automatic and manual commits for comparsion (""librdkafka..."")

The following results are for this baseline (1000 messages):
```
Host 'xxx-MacBook-Pro.local' with 12 'arm64' processors with 96 GB memory, running:
Darwin Kernel Version 23.1.0: Mon Oct  9 21:28:45 PDT 2023; root:xnu-10002.41.9~6/RELEASE_ARM64_T6020

============================
SwiftKafkaConsumerBenchmarks
============================

SwiftKafkaConsumer - basic consumer (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │    2056 │    2057 │    2061 │    2063 │    2063 │    2063 │    2063 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │     168 │     168 │     170 │     174 │     174 │     174 │     174 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      21 │      21 │      21 │      22 │      22 │      22 │      22 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │    4109 │    4111 │    4115 │    4117 │    4117 │    4117 │    4117 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases (K)                     │      24 │      24 │      24 │      24 │      24 │      24 │      24 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains (K)                      │      18 │      18 │      18 │      18 │      18 │      18 │      18 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       1 │       1 │       1 │       1 │       1 │       1 │       1 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │      19 │      19 │      19 │      20 │      20 │      20 │      20 │       3 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │    1564 │    1564 │    1574 │    1677 │    1677 │    1677 │    1677 │       3 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

SwiftKafkaConsumer - with offset commit (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │    5039 │    5039 │    5039 │    5039 │    5039 │    5039 │    5039 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches (K)             │      10 │      10 │      10 │      10 │      10 │      10 │      10 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      22 │      22 │      22 │      22 │      22 │      22 │      22 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs (K)                │      13 │      13 │      13 │      13 │      13 │      13 │      13 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases (K)                     │      47 │      47 │      47 │      47 │      47 │      47 │      47 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains (K)                      │      29 │      29 │      29 │      29 │      29 │      29 │      29 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │     662 │     662 │     662 │     662 │     662 │     662 │     662 │       1 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (s)            │     104 │     104 │     104 │     104 │     104 │     104 │     104 │       1 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

librdkafka - basic consumer (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │     118 │     127 │     133 │     135 │     149 │     149 │     149 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      21 │      32 │      44 │      55 │      64 │      64 │      64 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases                         │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains                          │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       2 │       2 │       2 │       2 │       2 │       2 │       2 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (μs)            │    4571 │    6066 │    6684 │    7806 │    8607 │    8607 │    8607 │       9 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │     611 │     614 │     619 │     624 │     626 │     626 │     626 │       9 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛

librdkafka - with offset commit (messages: 1000)
╒══════════════════════════════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╤═════════╕
│ Metric                           │      p0 │     p25 │     p50 │     p75 │     p90 │     p99 │    p100 │ Samples │
╞══════════════════════════════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╪═════════╡
│ (Alloc + Retain) - Release Δ     │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Context switches                 │    5118 │    5123 │    5127 │    5139 │    5147 │    5147 │    5147 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Memory (allocated resident) (M)  │      20 │      26 │      32 │      43 │      47 │      47 │      47 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Object allocs                    │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Releases                         │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Retains                          │       0 │       0 │       0 │       0 │       0 │       0 │       0 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Throughput (# / s)               │       1 │       1 │       1 │       1 │       1 │       1 │       1 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (total CPU) (ms)            │      73 │      74 │      76 │      77 │      80 │      80 │      80 │       6 │
├──────────────────────────────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
│ Time (wall clock) (ms)           │     980 │     983 │     987 │     995 │    1012 │    1012 │    1012 │       6 │
╘══════════════════════════════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╧═════════╛
```",True,149,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/149,https://github.com/swift-server/swift-kafka-client/pull/149,closed,782,216,16,27,5,0,0,0,[],2023-11-28 17:44:59+00:00,2024-03-11 08:56:53+00:00,8953914.0,"103 days, 15:11:54",[],"[{'commit_sha': '98f17fae5cb602437672c0d0248480433d6a4636', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '57a349ef67161c14f7ac5e7b172d3011f957a575', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0123cafd9337daa1cf452666cd2c5160987e6e45', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '61b7aa573150650db2b0371cb2ed8d7aa7970977', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '376b30cb8cca623239eaecdfb20be789f44207f1', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '01a94481595c5c5b7f5e0e2a2b6c82d4a214bd16', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '274e4d987899fcb4c00ba8ace3fee7eff406e776', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1811752714ebb5797b05360b8ea39fb5a6e11fdf', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '632b6b71b52c1e0f1b6c7bb5aaa5b483cf4af2dc', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a617092d332da14e3c16da49278ffbe33fd94cb5', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e0c7ae783040bcb7c0bf2f409c4359899100fee9', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f9b1d5555398f7ae2294da4569f8b274dfcc8c73', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7de0be798d1a7817c7fe57bda037cca80a94ce5e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6a2a1b78d0bf71041ba3408ad870ab666743cbfe', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '34e7b4d1b91d62a91b15391476ab63358d83318c', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7f4c8e250ea9ec2e7665a3101dc3b6234ddb074c', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '01779edae1b2d58ac2574a4caebcae6823cc15d7', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'df17518b5c33e634f5cdf9d2093b5604d2bc6947', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3255efcd6e1253343e47315ab0ea5eba6d17346d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd316aacb28148516e120a0ea6f61d304b4cedd35', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4b7bbdd8ead3a1c14ffa0777b0191cc8868e3c05', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '860e1d5c0f7e5bd2769d0b31c7ce07eb7fa92306', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e328b68f3f3ca5b48e8116f74bee559ee05abc1d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4702bbbef7fe414d463619277c14d825f5ef920e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7d2828bd61d346e79637f8048bd59597900246a6', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fedbeff1d281dd8800b6551d619f39b0de7febcb', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2799c02056accb77e5501b9bc1789fec38ed983f', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}]",,127803250,,User,,4,,0,0
1465174120,Rename to `swift-kafka-client`,"### Modifications:

* change project name to `swift-kafka-client`
* replace package name `SwiftKafka` with `Kafka`
",True,108,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/108,https://github.com/swift-server/swift-kafka-client/pull/108,closed,177,177,46,1,0,1,0,0,[],2023-08-07 12:41:57+00:00,2023-08-07 12:48:39+00:00,402.0,0:06:42,"[{'comment_id': 1285818483, 'comment_body': 'Can we check in a follow up if we can get rid of all the `@testable` imports and just test the public API.', 'comment_created': datetime.datetime(2023, 8, 7, 12, 47, 4, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}]","[{'commit_sha': 'ded5a09649b9ee2b2ec14ed13336988511a3ea1c', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1315055320,`librdkafka` as submodule,"### Motivation

Previously users of our Package had to install `librdkafka` through their package managers to be able to run this package, as we relied on linking `librdkafka` **dynamically**.

With this PR, we ship `librdkafka` as a **git submodule** that is then built with SPM. This overcomes the issues we previously had with dynamic linking (e.g. not finding header files etc.).

### Modifications:

* add `librdkafka` submodule to project
* create a hardcoded `config.h` files that contain information on how
  `librdkafka` should be compiled (normally this is done through a the
`librdkafka/configure.sh` script, though we cannot invoke this at
buildtime with SPM)
* add package dependencies to `zstd` and `swift-nio-ssl`
* build `librdkafka` package with SPM instead of relying on a
  `.systemLibary` target
* create bridge between `<openssl/*>` headers and `swift-nio-ssl` with
  `custom` include folder
* update Docker to install `zlib`
* remove librdkafka installation from Docker
* create hard-coded `config.h` files used to compile librdkafka
* automatically update submodule from Docker

### Known Issues

* our Package assumes that `zlib`, `curl` and `sasl` are already installed on the system we are building on
* the new build process has **not** been tested on **x86_64**
* to build `librdkafka`, a config script has to be run that creates a file called `config.h` that configures the `lirbdkafka` build according to the underlying system, as we cannot run a build-script with SPM (I think 😅) I hardcoded a couple of `config.h` files to build `librdkafka` for the most used arch/os combinations (See: [Building librdkafka](https://github.com/confluentinc/librdkafka#building))
* at the moment, our [facebook/zstd](https://github.com/facebook/zstd) dependency throws out a lot of build warnings, however, this is a know issue: https://github.com/facebook/zstd/issues/3328",True,50,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/50,https://github.com/swift-server/swift-kafka-client/pull/50,closed,306,102,18,14,2,13,0,0,[],2023-04-15 12:12:42+00:00,2023-05-12 09:15:42+00:00,2322180.0,"26 days, 21:03:00","[{'comment_id': 1177966870, 'comment_body': 'This won\'t work because the `Package.swift` file gets compiled on the host that is building something, however, what you are interested in here is the target. However, I think we can solve this by using `.headerSearchPath("""", .when(platforms: [.linux]))` ', 'comment_created': datetime.datetime(2023, 4, 26, 14, 28, 16, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177973424, 'comment_body': 'Are these warnings or errors?', 'comment_created': datetime.datetime(2023, 4, 26, 14, 32, 57, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177974729, 'comment_body': 'I see what you did here. You used `swift-nio-ssl` to get a copy of BoringSSL. This is not supported though since BoringSSL is just an implementation detail of nio-ssl and might go away at any point. We would need to vendor our own copy here. @Lukasa might be able to point you into the right direction.', 'comment_created': datetime.datetime(2023, 4, 26, 14, 33, 46, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177978015, 'comment_body': 'I assume this is a copy of the file in `src/rdkafka.h` right? Can we just use a symlink instead here instead of copying?', 'comment_created': datetime.datetime(2023, 4, 26, 14, 36, 14, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177979557, 'comment_body': 'Is this pointing at the commit of the latest release?', 'comment_created': datetime.datetime(2023, 4, 26, 14, 37, 18, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1184762572, 'comment_body': 'Yes, now we are pointing at [librdkafka-v2.1.1](https://github.com/confluentinc/librdkafka/releases/tag/v2.1.1)', 'comment_created': datetime.datetime(2023, 5, 4, 9, 19, 11, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1184764527, 'comment_body': 'I talked to @lukasa, and our new approach is to have `openssl` as a `.systemLibrary` target.', 'comment_created': datetime.datetime(2023, 5, 4, 9, 21, 7, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1184765421, 'comment_body': 'Just warnings ⚠️ :\r\n\r\n```bash\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDLIB_VISIBLE\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDLIB_VISIBLE=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd.h:28:13: note: macro was defined here\r\n#    define ZSTDLIB_VISIBLE __attribute__ ((visibility (""default"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDLIB_HIDDEN\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDLIB_HIDDEN=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd.h:36:13: note: macro was defined here\r\n#    define ZSTDLIB_HIDDEN __attribute__ ((visibility (""hidden"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTD_CLEVEL_DEFAULT\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTD_CLEVEL_DEFAULT=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd.h:129:11: note: macro was defined here\r\n#  define ZSTD_CLEVEL_DEFAULT 3\r\n          ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZDICTLIB_VISIBLE\' has no effect on the import of \'libzstd.errors\'; pass \'-DZDICTLIB_VISIBLE=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zdict.h:28:13: note: macro was defined here\r\n#    define ZDICTLIB_VISIBLE __attribute__ ((visibility (""default"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZDICTLIB_HIDDEN\' has no effect on the import of \'libzstd.errors\'; pass \'-DZDICTLIB_HIDDEN=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zdict.h:36:13: note: macro was defined here\r\n#    define ZDICTLIB_HIDDEN __attribute__ ((visibility (""hidden"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDERRORLIB_VISIBLE\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDERRORLIB_VISIBLE=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd_errors.h:28:13: note: macro was defined here\r\n#    define ZSTDERRORLIB_VISIBLE __attribute__ ((visibility (""default"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDERRORLIB_HIDDEN\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDERRORLIB_HIDDEN=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd_errors.h:36:13: note: macro was defined here\r\n#    define ZSTDERRORLIB_HIDDEN __attribute__ ((visibility (""hidden"")))\r\n```', 'comment_created': datetime.datetime(2023, 5, 4, 9, 22, 3, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1184768744, 'comment_body': 'The `.when(...)` approach works for the target platform, though I have not yet found a better way to find out the target `arch` in SwiftPM 😅 ', 'comment_created': datetime.datetime(2023, 5, 4, 9, 25, 11, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1187734012, 'comment_body': 'where do these come from? system dependencies?', 'comment_created': datetime.datetime(2023, 5, 8, 18, 4, 24, tzinfo=datetime.timezone.utc), 'commenter': 'tomerd', 'type': 'User'}, {'comment_id': 1187735513, 'comment_body': 'are these all generated by kayaks build process ie by running `./configure` for the platform in question?', 'comment_created': datetime.datetime(2023, 5, 8, 18, 6, tzinfo=datetime.timezone.utc), 'commenter': 'tomerd', 'type': 'User'}, {'comment_id': 1187736483, 'comment_body': 'cc @yim-lee', 'comment_created': datetime.datetime(2023, 5, 8, 18, 7, 13, tzinfo=datetime.timezone.utc), 'commenter': 'tomerd', 'type': 'User'}, {'comment_id': 1187745105, 'comment_body': 'Yes, so `/usr/bin/curl` and `/usr/lib/sasl2` come with macOS, and `zlib` is included in the `Command Line Tools`', 'comment_created': datetime.datetime(2023, 5, 8, 18, 16, 53, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}]","[{'commit_sha': 'b2d3b201040312f7ee5c346d4d0b5acd0d3b5ebc', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e1fba124ea3aad58f3670eadb00658347b26758', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b253641965ba41fc9d3b37931c79b4efc18e826f', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b5d30d2e677e67582aebe5aa45af98612f8943e', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '994a183538d563091019862730f2efdb39ebad64', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a867d0f4e152274df95b27ab2ca0832220e58648', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '47547fabd3d26565fdb9a591a3ea301e30678d0e', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd44e0cf2b8cf5e339a1c281bb46f92880d678711', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '69f442bc65942434481d5f38c6f7d2c66a2ae5d1', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '78d38ba75e0e4f810ba240ed225e7dd75a016ed6', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fc83776b5676f54d1c852dcfd8fb6428bbb87265', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1eeeae5cb105775ea23f7ce9fcb3ae2982d74b2f', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd8ea4f96874b03aa821f40321f4d0027c5be9e6f', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9f9554290b727ec0abd2ea5ac2b1f0150bf755a6', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1598860660,Add benchmark infratructure without actual tests,There is an infrastructure for adding benchmark tests for swift-kafka-client.,True,146,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/146,https://github.com/swift-server/swift-kafka-client/pull/146,closed,192,3,14,4,4,0,0,0,[],2023-11-13 13:19:54+00:00,2023-11-24 11:20:46+00:00,943252.0,"10 days, 22:00:52",[],"[{'commit_sha': '9249ea06ef092f08ce5a055b7cc3a525ccac7a85', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5bde1e9596c19a6dffb975b564a066a1b6ef8c48', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '59553c2bd092d4e60595f2ad728c460b9e42b414', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f031d40b65ffaa05326714ec9e0e48b335702d0d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}]",,127803250,,User,,4,,0,0
1315055320,`librdkafka` as submodule,"### Motivation

Previously users of our Package had to install `librdkafka` through their package managers to be able to run this package, as we relied on linking `librdkafka` **dynamically**.

With this PR, we ship `librdkafka` as a **git submodule** that is then built with SPM. This overcomes the issues we previously had with dynamic linking (e.g. not finding header files etc.).

### Modifications:

* add `librdkafka` submodule to project
* create a hardcoded `config.h` files that contain information on how
  `librdkafka` should be compiled (normally this is done through a the
`librdkafka/configure.sh` script, though we cannot invoke this at
buildtime with SPM)
* add package dependencies to `zstd` and `swift-nio-ssl`
* build `librdkafka` package with SPM instead of relying on a
  `.systemLibary` target
* create bridge between `<openssl/*>` headers and `swift-nio-ssl` with
  `custom` include folder
* update Docker to install `zlib`
* remove librdkafka installation from Docker
* create hard-coded `config.h` files used to compile librdkafka
* automatically update submodule from Docker

### Known Issues

* our Package assumes that `zlib`, `curl` and `sasl` are already installed on the system we are building on
* the new build process has **not** been tested on **x86_64**
* to build `librdkafka`, a config script has to be run that creates a file called `config.h` that configures the `lirbdkafka` build according to the underlying system, as we cannot run a build-script with SPM (I think 😅) I hardcoded a couple of `config.h` files to build `librdkafka` for the most used arch/os combinations (See: [Building librdkafka](https://github.com/confluentinc/librdkafka#building))
* at the moment, our [facebook/zstd](https://github.com/facebook/zstd) dependency throws out a lot of build warnings, however, this is a know issue: https://github.com/facebook/zstd/issues/3328",True,50,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/50,https://github.com/swift-server/swift-kafka-client/pull/50,closed,306,102,18,14,2,13,0,0,[],2023-04-15 12:12:42+00:00,2023-05-12 09:15:42+00:00,2322180.0,"26 days, 21:03:00","[{'comment_id': 1177966870, 'comment_body': 'This won\'t work because the `Package.swift` file gets compiled on the host that is building something, however, what you are interested in here is the target. However, I think we can solve this by using `.headerSearchPath("""", .when(platforms: [.linux]))` ', 'comment_created': datetime.datetime(2023, 4, 26, 14, 28, 16, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177973424, 'comment_body': 'Are these warnings or errors?', 'comment_created': datetime.datetime(2023, 4, 26, 14, 32, 57, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177974729, 'comment_body': 'I see what you did here. You used `swift-nio-ssl` to get a copy of BoringSSL. This is not supported though since BoringSSL is just an implementation detail of nio-ssl and might go away at any point. We would need to vendor our own copy here. @Lukasa might be able to point you into the right direction.', 'comment_created': datetime.datetime(2023, 4, 26, 14, 33, 46, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177978015, 'comment_body': 'I assume this is a copy of the file in `src/rdkafka.h` right? Can we just use a symlink instead here instead of copying?', 'comment_created': datetime.datetime(2023, 4, 26, 14, 36, 14, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1177979557, 'comment_body': 'Is this pointing at the commit of the latest release?', 'comment_created': datetime.datetime(2023, 4, 26, 14, 37, 18, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1184762572, 'comment_body': 'Yes, now we are pointing at [librdkafka-v2.1.1](https://github.com/confluentinc/librdkafka/releases/tag/v2.1.1)', 'comment_created': datetime.datetime(2023, 5, 4, 9, 19, 11, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1184764527, 'comment_body': 'I talked to @lukasa, and our new approach is to have `openssl` as a `.systemLibrary` target.', 'comment_created': datetime.datetime(2023, 5, 4, 9, 21, 7, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1184765421, 'comment_body': 'Just warnings ⚠️ :\r\n\r\n```bash\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDLIB_VISIBLE\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDLIB_VISIBLE=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd.h:28:13: note: macro was defined here\r\n#    define ZSTDLIB_VISIBLE __attribute__ ((visibility (""default"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDLIB_HIDDEN\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDLIB_HIDDEN=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd.h:36:13: note: macro was defined here\r\n#    define ZSTDLIB_HIDDEN __attribute__ ((visibility (""hidden"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTD_CLEVEL_DEFAULT\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTD_CLEVEL_DEFAULT=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd.h:129:11: note: macro was defined here\r\n#  define ZSTD_CLEVEL_DEFAULT 3\r\n          ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZDICTLIB_VISIBLE\' has no effect on the import of \'libzstd.errors\'; pass \'-DZDICTLIB_VISIBLE=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zdict.h:28:13: note: macro was defined here\r\n#    define ZDICTLIB_VISIBLE __attribute__ ((visibility (""default"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZDICTLIB_HIDDEN\' has no effect on the import of \'libzstd.errors\'; pass \'-DZDICTLIB_HIDDEN=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zdict.h:36:13: note: macro was defined here\r\n#    define ZDICTLIB_HIDDEN __attribute__ ((visibility (""hidden"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDERRORLIB_VISIBLE\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDERRORLIB_VISIBLE=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd_errors.h:28:13: note: macro was defined here\r\n#    define ZSTDERRORLIB_VISIBLE __attribute__ ((visibility (""default"")))\r\n            ^\r\n/swift-kafka-gsoc/Sources/Crdkafka/librdkafka/src/rdkafka_zstd.c:38:2: warning: definition of configuration macro \'ZSTDERRORLIB_HIDDEN\' has no effect on the import of \'libzstd.errors\'; pass \'-DZSTDERRORLIB_HIDDEN=...\' on the command line to configure the module [-Wconfig-macros]\r\n#include <zstd_errors.h>\r\n ^\r\n/swift-kafka-gsoc/.build/checkouts/zstd/lib/zstd_errors.h:36:13: note: macro was defined here\r\n#    define ZSTDERRORLIB_HIDDEN __attribute__ ((visibility (""hidden"")))\r\n```', 'comment_created': datetime.datetime(2023, 5, 4, 9, 22, 3, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1184768744, 'comment_body': 'The `.when(...)` approach works for the target platform, though I have not yet found a better way to find out the target `arch` in SwiftPM 😅 ', 'comment_created': datetime.datetime(2023, 5, 4, 9, 25, 11, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1187734012, 'comment_body': 'where do these come from? system dependencies?', 'comment_created': datetime.datetime(2023, 5, 8, 18, 4, 24, tzinfo=datetime.timezone.utc), 'commenter': 'tomerd', 'type': 'User'}, {'comment_id': 1187735513, 'comment_body': 'are these all generated by kayaks build process ie by running `./configure` for the platform in question?', 'comment_created': datetime.datetime(2023, 5, 8, 18, 6, tzinfo=datetime.timezone.utc), 'commenter': 'tomerd', 'type': 'User'}, {'comment_id': 1187736483, 'comment_body': 'cc @yim-lee', 'comment_created': datetime.datetime(2023, 5, 8, 18, 7, 13, tzinfo=datetime.timezone.utc), 'commenter': 'tomerd', 'type': 'User'}, {'comment_id': 1187745105, 'comment_body': 'Yes, so `/usr/bin/curl` and `/usr/lib/sasl2` come with macOS, and `zlib` is included in the `Command Line Tools`', 'comment_created': datetime.datetime(2023, 5, 8, 18, 16, 53, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}]","[{'commit_sha': 'b2d3b201040312f7ee5c346d4d0b5acd0d3b5ebc', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e1fba124ea3aad58f3670eadb00658347b26758', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b253641965ba41fc9d3b37931c79b4efc18e826f', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b5d30d2e677e67582aebe5aa45af98612f8943e', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '994a183538d563091019862730f2efdb39ebad64', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a867d0f4e152274df95b27ab2ca0832220e58648', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '47547fabd3d26565fdb9a591a3ea301e30678d0e', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd44e0cf2b8cf5e339a1c281bb46f92880d678711', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '69f442bc65942434481d5f38c6f7d2c66a2ae5d1', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '78d38ba75e0e4f810ba240ed225e7dd75a016ed6', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fc83776b5676f54d1c852dcfd8fb6428bbb87265', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1eeeae5cb105775ea23f7ce9fcb3ae2982d74b2f', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd8ea4f96874b03aa821f40321f4d0027c5be9e6f', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9f9554290b727ec0abd2ea5ac2b1f0150bf755a6', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1338362399,Fix failing CI Builds,"## Motivation:

CI failed as our `soundness.sh` script was not correctly adjusted to the project.

## Modifications:

* excluded `CODE_OF_CONDUCT.md` from soundness check as it deliberately gives examples of what unacceptable language looks like
* excluded all `*Config.swift` files from soundness check as Kafka configuration properties rely on terminology which is considered unacceptable
* add instructions for installing `nicklockwood/SwiftFormat` to
  `Dockerfile`
* add copyright header to `Sources/Crdkafka/shim.h`
* exclude `librdkafka` from the copyright header check in `soundness.sh`
* update files to conform to **SwiftFormat** rules to stop failing build

## Result:

The soundness CI check succeeds.",True,52,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/52,https://github.com/swift-server/swift-kafka-client/pull/52,closed,46,15,6,6,3,1,0,0,[],2023-05-04 12:29:53+00:00,2023-05-10 12:04:20+00:00,516867.0,"5 days, 23:34:27","[{'comment_id': 1186143030, 'comment_body': ""We usually prefer to disable `hoistTry` (and `hoistAwait`) to avoid moving `try`s and `await`s to the beginning of the line. It's generally not useful to lose clarity of what is throwing/async, and sometimes actually generates compiler errors because you can end up with malformed syntax.\r\n\r\nYou can disable both options by adding the following to `.swiftformat`:\r\n```\r\n--disable hoistTry\r\n--disable hoistAwait\r\n```\r\n\r\nYou can read more about the options [here](https://github.com/nicklockwood/SwiftFormat/blob/master/Rules.md#hoistTry) and [here](https://github.com/nicklockwood/SwiftFormat/blob/master/Rules.md#hoistAwait)."", 'comment_created': datetime.datetime(2023, 5, 5, 14, 9, 19, tzinfo=datetime.timezone.utc), 'commenter': 'gjcairo', 'type': 'User'}]","[{'commit_sha': 'd8da1216450b3f48c80f8349447c267df6d97c50', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '56e8140d8da3aedfa1fadfe17f6b601739042deb', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1f30c9383b8f56d1a9e9423a29549aabfc8e7889', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eb8fb33af7eb041d5b6de09996a6c33894d051a2', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '641488883123a9839b04d15bc2d27aa57d642796', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '76e93f96410167a92c47c35d8fc52032c7f1924f', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1384133360,Adopt the Swift Coc,"### Motivation

We're centralizing on the Swift code of conduct, so we'll x-reference that instead of holding our own.

### Modifications

Hyperlink out to Swift.

### Result

Shared CoC across the projects.",True,58,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/58,https://github.com/swift-server/swift-kafka-client/pull/58,closed,2,45,1,1,0,0,0,0,[],2023-06-08 10:00:22+00:00,2023-06-08 13:21:26+00:00,12064.0,3:21:04,[],"[{'commit_sha': '16fe579af1d5f2ba446dc3196d0efbe645b5be23', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1465174120,Rename to `swift-kafka-client`,"### Modifications:

* change project name to `swift-kafka-client`
* replace package name `SwiftKafka` with `Kafka`
",True,108,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/108,https://github.com/swift-server/swift-kafka-client/pull/108,closed,177,177,46,1,0,1,0,0,[],2023-08-07 12:41:57+00:00,2023-08-07 12:48:39+00:00,402.0,0:06:42,"[{'comment_id': 1285818483, 'comment_body': 'Can we check in a follow up if we can get rid of all the `@testable` imports and just test the public API.', 'comment_created': datetime.datetime(2023, 8, 7, 12, 47, 4, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}]","[{'commit_sha': 'ded5a09649b9ee2b2ec14ed13336988511a3ea1c', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1524520769,Generate CONTRIBUTORS.txt,,True,134,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/134,https://github.com/swift-server/swift-kafka-client/pull/134,closed,1,0,1,1,0,0,0,0,[],2023-09-21 09:57:50+00:00,2023-09-21 10:06:05+00:00,495.0,0:08:15,[],"[{'commit_sha': '449054c067b7edd44c52f59c51511277ba650369', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1465174120,Rename to `swift-kafka-client`,"### Modifications:

* change project name to `swift-kafka-client`
* replace package name `SwiftKafka` with `Kafka`
",True,108,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/108,https://github.com/swift-server/swift-kafka-client/pull/108,closed,177,177,46,1,0,1,0,0,[],2023-08-07 12:41:57+00:00,2023-08-07 12:48:39+00:00,402.0,0:06:42,"[{'comment_id': 1285818483, 'comment_body': 'Can we check in a follow up if we can get rid of all the `@testable` imports and just test the public API.', 'comment_created': datetime.datetime(2023, 8, 7, 12, 47, 4, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}]","[{'commit_sha': 'ded5a09649b9ee2b2ec14ed13336988511a3ea1c', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38
1439400852,Feature: expose librdkafka statistics as swift metrics,"This is approximate solution for exposing librdkafka statistics callback (https://github.com/swift-server/swift-kafka-gsoc/issues/79)

Main ideas:
1. Specify interval for metrics updates
2. Allow to specify metrics per librdkafka key",True,92,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/92,https://github.com/swift-server/swift-kafka-client/pull/92,closed,357,7,12,26,12,104,0,0,[],2023-07-18 14:51:50+00:00,2023-11-06 13:59:52+00:00,9587282.0,"110 days, 23:08:02","[{'comment_id': 1267869491, 'comment_body': ""I don't think we need the guard here"", 'comment_created': datetime.datetime(2023, 7, 19, 10, 16, 9, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1267871770, 'comment_body': 'NIT: `XCTAssertFalse`', 'comment_created': datetime.datetime(2023, 7, 19, 10, 18, 26, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1269640154, 'comment_body': 'This can be part of the TaskGroup I think\r\n\r\n(you can then await for its completion with `await group.next()`)', 'comment_created': datetime.datetime(2023, 7, 20, 15, 31, 37, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1269676090, 'comment_body': 'Oh, certainly yes, thank you for the hint!\r\nShould we probably collect all tasks from the group as they all should be finished? \r\nLike this:\r\n```\r\nfor try await _ in group { }\r\n```\r\nUPD: or it is even not required as on exit from `withTaskGroup` all tasks will be collected anyway', 'comment_created': datetime.datetime(2023, 7, 20, 16, 1, 55, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1269694847, 'comment_body': ""Short answer: tasks will be collected anyway, we use `group.next()` to time `triggerGracefulShutdown` correctly\r\n\r\nYou invoke `group.next()` to receive the result of the next completed task. You don't have to invoke it for all of the Tasks you add. When you take a look at the `SwiftKafkaTests.swift` you can see that I used `group.next()` to wait for the producer/consumer task to be finished so I can safely `triggerGracefulShutdown`  _after_ all my producer/consumer testing logic has run.\r\n\r\n[Documentation for reference](https://developer.apple.com/documentation/swift/taskgroup/next())"", 'comment_created': datetime.datetime(2023, 7, 20, 16, 19, 31, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1269838337, 'comment_body': 'I was thinking whether we need anything to do with this sequence, i.e.:\r\n1. to call `finish()` in Consumer/Producer delegate (`KafkaConsumerCloseOnTerminate/KafkaProducerCloseOnTerminate`) or \r\n2. to call it here ', 'comment_created': datetime.datetime(2023, 7, 20, 18, 41, 57, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1270464193, 'comment_body': ""I think ideally what we would do here is something like we do in the `KafkaConsumer` where we enter a state in which we are still polling for events but then in this case drop any incoming statistics events so that new statistics emitted after termination of the `AsyncSequence` don't buffer in memory."", 'comment_created': datetime.datetime(2023, 7, 21, 9, 28, 19, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1270485854, 'comment_body': ""The main problem is that there is one state machine, so one switch to `.consumptionStopped` should be enough on terminate of any of these sequences\r\nUPD: so, I've added this finish to Consumer/Producer specific .*Terminate delegates. But if add here, I am not sure how it should look like..."", 'comment_created': datetime.datetime(2023, 7, 21, 9, 50, 10, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1270557269, 'comment_body': 'Yeah, we have to work around this here. There are two things that I can currently think of:\r\n\r\n1. In `KafkaClient` (now `RDKafkaClient` on `main`) keep track of all the `RDKafkaEvent`s we are listening to and drop inside of `KafkaClient` when `RDKafkaEvent` is not part of the list of `RDKafkaEvent`s we are listening to -> in `KafkaConsumer` / `KafkaProducer` you would then just change what the `RDKafkaClient` should listen to\r\n2. Have something like a `StatisticaHandler` type that has its own state and just forwards stuff to the `source` or not ', 'comment_created': datetime.datetime(2023, 7, 21, 11, 13, 4, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1272229059, 'comment_body': ""We seem to handle all events anyway, so it should work as expected. But additionally, I've added separate shutdown for statistics, merged two states for consuming and consuming stopped into one by making sources optional.\r\nPlease, feel free to re-open in case of any doubts."", 'comment_created': datetime.datetime(2023, 7, 24, 12, 58, 19, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1286898470, 'comment_body': 'After you rebase onto `main` this extension should become obsolete (we now have a similar extension on `main`)', 'comment_created': datetime.datetime(2023, 8, 8, 10, 2, 34, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1286902597, 'comment_body': 'Can we wrap that in a `struct` with `static` properties like we did with other config properties e.g.:\r\n\r\n```swift\r\n            /// Minimum time between key refresh attempts.\r\n            public struct KeyRefreshAttempts: Sendable, Hashable {\r\n                internal let rawValue: UInt\r\n\r\n                private init(rawValue: UInt) {\r\n                    self.rawValue = rawValue\r\n                }\r\n\r\n                /// (Lowest granularity is milliseconds)\r\n                public static func value(_ value: Duration) -> KeyRefreshAttempts {\r\n                    precondition(\r\n                        value.canBeRepresentedAsMilliseconds,\r\n                        ""Lowest granularity is milliseconds""\r\n                    )\r\n                    return .init(rawValue: UInt(value.inMilliseconds))\r\n                }\r\n\r\n                /// Disable automatic key refresh by setting this property.\r\n                public static let disable: KeyRefreshAttempts = .init(rawValue: 0)\r\n            }\r\n\r\n```', 'comment_created': datetime.datetime(2023, 8, 8, 10, 6, 27, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1286906479, 'comment_body': 'See comment above', 'comment_created': datetime.datetime(2023, 8, 8, 10, 10, 9, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1286908068, 'comment_body': 'This makes sense for both `KafkaConsumer` and `KafkaProducer`', 'comment_created': datetime.datetime(2023, 8, 8, 10, 11, 35, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1286913111, 'comment_body': '`!= .disable`', 'comment_created': datetime.datetime(2023, 8, 8, 10, 16, 34, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1286913535, 'comment_body': '`!= .disable`', 'comment_created': datetime.datetime(2023, 8, 8, 10, 16, 57, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1287034790, 'comment_body': ""I'd just do\r\n\r\n```swift\r\ngroup.addTask {\r\n    var statistics: KafkaStatistics?\r\n    for try await event in events {\r\n        ...\r\n    }\r\n    XCTAssert(statistics ...)\r\n}\r\n```\r\n\r\nSo you don't have to bother with the lock "", 'comment_created': datetime.datetime(2023, 8, 8, 12, 18, 50, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1287034947, 'comment_body': 'Same here', 'comment_created': datetime.datetime(2023, 8, 8, 12, 18, 59, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1287036407, 'comment_body': 'Why an optional initialiser here?', 'comment_created': datetime.datetime(2023, 8, 8, 12, 20, 17, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1287042862, 'comment_body': 'Nit (please also change for other newly created files)\r\n\r\n```suggestion\r\n// Copyright (c) 2023 Apple Inc. and the swift-kafka-client project authors\r\n```', 'comment_created': datetime.datetime(2023, 8, 8, 12, 25, 52, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1287110728, 'comment_body': 'Sorry for this back and forth but I think we would ideally use [`swift-metrics`](https://github.com/apple/swift-metrics) to emit statistics instead of having these structs that we emit through the `KafkaConsumerEvents` sequence. I am happy to discuss this and help along the way!', 'comment_created': datetime.datetime(2023, 8, 8, 13, 20, 55, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1290009943, 'comment_body': 'Thank you for your comment!\r\n\r\nI think that `swift-metrics` is a good thing and should be used to deliver statistics and that is the most important thing.\r\n\r\nHowever, from my perspective, there could be other scenarios when statistics can be used by an end-user application directly for adjusting its behaviour. \r\nThere are some examples: \r\n1. measure lag to the final offset to estimate [when/are/time for] all records received \r\n2. work with latency metrics to provide approximate latency for end user\r\n3. understand the number messages in flight to adjust internal throttling/coalescing/backpressure\r\n\r\nI believe there could be other various scenarios when it is required by end-user application. However..\r\n\r\nNext thing that comes to mind is about delivery of this statistics to `swift-metrics`: I am not sure if there is an automatic way to deliver the whole json to swift-metics directly...\r\nTherefore, I am a little bit confused if there is a suggestion to use some other model instead of proposed. \r\nShould we?', 'comment_created': datetime.datetime(2023, 8, 10, 11, 53, 35, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1290045295, 'comment_body': 'That is definitely not required any more.', 'comment_created': datetime.datetime(2023, 8, 10, 12, 24, 17, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1290045714, 'comment_body': 'That sounds better', 'comment_created': datetime.datetime(2023, 8, 10, 12, 24, 36, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1290125271, 'comment_body': 'I was thinking about property wrapper but looked at other properties that are checked in place, e.g.:\r\n```\r\n    /// Metadata cache max age.\r\n    /// (Lowest granularity is milliseconds)\r\n    /// Default: `.milliseconds(900_000)`\r\n    public var maximumMetadataAge: Duration = .milliseconds(900_000) {\r\n        didSet {\r\n            precondition(\r\n                self.maximumMetadataAge.canBeRepresentedAsMilliseconds,\r\n                ""Lowest granularity is milliseconds""\r\n            )\r\n        }\r\n    }\r\n```', 'comment_created': datetime.datetime(2023, 8, 10, 13, 22, 15, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1290308059, 'comment_body': ""Hello @blindspotbounty ,\r\n\r\nI don't think providing metrics to an end-user application is a priority. Users should just tweak their configurations to work well and should not have some statistics-dependent magic running in their applications IMO.\r\n\r\nUnfortunately, there is no direct mapping from `json` to `swift-metrics`. However, here is how I would go about implementing this:\r\n\r\n1. Have a new type called `KafkaMetricsReporting` that you pass as an _optional_ argument as part of `KafkaConsumerConfiguration`/`KafkaProducerConfiguration`\r\n\r\nThis could look something like this:\r\n\r\n```swift\r\npublic struct KafkaMetricsReporting {\r\n    public let myCounter: Metrics.Counter?\r\n    public let myGauge: Metrics.Gauge?\r\n    public let myTimer: Metrics.Timer?\r\n}\r\n```\r\n\r\n```swift\r\npublic struct KafkaConsumerConfig {\r\n    public var metrics: KafkaMetricsReporting?\r\n}\r\n```\r\n\r\nThis can be similar to the `KafkaStatistics` type you already have. However, you'd have to find suitable [metric types](https://github.com/apple/swift-metrics#metric-types) for each statistics property.\r\n\r\n2. If the `Kafka[Consumer|Producer]Configuration` is non-`nil` and not all of its properties are `nil`, enable for statistics and update the metrics accordingly when a new statistics event is received\r\n\r\n3. When you have received the event, update all metrics in you `KafkaMetricsReporting` that are non-`nil`"", 'comment_created': datetime.datetime(2023, 8, 10, 15, 23, 28, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1294370110, 'comment_body': ""That sounds nice and should be pretty much convenient.\r\nHowever, there could be a number of topics and partitions in them. Currently, I see just several solutions that might suit here:\r\n1. Provide metrics factory that would make counters with labels topic=abc partition=xx\r\n2. Calculate averages/totals for all topics/partitions for specific counters (probably the best)\r\n3. Provide different gauges/counters in a dictionary to configuration\r\n4. Don't cover array fields so far\r\n \r\nMaybe there is some better solution, let me know if you have something in mind, please. "", 'comment_created': datetime.datetime(2023, 8, 15, 9, 21, 58, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1294409850, 'comment_body': 'Hey @blindspotbounty , I haven’t really thought about how we should handle these array based metrics for topic / partitions etc. however I am inclined to not aggregate them to averages but rather expose topic / partition … -specific information.\r\n\r\nMetrics has evolved into quite a big feature now so I would suggest not covering all metrics at once but rather start by getting the general structure right and listening to a hand full of metrics.\r\n\r\nYou can then just add the remaining metrics in a follow-up pull request once we get the basics right :smile:\r\n\r\nI believe starting with some of the [Top Level Metrics](https://github.com/confluentinc/librdkafka/blob/master/STATISTICS.md#top-level) is a good start', 'comment_created': datetime.datetime(2023, 8, 15, 9, 59, 28, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1297048403, 'comment_body': ""I've made preliminary change to the code to fit this suggestion.\r\nPlease, let me know if my understanding is correct."", 'comment_created': datetime.datetime(2023, 8, 17, 10, 48, 36, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1298426329, 'comment_body': '```suggestion\r\n    public struct KafkaMetrics: Sendable {\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 13, 1, 50, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298429879, 'comment_body': '```suggestion\r\n        case disabled\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 13, 5, 8, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298430076, 'comment_body': '```suggestion\r\n        case enabled(updateInterval: KafkaConfiguration.KeyRefreshAttempts, options: MetricsOptions)\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 13, 5, 21, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298430385, 'comment_body': '`KeyRefreshAttempts` seems wrong here', 'comment_created': datetime.datetime(2023, 8, 18, 13, 5, 41, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298432299, 'comment_body': 'This type exists in `KafkaConfiguration+Security.swift`, why did you add it here?', 'comment_created': datetime.datetime(2023, 8, 18, 13, 7, 34, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298432580, 'comment_body': '```suggestion\r\n    public var metrics: KafkaConfiguration.Metrics = .disabled\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 13, 7, 51, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298433187, 'comment_body': '```suggestion\r\n        if case .enabled(let interval, _) = metrics {\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 13, 8, 21, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298433427, 'comment_body': '```suggestion\r\n    public var metrics: KafkaConfiguration.Metrics = .disabled\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 13, 8, 34, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298433626, 'comment_body': '```suggestion\r\n        if case .enabled(let interval, _) = metrics {\r\n```', 'comment_created': datetime.datetime(2023, 8, 18, 13, 8, 46, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298437248, 'comment_body': 'Can you please explicitly `switch` over all `event` cases here?\r\n\r\nHaving the\r\n\r\n```swift\r\nif case let () {\r\n    continue\r\n}\r\n```\r\n\r\nseems hard to read', 'comment_created': datetime.datetime(2023, 8, 18, 13, 12, 20, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298463076, 'comment_body': 'Generally no abbreviations please\r\n\r\n(also look at other properties)', 'comment_created': datetime.datetime(2023, 8, 18, 13, 37, 6, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298473283, 'comment_body': 'Please also check that **not all** of the properties of `KafkaMetrics` are `nil` in order to listen to `.statistics` events\r\n\r\nIn that case, listening to the `.statistics` event is still pointless', 'comment_created': datetime.datetime(2023, 8, 18, 13, 46, 23, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298476945, 'comment_body': 'Please also check that **not all** of the properties of `KafkaMetrics` are `nil` in order to listen to `.statistics` events\r\n\r\nIn that case, listening to the `.statistics` event is still pointless', 'comment_created': datetime.datetime(2023, 8, 18, 13, 49, 36, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298480180, 'comment_body': 'This adds no semantic value but I would use a `switch` here and explicitly set         `resultDict[""statistics.interval.ms""] = 0` in the case of `.disabled`', 'comment_created': datetime.datetime(2023, 8, 18, 13, 52, 27, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298481070, 'comment_body': 'This adds no semantic value but I would use a `switch` here and explicitly set `resultDict[""statistics.interval.ms""] = 0` in the case of `.disabled`', 'comment_created': datetime.datetime(2023, 8, 18, 13, 53, 17, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1298514281, 'comment_body': 'What I usually do for such cases is have an `AsyncStream`.\r\n\r\n**This way we can get rid of the `swift-atomics` dependency entirely.**\r\n\r\n```swift\r\nclass MockTimerHandler: TimerHandler {\r\n    let expectation: AsyncStream<Int64>\r\n    private let expectationContinuation: AsyncStream<Int64>.Continuation\r\n\r\n    init() {\r\n        var expectationContinuation: AsyncStream<Int64>.Continuation!\r\n        self.expectation = AsyncStream<Int64> { expectationContinuation = $0 }\r\n        self.expectationContinuation = expectationContinuation!\r\n    }\r\n\r\n     func recordNanoseconds(_ duration: Int64) {\r\n        self.expectation.yield(duration)\r\n    }\r\n}\r\n```\r\n\r\nThen in your test you can just do:\r\n\r\n```swift\r\nvar iterator = timerHandler.expectation.makeAsyncIterator()\r\nlet actualValue = await iterator.next()\r\n```\r\n\r\n(You can also rename `expectation` to `duration` if you like)', 'comment_created': datetime.datetime(2023, 8, 18, 14, 23, 21, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1299741070, 'comment_body': 'I took them from librdkafka statistics. \r\nSo, rename them all?', 'comment_created': datetime.datetime(2023, 8, 21, 7, 56, 28, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1299744269, 'comment_body': 'The suggestion was there https://github.com/swift-server/swift-kafka-client/pull/92#discussion_r1286902597\r\nShould we back to Duration?', 'comment_created': datetime.datetime(2023, 8, 21, 7, 59, 22, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1299745853, 'comment_body': 'Sure', 'comment_created': datetime.datetime(2023, 8, 21, 8, 0, 49, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1299806333, 'comment_body': 'Yes', 'comment_created': datetime.datetime(2023, 8, 21, 8, 43, 11, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1299827753, 'comment_body': 'Btw, should we rename them in json model?', 'comment_created': datetime.datetime(2023, 8, 21, 9, 1, 21, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1299857209, 'comment_body': 'Not a must as long as the JSON model remains `internal`, but it would make the code a lot more coherent 😄 ', 'comment_created': datetime.datetime(2023, 8, 21, 9, 27, 13, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1299866576, 'comment_body': ""I've added `didSet` with precondition for both: enabled metrics and for positive duration."", 'comment_created': datetime.datetime(2023, 8, 21, 9, 35, 34, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1299901836, 'comment_body': 'I can rename those field then mapping will just in coding keys.', 'comment_created': datetime.datetime(2023, 8, 21, 10, 5, 53, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1300037604, 'comment_body': 'Great!', 'comment_created': datetime.datetime(2023, 8, 21, 12, 22, 40, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1305610951, 'comment_body': 'done', 'comment_created': datetime.datetime(2023, 8, 25, 12, 41, 54, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1309027842, 'comment_body': ""```suggestion\r\n```\r\n\r\nNit: we don't need `import Atomics` here"", 'comment_created': datetime.datetime(2023, 8, 29, 15, 42, 3, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309032725, 'comment_body': '```suggestion\r\n        let serviceGroupConfiguration = ServiceGroupConfiguration(services: [consumer], logger: .kafkaTest)\r\n        let serviceGroup = ServiceGroup(configuration: serviceGroupConfiguration)\r\n```\r\n\r\nThe other `ServiceGroup` initializer has been deprecated', 'comment_created': datetime.datetime(2023, 8, 29, 15, 45, 57, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309033234, 'comment_body': '```suggestion\r\n        let serviceGroupConfiguration = ServiceGroupConfiguration(services: [producer], logger: .kafkaTest)\r\n        let serviceGroup = ServiceGroup(configuration: serviceGroupConfiguration)\r\n```', 'comment_created': datetime.datetime(2023, 8, 29, 15, 46, 20, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309046862, 'comment_body': '`options` is a very generic name, maybe call it `metrics`?', 'comment_created': datetime.datetime(2023, 8, 29, 15, 56, 44, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309047187, 'comment_body': 'Same here, `options` very generic', 'comment_created': datetime.datetime(2023, 8, 29, 15, 57, 1, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309047547, 'comment_body': 'Same here, `options` very generic', 'comment_created': datetime.datetime(2023, 8, 29, 15, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309047661, 'comment_body': 'Same here, `options` very generic', 'comment_created': datetime.datetime(2023, 8, 29, 15, 57, 24, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309048967, 'comment_body': '```suggestion\r\n            resultDict[""statistics.interval.ms""] = ""0"" // Disables metrics\r\n```', 'comment_created': datetime.datetime(2023, 8, 29, 15, 58, 30, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309049232, 'comment_body': '```suggestion\r\n            resultDict[""statistics.interval.ms""] = ""0"" // Disables metrics\r\n```', 'comment_created': datetime.datetime(2023, 8, 29, 15, 58, 43, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309052997, 'comment_body': '```suggestion\r\n    }\r\n\r\n```', 'comment_created': datetime.datetime(2023, 8, 29, 16, 1, 41, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309054235, 'comment_body': 'I think we would not want to `fatalError` in this case', 'comment_created': datetime.datetime(2023, 8, 29, 16, 2, 44, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309097843, 'comment_body': ""I'd probably move this to the `RDKafka/` folder and call it something like `RDKafkaStatistics`\r\n\r\nThe `RDKafka/` folder is for everything that is still Swift but rather a wrapper / a port of something that `librdkafka` provides us"", 'comment_created': datetime.datetime(2023, 8, 29, 16, 41, 36, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309115802, 'comment_body': 'The existence of this `KafkaStatistics` type can be avoided I believe:\r\n\r\nWhat if we do:\r\n\r\n```swift\r\nenum RDKafkaEvent {\r\n    ...\r\n    case statistics(RDKafkaStatistics) // <- decoded JSON (see other comment. aka KafkaStatisticsJsonModel)\r\n    ...\r\n}\r\n```\r\n\r\nAnd then just have a method somewhere in `KafkaMetrics` or so which does what fill does at the moment:\r\n\r\n```swift\r\ninternal func update(with statistics: RDKafkaStatistics) {\r\n  ...\r\n}\r\n```\r\n\r\nSo in `KafkaConsumer` and `KafkaProducer` we do:\r\n\r\n```swift\r\ncase .statistics(let statistics):\r\n    self.config.metrics.update(with: statistics)\r\n```', 'comment_created': datetime.datetime(2023, 8, 29, 16, 57, 44, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1309854225, 'comment_body': 'Nice idea!', 'comment_created': datetime.datetime(2023, 8, 30, 8, 1, 38, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1309857812, 'comment_body': ""Let's make an assert?"", 'comment_created': datetime.datetime(2023, 8, 30, 8, 4, 5, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1332883326, 'comment_body': 'Can we please use `Foundation.JSONDecoder` here instead.', 'comment_created': datetime.datetime(2023, 9, 21, 11, 5, 49, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332883692, 'comment_body': '```suggestion\r\n    public struct Metrics: Sendable {\r\n```', 'comment_created': datetime.datetime(2023, 9, 21, 11, 6, 7, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332884078, 'comment_body': '```suggestion\r\n    /// Configuration for the metrics emitted by `SwiftKafka`.\r\n```', 'comment_created': datetime.datetime(2023, 9, 21, 11, 6, 27, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332885163, 'comment_body': ""I don't know if we need those. Do we have a concrete use-case how those would be observed?"", 'comment_created': datetime.datetime(2023, 9, 21, 11, 7, 19, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332886118, 'comment_body': '```suggestion\r\n        /// Number of operations (callbacks, events, etc) waiting in the queue.\r\n        public var queuedOperation: Gauge?\r\n```', 'comment_created': datetime.datetime(2023, 9, 21, 11, 8, 20, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332886832, 'comment_body': ""Isn't this threshold set by the configuration? Can this change over time? Wondering if should expose this"", 'comment_created': datetime.datetime(2023, 9, 21, 11, 9, 1, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332887926, 'comment_body': 'This is producer specific should we only make this available on the producer configuration?\r\n\r\n```suggestion\r\n        /// Current number of queued producer messages.\r\n        public var queuedProducerMessages: Gauge?\r\n        /// Current total size in bytes of queued producer messages.\r\n        public var queuedProducerMessagesSize: Gauge?\r\n```', 'comment_created': datetime.datetime(2023, 9, 21, 11, 10, 4, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332888653, 'comment_body': ""If this is a total then it shouldn't be a `Gauge` but rather a `Counter` or are we using a `Gauge` because we only get the latest values and just have to set it?\r\n```suggestion\r\n        /// Total number of requests sent to Kafka brokers.\r\n        public var totalKafkaBrokerRequests: Counter?\r\n```"", 'comment_created': datetime.datetime(2023, 9, 21, 11, 10, 49, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332890472, 'comment_body': '```suggestion\r\n        /// Total number of bytes transmitted to Kafka brokers.\r\n        public var totalKafkaBrokerRequestsSize: Counter?\r\n        /// Total number of responses received from Kafka brokers.\r\n        public var totalKafkaBrokerResponses: Counter?\r\n        /// Total number of bytes received from Kafka brokers.\r\n        public var totalKafkaBrokerResponsesSize: Gauge?\r\n```', 'comment_created': datetime.datetime(2023, 9, 21, 11, 12, 23, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332890831, 'comment_body': 'Same for all of those', 'comment_created': datetime.datetime(2023, 9, 21, 11, 12, 43, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332891839, 'comment_body': '```suggestion\r\n        /// Number of topics in the metadata cache.\r\n        public var topicsInMetadataCache: Gauge?\r\n```', 'comment_created': datetime.datetime(2023, 9, 21, 11, 13, 40, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332893849, 'comment_body': ""We don't nee this struct. Let's just make it an optional in the producer and consumer configuration and add the `updateInterval` into the current `KafkaMetrics` struct."", 'comment_created': datetime.datetime(2023, 9, 21, 11, 15, 35, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332894781, 'comment_body': 'Can we please put each property into a separate line here', 'comment_created': datetime.datetime(2023, 9, 21, 11, 16, 24, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332894937, 'comment_body': 'Can we remove the commented out code please', 'comment_created': datetime.datetime(2023, 9, 21, 11, 16, 33, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1332895499, 'comment_body': ""There is a `MetricsTestingKit` which we should use here instead so we don't need the `MockTimerHandler`"", 'comment_created': datetime.datetime(2023, 9, 21, 11, 17, 11, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1343903269, 'comment_body': 'That make sense. As seems that JSONDecoder is supported for all platforms\r\nThank you', 'comment_created': datetime.datetime(2023, 10, 3, 10, 49, 6, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343909225, 'comment_body': ""I don't see much value in timestamp and time. However, age of specific client can be useful to see its correlation with sent/received data and other things.\r\n"", 'comment_created': datetime.datetime(2023, 10, 3, 10, 53, 30, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343913002, 'comment_body': 'That is good question. I will check and remove if it is static fields', 'comment_created': datetime.datetime(2023, 10, 3, 10, 56, 49, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343915068, 'comment_body': 'Yep, I think we can', 'comment_created': datetime.datetime(2023, 10, 3, 10, 58, 37, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343918346, 'comment_body': 'I agree that it should be a counter but your guess is right - we receive the latest values for this field. Therefore, using gauge here.', 'comment_created': datetime.datetime(2023, 10, 3, 11, 1, 41, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343919263, 'comment_body': 'Sure!', 'comment_created': datetime.datetime(2023, 10, 3, 11, 2, 31, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343919478, 'comment_body': ""Let's do that way"", 'comment_created': datetime.datetime(2023, 10, 3, 11, 2, 42, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343920666, 'comment_body': ""Let's remove it for now and add back when will add those metrics"", 'comment_created': datetime.datetime(2023, 10, 3, 11, 3, 49, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1343921026, 'comment_body': 'Good to know, let me use it', 'comment_created': datetime.datetime(2023, 10, 3, 11, 4, 9, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1345826405, 'comment_body': 'Can we leave the age out for now as well. This is always something that can be tracked outside of kafka itself', 'comment_created': datetime.datetime(2023, 10, 4, 13, 46, 7, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1352300338, 'comment_body': ""I've removed them as they are static"", 'comment_created': datetime.datetime(2023, 10, 10, 11, 42, 59, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1352301535, 'comment_body': ""I've renamed it but do you think we should make `ProducerMetrics` and `ConsumerMetrics` and allow only specific ones?"", 'comment_created': datetime.datetime(2023, 10, 10, 11, 44, 10, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1352302406, 'comment_body': ""I've renamed all of them, let me know if you have some other names in mind"", 'comment_created': datetime.datetime(2023, 10, 10, 11, 44, 58, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1352386940, 'comment_body': 'Do we still need this here?', 'comment_created': datetime.datetime(2023, 10, 10, 12, 37, 38, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}, {'comment_id': 1355383811, 'comment_body': 'Surely not! Thank you for catching that :)', 'comment_created': datetime.datetime(2023, 10, 11, 17, 0, 13, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1356552761, 'comment_body': 'Can we remove this comment. I assume we are going to hand edit it in the future.', 'comment_created': datetime.datetime(2023, 10, 12, 9, 30, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1356554750, 'comment_body': 'I think this looks really good now. The only thing left is that I think we should split this into two structs on inside the producer and one inside the consumer configuration and only pull out the fields that make sense to them. Then we should be good to merge this.', 'comment_created': datetime.datetime(2023, 10, 12, 9, 31, 38, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1367026174, 'comment_body': 'removed!', 'comment_created': datetime.datetime(2023, 10, 20, 14, 8, 11, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}, {'comment_id': 1367026962, 'comment_body': 'Now it is `ProducerMetrics` and `ConsumerMetrics`', 'comment_created': datetime.datetime(2023, 10, 20, 14, 8, 50, tzinfo=datetime.timezone.utc), 'commenter': 'blindspotbounty', 'type': 'User'}]","[{'commit_sha': 'c870864d290b7e1939c9b73c07ef74ec0fd604f4', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '633773f254a0242c4e8eb830fb417539c49e3403', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9887b955944a53c570ee91f711f30d9da8f64b0', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e5f0483325e141c0edeb048f0d7900c69e3f942f', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd55a7fda49c809189f08fc0514b6c59c655168a4', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8b4525bf641081baec2ea8406d5dcc35101d5b8c', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23e08fcab1d54ae4f03140ecf8f205a7d119a19b', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '612a3c4e1c506654933ad4af64fa1f5a25eb9906', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5c10435afbdc04604985ea4e4370d0d9d7119aa2', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2be2bd9d958ffe9bcfc93213a08b45253fcd0eb9', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2cd0f8b2b57a3428dad68f450b21a0818a73277e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'abd97deb6ae442131d7b63e0b98349776bc450e7', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '15284e1fc960b35fdf6ccf89bc5899d9bc562c92', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4ee67807a3c2eacd2015e12c20ea7fb8240dab0', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0a0f1b8bf66f41cf30fc62ef22071606a017844e', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dcdbe212a7ffbd13c8f401b51ea3c89470b971d0', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5448eb43c403079acaef74fe76fe116f3924f768', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '900cb38b9fe7373727fa4dc4a1a127d2870fa643', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a83c97066570718d3916533b501fbb5933cac0c4', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4ebdf9d2c4bacbcc6bec634d1ab8b121083360cf', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '05cf1b9f4bcf2d5a4c688faaf318289ab5e79c29', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3febfcd776b30e33986f06f9b0b4fa4a4ae0b15a', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '455be80d4f2167fdf6cf38a1a22da2f36951d054', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a96edf708f4c203131eb25ad0a8bf43f0a7c4460', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'af05f5b64832ee2c99db9093082125bbb55bd74d', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a3caf3859069887fdc4a1f14fb452d7148aad1a', 'committer_username': 'blindspotbounty', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2023, 3, 13, 23, 57, 24, tzinfo=datetime.timezone.utc)}]",,127803250,,User,,4,,0,0
1468536947,`TLSConfiguration`: separate client and broker TLS configuration ,"### Motivation:

Previously, `TLSConfiguration` forced users into providing a key store /
key pair for client verification and did not expose a canonical way to
disable client verification.

### Modifications:

* `KafkaConfiguration.TLSConfiguration`
    * separate `Client` and `Broker` `TLS` configuration
    * provide default `TLSConfiguration`: `.disableClientVerification`,
      and verify broker identity
* `KafkaConfiguration.SecurityProtocol`:
    * provide `TLSConfiguration()` as default parameter value for
      `TLSConfiguration:`
* update `TLSConfiguration` examples in `README`

cc: @dnadoba",True,111,https://api.github.com/repos/swift-server/swift-kafka-client/pulls/111,https://github.com/swift-server/swift-kafka-client/pull/111,closed,110,125,3,6,2,14,0,0,[],2023-08-09 12:39:55+00:00,2023-08-14 12:51:33+00:00,432698.0,"5 days, 0:11:38","[{'comment_id': 1290171528, 'comment_body': '```suggestion\r\n        /// Configuration for the TLS identity of the client.\r\n```', 'comment_created': datetime.datetime(2023, 8, 10, 13, 53, 42, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1290172958, 'comment_body': 'Leaf and optional intermediates can be more than one\r\n```suggestion\r\n                    certificates: LeafAndIntermediates\r\n```', 'comment_created': datetime.datetime(2023, 8, 10, 13, 54, 38, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1290173226, 'comment_body': '```suggestion\r\n                certificates: LeafAndIntermediates\r\n```', 'comment_created': datetime.datetime(2023, 8, 10, 13, 54, 49, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1290173992, 'comment_body': '```suggestion\r\n                    rootCertificates: TrustRoots,\r\n```', 'comment_created': datetime.datetime(2023, 8, 10, 13, 55, 21, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1290174303, 'comment_body': '```suggestion\r\n                rootCertificates: TrustRoots = .probe,\r\n```', 'comment_created': datetime.datetime(2023, 8, 10, 13, 55, 33, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1292317673, 'comment_body': '```suggestion\r\nlet trustRoots = KafkaConfiguration.TLSConfiguration.TrustRoots.pem(""YOUR_ROOT_CERTIFICATE"")\r\n```', 'comment_created': datetime.datetime(2023, 8, 12, 14, 1, 19, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1292318071, 'comment_body': '```suggestion\r\n            public static let disabled: BrokerVerification = .init(_internal: .disable)\r\n```', 'comment_created': datetime.datetime(2023, 8, 12, 14, 3, 3, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1292318229, 'comment_body': '```suggestion\r\n                trustRoots: TrustRoots = .probe,\r\n                certificateRevocationListPath: String?\r\n```', 'comment_created': datetime.datetime(2023, 8, 12, 14, 3, 37, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1292318287, 'comment_body': ""```suggestion\r\n            ///     - crlLocation: Path to CRL for verifying broker's certificate validity.\r\n```"", 'comment_created': datetime.datetime(2023, 8, 12, 14, 3, 41, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1292319853, 'comment_body': ""Let's discuss if we should also default the crl to `nil`. I expect not a lot of people will pass a custom one here."", 'comment_created': datetime.datetime(2023, 8, 12, 14, 5, tzinfo=datetime.timezone.utc), 'commenter': 'FranzBusch', 'type': 'User'}, {'comment_id': 1293250645, 'comment_body': 'This should default to `nil`. ', 'comment_created': datetime.datetime(2023, 8, 14, 9, 52, 51, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1293251323, 'comment_body': 'Does DocC render this with the default values?', 'comment_created': datetime.datetime(2023, 8, 14, 9, 53, 32, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1293287849, 'comment_body': 'We are no longer using the above defined certs and key which seems unintentionally.  ', 'comment_created': datetime.datetime(2023, 8, 14, 10, 27, 26, tzinfo=datetime.timezone.utc), 'commenter': 'dnadoba', 'type': 'User'}, {'comment_id': 1293383579, 'comment_body': 'Thanks for pointing that out! Reduced the security examples to a minimum now!', 'comment_created': datetime.datetime(2023, 8, 14, 12, 15, 26, tzinfo=datetime.timezone.utc), 'commenter': 'felixschlegel', 'type': 'User'}]","[{'commit_sha': '42a7101d8e640e95db151d07d502d54d022b8ddb', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '34e019b9a132fbecc369f74a81e60af656ab133e', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3e3744fcc43f14898b0f80b53fe04d07f7746572', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd4510146d8a50e02cb6626e3134ed94991f8ecc1', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5d866da185cae71975a6c0fc9e678e9887d3ba71', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '412f2c45a15c2d416f50352d2ce1783bb4ef5936', 'committer_username': 'felixschlegel', 'committer_name': 'Felix Schlegel', 'committer_email': None, 'commit_date': datetime.datetime(2017, 2, 24, 20, 23, 11, tzinfo=datetime.timezone.utc)}]",Felix Schlegel,26013286,,User,,18,,51,38

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
503430079,swift-kafka-client,swift-server/swift-kafka-client,Swift,18,77,14,12,91,31,5,6,"[{'id': 2004346234, 'number': 169, 'closed': None, 'created': datetime.datetime(2024, 8, 5, 16, 17, 17, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 17, 'deletions': 3, 'state': 'open'}, {'id': 1791297714, 'number': 163, 'closed': datetime.datetime(2024, 3, 27, 9, 42, 25, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2024, 3, 26, 10, 26, 1, tzinfo=datetime.timezone.utc), 'time_taken': 83784.0, 'time_delta': '23:16:24', 'additions': 1, 'deletions': 1, 'state': 'closed'}, {'id': 1639210990, 'number': 158, 'closed': datetime.datetime(2024, 4, 26, 16, 1, 28, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 12, 11, 16, 47, 7, tzinfo=datetime.timezone.utc), 'time_taken': 11834061.0, 'time_delta': '136 days, 23:14:21', 'additions': 213, 'deletions': 391, 'state': 'closed'}, {'id': 1633096211, 'number': 157, 'closed': datetime.datetime(2024, 2, 14, 8, 18, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 12, 6, 19, 5, 29, tzinfo=datetime.timezone.utc), 'time_taken': 6009161.0, 'time_delta': '69 days, 13:12:41', 'additions': 3, 'deletions': 1, 'state': 'closed'}, {'id': 1625518788, 'number': 154, 'closed': datetime.datetime(2023, 12, 1, 15, 58, 49, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 12, 1, 11, 28, 13, tzinfo=datetime.timezone.utc), 'time_taken': 16236.0, 'time_delta': '4:30:36', 'additions': 98, 'deletions': 2, 'state': 'closed'}, {'id': 1625388294, 'number': 153, 'closed': datetime.datetime(2023, 12, 1, 10, 48, 20, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 12, 1, 10, 7, 31, tzinfo=datetime.timezone.utc), 'time_taken': 2449.0, 'time_delta': '0:40:49', 'additions': 3, 'deletions': 2, 'state': 'closed'}, {'id': 1620399588, 'number': 149, 'closed': datetime.datetime(2024, 3, 11, 8, 56, 53, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 11, 28, 17, 44, 59, tzinfo=datetime.timezone.utc), 'time_taken': 8953914.0, 'time_delta': '103 days, 15:11:54', 'additions': 782, 'deletions': 216, 'state': 'closed'}, {'id': 1598860660, 'number': 146, 'closed': datetime.datetime(2023, 11, 24, 11, 20, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 11, 13, 13, 19, 54, tzinfo=datetime.timezone.utc), 'time_taken': 943252.0, 'time_delta': '10 days, 22:00:52', 'additions': 192, 'deletions': 3, 'state': 'closed'}, {'id': 1590727846, 'number': 143, 'closed': datetime.datetime(2023, 11, 7, 14, 34, 1, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 11, 7, 14, 33, 52, tzinfo=datetime.timezone.utc), 'time_taken': 9.0, 'time_delta': '0:00:09', 'additions': 2334, 'deletions': 245, 'state': 'closed'}, {'id': 1554452762, 'number': 140, 'closed': None, 'created': datetime.datetime(2023, 10, 12, 16, 14, 13, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 1372, 'deletions': 303, 'state': 'open'}, {'id': 1512172296, 'number': 130, 'closed': datetime.datetime(2023, 9, 21, 9, 49, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 9, 12, 13, 48, tzinfo=datetime.timezone.utc), 'time_taken': 763260.0, 'time_delta': '8 days, 20:01:00', 'additions': 2, 'deletions': 2, 'state': 'closed'}, {'id': 1455973357, 'number': 107, 'closed': datetime.datetime(2023, 8, 21, 9, 43, 1, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 31, 10, 25, tzinfo=datetime.timezone.utc), 'time_taken': 1811881.0, 'time_delta': '20 days, 23:18:01', 'additions': 21, 'deletions': 0, 'state': 'closed'}, {'id': 1447087737, 'number': 98, 'closed': None, 'created': datetime.datetime(2023, 7, 24, 17, 19, 7, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 807, 'deletions': 12, 'state': 'open'}, {'id': 1439400852, 'number': 92, 'closed': datetime.datetime(2023, 11, 6, 13, 59, 52, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2023, 7, 18, 14, 51, 50, tzinfo=datetime.timezone.utc), 'time_taken': 9587282.0, 'time_delta': '110 days, 23:08:02', 'additions': 357, 'deletions': 7, 'state': 'closed'}]"

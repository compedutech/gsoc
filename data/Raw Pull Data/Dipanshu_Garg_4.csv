pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
440917950,Enum parameters for Tf-idf weight,"Now tfidf weight will also support 3 separate normalisation parameters besides the normalisation string .
This will help to implement normalizations that require more than 1 character to specify normalization.

",False,302,https://api.github.com/repos/xapian/xapian/pulls/302,https://github.com/xapian/xapian/pull/302,closed,450,71,4,20,7,51,0,0,[],2020-06-27 14:21:47+00:00,2020-07-27 06:45:54+00:00,2564647.0,"29 days, 16:24:07","[{'comment_id': 446671741, 'comment_body': 'You can pull this into a private initialiser method to avoid the duplication.', 'comment_created': datetime.datetime(2020, 6, 28, 16, 40, 54, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446671920, 'comment_body': ""Since this is now an enum, you don't need to assert anything — the compiler should pick up any attempt to violate this."", 'comment_created': datetime.datetime(2020, 6, 28, 16, 42, 39, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446672162, 'comment_body': ""Since this is an enum, you can change the `default` into a specific case (nothing else will appear). Some compilers will warn if you don't provide cases for every possibility of an enum. Then you won't have to assert, either."", 'comment_created': datetime.datetime(2020, 6, 28, 16, 45, 10, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446672263, 'comment_body': 'Same comment about `default`.', 'comment_created': datetime.datetime(2020, 6, 28, 16, 46, 11, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446672515, 'comment_body': ""I think this at least warrants a comment somewhere that it's serialising as single a byte, so that in the (unlikely) event we end up with > 256 there's documentation somewhere of what will go wrong. (What would happen? Will static_cast<> fail to compile, or will it truncate or something?)"", 'comment_created': datetime.datetime(2020, 6, 28, 16, 49, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446672626, 'comment_body': 'Can the compiler allow through something that would trigger this? It feels like this is just going to increase maintenance effort without adding anything useful.', 'comment_created': datetime.datetime(2020, 6, 28, 16, 50, 10, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446672763, 'comment_body': 'Is there a reason not to start at `0`?', 'comment_created': datetime.datetime(2020, 6, 28, 16, 51, 37, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446672909, 'comment_body': 'Is this still used anywhere?', 'comment_created': datetime.datetime(2020, 6, 28, 16, 52, 59, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 446835854, 'comment_body': 'Yes ,In switch I added.', 'comment_created': datetime.datetime(2020, 6, 29, 7, 50, 31, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 446838706, 'comment_body': ""I wasn't sure that 0 will be fine during serialise(). ( \\0 may cause problem.)\r\nAlso I looked at other enums defined in weight class .They were also beginning form 1 .\r\nSo I chose 1 instead of 0.  "", 'comment_created': datetime.datetime(2020, 6, 29, 7, 55, 21, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 446839340, 'comment_body': 'Yes , This is avoidable. Thanks for pointing it out . ', 'comment_created': datetime.datetime(2020, 6, 29, 7, 56, 33, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 446839806, 'comment_body': 'I have now added comments where I declared these enum classes.', 'comment_created': datetime.datetime(2020, 6, 29, 7, 57, 26, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 446840778, 'comment_body': 'When I removed default and added a case, I got this error -\r\nerror: control reaches end of non-void function [-Werror=return-type]\r\n', 'comment_created': datetime.datetime(2020, 6, 29, 7, 59, 8, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 446841026, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 6, 29, 7, 59, 33, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 446842102, 'comment_body': 'I have used delegating constructors . This would help avoid other duplication (apart from switch) as well.', 'comment_created': datetime.datetime(2020, 6, 29, 8, 1, 34, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 449190625, 'comment_body': 'Surely 255? Sorry, I think I said 256 but that was when I was thinking we\'d renumber to start at 0. At the number 256 it will overflow 1 byte.\r\n\r\nMore minor: ""three enum classes"" rather than ""class"", ""up to"" rather than ""upto"", and don\'t leave a space before the full stop. Also `static_cast<>` instead of `static_cast()`.', 'comment_created': datetime.datetime(2020, 7, 2, 18, 13, 22, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 449192188, 'comment_body': ""I don't think you need to though — since that switch is in a constructor, you could just use the formal parameter (`normals`) directly."", 'comment_created': datetime.datetime(2020, 7, 2, 18, 16, 37, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 449557960, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 7, 3, 12, 29, 15, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 449559155, 'comment_body': 'Updated to use normals', 'comment_created': datetime.datetime(2020, 7, 3, 12, 32, 9, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 453268626, 'comment_body': ""While constants such as the values of an `enum` are conventionally all-caps, the `enum` type itself usually isn't.  We don't have any other `enum class` in the API so far but we do have `typedef`-ed `enum` - e.g.\r\n\r\n```\r\n    typedef enum {\r\n\tSTEM_NONE, STEM_SOME, STEM_ALL, STEM_ALL_Z, STEM_SOME_FULL_POS\r\n    } stem_strategy;\r\n```\r\n\r\nSo I think this type should be `wdf_norm` or similar for consistency.\r\n\r\n(We only don't use `enum class` yet because it was new in C++11, and for 1.4.x we require a C++11 compiler to build Xapian, but aim to support use of a non-C++11 compiler for building applications using Xapian so we avoid C++11 features in the API headers - for git master we now require a C++11 compiler for building applications too, so it's OK to start using it.)\r\n\r\nThere should probably be a space before the `:` too (there isn't a precedent since we don't have an `enum class` yet, but it's `class Foo : public Base` and this seems equivalent to that situation.)"", 'comment_created': datetime.datetime(2020, 7, 12, 5, 12, 11, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 453269583, 'comment_body': 'You could make the final `case` in the `switch` just do `break;` and then have its `return` at the end of the function - then you won\'t get the ""control reaches end of non-void function"".\r\n\r\nAs James says, the major advantage of having all the enum values listed as explicit cases with no `default:` is that compilers will warn if a new enum value is added without new cases being added for it (which is an easy mistake for a future developer working on the code to make).  If there\'s a `default:` then there\'s no such warning (since the new value is handled by the `default:`).', 'comment_created': datetime.datetime(2020, 7, 12, 5, 25, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 453520626, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 7, 13, 9, 33, 52, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 454110082, 'comment_body': ""Not sure I like `wdfn_type`, etc - we don't have any other type names that end `_type` in the API currently (except for sub-types like `Xapian::TermIterator::value_type` which are required for compatibility with the C++ STL)."", 'comment_created': datetime.datetime(2020, 7, 14, 5, 28, 1, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 454110651, 'comment_body': 'Also, `wdfn_type::BOOLEAN`, etc seem less clear than `wdf_norm::BOOLEAN`.', 'comment_created': datetime.datetime(2020, 7, 14, 5, 29, 55, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 454113250, 'comment_body': 'Rather than just documenting this in the comment (which could be missed), I think it makes more sense to instead specify the underlying type of the `enum` as `unsigned char`.  Then the compiler knows to complain if an out of range value is specified - e.g. GCC gives the error:\r\n\r\n```\r\nerror: enumerator value ‘256’ is outside the range of underlying type ‘unsigned char’\r\n```\r\n\r\nBetter to let the compiler check such requirements for us when we can get it to.', 'comment_created': datetime.datetime(2020, 7, 14, 5, 38, 8, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 454145542, 'comment_body': ""There's no need to put extra parentheses around each equality test, and the code seems harder to read that way.\r\n\r\nWhy did you change the sense of the tests here?  Previously we checked the norm wasn't one of two, but now we check it is one of the other four - twice as many comparisons!"", 'comment_created': datetime.datetime(2020, 7, 14, 7, 2, 1, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 454292433, 'comment_body': 'I have now changed the class name to wdf_norm, etc. The parameter names are now wdf_norm_, etc.', 'comment_created': datetime.datetime(2020, 7, 14, 11, 36, 20, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 454292753, 'comment_body': 'Yes, This is better. Updated.', 'comment_created': datetime.datetime(2020, 7, 14, 11, 36, 54, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 454293832, 'comment_body': 'This change was supposed to be after I add more normalization. For now I have restored the previous version.\r\nThanks for pointing it out.', 'comment_created': datetime.datetime(2020, 7, 14, 11, 38, 59, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 456716032, 'comment_body': 'Comment typo: ""wth""\r\n\r\nAlso, ""upper_case"" is a bit weird here - ""upper case"" with a space would be better.', 'comment_created': datetime.datetime(2020, 7, 17, 23, 40, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456738226, 'comment_body': ""It would be better to just inline this forwarding constructor from the header.\r\n\r\nThe extra code that adds to the application is very small (I'd expect it's just loading two floating point constants) and it saves having an extra symbol exported by the shared library just for the forwarding version (such symbols need to be resolved at library load time, and that slows start up so it's good to avoid adding symbols for no good reason)."", 'comment_created': datetime.datetime(2020, 7, 18, 2, 33, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456738329, 'comment_body': 'Same arguments for inlining apply here too.', 'comment_created': datetime.datetime(2020, 7, 18, 2, 34, 29, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456739224, 'comment_body': ""This and the constructor which takes a 3 character code for compatibility share all the logic to select which stats are needed, and to vet the other parameters.\r\n\r\nIt'd be much cleaner for the compatibility one to forward to this, then we only need to have one copy of that code.\r\n\r\nYou just need to arrange that the decoding code can be done in the forwarding constructor call, e.g. with a function for each one, something like:\r\n\r\n```\r\nTfIdfWeight::TfIdfWeight(const string& normals, double slope, double delta)\r\n    : TfIdfWeight(decode_wdf_norm(normals).\r\n                  decode_idf_norm(normals),\r\n                  decode_wt_norm(normals),\r\n                  slope,\r\n                  delta) {}\r\n```"", 'comment_created': datetime.datetime(2020, 7, 18, 2, 44, 57, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456739875, 'comment_body': ""This doesn't check that there's actually enough data in the string supplied (the existing code isn't quite right either).  (The first byte read is OK as there's guaranteed to be a zero byte on the end (since C++11), but the others are off the end of the string, so undefined behaviour).\r\n\r\nThese serialisations are passed across the network, so we need to take extra care not to assume they are valid.\r\n\r\nInstead of throwing an exception if `ptr != end` after we process these bytes, we can instead throw if `end - ptr != 3` before we process them - that way if the string is too short we throw an exception instead of invoking undefined behaviour."", 'comment_created': datetime.datetime(2020, 7, 18, 2, 53, 28, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456786909, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 7, 18, 12, 49, 13, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 456787112, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 7, 18, 12, 51, 18, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 456787201, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 7, 18, 12, 52, 12, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 456787216, 'comment_body': 'Fixed', 'comment_created': datetime.datetime(2020, 7, 18, 12, 52, 27, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 456824537, 'comment_body': ""There's no longer a check on the length of `normals` before we access its characters - pass in an empty string and this will read off the end of it.  That's why in my sketch of the code I passed `normals` to these helpers - then they can check `normals.size() == 3`.  We probably need to repeat that check in each helper since the order in which parameters are evaluated isn't specified in C++, but these functions are only called once so the compiler is likely to decide to inline them all, and then it can see that the repeat length checks are redundant and remove them.  And if it fails to, then the length check is cheap (and this is compatibility code anyway)."", 'comment_created': datetime.datetime(2020, 7, 18, 20, 22, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456824938, 'comment_body': 'OK, except that it might be more or less data now - ""Incorrect data ..."" maybe?', 'comment_created': datetime.datetime(2020, 7, 18, 20, 27, 48, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456825622, 'comment_body': 'Since all the other cases `return`, you could handle the default case outside the `switch` which would avoid the wrapping.', 'comment_created': datetime.datetime(2020, 7, 18, 20, 36, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 456881747, 'comment_body': 'Done.', 'comment_created': datetime.datetime(2020, 7, 19, 8, 54, 42, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 456881847, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 7, 19, 8, 55, 30, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 456881930, 'comment_body': 'ohh, I missed that. I have now updated it.', 'comment_created': datetime.datetime(2020, 7, 19, 8, 56, 29, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 460480201, 'comment_body': ""There's an unwanted space in front of the second `,` here."", 'comment_created': datetime.datetime(2020, 7, 26, 5, 20, 52, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 460480229, 'comment_body': '`""t""` doesn\'t make sense here...', 'comment_created': datetime.datetime(2020, 7, 26, 5, 21, 10, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 460480616, 'comment_body': 'Nor `""p""` here - when updating code you really need to also fully update the comments to match the updated code.', 'comment_created': datetime.datetime(2020, 7, 26, 5, 26, 30, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 460480768, 'comment_body': 'You appear to be adding another copy of an existing test of `""npn""` here - presumably you failed to convert this one to the enums?', 'comment_created': datetime.datetime(2020, 7, 26, 5, 28, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 460487536, 'comment_body': 'Updated.', 'comment_created': datetime.datetime(2020, 7, 26, 6, 46, 31, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 460487542, 'comment_body': 'Updated.', 'comment_created': datetime.datetime(2020, 7, 26, 6, 46, 40, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 460487603, 'comment_body': 'Yes, I missed this one. I have now fixed it.', 'comment_created': datetime.datetime(2020, 7, 26, 6, 47, 19, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}]","[{'commit_sha': 'd9f8820eab8179c4a9a14f8bcb77d21b19fb767c', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6847d143f5fe2b443ad9c02bb6127a5de720a366', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e284cd7e4e16b6cc6752ba85fcfdf3ac8d2f2411', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8c810f9960a57d5ebb6779f6794bf02806b1f698', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7dd3752ff8e435bafe8b94cb60070270632fae2', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '193ededc18510c3a76579d1085dec03f150add0a', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6a658c37a87194d225bb4fc6009335ec651c0468', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7f9d4d45aff33ba6d089dc48489d607ebef6cc22', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0cda2e024549fce3d9e836862386dd953fcf4592', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '08cdff279a5ac8af34d033c587c673f08b091606', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b2d5c1af98db69802f1d02f3dfdfb75a34c9106a', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4071389c637e8a9141bd16df68b984386927eb18', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3103adcfecdfde18c299d6a4086e703d2641d312', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'abcf177b3029a14e1c8df578b73054ea0c2c2785', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f0db58155a25fe53876ea3210d008931a6675fc2', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'caa206709d48a656b87dfd98c77aa1b285930974', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a13c98b056bd5c94fbc40525f16b562ec951cddd', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ab15174e6b19593893e2f3a6f65837aa3185d9c7', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '93647134aa60c7c5b6dd03861465d9f2de0a7add', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9108567f4d4ec17e52ebe9f623c6df1fa41aa61', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
429877733,Add New normalizations for Tf-Idf weighting schemes,"Add **Global frequency IDF , Augmented log , Log Global frequency IDF and Square root** Normalizations along with tests . ",False,298,https://api.github.com/repos/xapian/xapian/pulls/298,https://github.com/xapian/xapian/pull/298,closed,100,5,3,28,2,20,0,0,[],2020-06-07 08:49:04+00:00,2020-07-31 07:12:28+00:00,4659804.0,"53 days, 22:23:24","[{'comment_id': 444599123, 'comment_body': ""There's no `case 'E':` here."", 'comment_created': datetime.datetime(2020, 6, 24, 1, 48, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444599472, 'comment_body': ""Perhaps better to check against a list of those normalisations which do need it, rather than those than don't?  Especially as that's a shorter list."", 'comment_created': datetime.datetime(2020, 6, 24, 1, 50, 9, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444600082, 'comment_body': ""We're about to switch on `c`, so it seems cleaner to call `get_collection_freq()` directly in the cases that need it, rather than effectively have a pre-dispatch on `c`.\r\n\r\n(I realise this is an existing pattern in this code, but I don't think it's a good pattern to extend further)"", 'comment_created': datetime.datetime(2020, 6, 24, 1, 52, 21, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444600252, 'comment_body': ""Your new normalisations don't seen to use `N`."", 'comment_created': datetime.datetime(2020, 6, 24, 1, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444603244, 'comment_body': 'This doesn\'t seem to match the definition of ""a"" for the first normalisation at http://people.csail.mit.edu/jrennie/ecoc-svm/smart.html : \r\n\r\n> ""**a**ug-norm"" : new-tf = 0.5 + 0.5 * (tf / max-tf)\r\n>              augmented normalized tf.  0.5 < new-tf <= 1.0\r\n', 'comment_created': datetime.datetime(2020, 6, 24, 2, 4, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444604396, 'comment_body': 'Where\'s ""S"" defined?  I don\'t see it listed at http://people.csail.mit.edu/jrennie/ecoc-svm/smart.html or https://nlp.stanford.edu/IR-book/html/htmledition/document-and-query-weighting-schemes-1.html', 'comment_created': datetime.datetime(2020, 6, 24, 2, 9, 15, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444604623, 'comment_body': ""You've not documented any of your new normalisations in the API docs (see `include/xapian/weight.h` for where all the currently supported ones are defined)."", 'comment_created': datetime.datetime(2020, 6, 24, 2, 10, 10, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444604898, 'comment_body': ""There's no test of 'E' for the second character here (which would probably have revealed that you didn't actually provide an implementation for it)."", 'comment_created': datetime.datetime(2020, 6, 24, 2, 11, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444605091, 'comment_body': 'Xapian coding style is to avoid blank lines at the end of a block.', 'comment_created': datetime.datetime(2020, 6, 24, 2, 11, 50, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444606633, 'comment_body': 'Also, where are ""E"", ""G"" and ""l"" defined?', 'comment_created': datetime.datetime(2020, 6, 24, 2, 17, 27, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444662046, 'comment_body': 'OK, it seems these are from the paper you link to from https://trac.xapian.org/wiki/GSoC2020/WeightingSchemes/ProjectPlan\r\n\r\nHowever that doesn\'t seem to define the single letter codes you use here.  I think we need to take a lot of care if we\'re inventing new single letter codes as this is a pre-existing naming scheme rather than something we came up with, there are only 52 different letters (allowing for case-sensitivity) and it would be awkward to deal with if we picked one which was already used for a different normalisation elsewhere (I\'m guessing that\'s why your implementation of ""a"" below doesn\'t match the definition of ""a"" I was looking at).  Or indeed if we picked an unused one and somebody else picked the same one later for a different purpose.', 'comment_created': datetime.datetime(2020, 6, 24, 6, 0, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 444766600, 'comment_body': 'Updated.', 'comment_created': datetime.datetime(2020, 6, 24, 9, 30, 9, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 444766998, 'comment_body': 'Right, I will take of it .', 'comment_created': datetime.datetime(2020, 6, 24, 9, 30, 52, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 444769306, 'comment_body': ""'E' is for Entropy normalization . I haven't implemented it yet .\r\nIt requires visibility of wdf of the term in every document in the collection . The idea was to use the postlist to get that.\r\nBut the concern is that won't be very efficient.\r\nSo it is still to be implemented"", 'comment_created': datetime.datetime(2020, 6, 24, 9, 35, 4, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 444771035, 'comment_body': ""'A' is for Augmented log (I have changed from 'a' to 'A') .\r\n"", 'comment_created': datetime.datetime(2020, 6, 24, 9, 38, 18, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 444782352, 'comment_body': ""All these characters I used, represent the weighting schemes mentioned in the paper I link to from https://trac.xapian.org/wiki/GSoC2020/WeightingSchemes/ProjectPlan .\r\nSince the paper used 4 letters to define a particular normalization (for which we use only 1 letter) , I took the liberty of changing the 4 letter name to a relevant 1 letter parameter (Sorry, I should have consulted before doing that.)\r\nI have ensured that the parameters I used haven't been used elsewhere till now .(I have changed 'a' to 'A' for Augmented log.)\r\nI have now defined these parameters in API docs .\r\nIf we can't use an unused character , what else can be done?"", 'comment_created': datetime.datetime(2020, 6, 24, 9, 57, 47, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 445045217, 'comment_body': 'Can we come up with a way of maintaining compatibility with single letter approach we used that matched the original paper (for people who are close to the literature and might expect that), but also start providing a more user-friendly API using a bitfield or similar?\r\n\r\nWe could provide both, but the bitfield would enable us to support normalisations that don\'t have single letter variants (giving us options beyond 26 letters), which could include this situation rather than trying to come up with our own single letter abbreviations.\r\n\r\n(The constants for a bitfield approach could if necessary include both ""verbose and clear"" and ""mnemonic from papers"", which could be say `IDFB` or `CK_IDFB` or similar, with API doc comments explaining that CK means that particular paper.)\r\n\r\nThinking aloud here a little, so I suspect there\'s a discussion and maybe worth sketching out different ways of doing the API to determine a good route forward.', 'comment_created': datetime.datetime(2020, 6, 24, 17, 9, 12, tzinfo=datetime.timezone.utc), 'commenter': 'jaylett', 'type': 'User'}, {'comment_id': 445355303, 'comment_body': 'Yes, I think enums might be a better approach (though perhaps with a separate parameter for each of the 3 normalisation types rather than a bitmask, since that provides more scope for compile-time type-checking).\r\n\r\nIt\'s inherently problematic to have such a small space to allocate from without a central allocation authority (though it is 52 not 26 as it\'s case sensitive) .  For academic papers it presumably works out OK because academics who write papers which extend the SMART codes will have read the existing literature in the area they\'re working in (and if they miss one, the paper gets peer reviewed and there\'s a second opportunity for someone to catch a collision).  But I suspect academics are less likely to spot an ""allocation"" which is only recorded in Xapian.\r\n\r\nThe 3 letter codes are also rather cryptic.  They come from SMART which originated more than 50 years ago - we can afford to be a bit more verbose now than they could then.\r\n\r\nThe one advantage of a string code which remains is it\'s easy to support as a config option in an application built on Xapian, but we now support creating a `Weight` object from a string description so that\'s no longer really relevant.', 'comment_created': datetime.datetime(2020, 6, 25, 7, 20, 4, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 462954895, 'comment_body': 'I will make a separate PR for Entropy normalization.', 'comment_created': datetime.datetime(2020, 7, 30, 12, 18, 41, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 463419114, 'comment_body': 'Good plan.', 'comment_created': datetime.datetime(2020, 7, 31, 5, 56, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}]","[{'commit_sha': '22582bd5f4d69b101f40c0ae01d86588a16aa02e', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f684416af8c617cbc34e0f045558793aceefc9dc', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4f31401c528fb87b98bde8c2e03b586005fe695d', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0f2ddd159b6e7b826bc9d41dabd4b1a83cbcc98', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '273e84f93259580ab8576017f3f107978f4859d4', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3fcf0f1704fa3e4278a27507d90c14e9f221090c', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ac8bea32b8d6bc0f774db3ead1f689076b23149d', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd0c9a1dba8bbb8fb6cd40d44dd51d80ccae5dbcc', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e1d9d199c7b344ec6c55fedced374ce5967f2ae1', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c10c7a90c6f5b91055927437d930ddfe1aa03c38', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'aff2bd9c7dc3bf95168987a208a99478e346cc07', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9ccdad31d7adcca39cbc6503f66ce4ea373579e3', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c5f185ab3b17b281eba94aeb901d5e57e7368612', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe634d283c99faf92272da9c1925ef70fd3beebe', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ce706201b21f0a1fb1b30ebecdf4280fca2dac0b', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2c2dd3e04de99f8415a3dd80e2ef82713001480e', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f55264487ee0ed17091f2bccb68352f06762433b', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '35b6f947b15c1a734518d548ee62425653072cda', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '513a0c530c2049c293e3aecfc3eb721cd2aaf6af', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'acbcdfd3991af1a9c42c694651628d37a280aa0e', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9b1f566b1521b04c02780e21dea788d73b29d5c8', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '244d7499da315ee80ef40375152f36d1962d10b6', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9d4580d2024ff1635f8acebcfaa6cf0455cc23c3', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '957e76cc88cf8e95b2dadaaf7588d0ca2480a602', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '644dfb5caa9e849fb97a1afc429b3615668b43f7', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3573a9987c5d64e3dc7ed3dd1a0ef01c8ed16b51', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4514549d9f70c8889d7f9d05ee44c12d7af34a93', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '16fbb369e1f72f1949166f00a789c9fc9a08a4c0', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
460079315,Support more normalisations in TfIdfWeight,"Add support for wdf normalisation ""augmented average term frequency"",
and IDF normalisations ""incremented global frequency"" and
""square root global frequency"".",False,308,https://api.github.com/repos/xapian/xapian/pulls/308,https://github.com/xapian/xapian/pull/308,closed,73,4,3,2,2,0,0,0,[],2020-07-31 12:00:03+00:00,2020-07-31 22:22:09+00:00,37326.0,10:22:06,[],"[{'commit_sha': 'b892c267916c17a75c69f6f946396d3ea440fcb1', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6174ca40b591f4bb6ce8e4188034c6fe47125a06', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
467867013,Support more normalisations for TfIdfWeight,"Add support for wdf normalisations ""max-norm"" and ""aug-norm""
described by SMART.",False,312,https://api.github.com/repos/xapian/xapian/pulls/312,https://github.com/xapian/xapian/pull/312,closed,73,8,3,3,1,0,0,0,[],2020-08-14 09:05:15+00:00,2020-08-19 07:48:32+00:00,427397.0,"4 days, 22:43:17",[],"[{'commit_sha': 'a65d5e30df3a12116ce3d04894e0d988b21fe3c9', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9578ccacb0e969faccdbe8c53ca833f4b2bf3cf7', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8c8bb899001c611ffbd315ef7419a0fe8cb35c35', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
463943365,"Extract stat ""wdfdocmax"" for TfIdf Weight","Some TfIdf normalisations require the max wdf in the document.
This change adds remote and honey backend support for wdfdocmax,
hence fixes one issue of  #744.",False,309,https://api.github.com/repos/xapian/xapian/pulls/309,https://github.com/xapian/xapian/pull/309,closed,447,96,74,8,6,9,0,0,[],2020-08-06 10:39:09+00:00,2020-08-10 20:11:59+00:00,379970.0,"4 days, 9:32:50","[{'comment_id': 466858721, 'comment_body': 'Unwanted blank line at the end of a block here.', 'comment_created': datetime.datetime(2020, 8, 7, 7, 1, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 466860552, 'comment_body': '`remote_protocol.rst` needs updating with the details of these new messages.', 'comment_created': datetime.datetime(2020, 8, 7, 7, 6, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 466862747, 'comment_body': ""We can definitely check more than this (and I'm not sure this condition is actually correct - if all the wdf values are 0 in a document then wdfdocmax would be 0).\r\n\r\nFor example, wdfdocmax should be the largest wdf in the document, so wdfdocmax => wdf.\r\n\r\nBut it should be equal to some wdf value, so wdfdocmax <= wdf_upper.\r\n\r\nThere are probably some others.\r\n\r\n"", 'comment_created': datetime.datetime(2020, 8, 7, 7, 11, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 467070621, 'comment_body': 'Fixed.', 'comment_created': datetime.datetime(2020, 8, 7, 14, 19, 26, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 467070910, 'comment_body': 'Updated.', 'comment_created': datetime.datetime(2020, 8, 7, 14, 19, 55, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 467081887, 'comment_body': 'I add `TEST_REL(wdfdocmax,>=,1)` assuming `TEST_REL(uniqueterms,>=,1)` is correct.\r\nI think it would make sense to remove both of these.\r\n\r\nwdfdocmax <= wdf_upper is not true in general. (Suppose the current term has Coll freq 1, then wdf_upper takes value 2. But wdfdocmax can take a value greater than 2 (due to some other term in the same doc.))\r\n\r\nFor wdfdocmax => wdf, wdfdocmax has to be made synonym aware.(I am figuring how to do that.)\r\n\r\nI have added `TEST_REL(wdfdocmax,<=doclen)` for now.', 'comment_created': datetime.datetime(2020, 8, 7, 14, 37, 42, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 467326820, 'comment_body': ""`TEST_REL(uniqueterms,>=,1);` is indeed interesting.  The case of a document not indexed by any terms isn't relevant here, as no terms means `get_sumpart()` won't get called, so the question comes down to whether uniqueterms is just the number of different terms in the document (in which case it counts terms which have zero wdf too, and the check is OK) or whether it only counts terms with non-zero wdf.  I thought we'd actually settled on the latter interpretation (since it seems undesirable that adding more filter terms changes the relevance weights, and it's also sometimes handy that the document length provides an upper bound on the number of unique terms), but the API documentation currently says:\r\n\r\n> This is the number of different terms which index the given document.\r\n\r\nIf this count includes zero wdf terms too, then `TEST_REL(uniqueterms,<=,doclen);` is actually wrong instead.\r\n\r\nI'll dig into this a bit more, but I think we probably just failed to clarify the API docs when we decided on this interpretation so let's assume that here for now.\r\n\r\nRather than removing these two `>= 1` checks, I think we should conditionalise them on `if (doclen > 0)` since `doclen` is the sum of all the wdfs in the document, so if that's non-zero there must be at least one non-zero wdf value in the document."", 'comment_created': datetime.datetime(2020, 8, 7, 23, 30, 18, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 467413934, 'comment_body': 'I have now conditionalise it.\r\nAlso added `wdfdocmax>=wdf`  by setting `wdfdocmax` to `doclen` in case of synonym.', 'comment_created': datetime.datetime(2020, 8, 8, 9, 16, 15, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 467534569, 'comment_body': ""This dosn't seem quite right.\r\n\r\nOne problem is it only currently gets executed if `want_wdf` is set, but there's no inherent reason why a weighting scheme which uses wdfdocmax would also use wdf so this should be outside that `if`.\r\n\r\nAnother problem is that `doclen` may not have been read here (a weighting scheme could use wdfdocmax, but not doclen, and in that case the doclen won't be set unless the `(!wdf_disjoint && wdf > doclen_lower_bound)` condition above was true.  The approach we currently take to this for clamping wdf to doclen can be seen just above, though unlike that situation, for wdfdocmax we'll always want doclen available here so it's probably better to have `WDFDOCMAX` automatically enable `DOCLEN` when weighting a synonym (which is handled by a separate overloaded form of `Weight::init_()`).\r\n\r\nI've pushed a commit to your branch which adds a testcase to demonstrate these problems - it fails currently, but I think it should pass for all 3 flag combinations tested."", 'comment_created': datetime.datetime(2020, 8, 9, 4, 28, 11, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}]","[{'commit_sha': '5e1122b1ac32ff131f6165a7b3558c1197462955', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '67ca9f8fcc295fd34efba87233327efd0587c6f1', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bef5476014de3aaa62d3989c166efb89a30f2c75', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd7a4cb1d5438a7fdbaca1cf677d708977b601dcf', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2f3ff82b2b87cb2e480da4476ae903c88941cf83', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eed11b49ac05f094b076e313b0cab435b7a3f08e', 'committer_username': 'ojwb', 'committer_name': 'Olly Betts', 'committer_email': None, 'commit_date': datetime.datetime(2009, 12, 7, 23, 8, 46, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3211c745804903aaff878dc2eb6cbc866c0a93da', 'committer_username': 'ojwb', 'committer_name': 'Olly Betts', 'committer_email': None, 'commit_date': datetime.datetime(2009, 12, 7, 23, 8, 46, tzinfo=datetime.timezone.utc)}, {'commit_sha': '46eefc87c138885b43834fc7e3d210c7af9a449e', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
465910660,Pass wdfdocmax to get_sumextra(),"Since we pass doclen and uniqterms to get_sumextra(), it makes
sense that we also pass wdfdocmax to it. This fixes the second
issue of #744. (the first was fixed by PR 309)",False,310,https://api.github.com/repos/xapian/xapian/pulls/310,https://github.com/xapian/xapian/pull/310,closed,116,46,23,4,1,6,0,0,[],2020-08-11 07:01:37+00:00,2020-08-13 22:52:40+00:00,229863.0,"2 days, 15:51:03","[{'comment_id': 468923764, 'comment_body': 'This comment needs updating too...', 'comment_created': datetime.datetime(2020, 8, 11, 23, 40, 1, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 468924701, 'comment_body': 'This seems to be an unrelated formatting change (and not really a useful one either).', 'comment_created': datetime.datetime(2020, 8, 11, 23, 42, 51, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 469028936, 'comment_body': ""I have updated it. (Not sure if it's completely correct.)"", 'comment_created': datetime.datetime(2020, 8, 12, 6, 18, 29, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 469029234, 'comment_body': 'Corrected.', 'comment_created': datetime.datetime(2020, 8, 12, 6, 19, 24, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 469048172, 'comment_body': 'What it said before about unique terms being unused is still correct - of the parameters, only `doclen` is currently used (which is perhaps the simpler way to put it now).', 'comment_created': datetime.datetime(2020, 8, 12, 7, 4, 51, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 469067443, 'comment_body': 'I have corrected it. (I was confused as we have TfIdf normalisations that use unique terms.)', 'comment_created': datetime.datetime(2020, 8, 12, 7, 42, 46, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}]","[{'commit_sha': '61db77cb6616babf1c231259799a473a2ddc1719', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cc77f5dd775bc4c881405dd18dde6c3006c9c251', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2c1b93d2ac64d109a2bf91473b6e644ab9f0e81b', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '39134d10c1e13eaaa01490fca91a6a0d29881252', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
470144588,Update TfIdfWeight::create_from_parameters() ,"We now use enums to specify normalisations. The parameters will be
specified as constant names.",False,314,https://api.github.com/repos/xapian/xapian/pulls/314,https://github.com/xapian/xapian/pull/314,closed,165,6,7,7,0,9,0,0,[],2020-08-19 12:52:53+00:00,2020-08-25 05:40:03+00:00,492430.0,"5 days, 16:47:10","[{'comment_id': 473275850, 'comment_body': 'This will have to construct these maps each time this method is called and then does one lookup in each - in general it very rarely makes sense to construct a complex data structure at run-time for a single lookup.  Building the data structure inevitably has to make a pass over all the data being put in it making in at least O(n), which is what a simple linear search over the data would be.\r\n\r\nConstructing a map is O(n*log(n)) if the input data isn\'t sorted, as here (pre-sorting the input would help as then it\'s O(n)) and then looking up in the map is O(log(n)) - if you just did a simple `if`-chain that\'d be O(n).  If the input data is sorted, binary chop is O(log(n)) (and `std::lower_bound()` provides a binary chop implementation) though that does rely on people adding new entries actually maintaining the sorted order.\r\n\r\nAdmittedly big-O scaling isn\'t necessarily the key concern when you have a small number of entries because the scale factor can matter more - e.g. a fast O(n²) can beat a slow O(log(n)) for bounded n - but I\'d expect the scale factor to be worse for building a std::map keyed on strings.\r\n\r\nAnother issue this hits is that the initialiser is probably essentially an array with string constants in it, and in a shared library each string constant in an array needs relocating by the dynamic linker at library load time, which makes loading the library slower so we try to avoid these.  If the string constants are sensibly bounded in length (as here) there\'s a trick to avoid this problem - however we have a mechanism to build lookup tables for string to enum (or integer) mapping at compile time which I think would make sense to also use here.\r\n\r\nIt\'s a perl module - you write a script which instantiates an object `$hdr` and then for each (string, enum) pair calls:\r\n\r\n```\r\n$hdr->add($string, $enum);\r\n```\r\n\r\nThis generates a header file which you then include from the code and to look up string `s`:\r\n\r\n```\r\nint r = keyword(whatever_the_generated_table_is_called, s.data(), s.size())\r\nif (r < 0) {\r\n    // Handle an unknown token.\r\n    throw some_exception();\r\n}\r\n// Known token, so safe to cast to enum_type.\r\nauto code = static_cast<enum_type>(r);\r\n```\r\n\r\n(There\'s also `keyword2()` which handles lookup tables which are large enough to need 2-byte offsets.)\r\n\r\nThis is used for keyword lookups in a number of places already - e.g. for stemmer names see `xapian-core/languages/collate-sbl` which generates `xapian-core/languages/sbl-dispatch.h` and is used in `xapian-core/languages/stem.cc`.  This script also has to allocate enum values and create an enum definition, which you don\'t need here as they are already defined so you don\'t need that part.\r\n\r\nYou\'ll want a separate lookup table for each type (or maybe just hard-code a simple `== ""NONE""` check for the last one for now.\r\n\r\nThe way the lookup works is essentially to dispatch first on the length of the input via a lookup table (which is O(1)) and then perform a binary chop just within a list of known tokens with that length, so it should be more efficient that a binary chop on the whole list and the lookup tables are compact.', 'comment_created': datetime.datetime(2020, 8, 19, 19, 42, 36, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 475883377, 'comment_body': ""It'd be better to add these in sorted order - that way it's easier to quickly locate an entry, and that also makes it harder to accidentally add a duplicate of an entry which is already there (because you'd be trying to add it in the place it already is)."", 'comment_created': datetime.datetime(2020, 8, 24, 20, 45, 18, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 475890903, 'comment_body': 'This seems like an unhelpful amount of duplication (https://en.wikipedia.org/wiki/Don%27t_repeat_yourself).  Someone adding a new entry would be likely to copy and modify an existing one and could easily fail to update it fully.\r\n\r\nBetter to loop over the names and have a single call to `$hdr->add(`...`)` - then the boilerplate code appears just once and is separate from the data - something like (untested):\r\n\r\n```\r\nfor my $enum (qw/\r\n    NONE\r\n    TFIDF\r\n    etc\r\n/) {\r\n    $hdr->add($enum, ""static_cast<unsigned char>(Xapian::TfIdfWeight::idf_norm::$enum)"");\r\n}\r\n```\r\n\r\nBetter still would be to extract the list of enum values automatically so a new one only needs adding to the header, but that seems more challenging.', 'comment_created': datetime.datetime(2020, 8, 24, 20, 59, 50, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 475893562, 'comment_body': ""Again, this new block ought to be in sorted order (but keep `xapian/weight.h` first as that's the header which has the definitions for this source file - we include that first as a simple way to try to ensure that our headers include any other headers they need (it doesn't ensure this for headers without a corresponding `.cc` file though)."", 'comment_created': datetime.datetime(2020, 8, 24, 21, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 475895008, 'comment_body': 'Better to declare these 3 below at the point you actually have the correct value to assign to them.  As this code is currently written the reader has to read it carefully to see that the values set here are never actually used.', 'comment_created': datetime.datetime(2020, 8, 24, 21, 7, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 476171955, 'comment_body': 'Updated.', 'comment_created': datetime.datetime(2020, 8, 25, 4, 49, 54, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 476173457, 'comment_body': 'Right, This was a lot of duplication which I could have avoided.\r\nI have corrected that.', 'comment_created': datetime.datetime(2020, 8, 25, 4, 51, 59, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 476173632, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 8, 25, 4, 52, 14, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 476174239, 'comment_body': 'Updated', 'comment_created': datetime.datetime(2020, 8, 25, 4, 53, 2, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}]","[{'commit_sha': '6825699d34f61aa0c8000164bdca2f58b4266490', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ec939142ed515072bb1722c398557d5b95d2697f', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe3b002c84c7b964210aa97ea88e33ad7bb09f9b', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '85e71e5850feb7f67cacd5dbe7afcf03b7a09568', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '701374d17b6ab89042bb8dbfd275535e8d4cf7da', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a979811ff977beb875bbf74eeff8d55b6cb691be', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bfd92c425b1953d5d74f69bad69e3849d73478cc', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
462723892,Specify TfIdf normalisations using newer API,Now we use enums to specify normalisations.,True,30,https://api.github.com/repos/xapian/xapian-docsprint/pulls/30,https://github.com/xapian/xapian-docsprint/pull/30,closed,29,0,1,2,0,2,0,0,[],2020-08-04 12:06:37+00:00,2020-08-09 20:29:45+00:00,462188.0,"5 days, 8:23:08","[{'comment_id': 466192308, 'comment_body': 'Shouldn\'t this be ""3."" not ""1.""?', 'comment_created': datetime.datetime(2020, 8, 6, 7, 12, 14, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 466276181, 'comment_body': 'Corrected.', 'comment_created': datetime.datetime(2020, 8, 6, 9, 26, 46, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}]","[{'commit_sha': '844da26a8b577691bfc51eac3b31bd3080cb6320', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8d3b53b0ce0b815e06e987fb732efa81c0b827e4', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13
454389502,Make readme more User-friendly,"Add build instructions for user. Also avoid full stop in heading.
Clarify which parameters are for input and which are to store output.
Fix white space irregularities.",False,17,https://api.github.com/repos/xapian/xapian-evaluation/pulls/17,https://github.com/xapian/xapian-evaluation/pull/17,closed,50,36,1,3,1,7,0,0,[],2020-07-21 11:01:49+00:00,2020-07-31 21:38:09+00:00,902180.0,"10 days, 10:36:20","[{'comment_id': 460480954, 'comment_body': 'The command is `autoreconf` not `autoreconfig`.', 'comment_created': datetime.datetime(2020, 7, 26, 5, 30, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 460488019, 'comment_body': 'Sorry, I have updated it now.', 'comment_created': datetime.datetime(2020, 7, 26, 6, 51, 41, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 462068928, 'comment_body': ""This won't work as currently documented since `.` sources a shell script (see `help .` in bash) but `./trec_index` is a binary file:\r\n\r\n```\r\nolly@gemse:~/git/xapian-evaluation/bin$ . ./trec_index \r\nbash: .: ./trec_index: cannot execute binary file\r\n```\r\n\r\nAlso, I don't think it's helpful to add `<`...`>` around placeholders like this, since this renders as a literal block and so suggests these characters should be literally included in the command.\r\n\r\nI think it would be clearer to just make these examples of the actual commands to run - i.e. use what one would typically call the configuration file in the example command.\r\n"", 'comment_created': datetime.datetime(2020, 7, 29, 6, 32, 59, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 462072727, 'comment_body': 'Looking at the code, this change is wrong - `""trad""` is what is checked for.', 'comment_created': datetime.datetime(2020, 7, 29, 6, 42, 30, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 463443952, 'comment_body': 'We ship an example configuration file called `config`, so that would be a good filename to use in these examples of how to run the programs.', 'comment_created': datetime.datetime(2020, 7, 31, 7, 13, 45, tzinfo=datetime.timezone.utc), 'commenter': 'ojwb', 'type': 'User'}, {'comment_id': 463573706, 'comment_body': 'I have corrected the command to `trec_index config`, etc.', 'comment_created': datetime.datetime(2020, 7, 31, 12, 11, 29, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}, {'comment_id': 463573888, 'comment_body': 'Corrected.', 'comment_created': datetime.datetime(2020, 7, 31, 12, 11, 58, tzinfo=datetime.timezone.utc), 'commenter': 'dipanshu124', 'type': 'User'}]","[{'commit_sha': '84f1af1d9f0bf123787c9974a0c8fc7f90677314', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e51677c74463e30fbc2b90c96a66f46e61bb8d1b', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a283830cdfb61e648ff77e75d472018e7326f07f', 'committer_username': 'dipanshu124', 'committer_name': 'Dipanshu Garg', 'committer_email': None, 'commit_date': datetime.datetime(2019, 10, 7, 7, 56, 58, tzinfo=datetime.timezone.utc)}]",Dipanshu Garg,56249922,,User,,13,,7,13

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
735981,xapian,xapian/xapian,C++,281,793,50,58,19774,12,272,12,"[{'id': 566052739, 'number': 320, 'closed': datetime.datetime(2022, 6, 29, 4, 51, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 2, 2, 15, 51, 21, tzinfo=datetime.timezone.utc), 'time_taken': 44197179.0, 'time_delta': '511 days, 12:59:39', 'additions': 219, 'deletions': 549, 'state': 'closed'}, {'id': 483496912, 'number': 316, 'closed': datetime.datetime(2021, 9, 24, 6, 9, 28, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 9, 10, 7, 47, 29, tzinfo=datetime.timezone.utc), 'time_taken': 32739719.0, 'time_delta': '378 days, 22:21:59', 'additions': 26, 'deletions': 2, 'state': 'closed'}, {'id': 470144588, 'number': 314, 'closed': datetime.datetime(2020, 8, 25, 5, 40, 3, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 19, 12, 52, 53, tzinfo=datetime.timezone.utc), 'time_taken': 492430.0, 'time_delta': '5 days, 16:47:10', 'additions': 165, 'deletions': 6, 'state': 'closed'}, {'id': 467867013, 'number': 312, 'closed': datetime.datetime(2020, 8, 19, 7, 48, 32, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 14, 9, 5, 15, tzinfo=datetime.timezone.utc), 'time_taken': 427397.0, 'time_delta': '4 days, 22:43:17', 'additions': 73, 'deletions': 8, 'state': 'closed'}, {'id': 465910660, 'number': 310, 'closed': datetime.datetime(2020, 8, 13, 22, 52, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 11, 7, 1, 37, tzinfo=datetime.timezone.utc), 'time_taken': 229863.0, 'time_delta': '2 days, 15:51:03', 'additions': 116, 'deletions': 46, 'state': 'closed'}, {'id': 463943365, 'number': 309, 'closed': datetime.datetime(2020, 8, 10, 20, 11, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 6, 10, 39, 9, tzinfo=datetime.timezone.utc), 'time_taken': 379970.0, 'time_delta': '4 days, 9:32:50', 'additions': 447, 'deletions': 96, 'state': 'closed'}, {'id': 460079315, 'number': 308, 'closed': datetime.datetime(2020, 7, 31, 22, 22, 9, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 31, 12, 0, 3, tzinfo=datetime.timezone.utc), 'time_taken': 37326.0, 'time_delta': '10:22:06', 'additions': 73, 'deletions': 4, 'state': 'closed'}, {'id': 440917950, 'number': 302, 'closed': datetime.datetime(2020, 7, 27, 6, 45, 54, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 27, 14, 21, 47, tzinfo=datetime.timezone.utc), 'time_taken': 2564647.0, 'time_delta': '29 days, 16:24:07', 'additions': 450, 'deletions': 71, 'state': 'closed'}, {'id': 437103352, 'number': 301, 'closed': datetime.datetime(2020, 8, 19, 8, 3, 57, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 19, 13, 30, 36, tzinfo=datetime.timezone.utc), 'time_taken': 5250801.0, 'time_delta': '60 days, 18:33:21', 'additions': 494, 'deletions': 134, 'state': 'closed'}, {'id': 429877733, 'number': 298, 'closed': datetime.datetime(2020, 7, 31, 7, 12, 28, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 7, 8, 49, 4, tzinfo=datetime.timezone.utc), 'time_taken': 4659804.0, 'time_delta': '53 days, 22:23:24', 'additions': 100, 'deletions': 5, 'state': 'closed'}, {'id': 378583266, 'number': 287, 'closed': datetime.datetime(2020, 2, 25, 22, 34, 14, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 2, 22, 12, 2, 6, tzinfo=datetime.timezone.utc), 'time_taken': 297128.0, 'time_delta': '3 days, 10:32:08', 'additions': 4, 'deletions': 4, 'state': 'closed'}]"
2670644,xapian-docsprint,xapian/xapian-docsprint,Python,66,60,10,17,865,4,4,3,"[{'id': 462723892, 'number': 30, 'closed': datetime.datetime(2020, 8, 9, 20, 29, 45, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 4, 12, 6, 37, tzinfo=datetime.timezone.utc), 'time_taken': 462188.0, 'time_delta': '5 days, 8:23:08', 'additions': 29, 'deletions': 0, 'state': 'closed'}]"
5000805,xapian-evaluation,xapian/xapian-evaluation,C++,7,6,5,4,97,1,2,0,"[{'id': 454389502, 'number': 17, 'closed': datetime.datetime(2020, 7, 31, 21, 38, 9, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 21, 11, 1, 49, tzinfo=datetime.timezone.utc), 'time_taken': 902180.0, 'time_delta': '10 days, 10:36:20', 'additions': 50, 'deletions': 36, 'state': 'closed'}]"

pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
678275604,Adding ICOS download functionality,"<!--- Provide a general summary of your changes in the Title above -->
<!--- Please select appropriate Priority, Status,and Type labels-->
<!--- If you do not have permission to select labels please state which labels you would like -->

## Description
This PR adds the functions for downloading and processing the ICOS ecosystem data products.
- [x] download function
- [x] met2cf conversion
- [x] registration file


## Motivation and Context
Closes #2594 Closes #2802 

## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [ ] Within one week
- [x] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [x] I have updated the documentation accordingly.
- [x] I have read the **CONTRIBUTING** document.
- [x] I have added tests to cover my changes.
- [ ] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2813,https://api.github.com/repos/PecanProject/pecan/pulls/2813,https://github.com/PecanProject/pecan/pull/2813,closed,608,3,15,45,6,33,0,1,[],2021-06-26 04:54:34+00:00,2021-08-19 19:42:13+00:00,4718859.0,"54 days, 14:47:39","[{'comment_id': 659282793, 'comment_body': ""Thanks Ayush for the PR, I'll review it closely during the week. However, I forgot about our discussion regarding ICOS data platform which could be good to remember and document here. \r\n\r\nIn ICOS network, I think there are sites and datasets that we are interested besides Drought2018 (while the primary aim of your project is to get this dataset of course). So I was curious, how different is it to retrieve the other datasets from ICOS data platform? I guess what I'm trying to ask is, how difficult is it to design this function as a `download.ICOS` generic function where Drought2018 is one of the cases? Did you have the chance to play with a non-Drought2018 ICOS dataset through this pipeline?"", 'comment_created': datetime.datetime(2021, 6, 27, 8, 16, 13, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 659295620, 'comment_body': ""Yes, we had discussed about having a generic ICOS function that would also retrieve the drought 18 data. However, while actually implementing it I found that there aren't that many data sets that could meet our requirements. The only one that I could find was the, [ICOS  Level 2 Ecosystem Archive data](https://www.icos-cp.eu/data-products), which has all of the variables that we might need (meteorological and fluxes).  If we want to access this dataset using the function in the PR, we'd need to replace the url [here](https://github.com/PecanProject/pecan/pull/2813/files#diff-ceb68ce8213bf7a6877ac52e45eb33398b93f9521c33d6bfa74cd12779925069R77) and probably also change the output file names, no other changes would be required. \r\n\r\nDo you know any other relevant ICOS datasets? I can see that some sites are also publishing ecosystem data in near real-time but those are raw data and do not contain all of the variables.\r\n\r\nIn principle, it is probably possible to download all of the ICOS datasets (Ecosystem, Atmospheric and Oceanic) with a single function but then we would need the exact product id for the site and not just the site name as we are able to  do [here.](https://github.com/PecanProject/pecan/pull/2813/files#diff-ceb68ce8213bf7a6877ac52e45eb33398b93f9521c33d6bfa74cd12779925069R71-R89) And the extraction steps might also not be generalisable.\r\n\r\nSo overall I think we can either modify this `download.Drought2018` function to accommodate the Ecosystem archive data by passing the choice as a parameter or we can have something like `download.ICOS_ecosystem_archive` with a slightly higher level of abstraction. What do you think?\r\n"", 'comment_created': datetime.datetime(2021, 6, 27, 10, 0, 52, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 659299188, 'comment_body': ""Thanks Ayush, this was helpful. Yes, exactly I'm just thinking of Ecosystem datasets, particularly the Level 2 products, I think these will keep expanding besides the Drought2018 and it would be very useful to have access to those as well. \r\n\r\nI haven't played with their near real-time data but that also sounds very interesting, and I think as long as variable names units etc. and retrieval approaches are not too different, some of the missing variables could be dealt with.\xa0 \r\n\r\nI agree that matching exact product ids may not be easily generalizable but your functions can hardcode the known ones and assume that it will be known in the future. In other words, I think figuring out which product id to pass your functions is easier than figuring out the rest of the pipeline, so aiming for a partially generalizable function could be valuable.\r\n\r\nOverall, I'll have a better grasp of the situation when I review your PR, but my initial feeling would be to aim for a generic `download.ICOS` function, have L2 and Drought2018 as different cases in there as a start. "", 'comment_created': datetime.datetime(2021, 6, 27, 10, 30, 28, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662064858, 'comment_body': 'Shall we use the same variable names as in download.AmerifluxLBL.R, i.e.:\r\n```\r\ndownload_file_flag <- TRUE\r\nextract_file_flag <- TRUE\r\n```', 'comment_created': datetime.datetime(2021, 7, 1, 7, 54, 36, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662076184, 'comment_body': 'I think this function shouldn\'t subset the dataset yet, it should only check if the dates requested are preceding or exceeding the data period (which you do). E.g. if end year in your example was 2017, here you would subset it until 2017 but write it to a `""FLX_FI-Sii_FLUXNET2015_FULLSET_HH_2016-2018_beta-3.csv""` file, right? `met2CF.csv` would loop over and write (subset) the requested years.', 'comment_created': datetime.datetime(2021, 7, 1, 8, 11, 11, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662078515, 'comment_body': ""Then (when you don't subset the data here) I think you need to get start and end year of data from file itself so that the DB record is complete, similar to [AmerifluxLBL](https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/download.AmerifluxLBL.R#L124_L140) case"", 'comment_created': datetime.datetime(2021, 7, 1, 8, 14, 28, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662082458, 'comment_body': 'Just to followup on the discussion above regarding generic `download.ICOS`, if we go that way, this function would be renamed to `met2CF.ICOS` and here you may deal with different formats and/or missing variables potentially (similar to `met2CF.AmerifluxLBL`)', 'comment_created': datetime.datetime(2021, 7, 1, 8, 19, 58, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662128458, 'comment_body': 'Should I not subset the variables either (i.e include all the 233 variables in the output file)? \r\n\r\n> E.g. if end year in your example was 2017, here you would subset it until 2017 but write it to a ""FLX_FI-Sii_FLUXNET2015_FULLSET_HH_2016-2018_beta-3.csv"" file, right?\r\n\r\nYes, I just realized I didn\'t change the end date in the file name to reflect the actual end date.', 'comment_created': datetime.datetime(2021, 7, 1, 9, 21, 55, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 662188738, 'comment_body': ""hmm I was only talking about the date-subsetting but I'm now wondering if we should keep all the variables in the csv as well. It would make files larger, but if we follow Ameriflux example we should keep the raw csv file as it is and then define columns in the format with respect to the full csv column numbers"", 'comment_created': datetime.datetime(2021, 7, 1, 10, 56, 59, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662780179, 'comment_body': '```suggestion\r\nIT-SR2,San Rossore 2,Italy,43.732022,10.29091,14.2,920.0,ENF,Csa,2013–2018,10.18160/FFK6-8ZV7\r\n```', 'comment_created': datetime.datetime(2021, 7, 2, 6, 54, 4, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662781100, 'comment_body': '```suggestion\r\n  geom_point(data=icos_d2018, aes(x=Longitude, y=Latitude), color=""red"", size=2)\r\n```', 'comment_created': datetime.datetime(2021, 7, 2, 6, 55, 46, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662781858, 'comment_body': '```suggestion\r\nDE-Hte,Huetelmoor,Germany,54.210278,12.176111,9.2,645.00,WET,Dfb,2009–2018,10.18160/63V0-08T4\r\n```', 'comment_created': datetime.datetime(2021, 7, 2, 6, 57, 11, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 662959401, 'comment_body': ""Is this fine? The ecosystem archive product is similar to drought except for 2-3 variables, if we were subsetting the variables, I think we could've used the same format. The other option I can think of is to have the same format but to subset the variables in `met2CF.ICOS` so that the column numbers remain same,"", 'comment_created': datetime.datetime(2021, 7, 2, 11, 58, 42, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 663887109, 'comment_body': ""I think this is fine. Not-subsetting variables increases your function's usability outside of PEcAn, so I'm liking it and defining two formats is not a big deal. Do the variables of our interest happen to have the same column numbers by any chance (in the raw files I mean)? :)\r\n\r\nLike you said, using a single format and handling the mapping in the `met2CF.ICOS` can also be an option. Actually, [met2CF.AmerifluxLBL](https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/met2CF.AmerifluxLBL.R#L44) does something similar. Normally I wouldn't like this (as it sort of obscures what is on the DB record versus what is being processed) but I suspect that the variable names are so similar that we may get away with one format for both ICOS products. Shall we give this a try?"", 'comment_created': datetime.datetime(2021, 7, 5, 12, 19, 18, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 664064901, 'comment_body': ""> Do the variables of our interest happen to have the same column numbers by any chance (in the raw files I mean)? \r\n\r\nOh yes, I just saw that the variables required for met2cf have the same column numbers. I think only the constraint data variables differ like NEE_VUT_REF is 98 in the ecosystem archive but 87 in drought 2018. I guess we can have the same format now without making any changes, but I'm not sure if we are going to use the same format while using the load functions.\r\n\r\n\r\n![Screenshot from 2021-07-05 22-51-58](https://user-images.githubusercontent.com/11568631/124503726-c6597c00-dde3-11eb-9198-14ea4c6cfd01.png)\r\n"", 'comment_created': datetime.datetime(2021, 7, 5, 17, 31, 30, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 664360308, 'comment_body': 'can we get rid of this `sitename` subfolder? see the following changes\r\n```suggestion\r\n        paste0(""ICOSETC_"", sitename, ""_FLUXNET_HH_01.csv"")\r\n```', 'comment_created': datetime.datetime(2021, 7, 6, 8, 46, 15, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 664360505, 'comment_body': '```suggestion\r\n        paste0(""ICOSETC_"", sitename, ""_FLUXNET_HH"")\r\n```', 'comment_created': datetime.datetime(2021, 7, 6, 8, 46, 30, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 664360823, 'comment_body': ""```suggestion\r\n          paste0('*', file_name),\r\n```"", 'comment_created': datetime.datetime(2021, 7, 6, 8, 46, 53, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 664361353, 'comment_body': '```suggestion\r\n                   files = zipped_csv_name,\r\n                   junkpaths = TRUE,\r\n```', 'comment_created': datetime.datetime(2021, 7, 6, 8, 47, 30, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 664371102, 'comment_body': ""yes, thanks I wasn't aware of this `junkpaths`"", 'comment_created': datetime.datetime(2021, 7, 6, 8, 59, 58, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 681645847, 'comment_body': 'I think this is a logical construction, but should we rather leave start year in this filename as a wildcard or something like that? Take the vignette example, for FI-Hyy the unzipped file ends up being `1996-2018_beta-3.csv`, but your filename stays as `2016-2018_beta-3.csv`\r\n\r\nOn L79 try different checks to see if csv file exists, then downstream if `zipped_csv_name` is different than `output_file_name`, overwrite it with `zipped_csv_name` maybe. This way DB record will be accurate', 'comment_created': datetime.datetime(2021, 8, 3, 10, 45, 57, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 681678905, 'comment_body': 'I guess for drought2018, it\'s safe to assume this could always be the case?\r\n```suggestion\r\n                   exdir = outfolder)\r\n      if (tolower(product) == ""drought2018"") {\r\n        output_file_name <- zipped_csv_name\r\n      }\r\n```', 'comment_created': datetime.datetime(2021, 8, 3, 11, 40, 36, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 681680765, 'comment_body': 'Will this always be `_01` do you know? shall we safeguard against potential future versions?', 'comment_created': datetime.datetime(2021, 8, 3, 11, 43, 31, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 682302364, 'comment_body': ""I'm not sure how to safeguard it. The future archive products will probably have their own datatype URL which might require a new if block to be added."", 'comment_created': datetime.datetime(2021, 8, 4, 5, 39, 46, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 682302590, 'comment_body': 'Yes', 'comment_created': datetime.datetime(2021, 8, 4, 5, 40, 25, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 682305755, 'comment_body': 'OK fair enough', 'comment_created': datetime.datetime(2021, 8, 4, 5, 48, 33, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 682574989, 'comment_body': '```suggestion\r\n           overwrite = FALSE, ...) {\r\n```', 'comment_created': datetime.datetime(2021, 8, 4, 12, 38, 16, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 682581668, 'comment_body': 'Similar to [Ameriflux case](https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/download.AmerifluxLBL.R#L29):\r\n```suggestion\r\n    sitename <- sub("".* \\\\((.*)\\\\)"", ""\\\\1"", sitename)\r\n```', 'comment_created': datetime.datetime(2021, 8, 4, 12, 47, 17, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 682588202, 'comment_body': '```suggestion\r\n           overwrite = FALSE, ...) {\r\n```', 'comment_created': datetime.datetime(2021, 8, 4, 12, 55, 43, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 683313184, 'comment_body': 'this one needs to be without the file extension I think\r\n```suggestion\r\n      dbfile.name = substr(basename(output_file_name), 1, nchar(basename(output_file_name)) - 4),\r\n```', 'comment_created': datetime.datetime(2021, 8, 5, 10, 2, 31, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 684996408, 'comment_body': ""aren't these 30 min resolution?\r\n```suggestion\r\nResolution: 30 min\r\n```"", 'comment_created': datetime.datetime(2021, 8, 9, 8, 17, 31, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 685006972, 'comment_body': '```suggestion\r\nResolution: 30 min\r\n```', 'comment_created': datetime.datetime(2021, 8, 9, 8, 34, 11, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 688381108, 'comment_body': '```suggestion\r\n dbcon <-DBI::dbConnect(\r\n    RPostgres::Postgres(),\r\n    host = \'localhost\',\r\n    user = \'bety\',\r\n    password = \'bety\',\r\n    dbname = \'bety\'\r\n  )\r\n ## or if you have different DB settings try:\r\n ## php_config <- "".../pecan/web/config.php"" # path to your PHP config file\r\n ## dcon <- betyConnect(php_config)\r\nformat <- PEcAn.DB::query.format.vars(bety = dbcon, format.id = 1000000136)\r\n```', 'comment_created': datetime.datetime(2021, 8, 13, 9, 35, 15, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}]","[{'commit_sha': '6c27a53aa9f4b63819e8152808e9c8a1493b247e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b1570b502b65a437a82bfc9d3f9efa748c82aaf9', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '375178510ce3637c91c1dd470fda71931114d79e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c29a2d7737edf172e31e06a60eb2c6c6ff159861', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '12653f3b4b7b0f8f96ee7882fa9b443d519462ad', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c779517c509ca27f933dba638ae3aa60bfa768e8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '421d2bd63d6c3218e48af0f3504ebc23cf18d854', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e616d8a03b1de956a6b59024480a3a4e199b2d4a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '39d4683bdfdabf18ce5e376c46ea6a464f1cd4ae', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9632c823f5ac1d7b58bc8ed7717c53581798e9e3', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0104242c5b4b11112626309f7077be7adc98e7a', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f146ee746146a86d0823721eedfb8755e7a2751c', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': '00b50e4d04d88b332d23810635a76c617b9e62c8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7514b9a28d2607e6b9d1ed919da17babf56f8bd', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0ee8935a6bcdd3d6c8c63beb572b5bec34a9ff14', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c5a8fba381e88c1f361843f9eb4347a73a089e50', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '98b1ae6c7045a8213aadfcad345f20f22158c851', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ea9c1ab1e26df370dfc87d4dfaa54b0417a7c869', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c6b3e3419dc550a8f29eff71d985b4fb06a78f99', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '73e2780bedf0bbfa137d61080934b64bda1df9df', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '578e64155fcf73cf8c3eb3c786453504df6b4973', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c4500ec342ac3d5a09e17bc466871b1cccb4a405', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '880cdbd54b4f8943a3bc83253eefd25afcf9a7a3', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c6fb6017df540f7c21fbff8716d9fcc14577cbca', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c6963b5c1736c92f395c8b916d7a1c7c35c98a6f', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9859b4c39523a1540f104542220ae8f5a0fd6aed', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f794a76ae09af5fc0774cdc0f7bbc30379f012d8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7bc72f5b2e5d81d4f871ff8a50e57503be99fa0f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b232c353e17a5fb21e6ddc20a7e8a9fa545f7f5b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '113f7ef21edd860bdaf02d3dccca5f667379e64c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ea30abfba55502590dc9a122731b855b8b67b68d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e63663c53daf30c7a36bb6e9f7aa32077b40aca8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b25601d82cfd116c811b62647656b12d2a38d0b0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bddb9fd0697e30a0a65669433614256ac56e4e95', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '665794f5cc5a5befb9488fbb61156473c8a8cc3b', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': '216a71f35b967887aa5b39505c9f029fc00b7958', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a40cd48199a7d4386dea83671b0e822602253313', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '339f5703393f1d0cb06f82c61d522671f02b2d2f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'be4ce2cbdca329f7494d7808957fb29a051c42d7', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9b07830d1229ea9c7f6b872c32b79456ffa30eac', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '198d4a169c09c46c1c4fbe260fbf9e7d24825e75', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8d07fd0d3304bd98b9e8e0b214fccee7e4f416f9', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd4d35d6456bc611ece7a61063470d0a287a4b52c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8f6b161077d56adf568d2d60a242b69d8198e48b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '801ebad27c72b1a1b35871cbc97f95a9c3ee1043', 'committer_username': 'dlebauer', 'committer_name': 'David LeBauer', 'committer_email': 'dlebauer@gmail.com', 'commit_date': datetime.datetime(2010, 11, 2, 21, 24, 33, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13
717124663,Adding GEDI download option to remote data module,"## Description
<!--- Describe your changes in detail -->
This PR adds the option to download GEDI L1B, L2A and L2B data using the LP DAAC data pool.

 Not sure if it would be relevant but I have also added a script to retrieve the [Global Forest Canopy Height, 2019](https://glad.umd.edu/dataset/gedi) dataset on GEE which is based on GEDI data.

To test the PR the following settings configuration can be used:
For testing the datapool option
```
  <remotedata>
  <out_get_data>gedi</out_get_data>
  <source>datapool</source>
  <collection>GEDI02_B.002</collection>
  </remotedata>
  <run>
    <site>
      <id>772</id>
      <met.start>2019-01-01 00:00:00</met.start>
      <met.end>2019-03-30 00:00:00</met.end>
    </site>
    <inputs>
      <met>
        <id></id>
      </met>
    </inputs>
    <start.date>2019/01/01</start.date>
    <end.date>2019/03/30</end.date>
  </run>
```


For testing the GEE option
```
  <remotedata>
  <out_get_data>gedi</out_get_data>
  <source>gee</source>
  <collection>users/potapovpeter/GEDI_V27</collection>
  </remotedata>
  <run>
    <site>
      <id>772</id>
      <met.start>2019-12-01 00:00:00</met.start>
      <met.end>2019-12-31 00:00:00</met.end>
    </site>
    <inputs>
      <met>
        <id></id>
      </met>
    </inputs>
    <start.date>2019/01/01</start.date>
    <end.date>2019/12/31</end.date>
  </run>
```



## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [ ] Within one week
- [x] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [x] I have updated the documentation accordingly.
- [x] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [x] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2840,https://api.github.com/repos/PecanProject/pecan/pulls/2840,https://github.com/PecanProject/pecan/pull/2840,closed,608,14,9,11,6,0,0,0,[],2021-08-21 09:28:17+00:00,2022-03-09 10:51:14+00:00,17284977.0,"200 days, 1:22:57",[],"[{'commit_sha': 'ce487f12ffbbaa7d3e757295c704e41bf756af1e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e113e9ed0af4a1a07ee4b9f3fc7ee1a96e111c79', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '16f88ca196a2e86a722ca98211e6cce5f4fc65d8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '55e1cf8474b8706e8023bc58c7c86331edb1cfeb', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7b355d1d645785a0379cbb1909e643d6694820d1', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f48e9d0eca089b855a416335ac0ff9cb901794ee', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9503e80d0fb8ebec4b5ae5bc10e5fbb6ae208d05', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ab11550db4017af453c1b86c4926d549870765d3', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': '604c70294463b26e965cd0e8333511b21daa461a', 'committer_username': 'istfer', 'committer_name': 'Istem Fer', 'committer_email': 'fer.istem@gmail.com', 'commit_date': datetime.datetime(2015, 8, 10, 9, 0, 15, tzinfo=datetime.timezone.utc)}, {'commit_sha': '600c775032584ac7ba5138f701f5e5f8ace85260', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '22075ed752e5ede9a1f21d9534a6e69abc5ec61e', 'committer_username': 'mdietze', 'committer_name': 'Michael Dietze', 'committer_email': 'dietze@bu.edu', 'commit_date': datetime.datetime(2012, 12, 19, 14, 18, 27, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
6857384,pecan,PecanProject/pecan,R,231,202,36,208,22867,449,18,24,"[{'id': 717124663, 'number': 2840, 'closed': datetime.datetime(2022, 3, 9, 10, 51, 14, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 8, 21, 9, 28, 17, tzinfo=datetime.timezone.utc), 'time_taken': 17284977.0, 'time_delta': '200 days, 1:22:57', 'additions': 608, 'deletions': 14, 'state': 'closed'}, {'id': 678275604, 'number': 2813, 'closed': datetime.datetime(2021, 8, 19, 19, 42, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 26, 4, 54, 34, tzinfo=datetime.timezone.utc), 'time_taken': 4718859.0, 'time_delta': '54 days, 14:47:39', 'additions': 608, 'deletions': 3, 'state': 'closed'}, {'id': 464505193, 'number': 2676, 'closed': datetime.datetime(2020, 8, 8, 19, 16, 48, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 7, 9, 41, 33, tzinfo=datetime.timezone.utc), 'time_taken': 120915.0, 'time_delta': '1 day, 9:35:15', 'additions': 10, 'deletions': 10, 'state': 'closed'}, {'id': 462004888, 'number': 2672, 'closed': datetime.datetime(2020, 10, 29, 18, 6, 19, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 3, 7, 34, 21, tzinfo=datetime.timezone.utc), 'time_taken': 7554718.0, 'time_delta': '87 days, 10:31:58', 'additions': 2483, 'deletions': 388, 'state': 'closed'}, {'id': 449912442, 'number': 2659, 'closed': datetime.datetime(2020, 7, 30, 13, 36, 23, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 16, 5, 40, 28, tzinfo=datetime.timezone.utc), 'time_taken': 1238155.0, 'time_delta': '14 days, 7:55:55', 'additions': 282, 'deletions': 19, 'state': 'closed'}, {'id': 447776486, 'number': 2652, 'closed': datetime.datetime(2020, 8, 7, 9, 42, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 11, 14, 43, 8, tzinfo=datetime.timezone.utc), 'time_taken': 2314778.0, 'time_delta': '26 days, 18:59:38', 'additions': 3, 'deletions': 3, 'state': 'closed'}, {'id': 442003582, 'number': 2645, 'closed': datetime.datetime(2020, 6, 30, 13, 32, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 30, 12, 46, 7, tzinfo=datetime.timezone.utc), 'time_taken': 2763.0, 'time_delta': '0:46:03', 'additions': 152, 'deletions': 0, 'state': 'closed'}, {'id': 440906973, 'number': 2642, 'closed': datetime.datetime(2020, 7, 9, 15, 2, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 27, 12, 39, 3, tzinfo=datetime.timezone.utc), 'time_taken': 1045417.0, 'time_delta': '12 days, 2:23:37', 'additions': 950, 'deletions': 485, 'state': 'closed'}, {'id': 435178571, 'number': 2637, 'closed': datetime.datetime(2020, 6, 19, 12, 11, 41, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 16, 12, 23, 48, tzinfo=datetime.timezone.utc), 'time_taken': 258473.0, 'time_delta': '2 days, 23:47:53', 'additions': 462, 'deletions': 27, 'state': 'closed'}, {'id': 433140671, 'number': 2634, 'closed': datetime.datetime(2020, 6, 16, 11, 14, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 11, 15, 2, 45, tzinfo=datetime.timezone.utc), 'time_taken': 418288.0, 'time_delta': '4 days, 20:11:28', 'additions': 837, 'deletions': 0, 'state': 'closed'}, {'id': 432930906, 'number': 2633, 'closed': datetime.datetime(2020, 6, 11, 12, 31, 3, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 11, 8, 46, 45, tzinfo=datetime.timezone.utc), 'time_taken': 13458.0, 'time_delta': '3:44:18', 'additions': 46463, 'deletions': 0, 'state': 'closed'}, {'id': 431021138, 'number': 2630, 'closed': datetime.datetime(2020, 6, 8, 13, 45, 15, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 8, 10, 4, 31, tzinfo=datetime.timezone.utc), 'time_taken': 13244.0, 'time_delta': '3:40:44', 'additions': 4, 'deletions': 4, 'state': 'closed'}, {'id': 417919922, 'number': 2611, 'closed': datetime.datetime(2020, 5, 18, 13, 25, 6, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 14, 11, 3, 2, tzinfo=datetime.timezone.utc), 'time_taken': 354124.0, 'time_delta': '4 days, 2:22:04', 'additions': 1, 'deletions': 1, 'state': 'closed'}, {'id': 416029683, 'number': 2606, 'closed': datetime.datetime(2020, 5, 13, 13, 7, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 11, 10, 59, 14, tzinfo=datetime.timezone.utc), 'time_taken': 180479.0, 'time_delta': '2 days, 2:07:59', 'additions': 22, 'deletions': 21, 'state': 'closed'}]"

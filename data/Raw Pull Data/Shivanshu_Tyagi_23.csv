pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
985150278,[GSoC] [WIP] Add Audio Visual Speech Recognition pre-processing functions,"# Audio Visual Speech Recognition sample
This PR corresponds to the GSoC22 project by the same name. It aims to develop a sample to do real-time speech recognition using a DNN and Audio and Video input. 

We tested the originally proposed model in pytorch and exported it to onnx format ( can be found [here](https://drive.google.com/drive/folders/1oO5vUbzHFmovKTIaDyMSc_ivHb5EBhjB?usp=sharing) ). However, the model was not generalizing well and the performance was not very good. So, we switched to a more recent model [AVHubert](https://github.com/facebookresearch/av_hubert). The results seems promising when tested in pytorch and we're currently working on exporting this model in onnx format.  This model is an ensemble model that processes audio and video and combines the result. Also, some of the operations in the model are not very efficient and hence will require some modification to export an efficient model that would work in realtime with opencv dnn.

This PR contains the pre-processing code for video that returns mouth ROIs from the video or camera feed. We chose to use OpenCV's Face Detection API that implements YUNet to detect face bbox and 5 facial landmarks. These landmarks are used to crop a mouth ROI using the landmark information of previous m (5 by default) frames. The reason to choose YUNet over dlib, even though dlib is more robust is the speed. YUNet is very fast and here is an FPS comparison of dlib v/s YUNet for an image of dim. (1080, 1920, 3):
* dlib:  1.0318715474540403 FPS
* OpenCV Face Detection API:  3.776787675994194 FPS

## Usage
* Download the YUNet onnx model file from here: https://github.com/opencv/opencv_zoo/blob/master/models/face_detection_yunet/face_detection_yunet_2022mar.onnx and keep it in the same folder as `audio_visual_speech_recognition.py`
* Then run `python audio_visual_speech_recognition.py`. This should start recording your video and giving the mouth ROIs.

NOTE: This is a WIP and currently only calculates mouth ROIs for the model. I will add the arg parser as the model is added. Majorly the work is being done on exporting the onnx model.
 

## Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
",False,22181,https://api.github.com/repos/opencv/opencv/pulls/22181,https://github.com/opencv/opencv/pull/22181,open,264,0,1,9,5,49,2,0,"[{'name': 'category: samples'}, {'name': 'GSoC'}]",2022-07-01 16:40:27+00:00,,0.0,,"[{'comment_id': 952668427, 'comment_body': ""Please refactor notebook:\r\n1. in the notebook  should be only the parts related to model conversion\r\n2. don't copypaste code from original repo, you can import necessary classes and functions. For example,\r\n```python\r\nfrom lipreading import model\r\nfrom lipreading import utils\r\nimport torch.onnx\r\n\r\nwith open('configs/lrw_resnet18_mstcn.json') as fp:\r\n    config = json.load(fp)\r\n\r\n\r\nclass CustomLipreading(model.Lipreading):\r\n  def forward(self, x):\r\n     lengths = [20]\r\n     return model.Lipreading.forward(self, x, lengths)\r\n\r\ntcn_options = {\r\n    'num_layers': config['tcn_num_layers'],\r\n    'kernel_size': config['tcn_kernel_size'],\r\n    'dropout': config['tcn_dropout'],\r\n    'dwpw': config['tcn_dwpw'],\r\n    'width_mult': config['tcn_width_mult'],\r\n}\r\n\r\naudio_model = model.Lipreading(\r\n    num_classes=500,\r\n    tcn_options=tcn_options,\r\n    backbone_type=config['backbone_type'],\r\n    relu_type=config['relu_type'],\r\n    width_mult=config['width_mult'],\r\n    extract_feats=False,\r\n    modality = 'raw_audio'\r\n)\r\n\r\nutils.load_model(Path('models/lrw_resnet18_mstcn_audio_adamw.pth.tar'), audio_model)\r\naudio_model.to('cpu')\r\naudio_model.eval()\r\n\r\naudio_input = torch.randn(1,1,20*640)\r\ntorch.onnx.export(audio_model, audio_input, 'lipreading_audio.onnx' , opset_version=11)\r\ntorch.onnx.export(audio_model, (audio_input, [20]), 'lipreading_audio.onnx' , opset_version=11)\r\n```"", 'comment_created': datetime.datetime(2022, 8, 23, 14, 0, 48, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 952674848, 'comment_body': ""It's enough to specify default detector_path, model_path, show_video, etc. in argparser only"", 'comment_created': datetime.datetime(2022, 8, 23, 14, 6, 6, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 952676128, 'comment_body': '```suggestion\r\n            source: video source path\r\n            detector_path: face detection model path\r\n            margin: margin for temporal window\r\n            video_width: video width\r\n            video_height: video height\r\n            score_threshold: score threshold for face detection\r\n            nms_threshold: nms threshold for face detection\r\n            top_k: top k faces for face detection\r\n```', 'comment_created': datetime.datetime(2022, 8, 23, 14, 7, 9, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 952677691, 'comment_body': 'Please look at https://github.com/opencv/opencv/blob/4.x/samples/dnn/classification.py#L17', 'comment_created': datetime.datetime(2022, 8, 23, 14, 8, 27, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 952680420, 'comment_body': 'please remove it', 'comment_created': datetime.datetime(2022, 8, 23, 14, 10, 30, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 952682312, 'comment_body': 'Please align your code with other opencv samples \r\nhttps://github.com/opencv/opencv/blob/4.x/samples/dnn/classification.py#L8', 'comment_created': datetime.datetime(2022, 8, 23, 14, 12, 5, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962627397, 'comment_body': 'Is it possible to replace it to\r\n```python\r\nif self.cap.isOpened(): # check once\r\n    while self.cap.grab():\r\n```', 'comment_created': datetime.datetime(2022, 9, 5, 8, 25, 56, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962627969, 'comment_body': 'Is it really needed?', 'comment_created': datetime.datetime(2022, 9, 5, 8, 26, 30, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962629914, 'comment_body': ""I didn't find a link to the model in sample description. Please copy link from PR description"", 'comment_created': datetime.datetime(2022, 9, 5, 8, 28, 18, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962640086, 'comment_body': '```suggestion\r\nimport argparse\r\n\r\nimport cv2 as cv\r\nfrom collections import deque\r\nimport numpy as np\r\n```', 'comment_created': datetime.datetime(2022, 9, 5, 8, 38, 39, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962645699, 'comment_body': 'I think we can do it inside `AVSpeechRecognition` class', 'comment_created': datetime.datetime(2022, 9, 5, 8, 44, 22, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962661436, 'comment_body': 'img_h, img_w = img.shape[0], img.shape[1]', 'comment_created': datetime.datetime(2022, 9, 5, 8, 54, 58, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962675421, 'comment_body': 'Looks like you can replace it to `list`', 'comment_created': datetime.datetime(2022, 9, 5, 9, 8, 10, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962680103, 'comment_body': 'No need to define', 'comment_created': datetime.datetime(2022, 9, 5, 9, 13, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962680902, 'comment_body': 'Why not\r\n```suggestion\r\n            signal_std = np.std(audio)\r\n```', 'comment_created': datetime.datetime(2022, 9, 5, 9, 13, 47, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 962683495, 'comment_body': '```suggestion\r\n        video = np.expand_dims(np.array(self.frames_queue , axis=(0,1))\r\n```', 'comment_created': datetime.datetime(2022, 9, 5, 9, 16, 19, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 966391036, 'comment_body': ""need it to have a maxLength. Can do it with list, but will need to check it's length and remove previous data at each iteration."", 'comment_created': datetime.datetime(2022, 9, 8, 20, 28, 3, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}, {'comment_id': 966761679, 'comment_body': 'I think we can omit such a description:)', 'comment_created': datetime.datetime(2022, 9, 9, 8, 16, 41, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 966831938, 'comment_body': '@spazewalker please remove link to notebook', 'comment_created': datetime.datetime(2022, 9, 9, 9, 26, 58, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969566229, 'comment_body': ""It's not a good solution to change the colab notebook to gist. Why do you copypaste the code from the original repo?\r\nI have provided the code to export the model before, what is the problem with it?"", 'comment_created': datetime.datetime(2022, 9, 13, 12, 34, 18, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969568080, 'comment_body': 'Did you check all backends and targets?', 'comment_created': datetime.datetime(2022, 9, 13, 12, 35, 59, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969593523, 'comment_body': '```suggestion\r\nimport cv2 as cv\r\n```', 'comment_created': datetime.datetime(2022, 9, 13, 12, 58, 42, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969595480, 'comment_body': '```suggestion\r\n                        img = cv.resize(img, (96,96))\r\n                        img = cv.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n```', 'comment_created': datetime.datetime(2022, 9, 13, 13, 0, 24, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969596334, 'comment_body': 'To speed up preprocessing', 'comment_created': datetime.datetime(2022, 9, 13, 13, 1, 12, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969597271, 'comment_body': '```suggestion\r\n                        for  audio in aud:\r\n                            self.audio_queue.append(audio)\r\n```', 'comment_created': datetime.datetime(2022, 9, 13, 13, 2, 6, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969599698, 'comment_body': ""```suggestion\r\n                            cv2.imshow('Audio-visual speech recognition in OpenCV', frame)\r\n```"", 'comment_created': datetime.datetime(2022, 9, 13, 13, 4, 9, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969601305, 'comment_body': 'Conflict with `i` defined above\r\n```suggestion\r\n                    for audio in aud:\r\n                        audio_queue.append(audio)\r\n```', 'comment_created': datetime.datetime(2022, 9, 13, 13, 5, 33, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969603738, 'comment_body': 'Can we reshape output and get arg max?\r\nFor example,\r\n```python\r\npred = out.reshape(-1).argmax()\r\n```', 'comment_created': datetime.datetime(2022, 9, 13, 13, 7, 36, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969605838, 'comment_body': 'Need to hardcode the lengths to be passed in TCN. For this, I had to overwrite the forward function in AVSpeechRecog class.', 'comment_created': datetime.datetime(2022, 9, 13, 13, 9, 18, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}, {'comment_id': 969605881, 'comment_body': 'What about audio?', 'comment_created': datetime.datetime(2022, 9, 13, 13, 9, 21, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969606913, 'comment_body': 'Please align docstring with method ', 'comment_created': datetime.datetime(2022, 9, 13, 13, 10, 13, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969608237, 'comment_body': 'Please align docstring with arguments', 'comment_created': datetime.datetime(2022, 9, 13, 13, 11, 18, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969608937, 'comment_body': 'Add params section', 'comment_created': datetime.datetime(2022, 9, 13, 13, 11, 51, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 969611938, 'comment_body': ""I hardcoded lengths in export function\r\n```python\r\ntorch.onnx.export(audio_model, (audio_input, [20]), 'lipreading_audio.onnx' , opset_version=11)\r\n```"", 'comment_created': datetime.datetime(2022, 9, 13, 13, 14, 22, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 970128338, 'comment_body': 'Initially, I was doing the same. But the model exported by this was not behaving correctly, as in this case, 20 is treated as an input and the graph comes out a little different', 'comment_created': datetime.datetime(2022, 9, 13, 22, 22, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}, {'comment_id': 970502356, 'comment_body': "">  But the model exported by this was not behaving correctly\r\n\r\nWhat do you mean? I think setting constant input isn't a problem\r\n\r\nAccording to documentation:\r\n> Any non-Tensor arguments will be hard-coded into the exported model"", 'comment_created': datetime.datetime(2022, 9, 14, 8, 39, 23, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 970542816, 'comment_body': ""You can inherit your class and override the sequence length\r\n\r\n```python\r\nfrom lipreading import model\r\nimport json\r\nfrom pathlib import Path\r\nfrom lipreading import utils\r\nimport torch.onnx\r\n\r\nwith open('configs/lrw_resnet18_mstcn.json') as fp:\r\n    config = json.load(fp)\r\n\r\nclass CustomLipreading(model.Lipreading):\r\n  def forward(self, x):\r\n     lengths = [20]\r\n     return model.Lipreading.forward(self, x, lengths)\r\n\r\ntcn_options = {\r\n    'num_layers': config['tcn_num_layers'],\r\n    'kernel_size': config['tcn_kernel_size'],\r\n    'dropout': config['tcn_dropout'],\r\n    'dwpw': config['tcn_dwpw'],\r\n    'width_mult': config['tcn_width_mult'],\r\n}\r\n\r\naudio_model = CustomLipreading(\r\n    num_classes=500,\r\n    tcn_options=tcn_options,\r\n    backbone_type=config['backbone_type'],\r\n    relu_type=config['relu_type'],\r\n    width_mult=config['width_mult'],\r\n    extract_feats=False,\r\n    modality = 'raw_audio'\r\n)\r\n\r\nutils.load_model(Path('models/lrw_resnet18_mstcn_audio_adamw.pth.tar'), audio_model)\r\naudio_model.to('cpu')\r\naudio_model.eval()\r\n\r\naudio_input = torch.randn(1,1,10666)\r\ntorch.onnx.export(audio_model, (audio_input), 'custom_lipreading_audio.onnx' , opset_version=11, input_names=['audio_input'])\r\n```"", 'comment_created': datetime.datetime(2022, 9, 14, 9, 17, 2, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 970556534, 'comment_body': ""I'll change this. Should i keep a link to gist in the sample then?"", 'comment_created': datetime.datetime(2022, 9, 14, 9, 29, 55, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}, {'comment_id': 970593879, 'comment_body': 'Yes, you can keep link', 'comment_created': datetime.datetime(2022, 9, 14, 10, 2, 15, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 971730993, 'comment_body': 'What about targets?', 'comment_created': datetime.datetime(2022, 9, 15, 9, 8, 22, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 971731972, 'comment_body': '```suggestion\r\n        self.fps = 30\r\n        self.source = source\r\n```\r\n', 'comment_created': datetime.datetime(2022, 9, 15, 9, 9, 23, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 971735619, 'comment_body': 'What is the problem with other backends?', 'comment_created': datetime.datetime(2022, 9, 15, 9, 12, 42, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 972105094, 'comment_body': 'I tested other backends, there were some errors, the same case was with targets. I tested the OpenVINO and FP16 one, both were giving out errors.', 'comment_created': datetime.datetime(2022, 9, 15, 15, 1, 23, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}, {'comment_id': 972108951, 'comment_body': 'What are the types of errors?', 'comment_created': datetime.datetime(2022, 9, 15, 15, 4, 50, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 972116527, 'comment_body': 'Not implemented error\r\n\r\n```\r\nPS C:\\Codes\\GSoC\\GSoC22\\opencv\\samples\\dnn> python .\\audio_visual_speech_recognition.py --show_video --input test.mp4 --target 0 --backend 2\r\nTraceback (most recent call last):\r\n  File ""C:\\Codes\\GSoC\\GSoC22\\opencv\\samples\\dnn\\audio_visual_speech_recognition.py"", line 266, in <module>\r\n    main()\r\n  File ""C:\\Codes\\GSoC\\GSoC22\\opencv\\samples\\dnn\\audio_visual_speech_recognition.py"", line 263, in main\r\n    recognizer.run()\r\n  File ""C:\\Codes\\GSoC\\GSoC22\\opencv\\samples\\dnn\\audio_visual_speech_recognition.py"", line 213, in run\r\n    pred = self.predict(image_queue, audio_queue)\r\n  File ""C:\\Codes\\GSoC\\GSoC22\\opencv\\samples\\dnn\\audio_visual_speech_recognition.py"", line 156, in predict\r\n    out = self.model.forward()\r\ncv2.error: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\legacy_backend.cpp:123: error: (-213:The function/feature is not implemented) Unknown backend identifier in function \'cv::dnn::dnn4_v20220524::detail::wrapMat\'\r\n```', 'comment_created': datetime.datetime(2022, 9, 15, 15, 11, 27, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}, {'comment_id': 972674570, 'comment_body': ""This means you don't build opencv with openvino or install opencl. You can run the classification sample with the same backends and targets to ensure that opencv has been build successfully. "", 'comment_created': datetime.datetime(2022, 9, 16, 6, 55, 11, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 973367342, 'comment_body': 'Yeah, I think openCL is not there in my local machine.', 'comment_created': datetime.datetime(2022, 9, 16, 20, 21, 31, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}, {'comment_id': 973970076, 'comment_body': 'You can find suitable drivers to your machine: https://github.com/intel/intel-graphics-compiler/releases\r\nAnd then try to rebuild opencv', 'comment_created': datetime.datetime(2022, 9, 19, 8, 9, 17, tzinfo=datetime.timezone.utc), 'commenter': 'l-bat', 'type': 'User'}, {'comment_id': 974390903, 'comment_body': ""There's an issue. I'm using WSL on windows. It's not working on WSL. To install and build openCV on windows would take some time and since my mid terms are going on, I'm unable to do so. If possible, can you test the backends on your machine? 😅"", 'comment_created': datetime.datetime(2022, 9, 19, 15, 24, 59, tzinfo=datetime.timezone.utc), 'commenter': 'spazewalker', 'type': 'User'}]","[{'commit_sha': '9eba1cdb0cfac4af68788976d10e0d3dfedd8346', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1a2e1b6b4b956303e9d49eaaf1a4da077910f04c', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '295a4440309335d37347240ee9485d9b0af12d7e', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7001e7e2bdf6f5dadb11a9929472623fb7abe8a8', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '846db9ce766e1225d43659073bfcf95bdd8f16ff', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '42fbf1ff46929fdeb44a9702d83cd843a5ddd466', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6264d001a3a0f5c83c57bf027cfcddc7ebf5e6a7', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '79a543c2d915bec0f694b8d8c58e3192ada54624', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6f93ec9c4933c96037bdfac5e48d8ba3ab39b662', 'committer_username': 'spazewalker', 'committer_name': 'Shivanshu Tyagi', 'committer_email': 'shivanshutyagi3@gmail.com', 'commit_date': datetime.datetime(2018, 8, 12, 15, 14, 29, tzinfo=datetime.timezone.utc)}]",Shivanshu Tyagi,42320317,shivanshutyagi3@gmail.com,User,,39,,127,80

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
5108051,opencv,opencv/opencv,C++,55708,77606,2656,2195,34493,2600,6,133,"[{'id': 985150278, 'number': 22181, 'closed': None, 'created': datetime.datetime(2022, 7, 1, 16, 40, 27, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 264, 'deletions': 0, 'state': 'open'}, {'id': 697103180, 'number': 20462, 'closed': datetime.datetime(2021, 8, 23, 7, 29, 34, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 7, 26, 14, 54, 43, tzinfo=datetime.timezone.utc), 'time_taken': 2392491.0, 'time_delta': '27 days, 16:34:51', 'additions': 9, 'deletions': 2, 'state': 'closed'}, {'id': 674770047, 'number': 20291, 'closed': datetime.datetime(2021, 10, 4, 18, 18, 2, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 21, 18, 9, 24, tzinfo=datetime.timezone.utc), 'time_taken': 9072518.0, 'time_delta': '105 days, 0:08:38', 'additions': 506, 'deletions': 0, 'state': 'closed'}]"

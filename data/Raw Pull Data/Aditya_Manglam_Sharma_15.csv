pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
415039822,cassandra support to spring boot,I think this is just a basic implementation of what I'm supposed to this with this feature. Kindly see and let me know what more things are to be done to get this right.,True,224,https://api.github.com/repos/teiid/teiid-spring-boot/pulls/224,https://github.com/teiid/teiid-spring-boot/pull/224,closed,215,1,6,2,13,0,0,0,[],2020-05-08 04:33:56+00:00,2020-05-14 15:35:06+00:00,558070.0,"6 days, 11:01:10",[],"[{'commit_sha': '0f2c66e347705644cdd12f030a9240e62bb3417c', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0733ed9aad6b5e9787d6628d70526e647198fc38', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5
421237539,adding cassandra sample for spring boot,"Facing an error. Logs:

15391 --- [           main] org.teiid.spring.example.Application     : Starting Application on aditya-Inspiron-5570 with PID 15391 (/home/aditya/Desktop/Teiid/teiid-spring-boot/samples/cassandra/target/classes started by aditya in /home/aditya/Desktop/Teiid/teiid-spring-boot)
2020-05-21 14:04:06.330 DEBUG 15391 --- [           main] org.teiid.spring.example.Application     : Running with Spring Boot v2.2.6.RELEASE, Spring v5.2.5.RELEASE
2020-05-21 14:04:06.332  INFO 15391 --- [           main] org.teiid.spring.example.Application     : No active profile set, falling back to default profiles: default
2020-05-21 14:04:10.000  INFO 15391 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2020-05-21 14:04:10.059  INFO 15391 --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 42ms. Found 0 JPA repository interfaces.
2020-05-21 14:04:11.073  INFO 15391 --- [           main] o.t.s.a.TeiidBeanDefinitionPostProcessor : Found data sources: []
2020-05-21 14:04:11.949  INFO 15391 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.teiid.spring.autoconfigure.TransactionManagerConfiguration' of type [org.teiid.spring.autoconfigure.TransactionManagerConfiguration$$EnhancerBySpringCGLIB$$89cf0ae0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-05-21 14:04:12.041  INFO 15391 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'platformTransactionManagerAdapter' of type [org.teiid.spring.autoconfigure.PlatformTransactionManagerAdapter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-05-21 14:04:12.365  INFO 15391 --- [           main] o.t.s.a.TeiidAutoConfiguration           : Starting Teiid Server.
2020-05-21 14:04:17.264  INFO 15391 --- [           main] org.teiid.RUNTIME.VDBLifeCycleListener   : TEIID40118 VDB spring.1.0.0 added to the repository
2020-05-21 14:04:17.273  INFO 15391 --- [           main] org.teiid.RUNTIME.VDBLifeCycleListener   : TEIID40003 VDB spring.1.0.0 is set to ACTIVE
2020-05-21 14:04:17.543  INFO 15391 --- [           main] o.s.j.d.e.EmbeddedDatabaseFactory        : Starting embedded database: url='jdbc:teiid:spring;PassthroughAuthentication=true;useCallingThread=true;autoFailover=true;waitForLoad=5000;autoCommitTxn=OFF;disableLocalTxn=true', username='null'
2020-05-21 14:04:19.233  INFO 15391 --- [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
2020-05-21 14:04:19.687  INFO 15391 --- [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 5.4.12.Final
2020-05-21 14:04:21.212  INFO 15391 --- [           main] o.hibernate.annotations.common.Version   : HCANN000001: Hibernate Commons Annotations {5.1.0.Final}
2020-05-21 14:04:21.477  INFO 15391 --- [           main] org.hibernate.dialect.Dialect            : HHH000400: Using dialect: org.teiid.dialect.TeiidDialect
2020-05-21 14:04:22.397  INFO 15391 --- [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2020-05-21 14:04:22.422  INFO 15391 --- [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2020-05-21 14:04:23.104  INFO 15391 --- [           main] o.t.spring.autoconfigure.TeiidServer     : Added accounts to the Teiid Database
2020-05-21 14:04:23.105  INFO 15391 --- [           main] org.teiid.RUNTIME.VDBLifeCycleListener   : TEIID40120 VDB spring.1.0.0 will be removed from the repository
2020-05-21 14:04:23.105  INFO 15391 --- [           main] org.teiid.RUNTIME.VDBLifeCycleListener   : TEIID40119 VDB spring.1.0.0 removed from the repository
2020-05-21 14:04:23.152  INFO 15391 --- [           main] org.teiid.RUNTIME.VDBLifeCycleListener   : TEIID40118 VDB spring.1.0.0 added to the repository
2020-05-21 14:04:23.174  INFO 15391 --- [           main] org.teiid.RUNTIME                        : TEIID50029 VDB spring.1.0.0 model ""accounts"" metadata is currently being loaded. Start Time: 21/5/20 2:04 PM
2020-05-21 14:04:23.351  INFO 15391 --- [           main] com.datastax.driver.core                 : DataStax Java driver 3.7.2 for Apache Cassandra
2020-05-21 14:04:23.473  INFO 15391 --- [           main] c.d.driver.core.GuavaCompatibility       : Detected Guava >= 19 in the classpath, using modern compatibility layer
2020-05-21 14:04:25.315  INFO 15391 --- [           main] com.datastax.driver.core.ClockFactory    : Using native clock to generate timestamps.
2020-05-21 14:04:25.972  INFO 15391 --- [           main] com.datastax.driver.core.NettyUtil       : Found Netty's native epoll transport in the classpath, using it
2020-05-21 14:04:26.250  WARN 15391 --- [           main] org.teiid.RUNTIME                        : TEIID50036 VDB spring.1.0.0 model ""accounts"" metadata failed to load. Reason:TEIID31178 Could not obtain connection for schema accounts, but one is required for metadata load.",True,228,https://api.github.com/repos/teiid/teiid-spring-boot/pulls/228,https://github.com/teiid/teiid-spring-boot/pull/228,closed,196,0,6,2,16,0,0,0,[],2020-05-21 09:02:08+00:00,2020-05-30 22:59:17+00:00,827829.0,"9 days, 13:57:09",[],"[{'commit_sha': '127ccd84b6bab83de345442a3a44a3d1fda8cbd2', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e2037b1272b344f64c2790bead897274c4701775', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5
429210523,Spring data hdfs,"1.) I did not find the filesystem class to be thread-safe. Source as mentioned in the doc ""The implementations of FileSystem shipped with Apache Hadoop do not make any attempt to synchronize access to the working directory field."" and was also mentioned on a stack overflow answer. 
2) I did not understand the wildcard part of the FIleConnectionImpl (the backward compatibility) and also a little more detail can help, thus I just did a simple glob matching there
3)When listing files I by the understanding of how things are done for fileConnectionImpl made the recursive boolean to false by default. 
4)The build will possibly fail as I was getting duplicate classes on the classpath on the build. I'll see as to how to resolve this or would ask for your help in case I'm not able to 
Submitting the first draft so that we can have an idea of things ahead!",True,242,https://api.github.com/repos/teiid/teiid-spring-boot/pulls/242,https://github.com/teiid/teiid-spring-boot/pull/242,closed,553,9,8,9,14,0,0,0,[],2020-06-06 13:44:00+00:00,2020-06-17 01:26:31+00:00,906151.0,"10 days, 11:42:31",[],"[{'commit_sha': '5dae57d865cb93cb8533a01758c9eae4e39f0568', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '63fafb9a11bcf20f78e8e156e0f51e8f134068a7', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '92e93b468e836fa76f3b526fb4f9b14e20a364e4', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4b6e75b365b40516295d15e8a0d8fd6a8e2e417e', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f7f5e6beff46e9c98cbd129b3d1233f1176ba24c', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23d2b7b0302c5962c3c07a105c94e97c3b9fa184', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8cb4c722e816f77a908b41d94dc27d291cd8279e', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ed24242a82bf5737f304c320689c3b792a4a0662', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a8ccd54460939a9a2ab67a681234ad23c2a35893', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5
440057699,TEIIDSB 211 spring data s3,,True,267,https://api.github.com/repos/teiid/teiid-spring-boot/pulls/267,https://github.com/teiid/teiid-spring-boot/pull/267,closed,613,70,8,5,5,4,0,0,[],2020-06-25 14:27:04+00:00,2020-07-01 17:46:59+00:00,530395.0,"6 days, 3:19:55","[{'comment_id': 445830318, 'comment_body': 'Can we change properties to match current amazon-s3? I mean remove ""aws"" from ""awsAccessKey"" ', 'comment_created': datetime.datetime(2020, 6, 25, 20, 50, 28, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 446094117, 'comment_body': 'I\'ve checked it with the s3executionfactory, it is ""awsAccessKey"" and not ""accessKey"" if you are saying about the field name.', 'comment_created': datetime.datetime(2020, 6, 26, 10, 9, 58, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 446135972, 'comment_body': ""I'd vote for removing the aws prefix regardless."", 'comment_created': datetime.datetime(2020, 6, 26, 11, 49, 40, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 446140856, 'comment_body': '+1', 'comment_created': datetime.datetime(2020, 6, 26, 12, 0, 57, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}]","[{'commit_sha': 'e8a080a355d1e5919910d847070f7dfede0679a9', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b555ee42e51f36d225c616c74dc30e37a6e68a2e', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3432fb3fa20efc573087cab9f5366998593bfd2c', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f389a24f74f2df814263a6a372d408a054272a29', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '638bced4afc4394fda0ee8b16559871bc091ce64', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5
439176684,TEIIDSB-206 adding sample for hdfs,"I Tried for a similar example as in FTP. The error shows : 
java.lang.IllegalStateException: Source type 'mysite' not supported on TextTable stock_price. Only ""file"",""rest"",""amazon-s3"" and ""ftp"" are supported
Is there something wrong that I am doing or the TextTable doesn't support files in hdfs?",True,265,https://api.github.com/repos/teiid/teiid-spring-boot/pulls/265,https://github.com/teiid/teiid-spring-boot/pull/265,closed,244,0,7,1,6,0,0,0,[],2020-06-24 12:31:16+00:00,2020-06-25 20:57:45+00:00,116789.0,"1 day, 8:26:29",[],"[{'commit_sha': '61853de0a8598fa1da88a56c0bdb205b4dd0c380', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5
443932506,"TEIIDSB-211 sample, addition to util and mustache",,False,276,https://api.github.com/repos/teiid/teiid-spring-boot/pulls/276,https://github.com/teiid/teiid-spring-boot/pull/276,closed,420,1,10,3,4,0,0,0,[],2020-07-03 08:42:02+00:00,2020-07-07 19:01:29+00:00,382767.0,"4 days, 10:19:27",[],"[{'commit_sha': '2e657ce6d197708cfadf283aa2bd8ac17da85ff1', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '79e137b4641d4878e48ab148a06a1a8fef79112e', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe4110c8ae7146637e5de99409a5daf3c8f286cc', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5
450270895,TEIID-4594 Parquet Translator,"This is the initial implementation of the execution logic for the parquet files. I think there should be a good amount of refinement required which can be done during testing as the java API docs for parquet don't explain anything, thus a little of the code is written with intuition. Kindly check!  ",True,1310,https://api.github.com/repos/teiid/teiid/pulls/1310,https://github.com/teiid/teiid/pull/1310,closed,1087,0,22,22,24,79,0,0,[],2020-07-16 15:07:54+00:00,2020-08-31 20:05:23+00:00,3992249.0,"46 days, 4:57:29","[{'comment_id': 455895595, 'comment_body': '.equals not != here', 'comment_created': datetime.datetime(2020, 7, 16, 15, 58, 17, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455898191, 'comment_body': 'what is need for the while?', 'comment_created': datetime.datetime(2020, 7, 16, 16, 2, 13, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455992294, 'comment_body': 'I believe logic needs to match to what is being asked of projected columns, but below looks like as `select *`, i.e. projected columns can be just a single column or two or may be all, your output should match to that not all in parquet record ', 'comment_created': datetime.datetime(2020, 7, 16, 18, 35, 24, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455994173, 'comment_body': 'I do think you supporting any of these below ""supports"" capabilities, these can be removed, you do not support `where` clause or `limit/offset`  or `in` which is what below are saying. Maybe there a way to extend current one to do that in that case keep it, next step could be that.', 'comment_created': datetime.datetime(2020, 7, 16, 18, 38, 49, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455995368, 'comment_body': 'Are we supporting updates and deletes with Paraquet? typically with file-based we do not support these. In that case this class goes away.', 'comment_created': datetime.datetime(2020, 7, 16, 18, 40, 57, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 456278324, 'comment_body': 'Got it!', 'comment_created': datetime.datetime(2020, 7, 17, 7, 50, 32, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456278792, 'comment_body': ""There's none. I took the inspiration from the excel one, but there the row was getting checked with the allow method and looped until a legit row was obtained. There's no need for it here. I got it wrong. Thanks for pointing out."", 'comment_created': datetime.datetime(2020, 7, 17, 7, 51, 22, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456279168, 'comment_body': ""Yeah, it clicked me later, what is meant by the projected columns. I'll correct it."", 'comment_created': datetime.datetime(2020, 7, 17, 7, 52, 4, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456279822, 'comment_body': ""There's an ExcelUpdateExecution in excel. Thus I just put a class in there. I don't know yet if these are to be supported in Parquet. You guys can tell better if it should be."", 'comment_created': datetime.datetime(2020, 7, 17, 7, 53, 14, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456280501, 'comment_body': 'Yes, I just put them as it is from excel to later figure out if we support these. ', 'comment_created': datetime.datetime(2020, 7, 17, 7, 54, 40, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456410152, 'comment_body': 'add a break even in the last case as well', 'comment_created': datetime.datetime(2020, 7, 17, 12, 28, 36, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 456858588, 'comment_body': 'done!', 'comment_created': datetime.datetime(2020, 7, 19, 4, 41, 6, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 460864880, 'comment_body': 'Remove this method and the associated class for now.  The engine will throw an appropriate exception about updates not being supported.', 'comment_created': datetime.datetime(2020, 7, 27, 12, 48, 23, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460867212, 'comment_body': 'Where is the is null pointer possible?', 'comment_created': datetime.datetime(2020, 7, 27, 12, 52, 36, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460869062, 'comment_body': ""There's an additional case of valueCount == 0 to handle - does that imply null for non-repeated fields, or is only possible with repeated fields?"", 'comment_created': datetime.datetime(2020, 7, 27, 12, 55, 59, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460870259, 'comment_body': 'For the engine to properly handle the result as an array it will need to be an instance of an array, not ArrayList.', 'comment_created': datetime.datetime(2020, 7, 27, 12, 58, 8, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460871394, 'comment_body': 'Go ahead and remove the supports methods for now.', 'comment_created': datetime.datetime(2020, 7, 27, 13, 0, 2, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460872933, 'comment_body': 'This is not yet wired in.  The projected columns should be determined from visiting the DerivedColumns.  You can either determine a projection index like Excel or just track the Columns that are being asked for and pass that to the execution to do further analysis.', 'comment_created': datetime.datetime(2020, 7, 27, 13, 2, 35, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460882678, 'comment_body': 'Once you have the expected columns, you can use that to read with a filtered schema.  That is you will construct a new MesssageType here that contains only fields that have been requested.  See the ColumnIOFactory.getColumnIO that take a requested schema argument.  I would guess that you would pass the filtered schema to the GroupRecordConverter as well.', 'comment_created': datetime.datetime(2020, 7, 27, 13, 18, 25, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 461080494, 'comment_body': 'Removed!', 'comment_created': datetime.datetime(2020, 7, 27, 18, 18, 23, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461081027, 'comment_body': 'fieldType.getLogicalTypeAnnotation() gives null for non logical types like int64 and .toString throws the exception. ', 'comment_created': datetime.datetime(2020, 7, 27, 18, 19, 27, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461082514, 'comment_body': ""Yes,  I didn't think of it to be one, but it does need to be handled. I can't find any doc, so played a little. I observed that the valuecount comes out to be null for non-repeated field. In case of repeated fields, I think it is only possible with the non-annotated types. "", 'comment_created': datetime.datetime(2020, 7, 27, 18, 22, 1, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461082916, 'comment_body': ""Do you mean array of objects or what? I don't quite follow here. "", 'comment_created': datetime.datetime(2020, 7, 27, 18, 22, 43, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461083393, 'comment_body': 'I have removed the support methods for now. I would do the projectedColumns part at the earliest. ', 'comment_created': datetime.datetime(2020, 7, 27, 18, 23, 32, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461083594, 'comment_body': ""I'll check this out! Thanks!"", 'comment_created': datetime.datetime(2020, 7, 27, 18, 23, 54, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461264824, 'comment_body': 'An Object array is fine.  The engine will convert to the internal representation from there.', 'comment_created': datetime.datetime(2020, 7, 28, 1, 33, 22, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462454463, 'comment_body': ""Based upon your other changes this loop can be removed.  You just need an if valueCount is 0 and an else case.  You can add an assertion if you want that the valueCount can't be greater than 1."", 'comment_created': datetime.datetime(2020, 7, 29, 17, 9, 4, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462455032, 'comment_body': 'It looks like there is an enum for FIXED_LEN_BYTE_ARRAY as well - does that need to be handled?', 'comment_created': datetime.datetime(2020, 7, 29, 17, 9, 57, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462456685, 'comment_body': ""Since the schema is keyed by name as well it is better to use the column name - column.getSourceName() - and use that filter the schema.  See MessageType.getFieldIndex(name).  That way there's no need for a new extension property on a column."", 'comment_created': datetime.datetime(2020, 7, 29, 17, 12, 39, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462898494, 'comment_body': 'I was thinking to remove this as well. ', 'comment_created': datetime.datetime(2020, 7, 30, 10, 19, 38, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 462899073, 'comment_body': 'Yes, it needs to be. Can we also return this as binary? The only difference between binary and FIXED_LEN_BYTE_ARRAY is that the latter is of fixed length and the former of variable. Or non-string binary and FIXED_LEN_BYTE_ARRAY both are to be returned as byte arrays? ', 'comment_created': datetime.datetime(2020, 7, 30, 10, 20, 53, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 462916838, 'comment_body': ""Yes, this looks better. I've implemented this. Thanks!"", 'comment_created': datetime.datetime(2020, 7, 30, 10, 57, 42, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 462971803, 'comment_body': 'It would be best to have a null check rather than to catch the NPE as that may mask other logic errors.', 'comment_created': datetime.datetime(2020, 7, 30, 12, 49, 52, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462972433, 'comment_body': 'You can return both as byte arrays.  We only support a varbinary type and not a fixed binary type.', 'comment_created': datetime.datetime(2020, 7, 30, 12, 51, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465209969, 'comment_body': 'you can remove this consideration from here and just inline the directoryBasedPartitioning method - you are simply trying to build the column / value map, then handle that after the visitor run.', 'comment_created': datetime.datetime(2020, 8, 4, 17, 23, 37, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465210944, 'comment_body': ""Thinking beyond the partitioning columns it is not required that the literal value will be a String.  It can be any of the comparable value types that are supported by the translator.  For the partitioning columns we would require that the type value is easily convertable to string - for example exact numeric would be allowable as well.  It's important to have the types represented correctly as there is a semantic difference between string an numeric types that comes into play once you support other comparisons.  For example with 10 > 2 as an integer comparison, but '10' < '2' as a string comparison.\r\n\r\nAlso, since the visitor is performing casts in any case, you may find it more straight-forward to do something like:\r\n\r\npublic void visit(Comparison obj) {\r\n  ColumnReference cr = (ColumnReference)obj.getLeftExpression();\r\n  Column column = cr.getMetadataObject();\r\n  Literal l = (Literal)obj.getRightExpression();\r\n  ...\r\n}\r\n\r\nThe ongoing expression logic will only be helpful if there ends up being handling that is common for very large expressions / subtrees.\r\n\r\nIf you want to consider the other comparisons and IN predicates at this point you also want to make what you are capturing pretty general - it will need more than just the column and the value to also convey the type of operation (for example less than vs. equality) and a set of values (IN ...)"", 'comment_created': datetime.datetime(2020, 8, 4, 17, 25, 14, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465225043, 'comment_body': ""Are you basing your example off of default spark partitioning?  We've also seen the convention where the directory structure contains the name and value:\r\n\r\ndir/dim1=value1/dim2=value2/*\r\n\r\nvs here we have\r\n\r\ndir/value1/value2/*\r\n\r\n Do you seen any taxonomy or template for how the partitioning scheme is capture in the hive metastore?"", 'comment_created': datetime.datetime(2020, 8, 4, 17, 49, 27, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465660360, 'comment_body': 'What I understand from this is that we might use the map even for non-partitioned column comparisons and thus there is no need for that, right?', 'comment_created': datetime.datetime(2020, 8, 5, 11, 30, 5, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 465665695, 'comment_body': ""> Thinking beyond the partitioning columns it is not required that the literal value will be a String.\r\n\r\nYes, I initially took it to be just the directory partitioning where the user can be asked to name the column as strings. But since we would also need to handle other aspects and comparison types other than equality, this would fail, we need to know the types of values too. What all types are we going to handle? Also, what datatypes would allow what kind of comparisons is also a question. For eg, I don't think a complex data type like an array would be supported. Isn't it?\r\n\r\n> The ongoing expression logic will only be helpful if there ends up being handling that is common for very large expressions / subtrees.\r\n\r\nRight! The visiting of them is not needed, I was also wondering if there's a need for this visiting even in the excel query visitor. That also seems similar and could be simplified like you mentioned. \r\n\r\n>If you want to consider the other comparisons and IN predicates at this point you also want to make what you are capturing pretty general - it will need more than just the column and the value to also convey the type of operation (for example less than vs. equality) and a set of values (IN ...)\r\n\r\nI think I should rather implement all of it together which would make the capability wholesome and things can be implemented accordingly. Otherwise, like you said they would have to be generalized or changed anyway in the future when the support is extended. What do you say?\r\n\r\n\r\n\r\n"", 'comment_created': datetime.datetime(2020, 8, 5, 11, 41, 14, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 465668016, 'comment_body': 'The spark used the ""="" i.e of the form dir/dim1=value1/dim2=value2/*,  according to https://spark.apache.org/docs/2.4.0/sql-data-sources-parquet.html.\r\n\r\nWhat I saw from a link, in hive partitioning looks like dir/value1/value2/*, see https://data-flair.training/blogs/apache-hive-partitions/ \r\n\r\nThen I checked a few pages today, one of then shows that it uses the same pattern dir/dim1=value1/dim2=value2/*, see https://www.guru99.com/hive-partitions-buckets-example.html\r\n\r\nI think this dir/dim1=value1/dim2=value2/* should be considered, what do you say?', 'comment_created': datetime.datetime(2020, 8, 5, 11, 46, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 465707170, 'comment_body': '> I think this dir/dim1=value1/dim2=value2/* should be considered, what do you say?\r\n\r\nYes it should be considered.  From what I can gather that is the dominant paradigm.', 'comment_created': datetime.datetime(2020, 8, 5, 12, 58, 7, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465714812, 'comment_body': '>  What all types are we going to handle? Also, what datatypes would allow what kind of comparisons is also a question. For eg, I don\'t think a complex data type like an array would be supported. Isn\'t it?\r\n\r\nGenerally the translator will need to support literal values that match the return values to the engine.  In this case you have string, varbinary, biginteger, long, integer, float, double, boolean - all of those are comparable types that can end up in a predicate of the form ""col = value literal"".  However partitioning columns may need additional restrictions, such as not using varbinary, float, double values - as those could have ambiguous string values.  \r\n\r\n> Otherwise, like you said they would have to be generalized or changed anyway in the future when the support is extended. What do you say?\r\n\r\nIt will be more difficult to fully implement everything at once, but you can make additional logic easier just by capturing more information, rather than less, in your visitation / query analysis.  Some things will be pretty easier to layer in, such as once you support predicates on non-partitioning columns you\'ll need to add the logic to convert those predicates into a filter.  Other things will be more difficult, such as once you support comparisons other than equality, then you can\'t simply build up a file pattern to honor the predicate - you\'d have to implement a check against the file path - which will also require updating the VirtualFile api to expose both a file name and a file path.', 'comment_created': datetime.datetime(2020, 8, 5, 13, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465715695, 'comment_body': 'Yes that is correct.  You can handle how the predicates are supposed to be interpreted after visitation and that will keep the visitor logic much simpler.', 'comment_created': datetime.datetime(2020, 8, 5, 13, 12, 12, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 466353882, 'comment_body': ""> However partitioning columns may need additional restrictions, such as not using varbinary, float, double values - as those could have ambiguous string values.\r\n\r\nSo, I'm implementing the visitor as something that builds a map on the HashMap<String(ColumnName), Literal>. So when I get the literal corresponding to a column, I would implement it using a switch case using the class name(Is there an enum for the same, I mean an API that would give us the teiid types for a corresponding literal) that would convert the respective string,  biginteger, long, integer,  boolean to strings using the toString methods and default the switch case to throw an exception for incompatible types for a directory path like the varbinary, float, and double. Thoughts?\r\n\r\n>  It will be more difficult to fully implement everything at once\r\n\r\nAlright, we'll do things one step at a time and make progress that way. \r\n\r\n> you'd have to implement a check against the file path - which will also require updating the VirtualFile api to expose both a file name and a file path.\r\n\r\nRight!!\r\n\r\n"", 'comment_created': datetime.datetime(2020, 8, 6, 11, 44, 17, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 466425012, 'comment_body': '> Thoughts?\r\n\r\nYes that is the right track.  Capture the full literal, or even the full predicate, for further work.\r\n\r\nAlso note that opening up to additional comparisons allows for thing like ""between"" scenarios - where col > \'value1\' and col < \'value2\' - which will further complicate handling.', 'comment_created': datetime.datetime(2020, 8, 6, 13, 47, 56, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 466455518, 'comment_body': '> or even the full predicate\r\n\r\nLike just store the complete comparison object, and later use it for different purposes, like here we can probably utilize it directly to build the directory path, right?\r\n\r\n> Also note that opening up to additional comparisons allows for thing like ""between"" scenarios - where col > \'value1\' and col < \'value2\' - which will further complicate handling.\r\n\r\nThis would be after the virtualfile API is capable to give the file path, right?', 'comment_created': datetime.datetime(2020, 8, 6, 14, 30, 30, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 466579194, 'comment_body': ""> Like just store the complete comparison object, and later use it for different purposes, like here we can probably utilize it directly to build the directory path, right?\r\n\r\nYes a map of columns to predicates would be the most general.\r\n\r\n> This would be after the virtualfile API is capable to give the file path, right?\r\n\r\nYes, and I'm trying to highlight that there could be more than one predicate for a given column.  That can be handled by a multi-map or similar."", 'comment_created': datetime.datetime(2020, 8, 6, 17, 40, 14, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 468123718, 'comment_body': ""I didn't handle the case of nextRowGroup != null here.  You'll need to account for that by resetting the pageRowCount and the rowIterator."", 'comment_created': datetime.datetime(2020, 8, 10, 19, 19, 27, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 468124534, 'comment_body': 'Be sure to add a test here in the non-partitioned case covering projecting a subset of columns.', 'comment_created': datetime.datetime(2020, 8, 10, 19, 21, 5, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470819514, 'comment_body': ""For now since we only have the one partitioning scheme let's default to assuming the current directory scheme.  So if there are partitioning columns specified, don't require partitioning scheme."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 12, 15, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470821658, 'comment_body': ""Given the other restrictions in place, let's just add ExecutionFactory.supportsPartialFiltering to true, then you won't have to throw this exception.  Either you can ignore the predicate, or if you know that the partitioning column is actually in the data files, then you can add it to the filter.  \r\n\r\nIf or when supportsOrCriteria is added, then supportsPartialFiltering would need to be handled differently."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 17, 28, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470823077, 'comment_body': 'This all could be collapsed further a lookup method:\r\n\r\nMethod m = FilterApi.class.getMethod(getMethodName(compison.getOperator()), Column.class, Comparable.class);\r\n...', 'comment_created': datetime.datetime(2020, 8, 14, 19, 20, 49, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470824099, 'comment_body': ""If you return FilterCompat.NOOP instead of null, you won't have to do any null checking in the calling logic."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 23, 22, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470824830, 'comment_body': 'Consider just returning the new value directly, the local filteredSchema name conflicts with the member variable of the same name.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 25, 5, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470825585, 'comment_body': 'Depending on what code quality tool you have running, you may get a warning in situations like this - where the else nesting is not needed as the if case can only complete by fully escaping.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 26, 42, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470826452, 'comment_body': ""We'll need to capture as an initial limitation that the partitioning column names cannot contain ',' as that would throw off this parsing.  It also won't tolerate whitespace of any kind."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 28, 47, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470826988, 'comment_body': 'This can be removed.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 29, 56, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470827575, 'comment_body': 'Please add a generic type or wildcard type to the constructor.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 31, 15, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470883904, 'comment_body': 'Are any of these in use?', 'comment_created': datetime.datetime(2020, 8, 14, 22, 3, 11, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 471308487, 'comment_body': ""Only TEIID23000. I haven't got the complete usage of this yet. It'd be great to know"", 'comment_created': datetime.datetime(2020, 8, 17, 8, 2, 24, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 471308853, 'comment_body': 'How do we do this?', 'comment_created': datetime.datetime(2020, 8, 17, 8, 3, 13, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 471379757, 'comment_body': 'How about deleting only those elements in the map which have equality comparison and leave others for the filtering? This shall work if the partitioned columns are also in the file.', 'comment_created': datetime.datetime(2020, 8, 17, 10, 14, 41, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 471493087, 'comment_body': '> This shall work if the partitioned columns are also in the file.\r\n\r\nCan we confirm if this is generally the case?\r\n\r\nIf so, then yes you can absolutely just let them be filters instead of part of the path.', 'comment_created': datetime.datetime(2020, 8, 17, 13, 51, 41, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 471495018, 'comment_body': ""Capture initial limitations / exceptions on the jira so that it's easier to create the documentation.  Especially without a metadata importer we should capture:\r\n\r\n- expectations for the partitioning property format\r\n- type expectations for partitioning columns\r\n- supported sources - it looks like path based partitioning will not yet work against ftp\r\n- supported types / type mapping"", 'comment_created': datetime.datetime(2020, 8, 17, 13, 54, 42, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 478347170, 'comment_body': '@shawkins this test is failing despite the correct rowGroupFilter, please have a look! It is not returning any row. ', 'comment_created': datetime.datetime(2020, 8, 27, 11, 30, 25, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 478388491, 'comment_body': 'This needs refined a bit more:\r\n\r\npath.append(""/"").append(s).append(""=""); \r\nString value = ""*"";\r\nComparison predicate = predicates.remove(s);\r\nif (predicate != null) {\r\n   ...\r\n} \r\npath.append(value);\r\n\r\nAlso if partial filters is ever turned off, we\'ll need to eventually add escape handling to the path syntax just in case a string value contains *.', 'comment_created': datetime.datetime(2020, 8, 27, 12, 42, 19, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 478389970, 'comment_body': 'Please use generic types when possible.  For example instead of just Iterator, use Iterator<Entry<String, Comparison>> - the ide should have an option to infer generic types as a formatting/cleanup task.', 'comment_created': datetime.datetime(2020, 8, 27, 12, 44, 47, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479181339, 'comment_body': 'Do you mean for this to always be a constant of 1?', 'comment_created': datetime.datetime(2020, 8, 28, 11, 44, 39, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479202306, 'comment_body': 'Yes, this is only to check if the column is a partitioned one or not! I could have used other DS, but this seemed best optimal to me!', 'comment_created': datetime.datetime(2020, 8, 28, 12, 3, 7, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 479644787, 'comment_body': ""It's usually best to just combine contains and remove since remove returns the value."", 'comment_created': datetime.datetime(2020, 8, 29, 12, 28, 45, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479645206, 'comment_body': ""A map with a constant value is effectively the same as a set.  You can change the type of partitionedColumnsHm to a HashSet or a LinkedHashSet if you want to preserve the order.\r\n\r\nAlso since it's not possible for partitionedColumnsHm to be null you can avoid null checks against it."", 'comment_created': datetime.datetime(2020, 8, 29, 12, 33, 17, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479645245, 'comment_body': 'This needs indented a little more.', 'comment_created': datetime.datetime(2020, 8, 29, 12, 33, 57, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479645516, 'comment_body': 'Capitalized NotEq does not appear to be correct - can you add a not equals test?', 'comment_created': datetime.datetime(2020, 8, 29, 12, 36, 49, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479647343, 'comment_body': ""Now that ordered predicates are supported the strategy of mapping to a single Comparison won't work.  For example add a test that has a predicate like WHERE id > 2 and id < 4.  You don't need to check for the case of an equality predicate and something else - the engine will always reduce down to a single equality predicate when possible."", 'comment_created': datetime.datetime(2020, 8, 29, 12, 57, 54, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479657057, 'comment_body': ""> Also since it's not possible for partitionedColumnsHm to be null you can avoid null checks against it.\r\n\r\nI think it's possible when there's no partitioning. "", 'comment_created': datetime.datetime(2020, 8, 29, 14, 52, 50, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 479657895, 'comment_body': ""> Now that ordered predicates are supported the strategy of mapping to a single Comparison won't work\r\n\r\nYeah, what do we need to do then, a multimap?\r\n\r\n>You don't need to check for the case of an equality predicate and something else - the engine will always reduce down to a single equality predicate when possible.\r\n\r\nSorry. but I didn't get this. where am I checking for an equality predicate? \r\n"", 'comment_created': datetime.datetime(2020, 8, 29, 15, 2, 16, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 479677681, 'comment_body': ""It's currently initialized as an empty map and never set to null."", 'comment_created': datetime.datetime(2020, 8, 29, 18, 38, 36, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479677917, 'comment_body': ""> Yeah, what do we need to do then, a multimap?\r\n\r\nYes a multi-map will work.\r\n\r\n> Sorry. but I didn't get this. where am I checking for an equality predicate?\r\n\r\nI just mean you don't have to do any additional special checks at the translator level or try to logically combine predicates."", 'comment_created': datetime.datetime(2020, 8, 29, 18, 41, 9, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479980815, 'comment_body': 'we can just check for a single predicate here instead of a for loop, just did that to make it look cleaner. ', 'comment_created': datetime.datetime(2020, 8, 31, 8, 36, 26, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}]","[{'commit_sha': 'a6a382545597abc78cd376cb70224da513365881', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '819395dc1d780134871d8327843182cf83ebad75', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6250ac65439140f6c6d1904b4a6c4dff2fcf6b8b', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b0db76bcc4a3ac80de479d635649438258f45d16', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '76b2ba43dd8bcd6d4cdc065cfb4a9b9f0fb69e0f', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dc5da7eb63f1f5364c1f84a4aad399fddadc9420', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2b7e6175174c465c4be137b2a13afa2ddc4ea451', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7a889639327251798e197c4371961c75a5a550e5', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a26ee433ec62724dd0b654568c1df5e645c32bc6', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b0acc4f1da0a2e3c6b1d08a897dc46edd7897c1e', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '51a30e2487052f5f1cb87bcdf47191849a91798e', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5781318decb29dd94cc2bc33d44db89d901c5fd6', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3010c12b32ca7d553fbd6e36c83a3ebd492459f4', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '853529f62f94a5f53a751727b5c294394957766c', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f0596c4485063e8a487cee1fa53a23b32d8eca46', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b85c1895f476688e1df81cff507e8b29c35b2bf', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': '626439c5b2bb63fe2e1f237d3d417edf19519d92', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c47903d4a2e271a38c581003c8841c4281c3c048', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '862d60ba54b0bc9f2a08fa615c209e5e2f4d06ef', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf9d6908f7579751694ef48136138061e92e8f43', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a63541e98d3c72f34cd5025b8d4e3904dd93782', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0091e2812f3a848b57e5b673fb5c4c8b4d7e70df', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5
450270895,TEIID-4594 Parquet Translator,"This is the initial implementation of the execution logic for the parquet files. I think there should be a good amount of refinement required which can be done during testing as the java API docs for parquet don't explain anything, thus a little of the code is written with intuition. Kindly check!  ",True,1310,https://api.github.com/repos/teiid/teiid/pulls/1310,https://github.com/teiid/teiid/pull/1310,closed,1087,0,22,22,24,79,0,0,[],2020-07-16 15:07:54+00:00,2020-08-31 20:05:23+00:00,3992249.0,"46 days, 4:57:29","[{'comment_id': 455895595, 'comment_body': '.equals not != here', 'comment_created': datetime.datetime(2020, 7, 16, 15, 58, 17, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455898191, 'comment_body': 'what is need for the while?', 'comment_created': datetime.datetime(2020, 7, 16, 16, 2, 13, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455992294, 'comment_body': 'I believe logic needs to match to what is being asked of projected columns, but below looks like as `select *`, i.e. projected columns can be just a single column or two or may be all, your output should match to that not all in parquet record ', 'comment_created': datetime.datetime(2020, 7, 16, 18, 35, 24, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455994173, 'comment_body': 'I do think you supporting any of these below ""supports"" capabilities, these can be removed, you do not support `where` clause or `limit/offset`  or `in` which is what below are saying. Maybe there a way to extend current one to do that in that case keep it, next step could be that.', 'comment_created': datetime.datetime(2020, 7, 16, 18, 38, 49, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 455995368, 'comment_body': 'Are we supporting updates and deletes with Paraquet? typically with file-based we do not support these. In that case this class goes away.', 'comment_created': datetime.datetime(2020, 7, 16, 18, 40, 57, tzinfo=datetime.timezone.utc), 'commenter': 'rareddy', 'type': 'User'}, {'comment_id': 456278324, 'comment_body': 'Got it!', 'comment_created': datetime.datetime(2020, 7, 17, 7, 50, 32, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456278792, 'comment_body': ""There's none. I took the inspiration from the excel one, but there the row was getting checked with the allow method and looped until a legit row was obtained. There's no need for it here. I got it wrong. Thanks for pointing out."", 'comment_created': datetime.datetime(2020, 7, 17, 7, 51, 22, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456279168, 'comment_body': ""Yeah, it clicked me later, what is meant by the projected columns. I'll correct it."", 'comment_created': datetime.datetime(2020, 7, 17, 7, 52, 4, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456279822, 'comment_body': ""There's an ExcelUpdateExecution in excel. Thus I just put a class in there. I don't know yet if these are to be supported in Parquet. You guys can tell better if it should be."", 'comment_created': datetime.datetime(2020, 7, 17, 7, 53, 14, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456280501, 'comment_body': 'Yes, I just put them as it is from excel to later figure out if we support these. ', 'comment_created': datetime.datetime(2020, 7, 17, 7, 54, 40, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 456410152, 'comment_body': 'add a break even in the last case as well', 'comment_created': datetime.datetime(2020, 7, 17, 12, 28, 36, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 456858588, 'comment_body': 'done!', 'comment_created': datetime.datetime(2020, 7, 19, 4, 41, 6, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 460864880, 'comment_body': 'Remove this method and the associated class for now.  The engine will throw an appropriate exception about updates not being supported.', 'comment_created': datetime.datetime(2020, 7, 27, 12, 48, 23, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460867212, 'comment_body': 'Where is the is null pointer possible?', 'comment_created': datetime.datetime(2020, 7, 27, 12, 52, 36, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460869062, 'comment_body': ""There's an additional case of valueCount == 0 to handle - does that imply null for non-repeated fields, or is only possible with repeated fields?"", 'comment_created': datetime.datetime(2020, 7, 27, 12, 55, 59, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460870259, 'comment_body': 'For the engine to properly handle the result as an array it will need to be an instance of an array, not ArrayList.', 'comment_created': datetime.datetime(2020, 7, 27, 12, 58, 8, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460871394, 'comment_body': 'Go ahead and remove the supports methods for now.', 'comment_created': datetime.datetime(2020, 7, 27, 13, 0, 2, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460872933, 'comment_body': 'This is not yet wired in.  The projected columns should be determined from visiting the DerivedColumns.  You can either determine a projection index like Excel or just track the Columns that are being asked for and pass that to the execution to do further analysis.', 'comment_created': datetime.datetime(2020, 7, 27, 13, 2, 35, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 460882678, 'comment_body': 'Once you have the expected columns, you can use that to read with a filtered schema.  That is you will construct a new MesssageType here that contains only fields that have been requested.  See the ColumnIOFactory.getColumnIO that take a requested schema argument.  I would guess that you would pass the filtered schema to the GroupRecordConverter as well.', 'comment_created': datetime.datetime(2020, 7, 27, 13, 18, 25, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 461080494, 'comment_body': 'Removed!', 'comment_created': datetime.datetime(2020, 7, 27, 18, 18, 23, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461081027, 'comment_body': 'fieldType.getLogicalTypeAnnotation() gives null for non logical types like int64 and .toString throws the exception. ', 'comment_created': datetime.datetime(2020, 7, 27, 18, 19, 27, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461082514, 'comment_body': ""Yes,  I didn't think of it to be one, but it does need to be handled. I can't find any doc, so played a little. I observed that the valuecount comes out to be null for non-repeated field. In case of repeated fields, I think it is only possible with the non-annotated types. "", 'comment_created': datetime.datetime(2020, 7, 27, 18, 22, 1, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461082916, 'comment_body': ""Do you mean array of objects or what? I don't quite follow here. "", 'comment_created': datetime.datetime(2020, 7, 27, 18, 22, 43, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461083393, 'comment_body': 'I have removed the support methods for now. I would do the projectedColumns part at the earliest. ', 'comment_created': datetime.datetime(2020, 7, 27, 18, 23, 32, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461083594, 'comment_body': ""I'll check this out! Thanks!"", 'comment_created': datetime.datetime(2020, 7, 27, 18, 23, 54, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 461264824, 'comment_body': 'An Object array is fine.  The engine will convert to the internal representation from there.', 'comment_created': datetime.datetime(2020, 7, 28, 1, 33, 22, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462454463, 'comment_body': ""Based upon your other changes this loop can be removed.  You just need an if valueCount is 0 and an else case.  You can add an assertion if you want that the valueCount can't be greater than 1."", 'comment_created': datetime.datetime(2020, 7, 29, 17, 9, 4, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462455032, 'comment_body': 'It looks like there is an enum for FIXED_LEN_BYTE_ARRAY as well - does that need to be handled?', 'comment_created': datetime.datetime(2020, 7, 29, 17, 9, 57, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462456685, 'comment_body': ""Since the schema is keyed by name as well it is better to use the column name - column.getSourceName() - and use that filter the schema.  See MessageType.getFieldIndex(name).  That way there's no need for a new extension property on a column."", 'comment_created': datetime.datetime(2020, 7, 29, 17, 12, 39, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462898494, 'comment_body': 'I was thinking to remove this as well. ', 'comment_created': datetime.datetime(2020, 7, 30, 10, 19, 38, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 462899073, 'comment_body': 'Yes, it needs to be. Can we also return this as binary? The only difference between binary and FIXED_LEN_BYTE_ARRAY is that the latter is of fixed length and the former of variable. Or non-string binary and FIXED_LEN_BYTE_ARRAY both are to be returned as byte arrays? ', 'comment_created': datetime.datetime(2020, 7, 30, 10, 20, 53, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 462916838, 'comment_body': ""Yes, this looks better. I've implemented this. Thanks!"", 'comment_created': datetime.datetime(2020, 7, 30, 10, 57, 42, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 462971803, 'comment_body': 'It would be best to have a null check rather than to catch the NPE as that may mask other logic errors.', 'comment_created': datetime.datetime(2020, 7, 30, 12, 49, 52, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 462972433, 'comment_body': 'You can return both as byte arrays.  We only support a varbinary type and not a fixed binary type.', 'comment_created': datetime.datetime(2020, 7, 30, 12, 51, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465209969, 'comment_body': 'you can remove this consideration from here and just inline the directoryBasedPartitioning method - you are simply trying to build the column / value map, then handle that after the visitor run.', 'comment_created': datetime.datetime(2020, 8, 4, 17, 23, 37, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465210944, 'comment_body': ""Thinking beyond the partitioning columns it is not required that the literal value will be a String.  It can be any of the comparable value types that are supported by the translator.  For the partitioning columns we would require that the type value is easily convertable to string - for example exact numeric would be allowable as well.  It's important to have the types represented correctly as there is a semantic difference between string an numeric types that comes into play once you support other comparisons.  For example with 10 > 2 as an integer comparison, but '10' < '2' as a string comparison.\r\n\r\nAlso, since the visitor is performing casts in any case, you may find it more straight-forward to do something like:\r\n\r\npublic void visit(Comparison obj) {\r\n  ColumnReference cr = (ColumnReference)obj.getLeftExpression();\r\n  Column column = cr.getMetadataObject();\r\n  Literal l = (Literal)obj.getRightExpression();\r\n  ...\r\n}\r\n\r\nThe ongoing expression logic will only be helpful if there ends up being handling that is common for very large expressions / subtrees.\r\n\r\nIf you want to consider the other comparisons and IN predicates at this point you also want to make what you are capturing pretty general - it will need more than just the column and the value to also convey the type of operation (for example less than vs. equality) and a set of values (IN ...)"", 'comment_created': datetime.datetime(2020, 8, 4, 17, 25, 14, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465225043, 'comment_body': ""Are you basing your example off of default spark partitioning?  We've also seen the convention where the directory structure contains the name and value:\r\n\r\ndir/dim1=value1/dim2=value2/*\r\n\r\nvs here we have\r\n\r\ndir/value1/value2/*\r\n\r\n Do you seen any taxonomy or template for how the partitioning scheme is capture in the hive metastore?"", 'comment_created': datetime.datetime(2020, 8, 4, 17, 49, 27, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465660360, 'comment_body': 'What I understand from this is that we might use the map even for non-partitioned column comparisons and thus there is no need for that, right?', 'comment_created': datetime.datetime(2020, 8, 5, 11, 30, 5, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 465665695, 'comment_body': ""> Thinking beyond the partitioning columns it is not required that the literal value will be a String.\r\n\r\nYes, I initially took it to be just the directory partitioning where the user can be asked to name the column as strings. But since we would also need to handle other aspects and comparison types other than equality, this would fail, we need to know the types of values too. What all types are we going to handle? Also, what datatypes would allow what kind of comparisons is also a question. For eg, I don't think a complex data type like an array would be supported. Isn't it?\r\n\r\n> The ongoing expression logic will only be helpful if there ends up being handling that is common for very large expressions / subtrees.\r\n\r\nRight! The visiting of them is not needed, I was also wondering if there's a need for this visiting even in the excel query visitor. That also seems similar and could be simplified like you mentioned. \r\n\r\n>If you want to consider the other comparisons and IN predicates at this point you also want to make what you are capturing pretty general - it will need more than just the column and the value to also convey the type of operation (for example less than vs. equality) and a set of values (IN ...)\r\n\r\nI think I should rather implement all of it together which would make the capability wholesome and things can be implemented accordingly. Otherwise, like you said they would have to be generalized or changed anyway in the future when the support is extended. What do you say?\r\n\r\n\r\n\r\n"", 'comment_created': datetime.datetime(2020, 8, 5, 11, 41, 14, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 465668016, 'comment_body': 'The spark used the ""="" i.e of the form dir/dim1=value1/dim2=value2/*,  according to https://spark.apache.org/docs/2.4.0/sql-data-sources-parquet.html.\r\n\r\nWhat I saw from a link, in hive partitioning looks like dir/value1/value2/*, see https://data-flair.training/blogs/apache-hive-partitions/ \r\n\r\nThen I checked a few pages today, one of then shows that it uses the same pattern dir/dim1=value1/dim2=value2/*, see https://www.guru99.com/hive-partitions-buckets-example.html\r\n\r\nI think this dir/dim1=value1/dim2=value2/* should be considered, what do you say?', 'comment_created': datetime.datetime(2020, 8, 5, 11, 46, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 465707170, 'comment_body': '> I think this dir/dim1=value1/dim2=value2/* should be considered, what do you say?\r\n\r\nYes it should be considered.  From what I can gather that is the dominant paradigm.', 'comment_created': datetime.datetime(2020, 8, 5, 12, 58, 7, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465714812, 'comment_body': '>  What all types are we going to handle? Also, what datatypes would allow what kind of comparisons is also a question. For eg, I don\'t think a complex data type like an array would be supported. Isn\'t it?\r\n\r\nGenerally the translator will need to support literal values that match the return values to the engine.  In this case you have string, varbinary, biginteger, long, integer, float, double, boolean - all of those are comparable types that can end up in a predicate of the form ""col = value literal"".  However partitioning columns may need additional restrictions, such as not using varbinary, float, double values - as those could have ambiguous string values.  \r\n\r\n> Otherwise, like you said they would have to be generalized or changed anyway in the future when the support is extended. What do you say?\r\n\r\nIt will be more difficult to fully implement everything at once, but you can make additional logic easier just by capturing more information, rather than less, in your visitation / query analysis.  Some things will be pretty easier to layer in, such as once you support predicates on non-partitioning columns you\'ll need to add the logic to convert those predicates into a filter.  Other things will be more difficult, such as once you support comparisons other than equality, then you can\'t simply build up a file pattern to honor the predicate - you\'d have to implement a check against the file path - which will also require updating the VirtualFile api to expose both a file name and a file path.', 'comment_created': datetime.datetime(2020, 8, 5, 13, 10, 43, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 465715695, 'comment_body': 'Yes that is correct.  You can handle how the predicates are supposed to be interpreted after visitation and that will keep the visitor logic much simpler.', 'comment_created': datetime.datetime(2020, 8, 5, 13, 12, 12, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 466353882, 'comment_body': ""> However partitioning columns may need additional restrictions, such as not using varbinary, float, double values - as those could have ambiguous string values.\r\n\r\nSo, I'm implementing the visitor as something that builds a map on the HashMap<String(ColumnName), Literal>. So when I get the literal corresponding to a column, I would implement it using a switch case using the class name(Is there an enum for the same, I mean an API that would give us the teiid types for a corresponding literal) that would convert the respective string,  biginteger, long, integer,  boolean to strings using the toString methods and default the switch case to throw an exception for incompatible types for a directory path like the varbinary, float, and double. Thoughts?\r\n\r\n>  It will be more difficult to fully implement everything at once\r\n\r\nAlright, we'll do things one step at a time and make progress that way. \r\n\r\n> you'd have to implement a check against the file path - which will also require updating the VirtualFile api to expose both a file name and a file path.\r\n\r\nRight!!\r\n\r\n"", 'comment_created': datetime.datetime(2020, 8, 6, 11, 44, 17, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 466425012, 'comment_body': '> Thoughts?\r\n\r\nYes that is the right track.  Capture the full literal, or even the full predicate, for further work.\r\n\r\nAlso note that opening up to additional comparisons allows for thing like ""between"" scenarios - where col > \'value1\' and col < \'value2\' - which will further complicate handling.', 'comment_created': datetime.datetime(2020, 8, 6, 13, 47, 56, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 466455518, 'comment_body': '> or even the full predicate\r\n\r\nLike just store the complete comparison object, and later use it for different purposes, like here we can probably utilize it directly to build the directory path, right?\r\n\r\n> Also note that opening up to additional comparisons allows for thing like ""between"" scenarios - where col > \'value1\' and col < \'value2\' - which will further complicate handling.\r\n\r\nThis would be after the virtualfile API is capable to give the file path, right?', 'comment_created': datetime.datetime(2020, 8, 6, 14, 30, 30, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 466579194, 'comment_body': ""> Like just store the complete comparison object, and later use it for different purposes, like here we can probably utilize it directly to build the directory path, right?\r\n\r\nYes a map of columns to predicates would be the most general.\r\n\r\n> This would be after the virtualfile API is capable to give the file path, right?\r\n\r\nYes, and I'm trying to highlight that there could be more than one predicate for a given column.  That can be handled by a multi-map or similar."", 'comment_created': datetime.datetime(2020, 8, 6, 17, 40, 14, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 468123718, 'comment_body': ""I didn't handle the case of nextRowGroup != null here.  You'll need to account for that by resetting the pageRowCount and the rowIterator."", 'comment_created': datetime.datetime(2020, 8, 10, 19, 19, 27, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 468124534, 'comment_body': 'Be sure to add a test here in the non-partitioned case covering projecting a subset of columns.', 'comment_created': datetime.datetime(2020, 8, 10, 19, 21, 5, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470819514, 'comment_body': ""For now since we only have the one partitioning scheme let's default to assuming the current directory scheme.  So if there are partitioning columns specified, don't require partitioning scheme."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 12, 15, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470821658, 'comment_body': ""Given the other restrictions in place, let's just add ExecutionFactory.supportsPartialFiltering to true, then you won't have to throw this exception.  Either you can ignore the predicate, or if you know that the partitioning column is actually in the data files, then you can add it to the filter.  \r\n\r\nIf or when supportsOrCriteria is added, then supportsPartialFiltering would need to be handled differently."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 17, 28, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470823077, 'comment_body': 'This all could be collapsed further a lookup method:\r\n\r\nMethod m = FilterApi.class.getMethod(getMethodName(compison.getOperator()), Column.class, Comparable.class);\r\n...', 'comment_created': datetime.datetime(2020, 8, 14, 19, 20, 49, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470824099, 'comment_body': ""If you return FilterCompat.NOOP instead of null, you won't have to do any null checking in the calling logic."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 23, 22, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470824830, 'comment_body': 'Consider just returning the new value directly, the local filteredSchema name conflicts with the member variable of the same name.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 25, 5, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470825585, 'comment_body': 'Depending on what code quality tool you have running, you may get a warning in situations like this - where the else nesting is not needed as the if case can only complete by fully escaping.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 26, 42, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470826452, 'comment_body': ""We'll need to capture as an initial limitation that the partitioning column names cannot contain ',' as that would throw off this parsing.  It also won't tolerate whitespace of any kind."", 'comment_created': datetime.datetime(2020, 8, 14, 19, 28, 47, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470826988, 'comment_body': 'This can be removed.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 29, 56, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470827575, 'comment_body': 'Please add a generic type or wildcard type to the constructor.', 'comment_created': datetime.datetime(2020, 8, 14, 19, 31, 15, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 470883904, 'comment_body': 'Are any of these in use?', 'comment_created': datetime.datetime(2020, 8, 14, 22, 3, 11, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 471308487, 'comment_body': ""Only TEIID23000. I haven't got the complete usage of this yet. It'd be great to know"", 'comment_created': datetime.datetime(2020, 8, 17, 8, 2, 24, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 471308853, 'comment_body': 'How do we do this?', 'comment_created': datetime.datetime(2020, 8, 17, 8, 3, 13, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 471379757, 'comment_body': 'How about deleting only those elements in the map which have equality comparison and leave others for the filtering? This shall work if the partitioned columns are also in the file.', 'comment_created': datetime.datetime(2020, 8, 17, 10, 14, 41, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 471493087, 'comment_body': '> This shall work if the partitioned columns are also in the file.\r\n\r\nCan we confirm if this is generally the case?\r\n\r\nIf so, then yes you can absolutely just let them be filters instead of part of the path.', 'comment_created': datetime.datetime(2020, 8, 17, 13, 51, 41, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 471495018, 'comment_body': ""Capture initial limitations / exceptions on the jira so that it's easier to create the documentation.  Especially without a metadata importer we should capture:\r\n\r\n- expectations for the partitioning property format\r\n- type expectations for partitioning columns\r\n- supported sources - it looks like path based partitioning will not yet work against ftp\r\n- supported types / type mapping"", 'comment_created': datetime.datetime(2020, 8, 17, 13, 54, 42, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 478347170, 'comment_body': '@shawkins this test is failing despite the correct rowGroupFilter, please have a look! It is not returning any row. ', 'comment_created': datetime.datetime(2020, 8, 27, 11, 30, 25, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 478388491, 'comment_body': 'This needs refined a bit more:\r\n\r\npath.append(""/"").append(s).append(""=""); \r\nString value = ""*"";\r\nComparison predicate = predicates.remove(s);\r\nif (predicate != null) {\r\n   ...\r\n} \r\npath.append(value);\r\n\r\nAlso if partial filters is ever turned off, we\'ll need to eventually add escape handling to the path syntax just in case a string value contains *.', 'comment_created': datetime.datetime(2020, 8, 27, 12, 42, 19, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 478389970, 'comment_body': 'Please use generic types when possible.  For example instead of just Iterator, use Iterator<Entry<String, Comparison>> - the ide should have an option to infer generic types as a formatting/cleanup task.', 'comment_created': datetime.datetime(2020, 8, 27, 12, 44, 47, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479181339, 'comment_body': 'Do you mean for this to always be a constant of 1?', 'comment_created': datetime.datetime(2020, 8, 28, 11, 44, 39, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479202306, 'comment_body': 'Yes, this is only to check if the column is a partitioned one or not! I could have used other DS, but this seemed best optimal to me!', 'comment_created': datetime.datetime(2020, 8, 28, 12, 3, 7, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 479644787, 'comment_body': ""It's usually best to just combine contains and remove since remove returns the value."", 'comment_created': datetime.datetime(2020, 8, 29, 12, 28, 45, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479645206, 'comment_body': ""A map with a constant value is effectively the same as a set.  You can change the type of partitionedColumnsHm to a HashSet or a LinkedHashSet if you want to preserve the order.\r\n\r\nAlso since it's not possible for partitionedColumnsHm to be null you can avoid null checks against it."", 'comment_created': datetime.datetime(2020, 8, 29, 12, 33, 17, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479645245, 'comment_body': 'This needs indented a little more.', 'comment_created': datetime.datetime(2020, 8, 29, 12, 33, 57, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479645516, 'comment_body': 'Capitalized NotEq does not appear to be correct - can you add a not equals test?', 'comment_created': datetime.datetime(2020, 8, 29, 12, 36, 49, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479647343, 'comment_body': ""Now that ordered predicates are supported the strategy of mapping to a single Comparison won't work.  For example add a test that has a predicate like WHERE id > 2 and id < 4.  You don't need to check for the case of an equality predicate and something else - the engine will always reduce down to a single equality predicate when possible."", 'comment_created': datetime.datetime(2020, 8, 29, 12, 57, 54, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479657057, 'comment_body': ""> Also since it's not possible for partitionedColumnsHm to be null you can avoid null checks against it.\r\n\r\nI think it's possible when there's no partitioning. "", 'comment_created': datetime.datetime(2020, 8, 29, 14, 52, 50, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 479657895, 'comment_body': ""> Now that ordered predicates are supported the strategy of mapping to a single Comparison won't work\r\n\r\nYeah, what do we need to do then, a multimap?\r\n\r\n>You don't need to check for the case of an equality predicate and something else - the engine will always reduce down to a single equality predicate when possible.\r\n\r\nSorry. but I didn't get this. where am I checking for an equality predicate? \r\n"", 'comment_created': datetime.datetime(2020, 8, 29, 15, 2, 16, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}, {'comment_id': 479677681, 'comment_body': ""It's currently initialized as an empty map and never set to null."", 'comment_created': datetime.datetime(2020, 8, 29, 18, 38, 36, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479677917, 'comment_body': ""> Yeah, what do we need to do then, a multimap?\r\n\r\nYes a multi-map will work.\r\n\r\n> Sorry. but I didn't get this. where am I checking for an equality predicate?\r\n\r\nI just mean you don't have to do any additional special checks at the translator level or try to logically combine predicates."", 'comment_created': datetime.datetime(2020, 8, 29, 18, 41, 9, tzinfo=datetime.timezone.utc), 'commenter': 'shawkins', 'type': 'User'}, {'comment_id': 479980815, 'comment_body': 'we can just check for a single predicate here instead of a for loop, just did that to make it look cleaner. ', 'comment_created': datetime.datetime(2020, 8, 31, 8, 36, 26, tzinfo=datetime.timezone.utc), 'commenter': 'aditya300899', 'type': 'User'}]","[{'commit_sha': 'a6a382545597abc78cd376cb70224da513365881', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '819395dc1d780134871d8327843182cf83ebad75', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6250ac65439140f6c6d1904b4a6c4dff2fcf6b8b', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b0db76bcc4a3ac80de479d635649438258f45d16', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '76b2ba43dd8bcd6d4cdc065cfb4a9b9f0fb69e0f', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dc5da7eb63f1f5364c1f84a4aad399fddadc9420', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2b7e6175174c465c4be137b2a13afa2ddc4ea451', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7a889639327251798e197c4371961c75a5a550e5', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a26ee433ec62724dd0b654568c1df5e645c32bc6', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b0acc4f1da0a2e3c6b1d08a897dc46edd7897c1e', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '51a30e2487052f5f1cb87bcdf47191849a91798e', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5781318decb29dd94cc2bc33d44db89d901c5fd6', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3010c12b32ca7d553fbd6e36c83a3ebd492459f4', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '853529f62f94a5f53a751727b5c294394957766c', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f0596c4485063e8a487cee1fa53a23b32d8eca46', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b85c1895f476688e1df81cff507e8b29c35b2bf', 'committer_username': 'shawkins', 'committer_name': 'Steven Hawkins', 'committer_email': None, 'commit_date': datetime.datetime(2012, 10, 3, 0, 38, 1, tzinfo=datetime.timezone.utc)}, {'commit_sha': '626439c5b2bb63fe2e1f237d3d417edf19519d92', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c47903d4a2e271a38c581003c8841c4281c3c048', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '862d60ba54b0bc9f2a08fa615c209e5e2f4d06ef', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf9d6908f7579751694ef48136138061e92e8f43', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a63541e98d3c72f34cd5025b8d4e3904dd93782', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0091e2812f3a848b57e5b673fb5c4c8b4d7e70df', 'committer_username': 'aditya300899', 'committer_name': 'Aditya Manglam Sharma', 'committer_email': 'aditya300899@gmail.com', 'commit_date': datetime.datetime(2018, 3, 31, 17, 14, 5, tzinfo=datetime.timezone.utc)}]",Aditya Manglam Sharma,37961206,aditya300899@gmail.com,User,,26,,10,5

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
91066791,teiid-spring-boot,teiid/teiid-spring-boot,Java,63,45,15,16,424,16,21,9,"[{'id': 443932506, 'number': 276, 'closed': datetime.datetime(2020, 7, 7, 19, 1, 29, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 3, 8, 42, 2, tzinfo=datetime.timezone.utc), 'time_taken': 382767.0, 'time_delta': '4 days, 10:19:27', 'additions': 420, 'deletions': 1, 'state': 'closed'}, {'id': 442674247, 'number': 269, 'closed': datetime.datetime(2020, 7, 8, 13, 29, 36, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 1, 12, 43, 7, tzinfo=datetime.timezone.utc), 'time_taken': 607589.0, 'time_delta': '7 days, 0:46:29', 'additions': 242, 'deletions': 83, 'state': 'closed'}, {'id': 440057699, 'number': 267, 'closed': datetime.datetime(2020, 7, 1, 17, 46, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 25, 14, 27, 4, tzinfo=datetime.timezone.utc), 'time_taken': 530395.0, 'time_delta': '6 days, 3:19:55', 'additions': 613, 'deletions': 70, 'state': 'closed'}, {'id': 439176684, 'number': 265, 'closed': datetime.datetime(2020, 6, 25, 20, 57, 45, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 24, 12, 31, 16, tzinfo=datetime.timezone.utc), 'time_taken': 116789.0, 'time_delta': '1 day, 8:26:29', 'additions': 244, 'deletions': 0, 'state': 'closed'}, {'id': 438621948, 'number': 263, 'closed': datetime.datetime(2020, 6, 25, 13, 9, 9, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 23, 14, 46, 48, tzinfo=datetime.timezone.utc), 'time_taken': 166941.0, 'time_delta': '1 day, 22:22:21', 'additions': 480, 'deletions': 0, 'state': 'closed'}, {'id': 429210523, 'number': 242, 'closed': datetime.datetime(2020, 6, 17, 1, 26, 31, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 6, 13, 44, tzinfo=datetime.timezone.utc), 'time_taken': 906151.0, 'time_delta': '10 days, 11:42:31', 'additions': 553, 'deletions': 9, 'state': 'closed'}, {'id': 426608640, 'number': 239, 'closed': datetime.datetime(2020, 6, 2, 19, 6, 33, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 2, 14, 4, 22, tzinfo=datetime.timezone.utc), 'time_taken': 18131.0, 'time_delta': '5:02:11', 'additions': 161, 'deletions': 0, 'state': 'closed'}, {'id': 421237539, 'number': 228, 'closed': datetime.datetime(2020, 5, 30, 22, 59, 17, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 21, 9, 2, 8, tzinfo=datetime.timezone.utc), 'time_taken': 827829.0, 'time_delta': '9 days, 13:57:09', 'additions': 196, 'deletions': 0, 'state': 'closed'}, {'id': 415039822, 'number': 224, 'closed': datetime.datetime(2020, 5, 14, 15, 35, 6, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 8, 4, 33, 56, tzinfo=datetime.timezone.utc), 'time_taken': 558070.0, 'time_delta': '6 days, 11:01:10', 'additions': 215, 'deletions': 1, 'state': 'closed'}, {'id': 410071956, 'number': 217, 'closed': datetime.datetime(2020, 4, 28, 23, 11, 50, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 28, 12, 0, 25, tzinfo=datetime.timezone.utc), 'time_taken': 40285.0, 'time_delta': '11:11:25', 'additions': 1, 'deletions': 1, 'state': 'closed'}]"
6092163,teiid,teiid/teiid,Java,227,300,42,52,8360,38,91,29,"[{'id': 467340491, 'number': 1322, 'closed': datetime.datetime(2020, 8, 17, 5, 58, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 13, 12, 3, 6, tzinfo=datetime.timezone.utc), 'time_taken': 323704.0, 'time_delta': '3 days, 17:55:04', 'additions': 25, 'deletions': 25, 'state': 'closed'}, {'id': 450270895, 'number': 1310, 'closed': datetime.datetime(2020, 8, 31, 20, 5, 23, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 16, 15, 7, 54, tzinfo=datetime.timezone.utc), 'time_taken': 3992249.0, 'time_delta': '46 days, 4:57:29', 'additions': 1087, 'deletions': 0, 'state': 'closed'}, {'id': 410748612, 'number': 1280, 'closed': datetime.datetime(2020, 5, 4, 16, 35, 12, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 29, 14, 27, 27, tzinfo=datetime.timezone.utc), 'time_taken': 439665.0, 'time_delta': '5 days, 2:07:45', 'additions': 176, 'deletions': 100, 'state': 'closed'}, {'id': 402672018, 'number': 1272, 'closed': datetime.datetime(2020, 5, 1, 13, 16, 27, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 13, 14, 33, 53, tzinfo=datetime.timezone.utc), 'time_taken': 1550554.0, 'time_delta': '17 days, 22:42:34', 'additions': 241, 'deletions': 97, 'state': 'closed'}]"

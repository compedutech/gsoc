pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
690016306,Integrating xtractmime into Scrapy,"As per the discussion with @elacuesta and @Gallaecio. This PR will integrate [xtractmime](https://github.com/scrapy/xtractmime) library into Scrapy for MIME sniffing

Fixes #2900, fixes #4240.

# Changes

Behavior:

- An empty body with no indication of a type through headers or file extensions now maps to `TextResponse` instead of to `Response`.
- A response with `Content-Encoding` is now always `Response` (until uncompressed, when the header is removed and the response class mapping re-evaluated). `Content-Disposition`, URL, and body can no longer result in a different response class.
- The file extension is no longer taken into account for HTTP requests, only for the file system and for FTP requests.
  - An exception *not contemplated in the MIME sniffing standard* is made for the `Content-Disposition` header: as long as `Content-Type` is not defined or has a value equivalent to not being defined (e.g. `*/*`), `Content-Disposition` is taken into account, i.e. the MIME type matching the file extension is considered the supplied MIME type, as if it had been defined in the `Content-Type` header. This is because in Scrapy we treat those responses the same as other responses (i.e. we do not download them in file pipelines automatically, we handle them in callbacks just like regular responses), so it seems appropriate to consider the server-suggested file extension to determine the right response class.
- The supplied MIME type (i.e. Content-Type in HTTP or based on file extension in filesystem or FTP) now takes priority over body sniffing even if it maps to `Response` where the body would map to something like `TextResponse`.
  Before, the first things in the (headers, url, filename, body) that would map to something other than `Response` would dictate the selected class. So, for example, if the header or URL indicated a binary response but the body was plain text, the result was `TextResponse`.
  - An exception is made for supplied plain-text MIME types related to an Apache bug, for which the body is inspected in case the response is binary, and if it is `Response` is used instead of `TextResponse`.
  - Another exception is made for `text/html`, for which the body is inspected in case it is actually a news feed file, and if so `XmlResponse` is used.
- Response class mapping based on the supplied MIME type has been changed as follows:
  - `application/xhtml+xml` and `application/vnd.wap.xhtml+xml` now map to `XmlResponse` instead of to `HtmlResponse`. See “Note that XHTML is best parsed as XML” @ https://lxml.de/parsing.html
  - `application/ecmascript` and `application/x-ecmascript` now map to `TextResponse` instead of `Response`.
  - MIME types ending in `+json` (e.g. `application/foo+json`, `application/ld+json`) now always map to `TextResponse`.
  - MIME types ending in `+xml` (e.g. `application/foo+xml`) now always map to `TextResponse`.
  - The following MIME types *not contemplated in the MIME sniffing standard* have been kept, mapped to `JsonResponse` or `TextResponse`, as keeping them seems harmless: `application/x-json`, `application/json-amazonui-streaming`, `application/x-javascript`. However, we may want to consider removing support for them to be more in line with the standard, since `TextResponse` should get selected anyway based on the body.
- Note that the end result for the new mappings above that used to point to `Response` or that did not exist at all, the actual response class used will generally not have changed, because for old `Response` mappings body-based detection used to always run, in case the body content could suggest other than `Response`. The advantage now is that we skip body-based detection altogether for those new mappings.
- The body is now only taken into account when there is no supplied MIME type otherwise, or in the 2 exceptions mentioned above (Apache bug and mislabeled feeds).
- Body-based detection has improved for corner cases, including:
  - `\0` is now considered binary. `\x0c` and `\x1b` are no longer considered binary.
  - Many more corner cases where HTML is now detected.
  - Many cases where binary files are now detected as such based on their file signature where before they could be misinterpreted as text if they happened not to have any binary bytes.
- Body-based detection now inspects the first 1445 bytes, not the first 5000.
- For data URIs, in addition to the declared MIME type, the body is now also taken into account.
- When faced with a multi-encoded response (e.g. `Content-Encoding: br, gzip`) the HTTP compression middleware now applies all decoding, instead of applying only the last one.
  This is an *unrelated* change that I (@Gallaecio) deemed worth applying when I realized the issue when working on relevant changes. We could move it into its own pull request, though, if desired.

API:
- The `scrapy.responsetypes` module is deprecated in favor of the new `scrapy.utils.response.get_response_class` function
- The `scrapy.utils.response.get_base_url` function is deprecated in favor of the new `TextResponse.base_url` property
  I do not recall the reason behind this change, it *seems unrelated* to this pull request, so we could move it into its own pull request if desired.

# Not implemented

- No option to disable sniffing (i.e. body-based type detection for scriptable content) has been implemented:
  - The option to disable sniffing on the Scrapy side is not implemented. It could be implemented in the future through a setting.
  - `X-Content-Type-Options` from a web server is not taken into account. We could implement it in the future. Note that it is not part of the MIME sniffing standard itself, but the result of its handling can be fed into the MIME sniffing standard algorithm, which accepts a nosniff flag.
- The MIME sniffing standard allows for the extension of body-based detection rules, as long as those additional rules are not for MIME types with rules already defined in the standard. We could eventually expose this through a setting, to let Scrapy users define their own rules. Or we could expose custom rules, e.g. using a magic-based library. However, since the MIME types for which we have specific classes are already covered, I do not expect much demand for such a feature at the moment.

# To-do

- [x] Upgrade the minimum version of xtractmime
  - [x] Release a new version of [xtractmime](https://github.com/scrapy/xtractmime) with https://github.com/scrapy/xtractmime/pull/14
  - [x] Update `setup.py` and `tox.ini` here accordingly.",False,5204,https://api.github.com/repos/scrapy/scrapy/pulls/5204,https://github.com/scrapy/scrapy/pull/5204,open,1137,145,25,88,45,71,0,0,[],2021-07-14 15:30:34+00:00,,0.0,,"[{'comment_id': 669748620, 'comment_body': ':lipstick: \r\n\r\n```suggestion\r\nfrom io import StringIO\r\n\r\nfrom xtractmime import extract_mime\r\n```', 'comment_created': datetime.datetime(2021, 7, 14, 15, 58, 21, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670776831, 'comment_body': 'Instead of doing this, use `mimetype.decode()` in the calling code, to keep the API of this method simple and unmodified (i.e. only allow strings as input).\r\n\r\nOnce you reimplement this method to rely on `xtractmime` methods instead of `CLASSES`, what you could do is support `bytes` as input but do the opposite: encode `mimetype` if it is `str`, and probably log a deprecation warning asking users to pass `bytes` instead.\r\n\r\nI’m also thinking that it _might_ make sense to perform the changes we discussed for this method in a separate pull request, if you are OK with that. Separate, minimal pull requests (as opposed to single, bloated pull requests) are easier to review and merge, and I think this is a change that can be implemented separately.', 'comment_created': datetime.datetime(2021, 7, 15, 20, 16, 51, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670778184, 'comment_body': 'Please, refrain from removing any existing (public) method. We need to keep them around and working as before for backward compatibility, to avoid existing user code that may be using them.\r\n\r\nInstead, log a deprecation warning at the beginning of each one, asking users to use `from_args` instead. Look for `DeprecationWarning` usage in the code base to get an idea on how to use it, and make sure you use the parameter of the warn function that makes the warning be about the calling code.', 'comment_created': datetime.datetime(2021, 7, 15, 20, 19, 22, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670779482, 'comment_body': ""`cls` is always `Response` at this point.\r\n\r\nAlso, maybe we should assume the body to be `b''` if it is `None`, and pass `b''` to xtractmime as `body`."", 'comment_created': datetime.datetime(2021, 7, 15, 20, 21, 35, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670780870, 'comment_body': 'Since the goal is for Scrapy to follow the standard, I believe that it is OK to remove this code completely, and rely on xtractmime only with whatever data is available.', 'comment_created': datetime.datetime(2021, 7, 15, 20, 23, 51, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670784874, 'comment_body': 'Since `xtractmime` expects all content-types from the response, you should use `headers.getlist()` here. The result will be the same (`headers[]` returns the last value, which is the only one the current implementation of xtractmime will use), but this way is more future-proof (i.e. things will work as expected if a future version of xtractmime takes multiple content types into account).', 'comment_created': datetime.datetime(2021, 7, 15, 20, 30, 54, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670786077, 'comment_body': 'You can remove the TODO above. Now that we are relying on a third-party library for MIME sniffing, that is no longer a concern of ours, it is xtractmime tests that should cover that.\r\n\r\nThe comment in this line can be removed as well.', 'comment_created': datetime.datetime(2021, 7, 15, 20, 33, 5, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670787687, 'comment_body': 'I believe we should deprecate the `filename` parameter, i.e. log a deprecation warning if it is something other than `None`, since the parameter no longer affects the outcome of the method.', 'comment_created': datetime.datetime(2021, 7, 15, 20, 35, 48, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 670794656, 'comment_body': 'I believe we need to rethink this test.\r\n\r\nBefore, it was a test of how specific input resulted in different response classes. Now that xtractmime is responsible for determining the right MIME type (and the tests for that hence belong to the `xtractmime` code base), and since the mapping from MIME type to response is responsibility of a different method (`from_mimetype`) and can hence be tested separately, this test needs to be about verifying that we are passing `xtractmime` the right parameters.\r\n\r\nYou could use `mock` to compare what the method gets with what `xtractmime`. Mock may not be the easiest to use if you have not used it in the past (or even if you have), but it might be the best approach here\r\n\r\nAlternatively, you could figure out scenarios that would have a different outcome if we were failing to pass certain parameters to `xtractmime`, and test those. For example, to verify that `xtractmime` gets the `URL` parameter, you could determine a scenario where http_origin being `True` or `False` affects the outcome of this method, and test both cases, what happens when an HTTP URL is passed and what happens when a non-HTTP URL is passed, verifying that the outcome is different, and hence having proof that the URL parameter is taken into account.', 'comment_created': datetime.datetime(2021, 7, 15, 20, 47, 50, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 671882116, 'comment_body': 'I have some additional thoughts.\r\n\r\nWe should probably keep the the old test scenarios around, as a backward-compatibility test, in a separate test function. In other words, you could leave the existing test function as-is, and rename it to something like `test_from_args_pre_xtractmime`.\r\n\r\nIt would also be great if you could compare the old and xtractmime-based implementations, and figure out behavior differences that are to be expected, so that we can cover these in the release notes as backward-incompatible changes (hopefully for the better) that people should expect. For example, with the new implementation any MIME type with `+xml` not in `CLASSES` would be an XmlResponse (right?); also, any previous mapping based on filename will stop working. It would be great if you could figure out all those changes in behavior, cover all of them in a test function (e.g. `test_from_args_post_xtractmime`) that checks the current behavior.', 'comment_created': datetime.datetime(2021, 7, 18, 18, 47, 26, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 676367307, 'comment_body': 'May this be a bug in xtractmime? As far as I can tell from the standard, an empty-body resource with `text/html` content type should be interpreted as text/html. Could you find out at which point in the implementation a different type (text/plain?) is chosen, and see if it matches the standard text?', 'comment_created': datetime.datetime(2021, 7, 26, 7, 44, 10, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 676370530, 'comment_body': 'The current Scrapy implementation seems to rely on Content-Disposition, URL and filename only if Content-Type did not yield a class other than `Response`.\r\n\r\nI’m thinking one approach we could take towards improving backward compatibility without altering xtractmime in any way but still largely relying on it, would be to guess the content-type from Content-Disposition, URL or filename if there is no Content-Type header, and pass that guess to xtractmime as Content-Type. (This would also mean stop deprecating `filename` as a parameter).', 'comment_created': datetime.datetime(2021, 7, 26, 7, 49, 7, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 676379788, 'comment_body': 'I’m not sure how to best deal with this case. It’s clear that [we do not want NUL bytes to cause a body to be interpreted as binary](https://github.com/scrapy/parsel/issues/123).\r\n\r\nOne possible approach, without altering xtractmime, would be to remove NUL bytes from a body if those are the only binary data bytes in the body. I’m thinking this may be best, to keep xtractmime true to the standard, even though string-replacement in a whole response could be inefficient; maybe we could expose xtractmime’s header lenght, and only replace in that part of the body (and maybe pass only that part to xtractmime, while at it).\r\n\r\nAnother approach would be to modify xtractmime, adding an extra parameter that allows customizing what is to be understood as a binary data byte. But I think this would increase the complexity of the xtractmime implementation for no good reason.', 'comment_created': datetime.datetime(2021, 7, 26, 8, 2, 41, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 676413435, 'comment_body': 'I figured out it\'s happening because of step 5 in section 7. Where we implemented essence part as \r\n```\r\nif supplied_type == b""text/html"":\r\n```\r\nand it is not considering `b\'text/html; charset=utf-8\'` as HTML type. Maybe we can replace the code as\r\n`if supplied_type.startswith(b""text/html"")`. Or same can go with the implementation of essence of a mime type in other parts of the xtractmime.', 'comment_created': datetime.datetime(2021, 7, 26, 8, 50, 42, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 679291107, 'comment_body': 'For this I think we can import `BINARY_BYTES` from `xtractmime._patterns.py` and remove NULL bytes from the body till it\'s resource header length i.e body[:1445]  :\r\n```\r\nfor byte in BINARY_BYTES:\r\n     body = body[:1445].replace(byte, b"""") + body[1445:]\r\n```', 'comment_created': datetime.datetime(2021, 7, 29, 16, 7, 4, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 679291188, 'comment_body': 'Should I open another PR for the above issue in xtractmime?', 'comment_created': datetime.datetime(2021, 7, 29, 16, 7, 11, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 679462106, 'comment_body': '> Should I open another PR for the above issue in xtractmime?\r\n\r\nYes!\r\n\r\nAlso, try to be careful with the fix. `supplied_type.startswith(b""text/html"")` would also include unintended stuff (however unlikely, like `text/htmllikepdfthing`). Ideally, the input MIME types should be parsed with https://mimesniff.spec.whatwg.org/#parsing-a-mime-type . That said, for the current implementation, maybe a simplification that only splits the parameters part out would suffice (e.g. split by `;` and pick the first item).', 'comment_created': datetime.datetime(2021, 7, 29, 20, 23, 3, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 679467373, 'comment_body': 'Will it be better to use the existing methods as-is to determine content-type using Content-Disposition, URL, or filename. Or implement all the logics in a separate function??', 'comment_created': datetime.datetime(2021, 7, 29, 20, 32, 55, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 679468793, 'comment_body': 'We only want to remove `NUL` bytes, not all binary bytes. That is, if the body contains any other binary byte, it is OK for xtractmime to consider it binary.\r\n\r\nWhat we don’t want is to remove NUL bytes _if_ the header contains any other binary bytes. We only want to remove NUL bytes if all the bytes (in the header subset) are either non-binary or NUL.\r\n\r\nAlso, we need to be careful not to leave any NUL byte unchanged in the header part. If we use `body = body[:1445].replace(byte, b"""") + body[1445:]` and there is at least 1 NUL byte in the input `body[:1445]` and also one at `body[1445]`, then we would only be removing the first one and moving the other one to `body[1444]` in the outgoing `body`, not fixing the issue for such a corner case. Since the header length is rather arbitrary, the best approach may be not to append the remainder of the body, and instead just do `body = body[:1445].replace(byte, b"""")`. The body we would be passing would be shorter than the header limit, but I cannot think of a reason why that would be a significant problem, the xtractmime algorithm would still remain “deterministic for the majority of cases”, as the standard says.\r\n\r\nI would also suggest not to hardcode 1445 in Scrapy, and instead import the number from xtractmime, where it could be exposed as a public constant (`RESOURCE_HEADER_BUFFER_LENGTH`? `RESOURCE_HEADER_MAX_LENGTH`?).', 'comment_created': datetime.datetime(2021, 7, 29, 20, 35, 14, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 679470597, 'comment_body': 'Since the current logic for this is split into several methods, and from the one parsing headers we only want the Content-Disposition part, I think a new, private method may be easier to read (and slightly more efficient, although I don’t expect that to be a concern here).', 'comment_created': datetime.datetime(2021, 7, 29, 20, 38, 26, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 680313610, 'comment_body': 'Double underscore is rarely use, usually only when there is a significant probability of subclasses reusing the same single underscode name without realizing they are overwriting a parent class name. I don’t think that’s the case here, so I would go with a single underscore.', 'comment_created': datetime.datetime(2021, 7, 31, 5, 52, 29, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 680313851, 'comment_body': 'This `if` statement should not be necessary:\r\n\r\n- `-1` index works the same as `0` for single-item lists:\r\n\r\n```python\r\n>>> foo = [0]\r\n>>> foo[0]\r\n0\r\n>>> foo[-1]\r\n0\r\n```\r\n\r\n- I imagine `.split(b\'=\')[1].strip(b\'""\\\'\')` is needed in both sides of the `if` statement.', 'comment_created': datetime.datetime(2021, 7, 31, 5, 54, 53, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 680314274, 'comment_body': 'I think you could rewrite this function so that there is a single `return self.mimetypes.guess_type(filename)[0]` call.\r\n\r\nAlso, for the case where all input is `None`, and explicit `return None` would be good. Usually, when functions and methods return a value, using a return even when that value is `None` is considered more readable. Some static analyzers even complain otherwise (I think pylint has a rule for this).', 'comment_created': datetime.datetime(2021, 7, 31, 5, 59, 16, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 680314565, 'comment_body': 'I suggest you modify the `__guess_content_type` function so that here you can replace all these lines with a single call to that function.', 'comment_created': datetime.datetime(2021, 7, 31, 6, 1, 55, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 680331140, 'comment_body': 'What should be the priority of these parameters content-disposition, URL , filename?', 'comment_created': datetime.datetime(2021, 7, 31, 8, 46, 18, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 680332113, 'comment_body': 'Yes, to keep the same priorities as the earlier implementation. You could also move the Content-Type part into the function.', 'comment_created': datetime.datetime(2021, 7, 31, 8, 54, 51, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 680354000, 'comment_body': 'If you move a bit more logic to `_guess_content_type`, you could reduce this part to 2 lines without losing readability, I think:\r\n\r\n```suggestion\r\n        http_origin = not url or urlparse(url).scheme in (""http"", ""https"")\r\n        content_types = self._guess_content_type(headers=headers, url=url, filename=filename)\r\n```', 'comment_created': datetime.datetime(2021, 7, 31, 12, 33, 36, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 680799590, 'comment_body': 'I think some of these tests would have also passed with the pre-xtractmime implementation, in which case you should move them to `test_from_args_pre_xtractmime`; let’s keep here only the expected behavioral changes.', 'comment_created': datetime.datetime(2021, 8, 2, 9, 2, 56, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 684024595, 'comment_body': 'Is it OK to import a private module here?', 'comment_created': datetime.datetime(2021, 8, 6, 7, 49, 44, tzinfo=datetime.timezone.utc), 'commenter': 'wRAR', 'type': 'User'}, {'comment_id': 684028923, 'comment_body': ""What's the reason for removing them (and not counting them as binary)?"", 'comment_created': datetime.datetime(2021, 8, 6, 7, 56, 45, tzinfo=datetime.timezone.utc), 'commenter': 'wRAR', 'type': 'User'}, {'comment_id': 684040980, 'comment_body': 'For `xtractmime`, a NULL byte in a body causes the body to be interpreted as binary. Please refer [this comment ](https://github.com/scrapy/scrapy/pull/5204#discussion_r676379788)for an example', 'comment_created': datetime.datetime(2021, 8, 6, 8, 16, 3, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 684041866, 'comment_body': 'I am not sure about this. Maybe we can move the `contains_binary` function to `__init__.py` of `xtractmime`. @Gallaecio ?', 'comment_created': datetime.datetime(2021, 8, 6, 8, 17, 22, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 684067095, 'comment_body': ':+1: \r\n\r\nI also suggest renaming it as `is_binary_data`, to be consistent with https://mimesniff.spec.whatwg.org/#binary-data-byte', 'comment_created': datetime.datetime(2021, 8, 6, 8, 49, 48, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 684780876, 'comment_body': ""These tests are failing with the older implementation of `from_args` and passing with the current implementation. For now, I don't see any more tests for which older implementation will fail."", 'comment_created': datetime.datetime(2021, 8, 8, 14, 8, 51, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 685089129, 'comment_body': ""There's an [`AttributeError: 'NoneType' object has no attribute 'encode'`](https://github.com/scrapy/scrapy/pull/5204/checks?check_run_id=3279070482#step:5:2645) at this line, which is consistent with the following (value for `filename` taken from the test):\r\n```python\r\nIn [1]: from mimetypes import MimeTypes\r\n\r\nIn [2]: mimetypes = MimeTypes()\r\n\r\nIn [3]: filename = '/tmp/pytest-of-runner/pytest-0/test_download0/tests.test_downloader_handlers/FileTestCase/test_download/18xzf8lw/temp^'\r\n\r\nIn [4]: mimetypes.guess_type(filename)\r\nOut[4]: (None, None)\r\n```"", 'comment_created': datetime.datetime(2021, 8, 9, 10, 46, 39, tzinfo=datetime.timezone.utc), 'commenter': 'elacuesta', 'type': 'User'}, {'comment_id': 685501872, 'comment_body': 'For clarity, maybe we could refactor this part into a `_remove_nul_byte_from_text` function, and mention https://github.com/scrapy/scrapy/issues/2481 in a comment here before the call, for future reference.', 'comment_created': datetime.datetime(2021, 8, 9, 20, 34, 12, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 685502744, 'comment_body': "":lipstick:\r\n\r\n```suggestion\r\n        body = body or b''\r\n```"", 'comment_created': datetime.datetime(2021, 8, 9, 20, 35, 40, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 685502983, 'comment_body': 'This line seems superfluous now.', 'comment_created': datetime.datetime(2021, 8, 9, 20, 36, 4, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 685503179, 'comment_body': ':lipstick: \r\n\r\n```suggestion\r\n        return self._guess_response_type(mime_type)\r\n```', 'comment_created': datetime.datetime(2021, 8, 9, 20, 36, 23, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 685504937, 'comment_body': 'I’m not sure, but this comment seems out of place.', 'comment_created': datetime.datetime(2021, 8, 9, 20, 39, 20, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 685507840, 'comment_body': ""I’m guessing this was the intention, given body-based detection is covered by the scenario above.\r\n\r\n```suggestion\r\n            ({'headers': Headers({'Content-Type': b'application/pdf'})}, Response),\r\n```"", 'comment_created': datetime.datetime(2021, 8, 9, 20, 44, 5, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 685554469, 'comment_body': ""I’ve reviewed the previous implementation and taken some notes for you to review, and check if there are behavioral changes and, if so, add test cases for them:\r\n\r\n- Before, a `Content-Encoding` header would always cause a `Response`. I imagine now that’s not always the case.\r\n  In fact, I suspect a non-binary body reporting some encoding before would cause the HTTPCompressionMiddleware to raise an exception, but with the new implementation the middleware should do nothing if the response is not recognized as binary.\r\n- Does the new implementation work with these types from `CLASSES`?\r\n  ```\r\n  'application/x-json': 'scrapy.http.TextResponse',\r\n  'application/json-amazonui-streaming': 'scrapy.http.TextResponse',\r\n  'application/x-javascript': 'scrapy.http.TextResponse',\r\n  ```\r\n- Before, a `Content-Type` missing or for a binary type would be ignored in favor of `Content-Disposition`, URL or file name. I am guessing, for example, that with `Content-Type` `application/octet-stream` but a path-like field of a non-binary type, before you would get a non-`Response` class, and now you get `Response`.\r\n- When inspecting the body:\r\n    - `0x0C` and `0x1B` were considered binary, and now are not (the standard does not include them in the binary data range set).\r\n    - `<html>` anywhere in the first 5000 bytes would trigger HtmlResponse, even if the body was: `this is not <html>`\r\n    - `<?xml` anywhere in the first 5000 bytes would trigger XmlResponse, even if the body was: `this is not <?xml either`"", 'comment_created': datetime.datetime(2021, 8, 9, 22, 9, 42, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 686609871, 'comment_body': 'yeah, I forgot to remove that 😅 ', 'comment_created': datetime.datetime(2021, 8, 11, 8, 22, 30, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 686675934, 'comment_body': ""> Before, a Content-Encoding header would always cause a Response. I imagine now that’s not always the case.\r\nIn fact, I suspect a non-binary body reporting some encoding before would cause the HTTPCompressionMiddleware to raise an exception, but with the new implementation the middleware should do nothing if the response is not recognized as binary.\r\n\r\nMaybe I am testing wrong, but both of these testcases are passing with older implementation\r\n\r\n ```\r\n({'body': b'Some binary\\1\\2 text', 'headers': Headers({'Content-Encoding': 'UTF-8'})},\r\n             Response),\r\n\r\n ({'body': b'Some plain text', 'headers': Headers({'Content-Encoding': 'UTF-8'})},\r\n             TextResponse),```"", 'comment_created': datetime.datetime(2021, 8, 11, 9, 49, 51, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 686679364, 'comment_body': "">     * Does the new implementation work with these types from `CLASSES`?\r\n>       ```\r\n>       'application/x-json': 'scrapy.http.TextResponse',\r\n>       'application/json-amazonui-streaming': 'scrapy.http.TextResponse',\r\n>       'application/x-javascript': 'scrapy.http.TextResponse',\r\n>       ```\r\n\r\nNope. I think we can hard-code them while detecting a text response in `_guess_response_type`??\r\n"", 'comment_created': datetime.datetime(2021, 8, 11, 9, 54, 44, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 686709963, 'comment_body': ""> Maybe I am testing wrong, but both of these testcases are passing with older implementation\r\n> \r\n> ```\r\n> ({'body': b'Some binary\\1\\2 text', 'headers': Headers({'Content-Encoding': 'UTF-8'})},\r\n>             Response),\r\n> \r\n> ({'body': b'Some plain text', 'headers': Headers({'Content-Encoding': 'UTF-8'})},\r\n>             TextResponse),```\r\n> ```\r\n\r\nI do think there’s a behavior difference, but I think the way I described it above was not accurate. Here are some scenarios that change their output with the new implementation (for the better):\r\n\r\n```python\r\n            (\r\n                {\r\n                    'headers': Headers(\r\n                        {\r\n                            'Content-Encoding': ['zip'],\r\n                            'Content-Type': ['text/html'],\r\n                        }\r\n                    ),\r\n                },\r\n                Response,\r\n            ),\r\n            (\r\n                {\r\n                    'headers': Headers(\r\n                        {\r\n                            'Content-Encoding': ['zip'],\r\n                            'Content-Type': ['text/plain'],\r\n                        }\r\n                    ),\r\n                },\r\n                Response,\r\n            ),\r\n            (\r\n                {\r\n                    'headers': Headers(\r\n                        {\r\n                            'Content-Encoding': ['zip'],\r\n                            'Content-Type': ['text/html'],\r\n                        }\r\n                    ),\r\n                    'body': b'Non HTML',\r\n                },\r\n                TextResponse,\r\n            ),\r\n```"", 'comment_created': datetime.datetime(2021, 8, 11, 10, 39, 21, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 686751548, 'comment_body': '> * Before, a `Content-Type` missing or for a binary type would be ignored in favor of `Content-Disposition`, URL or file name. I am guessing, for example, that with `Content-Type` `application/octet-stream` but a path-like field of a non-binary type, before you would get a non-`Response` class, and now you get `Response`.\r\n> \r\n> * When inspecting the body:\r\n>   \r\n>   * `0x0C` and `0x1B` were considered binary, and now are not (the standard does not include them in the binary data range set).\r\n>   * `<html>` anywhere in the first 5000 bytes would trigger HtmlResponse, even if the body was: `this is not <html>`\r\n>   * `<?xml` anywhere in the first 5000 bytes would trigger XmlResponse, even if the body was: `this is not <?xml either`\r\n\r\n👍🏼 ', 'comment_created': datetime.datetime(2021, 8, 11, 11, 45, 27, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 686781807, 'comment_body': ':lipstick: \r\n```suggestion\r\n            or mime_type in (\r\n                b""application/x-json"",\r\n                b""application/json-amazonui-streaming"",\r\n                b""application/x-javascript"",\r\n            )\r\n```', 'comment_created': datetime.datetime(2021, 8, 11, 12, 27, 55, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 686783783, 'comment_body': ':lipstick: If you use an early return here (`return text` instead of these 2 lines), you can simplify the function a bit.', 'comment_created': datetime.datetime(2021, 8, 11, 12, 30, 29, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 686789317, 'comment_body': 'Shouldn’t this one be in pre_args, alongside the `application/x-json` one? Also, maybe we should also cover `application/json-amazonui-streaming`, just in case.\r\n\r\nAlso, I’m thinking that it may be good to include a docstring that indicates that each of these test functions covers, scenarios that did not change when switching to xtractmime vs scenarios that changed (for the better) when switching to xtractmime.', 'comment_created': datetime.datetime(2021, 8, 11, 12, 37, 59, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 686792357, 'comment_body': 'Since this is one of those cases where we now go to a less-specific class when a more-specific class would have worked better for data extraction, maybe we should do something to cause this to remain as `TextResponse`.\r\n\r\nMaybe we could modify `_guess_content_type` not to return any MIME type that, when passed to `_guess_response_type`, returns `Response`.', 'comment_created': datetime.datetime(2021, 8, 11, 12, 42, 10, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 686864452, 'comment_body': '\r\n> Maybe we could modify `_guess_content_type` not to return any MIME type that, when passed to `_guess_response_type`, returns `Response`.\r\n\r\nI tried this change and following tests are failing \r\n```\r\n            ({\'headers\': Headers({\'Content-Disposition\': [\'attachment; filename=""data.xml.gz""\']}),\r\n              \'url\': \'http://www.example.com/page/\'}, Response),\r\n\r\n            ({\'filename\': \'file.pdf\'}, Response),\r\n\r\n            ({\'url\': \'http://www.example.com/item/file.pdf\'}, Response),\r\n\r\n            ({\'headers\': Headers({\'Content-Type\': [\'application/pdf\']})}, Response),\r\n\r\n\r\n```\r\n', 'comment_created': datetime.datetime(2021, 8, 11, 14, 4, 24, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 686930038, 'comment_body': 'I think it should be fine for those to return a class more specific than `Response` (I assume `TextResponse`) when there is no body.\r\n\r\nWe could keep those tests with new expectations as post-xtractmime behavior changes, and include new versions of these scenarios where there is a binary body (a single-byte binary body should suffice to cause `Response` to be returned).\r\n\r\nAlternatively, we could make the change to `_guess_content_type` conditional on there being a non-empty body, which should make those tests, with and without body, have the same result as before xtractmime.', 'comment_created': datetime.datetime(2021, 8, 11, 15, 15, 23, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 687110609, 'comment_body': 'As per my understanding, `_guess_content_type` will look like this\r\n```\r\n    def _guess_content_type(self, body=None, headers=None, url=None, filename=None):\r\n        mimetype = None\r\n\r\n        if headers and b\'Content-Type\' in headers:\r\n            mimetype = tuple(headers.getlist(b\'Content-Type\'))\r\n        else:\r\n            if headers and b\'Content-Disposition\' in headers:\r\n                filename = headers.get(b\'Content-Disposition\').split(b\';\')[-1].split(b\'=\')[-1].strip(b\'""\\\'\').decode()\r\n            elif url:\r\n                filename = url\r\n\r\n            if filename:\r\n                mimetype, encoding = self.mimetypes.guess_type(filename)\r\n                if encoding:\r\n                    mimetype = (f""application/{encoding}"".encode(),)\r\n                elif mimetype:\r\n                    mimetype = (mimetype.encode(),)\r\n\r\n        if body or (mimetype and self._guess_response_type(mimetype[-1]) == Response):\r\n            return None\r\n        \r\n        return mimetype\r\n```', 'comment_created': datetime.datetime(2021, 8, 11, 19, 23, 36, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 687150673, 'comment_body': 'I said it wrong, I think we need to return `None` when there is _no_ body:\r\n\r\n```python\r\n        if not body and mimetype and self._guess_response_type(mimetype[-1]) is Response:\r\n```\r\n\r\nIf there is no body, xtractmime will take the suggested type. We don’t want that to happen if the suggested type will lead to `Response`.', 'comment_created': datetime.datetime(2021, 8, 11, 20, 11, 46, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 688011085, 'comment_body': ""> \r\n            ({'body': b'Some plain text', 'headers': Headers({'Content-Type': 'application/octet-stream'})},\r\n             TextResponse),\r\nThe testcase is still failing with above implementation of `_guess_content_type` as body is not `None` so the if statement is failing and `_guess_content_type` is returning the `application/octet-stream` mimetype. \r\n\r\nMaybe we need a more complex condition here (which I can't figured out 😅)"", 'comment_created': datetime.datetime(2021, 8, 12, 19, 5, 29, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 688025278, 'comment_body': 'Apparently, just this condition is working with every testcase\r\n```python\r\n        if mimetype and self._guess_response_type(mimetype[-1]) is Response:\r\n            return None\r\n```\r\neven with these ones\r\n> We could keep those tests with new expectations as post-xtractmime behavior changes, and include new versions of these scenarios where there is a binary body (a single-byte binary body should suffice to cause Response to be returned).\r\n\r\n', 'comment_created': datetime.datetime(2021, 8, 12, 19, 27, 56, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 689345789, 'comment_body': 'I see some scenarios here that seem to belong to post_xtractmine. Please, review the scenarios that belong to each function, as the release notes will describe changes based on these 2 test functions.', 'comment_created': datetime.datetime(2021, 8, 16, 8, 41, 25, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 689429500, 'comment_body': '> > * Before, a `Content-Encoding` header would always cause a `Response`. I imagine now that’s not always the case.\r\n> >   In fact, I suspect a non-binary body reporting some encoding before would cause the HTTPCompressionMiddleware to raise an exception, but with the new implementation the middleware should do nothing if the response is not recognized as binary.\r\n> \r\n> I don’t think the tests cover this scenario. Although I might be wrong.\r\n\r\n\r\nI think these tests are covering this scenario.', 'comment_created': datetime.datetime(2021, 8, 16, 10, 47, 16, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 689437801, 'comment_body': 'Oops, I quoted the wrong list item :facepalm: \r\n\r\n> - Before, a `Content-Type` missing or for a binary type would be ignored in favor of `Content-Disposition`, URL or file name. I am guessing, for example, that with `Content-Type` `application/octet-stream` but a path-like field of a non-binary type, before you would get a non-`Response` class, and now you get `Response`.', 'comment_created': datetime.datetime(2021, 8, 16, 11, 0, 37, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 694397346, 'comment_body': ""```\r\n({'url': 'http://www.example.com/item/file.txt', 'headers': Headers({'Content-Type': 'application/octet-stream'})}, Response)\r\n```\r\nIs this the correct example for the above scenario?"", 'comment_created': datetime.datetime(2021, 8, 24, 0, 33, 58, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 694713696, 'comment_body': 'Yes, that’s what I had in mind. We might want variations with missing header and the alternatives to URL that affect the output (`Content-Disposition` and file name) for complete coverage, but that’s the base scenario.', 'comment_created': datetime.datetime(2021, 8, 24, 10, 13, 43, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 698048387, 'comment_body': '```\r\n            ({\'url\': \'http://www.example.com/item/file.txt\', \'headers\': Headers({\'Content-Type\': \'application/octet-stream\'})},\r\n             TextResponse),\r\n            ({\'headers\': Headers({\'Content-Disposition\': [\'attachment; filename=""data.xml.gz""\'], \'Content-Type\': \'application/octet-stream\'})},\r\n             TextResponse),\r\n```\r\nThese tests are passing with xtractmime. I think a missing `Content-Type` or a binary content type is still ignored.', 'comment_created': datetime.datetime(2021, 8, 29, 17, 45, 32, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 712141894, 'comment_body': ""It looks like it works for `TextResponse`. But this, for example, does not work now and I think (did not check) it would work before:\r\n\r\n```python\r\n({'url': 'http://www.example.com/item/file.xml', 'headers': Headers({'Content-Type': 'application/octet-stream'})}, XmlResponse),\r\n```"", 'comment_created': datetime.datetime(2021, 9, 20, 12, 58, 41, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 712650628, 'comment_body': 'yeah you are right. It is working as a pre xtractmime test', 'comment_created': datetime.datetime(2021, 9, 21, 2, 43, 27, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 716027134, 'comment_body': 'I think this change is something we should address, in the policy of not going backwards when it comes to finding a more specific response class.', 'comment_created': datetime.datetime(2021, 9, 25, 11, 4, 30, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 716158442, 'comment_body': '> I think this change is something we should address, in the policy of not going backwards when it comes to finding a more specific response class.\r\n\r\nBy this you mean to change ` _guess_content_type`, right? or I am interpreting something wrong?\r\n', 'comment_created': datetime.datetime(2021, 9, 26, 7, 33, 34, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 716190727, 'comment_body': 'I was not pointing at any specific way to address it, but yes, I think that’s where the changes need to be made.', 'comment_created': datetime.datetime(2021, 9, 26, 11, 39, 22, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 898717501, 'comment_body': 'Hey @Gallaecio, I was reviewing the `_guess_content_type` function. To resolve the above test issue, should I prefer (filename or URL) over the `Content-Type` header in the `if` statements? Or Please suggest a way to resolve the issue if you have any changes in mind. \r\nThanks', 'comment_created': datetime.datetime(2022, 6, 16, 5, 54, 3, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}, {'comment_id': 901389608, 'comment_body': 'Oh my, it took me a while to remember what this was about :facepalm: \r\n\r\nOK, so I understand that pre-xtractmime this test case would result in `XmlResponse`, but now it causes `TextResponse`. And we do not want that, because if before a more specific class was selected and made sense, going to a more generic class now (`XmlResponse` → `TextResponse`) may be considered a regression from the user point of view.\r\n\r\nLooking at `_guess_content_type`, I think we may need to refactor it to run the following logic instead when determining the value of the content-type to pass later to xtractmime:\r\n\r\n```python\r\ncontent_type_mime_type = ...\r\ncontent_disposition_mime_type = ...\r\nurl_mime_type = ...\r\n\r\nprioritized_mime_type_checkers = (\r\n    is_html_mime_type,\r\n    is_xml_mime_type,\r\n    _is_text_mime_type,\r\n)\r\ncandidate_mime_types = (\r\n    content_type_mime_type,\r\n    content_disposition_mime_type,\r\n    url_mime_type,\r\n)\r\nfor mime_type_checker in prioritized_mime_type_checkers:\r\n    for candidate_mime_type in candidate_mime_types:\r\n        if (\r\n            candidate_mime_type is not None \r\n            and mime_type_checker(candidate_mime_type)\r\n        ):\r\n            return candidate_mime_type\r\nreturn (\r\n    content_type_mime_type\r\n    or content_disposition_mime_type\r\n    or url_mime_type\r\n)\r\n```\r\n\r\nThis is untested, incomplete code, of course. `prioritized_mime_type_checkers` can be defined outside this function, its 2 first values are from xtractmime, and `_is_text_mime_type` can be refactored out of `_guess_response_type` (the `if` that returns `TextResponse`).\r\n\r\nBut I hope it gets the general idea through:\r\n1. Get all possible MIME types first\r\n2. Choose the one matching the most specific response class: HTML, XML, text, binary.', 'comment_created': datetime.datetime(2022, 6, 20, 8, 25, 13, tzinfo=datetime.timezone.utc), 'commenter': 'Gallaecio', 'type': 'User'}, {'comment_id': 901993236, 'comment_body': 'Yeah, It took me a while too to remember everything 😅 . \r\nAnyways, thank you so much for this. I will test this and let you know if things are working. ', 'comment_created': datetime.datetime(2022, 6, 20, 20, 53, 3, tzinfo=datetime.timezone.utc), 'commenter': 'akshaysharmajs', 'type': 'User'}]","[{'commit_sha': '0aa61cec13da3b3a9d6b0807c7c0be6153b221ef', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c85b780184b046fd596e4e3ed06ee3fba286cbd7', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cf19c4f5917574a0d952d82b82c2b67cb463604f', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '265301215ab8d15832a426075c6268c6a5da6acf', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c1ef25461e960acf818f04bfae11cd1e2a450207', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '211fc62b696896085750dc6ef66b58dc17ebde84', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '763ec07b7b6e599816879a00e2c6fe5d5e92a201', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1512ed22b264a04feef5823c7661db7ab3093507', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5c256d5c5faacd3e787e1b414c67cf53ad47be59', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '180b457f771ccfbb7f2ddd8dbb9989fe51d2929c', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5ee086e7b6b732f33553a0c8b7e34c488c660a63', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3a20b79de7259eda4c7ba6486331a7aa4e370eb6', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f573d11ec2a45d0aab14bc122b64242c8fe19455', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e0e99c1e5134d8261563bcfb5344ba7a6bffdc5', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '57d76df85c056aca3027f5cc6b107c677d62f8a3', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '841a218431a7739d079fe54cea727954594093c5', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0b52719e5f12f4241d834c9f3ddc9965ef9678c5', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2ba2f49ac52da715b9499d05ab092552b435024a', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9980a3d13412cea23a80672a0517c45eac16d9e5', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4169fd184f478653139cf37aedc7e96fe8d38bde', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3475f0049bcd927b434e30f2a5d82f1a2d2eacd5', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '22c33adb416bbfca40b66e7eb1f91f08f73d3c16', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4dbe9e11edf0070942636f4bed2e6b72ca8d8821', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c81605abe62e1ab6bcd8e46e425d0ede3f785c20', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '66e3b4004333140ae37841786fb490ce14c2dc21', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b2181d76d533c87705f683f701b4f92a6be00d25', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'b9effde875a7b9058524eb4638e34e80ad0ea7ac', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bedd4e51e148ca94ab72d630bb2fba2335056cb5', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0eb1de90e27af37833ca87b5d5cf2fcce40585df', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3e9efe26ceb7d4c8a9877257077152e25a1f66ef', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ef6290ef1b955cbe06a47053eda4a8064521713c', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8340394bcc2c1618da69e1b8b2f1a9ead20601c2', 'committer_username': 'akshaysharmajs', 'committer_name': 'Akshay Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 8, 9, 18, 6, 4, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9044ceb824be1f58b6ea41d8436a52c725b6d2e0', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3fc9b732cb24764dbe9266a6a2e3540b3d839378', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd2accf2e39dba6d6d48eeb9683081067fa46a352', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '19a00bd4ef58ed38d0c3c8e7b24a9f2cd45f65f5', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fd2317bd6de8810f6cf9b9900c19fea40b171679', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1ea5a8e9e0f9922218cba77724744af85eb321b6', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '54a024830182d2f799a36789c5a8cf4cf18fc6aa', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '55105ddc7cc61c51cb7f1b8997a3cd4afef459c5', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '948b9ba12567bb9b7ff5a76aa9c173acc1589aa5', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '983aa66687390abe4aad89df1263f7a02f5766d5', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4759c681934876351aea5ca18175e4f4efcc8633', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7ef061fc173ed7cedb5baa14e08d2ba38fbc06c2', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3d7e2e5021c74f0384726d65ce4e0c0dc55ef05a', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b7e88f4357eb11274693ece3618fb92cf7052d12', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0a77bfe2a0086abffe2681fdce659d9115712433', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '42bca211d97c1953b7bb2f808f62a94a88ceaaa8', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b336980bd1eca7eacf71078ded97b4eddbbe069d', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c6d416c69f85564942e401dec174b45a9692ef90', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e96b07bd4b8d69907407397a97331250132a77d2', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '160096b7cf2944908b4ce42c32522510d8271105', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '112b232023c43c2bc54020dc3bdc69c66d2f1502', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0d86d845e8d28c697f623f54dbdef48fcbde017b', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f029be3aa7f75a282dfbd429284abcbca3bf2a9d', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd319b62d16fe680cd076009d0b5b4454c9b3e42b', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fa3ba512d992346c5675aaaaa57559e3ced76934', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1c169895453f2f564bfab061078ebdac2b5de0bf', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e7d36a305d43362cd3a7aa6501eefc637c41d74f', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f9f9d61457656f68e23bb04c5d868a126ce33613', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b2f2788bd41febc62853bf38351844598d89f823', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '711a6093e125942a7ae278d4634b207f04c25926', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '827de3d28815996b2a2881acf4a20d780067943b', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '716561972b4366ff9f308d73ceacbb61641c7042', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '24e63f3294494321c12e5648e4e12f8092b65cee', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fcc9e9055399d12804fc5e673d00020a7f9ac21b', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eef1f127de24a204149b0b23ad3727cbc68aade6', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e7e201d0b9fe971311c896e12dc7fd2cc44ce77d', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '45b95c63d7e8e0f035897d73b117382c97560c76', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8908151608872d32879e11574f75e994005b77fc', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2178521a79a49207f7a1be32ddc653164654d9c3', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dd4f4f094ecb65fb96cefde80a976a6d5427748d', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14464388e8b852d3434b9389e0785519c6c13507', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f538252d3bf38f9758a22aec17e0147ca761dd0c', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '68fccc9f04bea9ecf0d31fb5ca77559bb9174dfb', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c34853100abfaf1c988f3db880672579fa3851fb', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ee6f5c56b287f14b175fe88118402ccba98b0571', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fc2833d6bd2ac06f553c3397ddd709adb87643c5', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'deab93b243248eec77f460ddd1bc0eac8cae0133', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ff37b274a66f1975ea99d635918da69e7aabb81e', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '86baef02a04dd5566e5ad8568011223cc29723f3', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7bb5289cedc2a7410c58e2c4fc8dfda692faaa9a', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9ee2ebea54c7c5e6a29e373eb083f8066d185521', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f8cdd092d5ac8a3a0e987713cc05c6aa86087369', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1ade9d2ed7dbbd268a75fd6b4228b868a48ee5d9', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2d9857b4412707dd377b949fffcf21e12a63b1f8', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a3fd6bea5ed97b5898d67c38bf64a8fa503e253', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'commit_sha': '13bc1499ac2191d39bf9643e6c3b3770a2207240', 'committer_username': 'Gallaecio', 'committer_name': 'Adrián Chaves', 'committer_email': 'adrian@chaves.io', 'commit_date': datetime.datetime(2011, 4, 2, 10, 9, 11, tzinfo=datetime.timezone.utc)}]",Akshay Sharma,42249933,,User,,28,,1,8

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
529502,scrapy,scrapy/scrapy,Python,10436,52155,1775,651,10531,669,39,220,"[{'id': 690016306, 'number': 5204, 'closed': None, 'created': datetime.datetime(2021, 7, 14, 15, 30, 34, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 1137, 'deletions': 145, 'state': 'open'}, {'id': 552894432, 'number': 4953, 'closed': None, 'created': datetime.datetime(2021, 1, 11, 17, 18, 49, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 26, 'deletions': 12, 'state': 'open'}, {'id': 545846689, 'number': 4939, 'closed': datetime.datetime(2021, 1, 5, 17, 29, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 12, 27, 19, 15, 27, tzinfo=datetime.timezone.utc), 'time_taken': 771223.0, 'time_delta': '8 days, 22:13:43', 'additions': 22, 'deletions': 3, 'state': 'closed'}, {'id': 469283326, 'number': 4736, 'closed': datetime.datetime(2021, 4, 1, 17, 39, 33, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 18, 8, 9, 36, tzinfo=datetime.timezone.utc), 'time_taken': 19560597.0, 'time_delta': '226 days, 9:29:57', 'additions': 27, 'deletions': 3, 'state': 'closed'}, {'id': 439141298, 'number': 4646, 'closed': datetime.datetime(2020, 10, 1, 18, 53, 9, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 24, 11, 21, 36, tzinfo=datetime.timezone.utc), 'time_taken': 8580693.0, 'time_delta': '99 days, 7:31:33', 'additions': 72, 'deletions': 21, 'state': 'closed'}, {'id': 437968477, 'number': 4640, 'closed': datetime.datetime(2020, 7, 13, 9, 52, 42, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 22, 14, 8, 8, tzinfo=datetime.timezone.utc), 'time_taken': 1799074.0, 'time_delta': '20 days, 19:44:34', 'additions': 19, 'deletions': 7, 'state': 'closed'}, {'id': 383858929, 'number': 4403, 'closed': datetime.datetime(2020, 7, 20, 12, 23, 39, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 4, 20, 38, 38, tzinfo=datetime.timezone.utc), 'time_taken': 11893501.0, 'time_delta': '137 days, 15:45:01', 'additions': 103, 'deletions': 3, 'state': 'closed'}, {'id': 383848119, 'number': 4402, 'closed': datetime.datetime(2020, 3, 4, 20, 18, 28, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 4, 20, 18, 4, tzinfo=datetime.timezone.utc), 'time_taken': 24.0, 'time_delta': '0:00:24', 'additions': 2, 'deletions': 0, 'state': 'closed'}, {'id': 376177341, 'number': 4338, 'closed': datetime.datetime(2020, 2, 18, 16, 58, 32, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 2, 17, 14, 50, 14, tzinfo=datetime.timezone.utc), 'time_taken': 94098.0, 'time_delta': '1 day, 2:08:18', 'additions': 27, 'deletions': 27, 'state': 'closed'}]"

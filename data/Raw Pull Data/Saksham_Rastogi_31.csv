pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
971194816,Add Time Series Block,"Added Time Series Container and Block. It is capable of loading all datasets from [timeseriesclassification](http://timeseriesclassification.com/dataset.php). The `.ts` files are loaded using Julia translation of this [method](https://github.com/timeseriesAI/tsai/blob/600a5ee7efe04c6ff19c7a27f596f947c75f31ef/tsai/data/external.py#L1389) .

I have also added a basic test case for the recipe. 
This allows us to do the following 


```julia
using FastAI

data, blocks = load(datarecipes()[""ecg5000""])
nobs(data)
sample = series, class = getobs(data, 10)
```

Just wanted to get some initial thoughts on the work, there might be more changes as I continue to work on the other parts.


",True,239,https://api.github.com/repos/FluxML/FastAI.jl/pulls/239,https://github.com/FluxML/FastAI.jl/pull/239,closed,8416,7380,175,22,23,51,0,0,[],2022-06-18 06:36:43+00:00,2022-07-29 10:55:53+00:00,3557950.0,"41 days, 4:19:10","[{'comment_id': 902153684, 'comment_body': 'Looks like the indentation got a little messed up in this file?', 'comment_created': datetime.datetime(2022, 6, 21, 4, 35, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 902154081, 'comment_body': ""We'll have to figure out how to deal with time series datasets in different formats eventually. This may involve changing the text file detection logic. No need to worry about that now, this is just a note for when that time comes :)"", 'comment_created': datetime.datetime(2022, 6, 21, 4, 36, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 902155185, 'comment_body': ""```suggestion\r\nstruct TimeSeriesDataset{T<:AbstractArray}\r\n    table::T\r\n```\r\nThe type parameter is required for avoid an abstract field type. I've loosened the array type bound as well, but it may need to be tuned up or down later."", 'comment_created': datetime.datetime(2022, 6, 21, 4, 39, 25, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 902156274, 'comment_body': ""There should be a way to extract out some of this logic. For now, having tests would help verify it's working."", 'comment_created': datetime.datetime(2022, 6, 21, 4, 42, 14, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 902461953, 'comment_body': ""I'm not sure of the block name here. I would prefer `TimeSeries`, but that's already the module name. Once #240 is through, the time-series functionality will be a subpackage `FastTimeSeries`, so then the name `TimeSeries` for the block would be available. Let's leave it for now, and maybe change it then. "", 'comment_created': datetime.datetime(2022, 6, 21, 10, 50, 38, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 902465483, 'comment_body': ""Do we need both the number of features and the observation length as type parameters? We should only do this if we need to dispatch on the number of features or observation length.\r\n\r\nAdditionally, a `Block` is constant for a dataset, so including the observation length means we wouldn't be able to support datasets where different samples have varying observation lengths. Is that the case for any of the datasets we're using? Do we need this information somewhere on the block-level? If we don't need it, I would suggest dropping the observation length from the block or allowing passing a colon `:` to allow variable-length observations.\r\n\r\nAlso, if we don't need to dispatch on the number of features (do we?), it can be added as a field.\r\n\r\nSo we'd have something like \r\n\r\n```julia\r\nstruct TimeSeriesRow <: Block\r\n    nfeatures::Int\r\n    obslength::Union{Int, Colon}\r\nend\r\n```\r\n\r\n"", 'comment_created': datetime.datetime(2022, 6, 21, 10, 54, 56, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 902469018, 'comment_body': ""Not sure how big this dataset is, but if it's really big, we may not want to run this on the CI, since it'll need to download it every time"", 'comment_created': datetime.datetime(2022, 6, 21, 10, 58, 11, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 902470472, 'comment_body': 'This will need to be updated to `Base.getindex` and `Base.length` now that #229 is merged', 'comment_created': datetime.datetime(2022, 6, 21, 10, 59, 22, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 902861960, 'comment_body': 'Yeah, probably. Will go through it again to sort it out.', 'comment_created': datetime.datetime(2022, 6, 21, 17, 2, 47, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 902863695, 'comment_body': 'Yeah I think it could be extracted out for the current datasets we are using. I just copied it over from python library to get it working. \r\nBy tests do you mean automated tests and creating a sample `.ts` file to run the test on ?', 'comment_created': datetime.datetime(2022, 6, 21, 17, 4, 49, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 902866473, 'comment_body': '- For the current datasets we are planning to use, the length is same for all observations, so we can have a constant block.\r\n\r\nFrom my understanding we build the model from the block ? So the parameters might depend on time series length and number of variables. \r\nSo ideally the block should just dispatch on parameters which are required in model building ?', 'comment_created': datetime.datetime(2022, 6, 21, 17, 8, 3, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 902866747, 'comment_body': 'The dataset is around 10mb, should we run this on CI ?', 'comment_created': datetime.datetime(2022, 6, 21, 17, 8, 23, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 902866890, 'comment_body': 'Sure, will update it.', 'comment_created': datetime.datetime(2022, 6, 21, 17, 8, 33, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 902892222, 'comment_body': 'That should be fine ðŸ‘ ', 'comment_created': datetime.datetime(2022, 6, 21, 17, 34, 58, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 902924333, 'comment_body': 'Just to clarify, is there a way to auto format the code ? ', 'comment_created': datetime.datetime(2022, 6, 21, 18, 11, 43, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 902925885, 'comment_body': 'Correct. You could also use a small existing one as long as the license is compatible.', 'comment_created': datetime.datetime(2022, 6, 21, 18, 13, 32, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 911954804, 'comment_body': '```suggestion\r\nsetup(::Type{TSPreprocessing}, ::TimeSeriesRow, data) = means, stds = tsdatasetstats(data)\r\n```', 'comment_created': datetime.datetime(2022, 7, 1, 13, 17, 18, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 911955646, 'comment_body': '```suggestion\r\nexport \r\n    TimeSeriesRow, TSClassificationSingle, TSPreprocessing\r\n```', 'comment_created': datetime.datetime(2022, 7, 1, 13, 18, 17, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 911986691, 'comment_body': 'What kind of transforms will be in here?', 'comment_created': datetime.datetime(2022, 7, 1, 13, 55, 33, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 911987394, 'comment_body': 'If the format of the time series is changed by the encoding, this should return a different block', 'comment_created': datetime.datetime(2022, 7, 1, 13, 56, 22, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 912306673, 'comment_body': ""No the format won't be changed, as I discussed with Brian earlier that different models might require different formats and so the encoding shouldn't depend on the model.\r\n"", 'comment_created': datetime.datetime(2022, 7, 2, 1, 58, 41, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 912307402, 'comment_body': ""Currently only Standardize, that's the only used in the tutorials. \r\nIf time permits we can also add normalisation using min-max, clipping outliers based on IQR, handle missing values in the time series."", 'comment_created': datetime.datetime(2022, 7, 2, 2, 6, 43, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 912442614, 'comment_body': 'Not sure we need this struct, it may be simpler to add `means` and `stds` fields to the `Encoding`. Then that also makes it easier to construct `TSPreprocessing` manually (i.e. without `setup`).', 'comment_created': datetime.datetime(2022, 7, 3, 7, 19, 38, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 912442821, 'comment_body': 'Should this be an `encode` method?', 'comment_created': datetime.datetime(2022, 7, 3, 7, 21, 37, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 912443039, 'comment_body': 'Can we add a check of the dimensions of `obs` against the means/stds here?', 'comment_created': datetime.datetime(2022, 7, 3, 7, 23, 23, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 912516268, 'comment_body': '```suggestion\r\ncheckblock(row::TimeSeriesRow, obs::AbstractMatrix{<:Number}) = size(obs) == (row.nfeatures, row.obslength)\r\n```', 'comment_created': datetime.datetime(2022, 7, 3, 17, 35, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 912516415, 'comment_body': '```suggestion\r\n    return (obs .- p.stats.means) ./ p.stats.stds\r\n```\r\nThis will fuse and save an intermediate allocation.', 'comment_created': datetime.datetime(2022, 7, 3, 17, 37, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 912516868, 'comment_body': ""```suggestion\r\n    drop_axis = by_var ? 2 : 3\r\n    axes = filter(!=(drop_axis), 1:3)\r\n```\r\nIt appears `drop_axes` only ever has one axis, so I've taken the liberty to simplify it here. Unless you were planning on having an if statement for `by_step` as well?"", 'comment_created': datetime.datetime(2022, 7, 3, 17, 42, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 912516900, 'comment_body': '```suggestion\r\n    std  = Statistics.std(data.table, dims=axes, mean=mean)\r\n```\r\nIf the data source supports it, this is more efficient.', 'comment_created': datetime.datetime(2022, 7, 3, 17, 42, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 912516928, 'comment_body': 'A little weird formatting going on here. Why is the reshape needed?', 'comment_created': datetime.datetime(2022, 7, 3, 17, 42, 51, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 912517245, 'comment_body': 'Returning one or two things based on a conditional is a little surprising. Consider either always returning class_val_list and/or making the second return value some meaningful null value (nothing, empty array, whatever makes the most sense).', 'comment_created': datetime.datetime(2022, 7, 3, 17, 46, 13, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 912517367, 'comment_body': 'You could also consider changing these to `AbstractMatrix{T}`, but it would be best to confirm first that they will always be 2-dimensional (what about higher-dimensional time series, for example?)', 'comment_created': datetime.datetime(2022, 7, 3, 17, 47, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 912620608, 'comment_body': 'Yeah this would work, we can have the normalisation over sample too but yeah for now this would look better.', 'comment_created': datetime.datetime(2022, 7, 4, 4, 39, 34, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 912623583, 'comment_body': 'Yeah this looks better, thanks ðŸ‘ ', 'comment_created': datetime.datetime(2022, 7, 4, 4, 49, 6, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 913352581, 'comment_body': 'Not sure about the higher dimensional series, I will have to check the literature or some examples online if I can find them.', 'comment_created': datetime.datetime(2022, 7, 5, 3, 11, 55, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 913355320, 'comment_body': 'Oh I can come up with examples easily enough, the question is whether the fastai docs have any :)', 'comment_created': datetime.datetime(2022, 7, 5, 3, 21, 57, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 913357792, 'comment_body': 'Oh, I will check that up before our meeting today.', 'comment_created': datetime.datetime(2022, 7, 5, 3, 30, 2, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 913358564, 'comment_body': ""Yes, I tried using `Statistics.stdm(itr, mean)` earlier, couldn't seem to get it working. Will look into it further and keep this comment open till then."", 'comment_created': datetime.datetime(2022, 7, 5, 3, 32, 53, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 922917001, 'comment_body': ""Something is a little weird here: you're returning a `Cell`, but inside that cell are `Recur`s and not `LSTMCell`s. Ideally `StackedLSTMCell` would be structured like the other Flux RNN cells, but if that's not possible I'd recommend renaming to `StackedLSTM` to better represent the model as stateful + containing internal mutation (transitively via `Recur` from `LSTM`)."", 'comment_created': datetime.datetime(2022, 7, 18, 0, 28, 29, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 922917023, 'comment_body': '```suggestion\r\nstruct StackedLSTMCell{A}\r\n```', 'comment_created': datetime.datetime(2022, 7, 18, 0, 28, 36, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 922917162, 'comment_body': 'This should be done explicitly through the `initb` argument of the LSTM(Cell) constructor if possible.', 'comment_created': datetime.datetime(2022, 7, 18, 0, 29, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 922917230, 'comment_body': '```suggestion\r\n```\r\nThis is redundant with the `@functor` above.', 'comment_created': datetime.datetime(2022, 7, 18, 0, 30, 8, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 922917406, 'comment_body': 'Is this always a sequence-to-one model?', 'comment_created': datetime.datetime(2022, 7, 18, 0, 31, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 922917549, 'comment_body': 'Is the input expected to be non-contiguous here? If not, I would compare against `size` instead of lengths of slices.', 'comment_created': datetime.datetime(2022, 7, 18, 0, 32, 9, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 922936839, 'comment_body': 'I think for classification and regression, this will always be a seq-to-one model ?\r\nFor some nlp tasks, it would not be.', 'comment_created': datetime.datetime(2022, 7, 18, 2, 24, 57, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 922987971, 'comment_body': ""Ok, then I think you should be able to rewrite this using `foldl`. It'll be more correct and likely perform better as well. It may also let you drop the `Recur` wrapper for the inner layer stack and use the cells directly instead (i.e. `LSTM -> LSTMCell`)."", 'comment_created': datetime.datetime(2022, 7, 18, 5, 49, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 928024947, 'comment_body': '```suggestion\r\n    X = collect(eachslice(X; dims=1))\r\n```\r\nShould be more efficient. But see comments below.', 'comment_created': datetime.datetime(2022, 7, 22, 22, 26, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 928025549, 'comment_body': ""I don't think we should be doing this dense to slices transform in the model itself. If you just need something RNN friendly, relying on the built-in support for dense inputs should be enough. The `permutedims` can stay for now, but even that probably shouldn't be in the gradient hot path (it allocates O(n) both ways)."", 'comment_created': datetime.datetime(2022, 7, 22, 22, 28, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 928025858, 'comment_body': 'An alternative for now is to make the data pipeline spit out the vector of arrays. We can then revisit if/when you add models like CNNs which expect dense inputs.', 'comment_created': datetime.datetime(2022, 7, 22, 22, 29, 43, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 928026031, 'comment_body': 'I think ""tabular"" is a bit of a misnomer here, but naming is not a priority.', 'comment_created': datetime.datetime(2022, 7, 22, 22, 30, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 928113822, 'comment_body': 'I think the ""ideal"" place to do this transform would be inside the training loop. I am not sure how to exactly do that for FastAI.jl. Is there a way ?\r\n\r\nSince the second phase would involve using some CNNs, using data pipeline to spit out vector of arrays would not work.', 'comment_created': datetime.datetime(2022, 7, 23, 11, 41, 35, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}]","[{'commit_sha': '62e05d8baba5dad951776aca861ea1e754c221a6', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f34952de9c83eee5d1840c481753d6049e676d21', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dd57498efe51eea8c1f706648fff1db96e7620f0', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9117ac6de2ceaa4d590186d3e990c1f0dd803419', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6d85a5dfdce0db38e8411575ae70aead154ce4f8', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd432f41ba4ab70170f5cd665a11cda2e22450704', 'committer_username': 'github-actions[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 30, 9, 30, 16, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b4fffa1e8f3eb0768fad066c8982431b488205de', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '972fa0c496fa902cb91bcf542b0eefa1de30fdb4', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4229f7edb1c9e625c02d8d2cc6f2c4014ee34b20', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c0cbc53b0d7adef5f6ce132701faf246b7d6319c', 'committer_username': 'lorenzoh', 'committer_name': None, 'committer_email': 'lorenz.ohly@gmail.com', 'commit_date': datetime.datetime(2017, 5, 19, 17, 4, 52, tzinfo=datetime.timezone.utc)}, {'commit_sha': '19b1af4e0b5fe6a3e34ce3e85bb7a4a62c99d491', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '06e6b070d36141f8821288368aefac99104fe0c1', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4ba57d95daa20a8f8e80c18d8923f953f126c7cf', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'aab2c1fc0bcf0e4cb45ceae7e2390543905571f5', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e543dc7d32a01af0300210ccb6ebed1248d13a35', 'committer_username': 'lorenzoh', 'committer_name': None, 'committer_email': 'lorenz.ohly@gmail.com', 'commit_date': datetime.datetime(2017, 5, 19, 17, 4, 52, tzinfo=datetime.timezone.utc)}, {'commit_sha': '024bc58806662474df88cd398f1f0b6c588e5bcf', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '371ae471f38f97fe8330b3aa340b790b3404ae58', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8b73eadfc6d3112d3077cce840e2adca3b4f133e', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cd7959073b4b6053ddee484ded4cf821f8b756c2', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '234d3fc0a2419546a9234a7253f53f28d66e7882', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a5236c8da9474fecfa65b69d50339a897d98a1a0', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9f84954475a8c050171f1ad3ef70624bf9e2b647', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}]",Saksham,40931412,,User,,59,,18,21
1012302192,Added Model for Time Series Classification,"I have added the code for a basic RNN Model for the task of time series classification.

```Julia
> data, blocks = load(datarecipes()[""ecg5000""]);
> task = TSClassificationSingle(blocks, data);
> model = FastAI.taskmodel(task);
> traindl, validdl = taskdataloaders(data, task, 32);
> callbacks = [ToGPU(), Metrics(accuracy)];
> learner = Learner(model, tasklossfn(task); data=(traindl, validdl), optimizer=ADAM(), callbacks = callbacks);
> fitonecycle!(learner, 10, 0.033)
```

<img width=""391"" alt=""image"" src=""https://user-images.githubusercontent.com/40931412/181833458-cbf60136-d34c-4dde-ae72-c3cc173efe35.png"">

As I discussed with @darsnack, the idea is to add an encoding to do the reshaping to (features, batch, time) instead of doing it inside on the RNN Model. Working on that right now.

Have remove the type from StackedLSTM as it was redundant. ",True,253,https://api.github.com/repos/FluxML/FastAI.jl/pulls/253,https://github.com/FluxML/FastAI.jl/pull/253,closed,952,78,14,5,9,17,0,0,[],2022-07-29 19:51:28+00:00,2022-09-16 19:46:44+00:00,4233316.0,"48 days, 23:55:16","[{'comment_id': 934041230, 'comment_body': '```suggestion\r\n    return RNNModel(recbackbone, Dense(recout, outsize))\r\n```', 'comment_created': datetime.datetime(2022, 7, 31, 21, 24, 45, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 934041450, 'comment_body': '```suggestion\r\n    return Models.RNNModel(backbone, outsize = length(outblock.classes), recout = size(output, 1))\r\n```', 'comment_created': datetime.datetime(2022, 7, 31, 21, 26, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960207297, 'comment_body': 'The `chain =` here can be a `return`.', 'comment_created': datetime.datetime(2022, 9, 1, 4, 28, 8, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960207997, 'comment_body': 'is it intentional to have the initial state trainable? If not, I would add `ChainRulesCore` as a dependency and wrap the `reset!` call like so:\r\n```suggestion\r\n    ChainRulesCore.ignore_derivatives() do\r\n        Flux.reset!(m.recbackbone)\r\n    end\r\n```', 'comment_created': datetime.datetime(2022, 9, 1, 4, 30, 18, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960208296, 'comment_body': '```suggestion\r\ntabular2rnn(X::AbstractArray{<:AbstractFloat, 3}) = permutedims(X, (1, 3, 2))\r\n```', 'comment_created': datetime.datetime(2022, 9, 1, 4, 31, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960208702, 'comment_body': 'Is this one-line code pattern used elsewhere? Otherwise it wouldn\'t hurt to add some newlines.\r\n```suggestion\r\n@testset ""blockbackbone"" begin\r\n    @test_nowarn FastAI.blockbackbone(TimeSeriesRow(1,140))\r\nend\r\n```', 'comment_created': datetime.datetime(2022, 9, 1, 4, 32, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960209043, 'comment_body': '```suggestion\r\n```\r\nNot relevant any more?', 'comment_created': datetime.datetime(2022, 9, 1, 4, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960209436, 'comment_body': 'Should be using [`Flux.outputsize`](https://fluxml.ai/Flux.jl/stable/utilities/#Flux.outputsize) (I think we talked about this in a meeting). Changes required should be minimal :)', 'comment_created': datetime.datetime(2022, 9, 1, 4, 34, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960210030, 'comment_body': ""```suggestion\r\n```\r\nI don't see Zygote used anywhere, so one less dependency doesn't hurt."", 'comment_created': datetime.datetime(2022, 9, 1, 4, 35, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960210155, 'comment_body': '```suggestion\r\n```\r\nSame as above.', 'comment_created': datetime.datetime(2022, 9, 1, 4, 35, 59, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 962119290, 'comment_body': 'I think I saw it somewhere, but yeah the new lines look better.', 'comment_created': datetime.datetime(2022, 9, 3, 7, 43, 42, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 962247642, 'comment_body': 'I tried doing that, but it throws an error \r\n```julia\r\nERROR: LoadError: ArgumentError: Package FastTimeSeries does not have Zygote in its dependencies:`\r\n```', 'comment_created': datetime.datetime(2022, 9, 4, 4, 21, 12, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 962249397, 'comment_body': 'I tried doing that, but seems to give an error. Will try to debug it later.\r\nhttps://pastebin.com/mB7aYvdD', 'comment_created': datetime.datetime(2022, 9, 4, 4, 44, 2, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 962350536, 'comment_body': ""This really could use a full stack trace, because AFAICT you're not using Zygote anywhere? Did you `] resolve` after removing it from the project?"", 'comment_created': datetime.datetime(2022, 9, 4, 18, 13, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 962352775, 'comment_body': ""I see, this is https://github.com/FluxML/Flux.jl/pull/1755#issue-1035506488. Can you do the following then?\r\n- Use `zeros` or `ones` instead of `rand`.\r\n- Pass a batch size of 1 instead of 32 and seq length of 1 instead of `inblock.obslength`. This will save some time and you don't need it because you only care about the first output dimension.\r\n- `reset!` the backbone after you calculate `output`."", 'comment_created': datetime.datetime(2022, 9, 4, 18, 35, 11, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 962355959, 'comment_body': 'seems to work now, might have missed the `resolve`. thanks :)', 'comment_created': datetime.datetime(2022, 9, 4, 19, 3, 6, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 962355975, 'comment_body': 'Yes, sounds great.', 'comment_created': datetime.datetime(2022, 9, 4, 19, 3, 18, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}]","[{'commit_sha': '52a193243cbb1b5c95201fef0d8aacac638c7c3f', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '18cb1da53773cc6cc01682caf1b87f8b2f180d5a', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ec6abe555dcacaaed6d0e2e49c2efd927ae0c46d', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f6834f64af9651cca1c03a64f524dfc96bbcbed5', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '54e8ebfad83e137e64de48f9da210b646d0c248d', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}]",Saksham,40931412,,User,,59,,18,21
1025797668,InceptionTime Model for Time Series,"This PR will contain the implementation of InceptionTime Model and it's use for classification and regression task.

Some of the commits from the PR #253 are also in this PR, but will take care of them when that PR is merged. ",True,256,https://api.github.com/repos/FluxML/FastAI.jl/pulls/256,https://github.com/FluxML/FastAI.jl/pull/256,closed,1021,54,13,12,9,13,0,0,[],2022-08-14 12:38:55+00:00,2022-09-27 03:41:20+00:00,3769345.0,"43 days, 15:02:25","[{'comment_id': 945332343, 'comment_body': ""I think all this could be done using Flux's built-in branching/sequencing layers. `Chain` and `Parallel` in particular."", 'comment_created': datetime.datetime(2022, 8, 14, 19, 23, 11, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 945332386, 'comment_body': ""Note that `BatchNorm` takes an activation function. I think it's faster than applying one externally, but either way it's more correct."", 'comment_created': datetime.datetime(2022, 8, 14, 19, 23, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 945332510, 'comment_body': '[`Flux.outputsize`](https://fluxml.ai/Flux.jl/stable/utilities/#Flux.outputsize) was designed for precisely this.', 'comment_created': datetime.datetime(2022, 8, 14, 19, 24, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 945408187, 'comment_body': 'Yeah just looked up the documentation, I think using Parallel for this would work. Would make the changes.\r\n', 'comment_created': datetime.datetime(2022, 8, 15, 3, 44, 17, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 960213751, 'comment_body': 'I thought permuting was not required for the conv-based models? Or are .ts datasets read in as `features x timesteps x batch`?', 'comment_created': datetime.datetime(2022, 9, 1, 4, 45, 12, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960214067, 'comment_body': ""I think it makes more sense to have `Conv1d` be lowercase `conv1d`, but that's a minor thing."", 'comment_created': datetime.datetime(2022, 9, 1, 4, 45, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 960215105, 'comment_body': ""```suggestion\r\n    ks = [iseven(ks[i]) ? ks[i] - 1 : ks[i] for i in 1:3]  # ensure odd ks\r\n```\r\nAlmost always prefer range syntax to the function (I haven't added suggestions for above and below, but this applies there too). I think it may also help not to use the same variable name (`ks`) for the original input parameter and your subsequent list of kernel sizes."", 'comment_created': datetime.datetime(2022, 9, 1, 4, 48, 43, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 962685142, 'comment_body': 'When we load the data, it has the shape `num_samples  x features x timesteps`. Intuitively this look easier to understand.', 'comment_created': datetime.datetime(2022, 9, 5, 9, 18, 3, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}, {'comment_id': 963231301, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2022, 9, 6, 4, 0, 29, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 963231439, 'comment_body': 'Still many wild `range`s floating around ;)', 'comment_created': datetime.datetime(2022, 9, 6, 4, 0, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 963232588, 'comment_body': ""```suggestion\r\nfunction RNNModel(recbackbone; outsize, recout)\r\n```\r\nExtra `kwargs` don't appear to be used here?"", 'comment_created': datetime.datetime(2022, 9, 6, 4, 3, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 963233326, 'comment_body': 'These `in` and `out` arg names should be harmonized across the various time series models (i.e. InceptionTime and StackedLSTM).', 'comment_created': datetime.datetime(2022, 9, 6, 4, 6, 11, tzinfo=datetime.timezone.utc), 'commenter': 'ToucheSir', 'type': 'User'}, {'comment_id': 963235106, 'comment_body': 'Yeah, will fix that in the next commit.', 'comment_created': datetime.datetime(2022, 9, 6, 4, 11, 18, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}]","[{'commit_sha': 'b5f4904819cd34aee5e3b6c87ead276d842b7020', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a810c60d3b285b843d7e2303786cce8612048245', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '44d4cbb19490007cec88b8fc6bc3d232a26033ab', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '66675f7f49db7cdf2a95ce7f7cabff3e709b9cc5', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '18f2eb3c5aaf8b6995dfc45b364693333812f3ac', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a326e36dfdd5a3c799f4448aae5cb0fae8d46bae', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ef979fc4449f0e1ec3dd27200f3466fa6a343c0f', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '07b16dc25a79f7732815775b7da5833cac6bf15d', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7a56399a50ff3b468ba0ab925e77c71e997ca1c', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '77109c3bf1a6ef48007b6c57ca73f2519b1615d6', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '67a989aeffa19a0714cfc652696de7baa7bf3077', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '45160f64f27e5ba3f3667fa00fe0463b322e9947', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}]",Saksham,40931412,,User,,59,,18,21
1052201034,[WIP]  Blog about working with Time Series Data using FastAI.jl,"This blog demonstrates the work done for adding time series support to FastAI.jl as part of GSoC 22. It contains basic sample code and gives an overview of currently supported features under this submodule. Will add more stuff in the future.
This was done under the mentorship of @darsnack @ToucheSir @lorenzoh .",False,140,https://api.github.com/repos/FluxML/fluxml.github.io/pulls/140,https://github.com/FluxML/fluxml.github.io/pull/140,open,103,0,2,4,4,13,0,0,[],2022-09-10 09:11:53+00:00,,0.0,,"[{'comment_id': 967825092, 'comment_body': '""Adding Time Series Support to FastAI.jl""  may be a bit clearer.  ', 'comment_created': datetime.datetime(2022, 9, 11, 13, 1, 37, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 967825298, 'comment_body': '```suggestion\r\nModels for time series data constitute an integral part of any machine learning stack. This blog post will demonstrate how to start working with time series data with FastAI.jl and the [FastTimeSeries](https://github.com/FluxML/FastAI.jl/tree/master/FastTimeSeries) submodule. The work presented here was done as part of [GSoC\'22](https://summerofcode.withgoogle.com/programs/2022/projects/Q9GVFW33) under the mentorship of Brian Chen, Kyle Daruwalla, and Lorenz Ohly.\r\n```\r\n\r\nLet\'s use ""time series"" (lowercase, no hyphen) consistently throughout the blog post since there are a few different spellings being used ', 'comment_created': datetime.datetime(2022, 9, 11, 13, 2, 54, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 968461891, 'comment_body': 'Might be worth crediting tsai here as an inspiration?', 'comment_created': datetime.datetime(2022, 9, 12, 14, 2, 30, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968464126, 'comment_body': '```suggestion\r\nThe library supports `TSClassificationSingle` and `TSRegression` tasks--used for single label time-series classification and single label time-series regression, respectively. We will pass our `data` and `blocks` from the previous step into the task:\r\n\r\n```julia\r\njulia> task = TSClassificationSingle(blocks, data);\r\n```\r\n```', 'comment_created': datetime.datetime(2022, 9, 12, 14, 4, 31, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968468207, 'comment_body': '```suggestion\r\nAlthough `data` can already be passed to `DataLoader` for loading during training, we would often like to perform transformations on it. We can encode a sample input using `encodesample(task, Phase(), sample)` where `Phase` is a [FluxTraining.jl phase](https://fluxml.ai/FluxTraining.jl/dev/documents/docs/reference/training.md).\r\n```', 'comment_created': datetime.datetime(2022, 9, 12, 14, 8, 5, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968469074, 'comment_body': 'Is this not what FluxTraining calls it @lorenzoh?\r\n```suggestion\r\njulia> encodesample(task, TrainingPhase(), (input, class))\r\n```', 'comment_created': datetime.datetime(2022, 9, 12, 14, 8, 47, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968469526, 'comment_body': '```suggestion\r\n- Basic stacked RNNs\r\n```', 'comment_created': datetime.datetime(2022, 9, 12, 14, 9, 12, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968469955, 'comment_body': 'Include a description of what the arguments mean?', 'comment_created': datetime.datetime(2022, 9, 12, 14, 9, 35, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968471062, 'comment_body': '```suggestion\r\n- [InceptionTime](https://arxiv.org/abs/1909.04939)\r\n```', 'comment_created': datetime.datetime(2022, 9, 12, 14, 10, 30, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968471301, 'comment_body': 'Same comment about the arguments', 'comment_created': datetime.datetime(2022, 9, 12, 14, 10, 42, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968473610, 'comment_body': 'Can you expand here more? A summary of everything above as a bulleted list would be good. Think of it as a way for GSoC reviewers to see your contributions at a glance. And as Brian mentioned, add some notes about future work.', 'comment_created': datetime.datetime(2022, 9, 12, 14, 12, 39, tzinfo=datetime.timezone.utc), 'commenter': 'darsnack', 'type': 'User'}, {'comment_id': 968493580, 'comment_body': ""Yeah, that's confusing ðŸ˜…  but the original is correct. `Training <: FastAI.Context` is used in data processing pipelines, while `TrainingPhase <: FluxTraining.Phase` is used when training. They are not the same thing, though. "", 'comment_created': datetime.datetime(2022, 9, 12, 14, 29, 28, tzinfo=datetime.timezone.utc), 'commenter': 'lorenzoh', 'type': 'User'}, {'comment_id': 968756973, 'comment_body': 'yes :)', 'comment_created': datetime.datetime(2022, 9, 12, 18, 13, 10, tzinfo=datetime.timezone.utc), 'commenter': 'codeboy5', 'type': 'User'}]","[{'commit_sha': 'c4727668115f6f101020ad682f87dd84c5d272c2', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1f820a08e0cca94230a67fb23e576e8115eac1ae', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e1cd2201e197c56d0ac27360ab991f14ea4b620f', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4eb6316085d9563df044b1f419c7bb1ef8945e5a', 'committer_username': 'codeboy5', 'committer_name': 'Saksham', 'committer_email': None, 'commit_date': datetime.datetime(2018, 7, 8, 7, 10, 20, tzinfo=datetime.timezone.utc)}]",Saksham,40931412,,User,,59,,18,21

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
265704822,FastAI.jl,FluxML/FastAI.jl,Julia,51,586,25,24,341,27,22,8,"[{'id': 1025797668, 'number': 256, 'closed': datetime.datetime(2022, 9, 27, 3, 41, 20, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 8, 14, 12, 38, 55, tzinfo=datetime.timezone.utc), 'time_taken': 3769345.0, 'time_delta': '43 days, 15:02:25', 'additions': 1021, 'deletions': 54, 'state': 'closed'}, {'id': 1012302192, 'number': 253, 'closed': datetime.datetime(2022, 9, 16, 19, 46, 44, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 7, 29, 19, 51, 28, tzinfo=datetime.timezone.utc), 'time_taken': 4233316.0, 'time_delta': '48 days, 23:55:16', 'additions': 952, 'deletions': 78, 'state': 'closed'}, {'id': 971194816, 'number': 239, 'closed': datetime.datetime(2022, 7, 29, 10, 55, 53, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 6, 18, 6, 36, 43, tzinfo=datetime.timezone.utc), 'time_taken': 3557950.0, 'time_delta': '41 days, 4:19:10', 'additions': 8416, 'deletions': 7380, 'state': 'closed'}, {'id': 871568888, 'number': 199, 'closed': datetime.datetime(2022, 5, 23, 12, 21, 8, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 3, 4, 11, 20, 12, tzinfo=datetime.timezone.utc), 'time_taken': 6915656.0, 'time_delta': '80 days, 1:00:56', 'additions': 370, 'deletions': 5, 'state': 'closed'}]"
106007826,fluxml.github.io,FluxML/fluxml.github.io,HTML,45,20,9,50,537,16,4,5,"[{'id': 1052201034, 'number': 140, 'closed': None, 'created': datetime.datetime(2022, 9, 10, 9, 11, 53, tzinfo=datetime.timezone.utc), 'time_taken': 0.0, 'time_delta': '', 'additions': 103, 'deletions': 0, 'state': 'open'}]"

pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
471941695,[ENH][DOC] local Geary statistics,"**Purpose of PR**

This PR addresses bullet point 7 and 8 of #61. Specifically, this PR adds two new functions to estimate:
- Local Geary statistics - univariate (function name: `Local_Geary`)
- Local Geary statistics - multivariate (function name: `Local_Geary_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

One notebook is included in the PR. The notebook reviews the core math of the statistic and explains the basic use of the statistic following examples provided by [Anselin (2017)](https://geodacenter.github.io/docs/LA_multivariateGeary1.pdf).

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in two .py test files that execute successfully [on a branch specifically for the Geary estimators](https://github.com/jeffcsauer/esda/tree/gearybranch). These new tests follow the lead of the existing tests, specifically `test_moran.py`.

**Notes for PR consideration**

- The univariate local Geary is numba-ized, whereas the multivariate local Geary uses a modified form of the old `_crand()` engine.",True,145,https://api.github.com/repos/pysal/esda/pulls/145,https://github.com/pysal/esda/pull/145,closed,2951,12,18,14,11,0,0,0,[],2020-08-22 05:38:15+00:00,2021-01-18 16:38:31+00:00,12913216.0,"149 days, 11:00:16",[],"[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '13dbad174e8e5652a83b566e0040cffbefa8ff6e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'dfab1cb1efc958b621d2b50c50b972096c94a58d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '449e767af469c5d10d82f784852352b3fd47e28c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '06485140033a0df7ed253eab373bda62ed8867a9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ffc1b30b90bc1ce86df06a7b90e32bbe65a2afcf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8cd43031c97513de9c78ae09d327d42c19ec4087', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7e3a566d57b48cd22a562cb6131d80ac718658b', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd4b0506bb3170aa85b06de9b3aa3941ce5f3b3f', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '303c188c1ce38e184a255ed8d04bdd7c53ff4e95', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '47cc073dae5d333003f57c5abdd18e928f7a9023', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '75318b4dc72e4d6bf83ef87a4c27420d33119cf3', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0fcf7ce885c8f6999ed9b62e87c6b3ce6d4ac05', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}]",Jeff Sauer,31426294,,User,,15,,144,34
471941695,[ENH][DOC] local Geary statistics,"**Purpose of PR**

This PR addresses bullet point 7 and 8 of #61. Specifically, this PR adds two new functions to estimate:
- Local Geary statistics - univariate (function name: `Local_Geary`)
- Local Geary statistics - multivariate (function name: `Local_Geary_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

One notebook is included in the PR. The notebook reviews the core math of the statistic and explains the basic use of the statistic following examples provided by [Anselin (2017)](https://geodacenter.github.io/docs/LA_multivariateGeary1.pdf).

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in two .py test files that execute successfully [on a branch specifically for the Geary estimators](https://github.com/jeffcsauer/esda/tree/gearybranch). These new tests follow the lead of the existing tests, specifically `test_moran.py`.

**Notes for PR consideration**

- The univariate local Geary is numba-ized, whereas the multivariate local Geary uses a modified form of the old `_crand()` engine.",True,145,https://api.github.com/repos/pysal/esda/pulls/145,https://github.com/pysal/esda/pull/145,closed,2951,12,18,14,11,0,0,0,[],2020-08-22 05:38:15+00:00,2021-01-18 16:38:31+00:00,12913216.0,"149 days, 11:00:16",[],"[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '13dbad174e8e5652a83b566e0040cffbefa8ff6e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'dfab1cb1efc958b621d2b50c50b972096c94a58d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '449e767af469c5d10d82f784852352b3fd47e28c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '06485140033a0df7ed253eab373bda62ed8867a9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ffc1b30b90bc1ce86df06a7b90e32bbe65a2afcf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8cd43031c97513de9c78ae09d327d42c19ec4087', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7e3a566d57b48cd22a562cb6131d80ac718658b', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd4b0506bb3170aa85b06de9b3aa3941ce5f3b3f', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '303c188c1ce38e184a255ed8d04bdd7c53ff4e95', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '47cc073dae5d333003f57c5abdd18e928f7a9023', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '75318b4dc72e4d6bf83ef87a4c27420d33119cf3', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0fcf7ce885c8f6999ed9b62e87c6b3ce6d4ac05', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}]",Jeff Sauer,31426294,,User,,15,,144,34
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
453658682,[ENH][DOC] local join count and LOSH statistics,"**Purpose of PR**

This PR addresses bullet point 1, 5, and 6 of #61. Specifically, this PR adds four new functions to estimate:
- Local spatial heteroskedasticity (function name: `losh`)
- Local join counts - univariate (function name: `Local_Join_Count`)
- Local join counts - bivariate (function name: `Local_Join_Count_BV`)
- Local join counts - multivariate (function name: `Local_Join_Count_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

Two notebooks are included in the PR. Each notebook briefly reviews the core math of the statistic and explains how a user might deploy the statistic in a geospatial workflow. The included examples match those found in [`R` `spdep::LOSH` and `spdep::LOSH.cs`](https://www.google.com/search?client=firefox-b-1-d&q=losh.cs) as well as the [GeoDa Local Join Counts tutorial](https://www.google.com/search?client=firefox-b-1-d&lei=ytAVX7L4EYKztAb23K9A&q=local%20indicators%20of%20spatial%20association&ved=2ahUKEwiyhYuJqtzqAhWCGc0KHXbuCwgQsKwBKAB6BAgPEAE&biw=1920&bih=938).  

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in four .py test files that execute successfully [on my fork](https://github.com/jeffcsauer/esda). These new tests follow the lead of the existing tests, specifically `test_moran.py` for the LOSH function and `test_join_counts.py` for the local join count functions.

**Notes for PR consideration**

- Local join count functions are currently using the default `n_jobs=1` to avoid issues fixed in potential [merges](#diff-1fd239570b4623d6ce23f0e268495633L510). Users may enter values other than 1. 
- One doctest dataset, `commpop`, appears to have a [dead link](https://geodacenter.github.io/data-and-lab/) at the moment. Having trouble loading this as a `libpysal.example`. Once this dataset is working the doctest can be updated. Currently hosting it on a personal Github link.",False,139,https://api.github.com/repos/pysal/esda/pulls/139,https://github.com/pysal/esda/pull/139,closed,1948,0,10,4,2,9,0,0,[],2020-07-20 17:19:07+00:00,2021-01-20 17:10:23+00:00,15897076.0,"183 days, 23:51:16","[{'comment_id': 479402614, 'comment_body': 'If you define permutations above, then you should probably not set the default here again! Maybe use `permutations=PERMUTATIONS`, or remove the constant from the top of the file?\r\n\r\nAlso `sklearn` estimators generally put these kinds of options in the init, not fit. And, all `sklearn` estimators, even the unsupervised ones, [take both an X and a y](https://scikit-learn.org/stable/developers/develop.html#fitting)... we should follow those conventions, I think.', 'comment_created': datetime.datetime(2020, 8, 28, 16, 13, 5, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403371, 'comment_body': 'Again, generally, sklearn calls these `X` and `y`. Can we use that here? ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403794, 'comment_body': 'This should be `LOSH` keeping with style elsewhere. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479403992, 'comment_body': '`a=2` should be in the init, and again on `X` and `y` as the arguments here. ', 'comment_created': datetime.datetime(2020, 8, 28, 16, 15, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ljwolf', 'type': 'User'}, {'comment_id': 479461156, 'comment_body': 'Changed to `LOSH` in https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9', 'comment_created': datetime.datetime(2020, 8, 28, 18, 10, 36, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479461449, 'comment_body': 'Moved `a=2` to init, and given that losh is univariate changed `y` to `x` in `fit(...)`, can you confirm on https://github.com/pysal/esda/pull/139/commits/3b47da838127a6e9677158ac9d11a2b321a8bef9? ', 'comment_created': datetime.datetime(2020, 8, 28, 18, 11, 16, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601447, 'comment_body': 'Fixed permutations such that it is part of `init(...)` and removed constant from top of file. Applied to all LJC functions. See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 31, 9, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}, {'comment_id': 479601586, 'comment_body': 'Changed for univariate and bivariate statistics. For multivariate statistics, kept input array as `variables`. Is this okay? Or should we change to `x`? Thought that `variables` is more explicit/clear compared to `x`, but totally open to changing it to be consistent! See https://github.com/pysal/esda/pull/139/commits/2eb0d37d059af4596a2ffd0e103820a7ae0dcd74.', 'comment_created': datetime.datetime(2020, 8, 29, 3, 33, 2, tzinfo=datetime.timezone.utc), 'commenter': 'jeffcsauer', 'type': 'User'}]","[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '3b47da838127a6e9677158ac9d11a2b321a8bef9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '2eb0d37d059af4596a2ffd0e103820a7ae0dcd74', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}]",Jeff Sauer,31426294,,User,,15,,144,34
471941695,[ENH][DOC] local Geary statistics,"**Purpose of PR**

This PR addresses bullet point 7 and 8 of #61. Specifically, this PR adds two new functions to estimate:
- Local Geary statistics - univariate (function name: `Local_Geary`)
- Local Geary statistics - multivariate (function name: `Local_Geary_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

One notebook is included in the PR. The notebook reviews the core math of the statistic and explains the basic use of the statistic following examples provided by [Anselin (2017)](https://geodacenter.github.io/docs/LA_multivariateGeary1.pdf).

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in two .py test files that execute successfully [on a branch specifically for the Geary estimators](https://github.com/jeffcsauer/esda/tree/gearybranch). These new tests follow the lead of the existing tests, specifically `test_moran.py`.

**Notes for PR consideration**

- The univariate local Geary is numba-ized, whereas the multivariate local Geary uses a modified form of the old `_crand()` engine.",True,145,https://api.github.com/repos/pysal/esda/pulls/145,https://github.com/pysal/esda/pull/145,closed,2951,12,18,14,11,0,0,0,[],2020-08-22 05:38:15+00:00,2021-01-18 16:38:31+00:00,12913216.0,"149 days, 11:00:16",[],"[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '13dbad174e8e5652a83b566e0040cffbefa8ff6e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'dfab1cb1efc958b621d2b50c50b972096c94a58d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '449e767af469c5d10d82f784852352b3fd47e28c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '06485140033a0df7ed253eab373bda62ed8867a9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ffc1b30b90bc1ce86df06a7b90e32bbe65a2afcf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8cd43031c97513de9c78ae09d327d42c19ec4087', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7e3a566d57b48cd22a562cb6131d80ac718658b', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd4b0506bb3170aa85b06de9b3aa3941ce5f3b3f', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '303c188c1ce38e184a255ed8d04bdd7c53ff4e95', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '47cc073dae5d333003f57c5abdd18e928f7a9023', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '75318b4dc72e4d6bf83ef87a4c27420d33119cf3', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0fcf7ce885c8f6999ed9b62e87c6b3ce6d4ac05', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}]",Jeff Sauer,31426294,,User,,15,,144,34
471941695,[ENH][DOC] local Geary statistics,"**Purpose of PR**

This PR addresses bullet point 7 and 8 of #61. Specifically, this PR adds two new functions to estimate:
- Local Geary statistics - univariate (function name: `Local_Geary`)
- Local Geary statistics - multivariate (function name: `Local_Geary_MV`)

Each function is written in the form of a scikit-learn style estimator. PEP8 formatting has been applied to all of the functions, although a handful of lines are left long due to readability.  

**Documentation**

One notebook is included in the PR. The notebook reviews the core math of the statistic and explains the basic use of the statistic following examples provided by [Anselin (2017)](https://geodacenter.github.io/docs/LA_multivariateGeary1.pdf).

All functions include docstrings and doctests that use built-in PySAL example datasets.

**Tests**

I have added in two .py test files that execute successfully [on a branch specifically for the Geary estimators](https://github.com/jeffcsauer/esda/tree/gearybranch). These new tests follow the lead of the existing tests, specifically `test_moran.py`.

**Notes for PR consideration**

- The univariate local Geary is numba-ized, whereas the multivariate local Geary uses a modified form of the old `_crand()` engine.",True,145,https://api.github.com/repos/pysal/esda/pulls/145,https://github.com/pysal/esda/pull/145,closed,2951,12,18,14,11,0,0,0,[],2020-08-22 05:38:15+00:00,2021-01-18 16:38:31+00:00,12913216.0,"149 days, 11:00:16",[],"[{'commit_sha': '066337fb4e1881566d831d65170aae81e64064b3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '55dd12308729a003d266ecbaf84534077ee0de1d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '13dbad174e8e5652a83b566e0040cffbefa8ff6e', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'dfab1cb1efc958b621d2b50c50b972096c94a58d', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '449e767af469c5d10d82f784852352b3fd47e28c', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '06485140033a0df7ed253eab373bda62ed8867a9', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': 'ffc1b30b90bc1ce86df06a7b90e32bbe65a2afcf', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '8cd43031c97513de9c78ae09d327d42c19ec4087', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7e3a566d57b48cd22a562cb6131d80ac718658b', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd4b0506bb3170aa85b06de9b3aa3941ce5f3b3f', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '303c188c1ce38e184a255ed8d04bdd7c53ff4e95', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '47cc073dae5d333003f57c5abdd18e928f7a9023', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': '75318b4dc72e4d6bf83ef87a4c27420d33119cf3', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0fcf7ce885c8f6999ed9b62e87c6b3ce6d4ac05', 'committer_username': 'ljwolf', 'committer_name': 'Levi John Wolf', 'committer_email': 'levi.john.wolf@gmail.com', 'commit_date': datetime.datetime(2012, 8, 30, 20, 40, 5, tzinfo=datetime.timezone.utc)}]",Jeff Sauer,31426294,,User,,15,,144,34

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
81873636,esda,pysal/esda,Jupyter Notebook,55,210,27,35,1126,37,3,11,"[{'id': 787997500, 'number': 195, 'closed': datetime.datetime(2021, 12, 10, 12, 54, 54, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 11, 24, 14, 17, 4, tzinfo=datetime.timezone.utc), 'time_taken': 1377470.0, 'time_delta': '15 days, 22:37:50', 'additions': 7, 'deletions': 1, 'state': 'closed'}, {'id': 595696388, 'number': 170, 'closed': datetime.datetime(2021, 6, 27, 18, 0, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 3, 18, 15, 42, 31, tzinfo=datetime.timezone.utc), 'time_taken': 8734659.0, 'time_delta': '101 days, 2:17:39', 'additions': 6, 'deletions': 8, 'state': 'closed'}, {'id': 471941695, 'number': 145, 'closed': datetime.datetime(2021, 1, 18, 16, 38, 31, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 22, 5, 38, 15, tzinfo=datetime.timezone.utc), 'time_taken': 12913216.0, 'time_delta': '149 days, 11:00:16', 'additions': 2951, 'deletions': 12, 'state': 'closed'}, {'id': 453658682, 'number': 139, 'closed': datetime.datetime(2021, 1, 20, 17, 10, 23, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 20, 17, 19, 7, tzinfo=datetime.timezone.utc), 'time_taken': 15897076.0, 'time_delta': '183 days, 23:51:16', 'additions': 1948, 'deletions': 0, 'state': 'closed'}, {'id': 392035262, 'number': 110, 'closed': datetime.datetime(2020, 3, 22, 16, 51, 44, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 22, 16, 41, 42, tzinfo=datetime.timezone.utc), 'time_taken': 602.0, 'time_delta': '0:10:02', 'additions': 2, 'deletions': 2, 'state': 'closed'}]"

pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
426779441,Improve Sync Data Structures,"<!-- Provide a general summary of your changes in the Title above -->
## Description
<!-- Describe your changes in detail -->
This PR is related to #249 . In this PR, we are implementing `SyncedCollection`, `SyncedAttrDict`, `SyncedList`, `JSONCollection`, `JSONDict`, `JSONList`.

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
This refractor is to provide support for the multiple backends and resolve #196.
## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [x] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac/blob/master/changelog.txt) and added all related issue and pull request numbers for future reference (if applicable). See example below.


Example for a changelog entry: `Fix issue with launching rockets to the moon (#101, #212).`
",True,336,https://api.github.com/repos/glotzerlab/signac/pulls/336,https://github.com/glotzerlab/signac/pull/336,closed,1356,13,9,58,20,217,1,1,[{'name': 'GSoC'}],2020-06-02 19:15:27+00:00,2020-07-31 14:39:59+00:00,5081072.0,"58 days, 19:24:32","[{'comment_id': 436014670, 'comment_body': 'Can you elaborate on the purpose of the explicit check?', 'comment_created': datetime.datetime(2020, 6, 5, 15, 57, 30, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 436015029, 'comment_body': ""This doc-string is non-standard. I'm surprised that the style checker didn't complain."", 'comment_created': datetime.datetime(2020, 6, 5, 15, 58, 10, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 438487983, 'comment_body': 'What’s the case that `Collection` can’t be imported? Is it only present in specific Python versions?', 'comment_created': datetime.datetime(2020, 6, 11, 1, 7, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438488815, 'comment_body': '@csadorf The style check is still only applied to a specific set of files. It is not yet active on the entire code base.', 'comment_created': datetime.datetime(2020, 6, 11, 1, 10, 30, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438489403, 'comment_body': 'This should probably be a static method.', 'comment_created': datetime.datetime(2020, 6, 11, 1, 12, 41, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438489972, 'comment_body': 'Should this class be abstract? Should it have abstract methods like `to_base`?', 'comment_created': datetime.datetime(2020, 6, 11, 1, 14, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438490669, 'comment_body': 'Do we care about specifying the behavior if an error occurs during synchronization? Should it be able to roll back any changes to `_data`? (This may be less important than performance.)', 'comment_created': datetime.datetime(2020, 6, 11, 1, 17, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438491594, 'comment_body': 'Should this be a module-level constant? I wonder if this creates memory space for the tuple with every instantiation of the object or just for the class.', 'comment_created': datetime.datetime(2020, 6, 11, 1, 21, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438492011, 'comment_body': 'When would this fail? Seems like `self._data` always exists after construction?', 'comment_created': datetime.datetime(2020, 6, 11, 1, 23, 5, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438492353, 'comment_body': 'This docstring sounds a little misleading to me. The conversion is to _base_ (unsynced) collections, not synced elements.', 'comment_created': datetime.datetime(2020, 6, 11, 1, 24, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438493243, 'comment_body': 'A non-string sequence.', 'comment_created': datetime.datetime(2020, 6, 11, 1, 27, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438495657, 'comment_body': ""Is there a reason to prefer `'rb'` and `decode()` versus just using `'r'`? (I have not tested this.)"", 'comment_created': datetime.datetime(2020, 6, 11, 1, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438496375, 'comment_body': 'We might put “parent” before “write_concern”?', 'comment_created': datetime.datetime(2020, 6, 11, 1, 40, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 438496450, 'comment_body': 'Update copyright years on any new files.', 'comment_created': datetime.datetime(2020, 6, 11, 1, 41, 16, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 439539910, 'comment_body': '`Collection` is not present in `Python3.5`. They added it 3.6 so need to define it for Pyhton3.5 ', 'comment_created': datetime.datetime(2020, 6, 12, 17, 3, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 439544200, 'comment_body': '`SyncedCollection` is an abstract class as it inherits from `Collection` (`__contains__, __iter__, __len__` are not defined). I have not defined `load` and `sync` as abstract so that I can create an instance of `SyncedDict` and `SyncedList`. But not sure about `to_base`. Should I define it as an abstract method?', 'comment_created': datetime.datetime(2020, 6, 12, 17, 13, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 439546730, 'comment_body': 'Okay, will change it.', 'comment_created': datetime.datetime(2020, 6, 12, 17, 18, 20, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 439554114, 'comment_body': 'No, there is no specific reason. I have tried to match the old implementation.', 'comment_created': datetime.datetime(2020, 6, 12, 17, 33, 19, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 439743072, 'comment_body': ""I think it's slightly more performant and explicit. "", 'comment_created': datetime.datetime(2020, 6, 13, 14, 27, 47, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 439762327, 'comment_body': ""It fails while creating an instance of a child of `SyncedDict`(before the data is assigned). I don't need to add the data members of the child in `_Protected_key` as long as they are assigned before the call of `super().__init__()`.  "", 'comment_created': datetime.datetime(2020, 6, 13, 19, 17, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 439853973, 'comment_body': 'This is a good solution! Python 3.5 will be end-of-life in September, so we may refactor and remove support for Python 3.5 someday. Please add a comment (suggestion below) indicating why you created the fallback. It\'s important that the comment includes the words ""3.5"" and ""3.6"" so we know when this support can be removed.\r\n```suggestion\r\n    # Collection does not exist in Python 3.5, only Python 3.6 or newer.\r\n```', 'comment_created': datetime.datetime(2020, 6, 14, 18, 3, 53, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 439854752, 'comment_body': ""You're right, it is abstract already. When do you need to instantiate `SyncedDict` or `SyncedList`? Should those classes (and `_load`, `_sync`) also be abstract, until you have a backend specified in a subclass? I agree that `to_base` should be abstract."", 'comment_created': datetime.datetime(2020, 6, 14, 18, 13, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 439854951, 'comment_body': ""Another possibility would be to use `__slots__` to have a static allocation of attributes. It might be worth a try, but don't worry about it if it is difficult or presents new problems. https://book.pythontips.com/en/latest/__slots__magic.html"", 'comment_created': datetime.datetime(2020, 6, 14, 18, 16, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 439855647, 'comment_body': 'I might retract my suggestion to use `__slots__`. I saw a comment on this webpage and maybe it is not a helpful idea. It sounds like all instances might share one copy of the `_PROTECTED_KEYS` data. https://www.python-course.eu/python3_slots.php\r\n\r\n> We mentioned in the beginning that slots are preventing a waste of space with objects. Since Python 3.3 this advantage is not as impressive any more. With Python 3.3 Key-Sharing Dictionaries are used for the storage of objects. The attributes of the instances are capable of sharing part of their internal storage between each other, i.e. the part which stores the keys and their corresponding hashes. This helps to reduce the memory consumption of programs, which create many instances of non-builtin types. ', 'comment_created': datetime.datetime(2020, 6, 14, 18, 25, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 439855909, 'comment_body': '@csadorf is probably right about performance. I will resolve this comment.', 'comment_created': datetime.datetime(2020, 6, 14, 18, 29, 31, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 440893727, 'comment_body': 'Sorry if this caused confusion, I suggested this to Vishav a while ago.', 'comment_created': datetime.datetime(2020, 6, 16, 14, 26, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440903765, 'comment_body': ""I agree, make methods abstract that must be implemented by specific back ends. In the long run, I don't think anything in the second level of the inheritance tree should be concrete, i.e. both SyncedDict and JSONCollection should be abstract. Until both parts are combined into a JSONDict, it shouldn't be possible to instantiate."", 'comment_created': datetime.datetime(2020, 6, 16, 14, 39, 48, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440913106, 'comment_body': ""For posterity, this code is adapted almost verbatim from the Python library itself (https://github.com/python/cpython/blob/master/Lib/_collections_abc.py). @vishav1771 we'll need to be careful and double-check that this implementation is valid. The Python documentation has conflicting information and I'm not 100% sure I gave you good advice regarding the implementation of `__instancecheck__` and `__subclasshook__`. The [Python Data Model](https://docs.python.org/3/reference/datamodel.html#customizing-instance-and-subclass-checks) says explicitly that these methods must be implemented on the *metaclass*, but the documentation for the [abc module](https://docs.python.org/3/library/abc.html#module-abc) says that they can be implemented as `classmethod`s of subclasses. My interpretation was that the `ABCMeta` class contains the magic ingredients to allow this, but honestly I haven't delved into the code enough to verify this so we'll just want to make sure that all calls to `isinstance` and `issubclass` are tested thoroughly when you write unit tests.\r\n\r\nThis issue also applies to the `__instancecheck__` that I implemented for `SyncedCollection`, so we'll need to carry over whatever decision we make here to that as well."", 'comment_created': datetime.datetime(2020, 6, 16, 14, 51, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440917072, 'comment_body': ""I think it's useful, or at least a feature we could consider including that could be turned on or off with a flag. Try/Except blocks are cheap as long as they don't trigger exceptions frequently."", 'comment_created': datetime.datetime(2020, 6, 16, 14, 56, 46, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440921501, 'comment_body': ""This isn't necessary, anything declared in the class is class-wide and will be shared among instances. To a first approximation, classes are also just objects in the hierarchy of the instance, and attribute lookups should just traverse that and find the class-level instance if the attribute is not found in the object. No copies should be created (even aside from the extra key-sharing magic referred to)."", 'comment_created': datetime.datetime(2020, 6, 16, 15, 2, 18, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440921966, 'comment_body': 'I would rename this to clearly indicate that this class only exists to add the `attr` functionality (although IIRC we decided to just merge these classes in one discussion).', 'comment_created': datetime.datetime(2020, 6, 16, 15, 2, 56, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440929160, 'comment_body': ""Python2 is officially gone, so I would use plain `super()` wherever possible. In this package you will eventually have to start being careful about that since we're creating diamonds all over the place. Once `SyncedDict` and `JSONCollection` become abstract, for instance, you'll want to make sure that if they require initialization that `JSONDict` contains the appropriate calls to `super(PARENT_TYPE, self).__init__(...)`. Using plain `super()` in Python3 _should_ handle walking the MRO tree for you (although of course we'll want to test and verify)."", 'comment_created': datetime.datetime(2020, 6, 16, 15, 12, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440932317, 'comment_body': ""I see that `reset` has rollback that catches `BaseException`, so that's a pretty broad safety measure that seems like we'd want to mirror safety here."", 'comment_created': datetime.datetime(2020, 6, 16, 15, 16, 54, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440943495, 'comment_body': 'I assume this is for debugging, just a note to remove at some point.', 'comment_created': datetime.datetime(2020, 6, 16, 15, 29, 59, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440953470, 'comment_body': 'To avoid having to hack through the MRO this way, I would recommend making all the parent class `__init__` methods accept (and ignore) arbitrary kwargs so that you can just call `super().__init__(...)` and have the arguments interpreted appropriately', 'comment_created': datetime.datetime(2020, 6, 16, 15, 43, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 440955460, 'comment_body': 'If you move this to `TestSyncedCollectionBase` and redefine it a\r\n```suggestion\r\n    def get_synced_collection(self, data=None):\r\n        return self._type(data)\r\n```\r\nor similar, you might be able to standardize some tests (like `test_init`) across all `SyncedCollection`s and not have to duplicate them.', 'comment_created': datetime.datetime(2020, 6, 16, 15, 46, 11, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 441058465, 'comment_body': 'Okay, will add that.', 'comment_created': datetime.datetime(2020, 6, 16, 18, 28, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 442045616, 'comment_body': ""I think it's ok to make the decision to develop this feature for Python 3.6+. Python 3.5 is almost EOL and major libraries like numpy have already dropped support in their latest releases. @glotzerlab/signac-committers "", 'comment_created': datetime.datetime(2020, 6, 18, 8, 9, 49, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 442472316, 'comment_body': '@csadorf I support that, and as you mentioned, it is in line with the drop schedule here: https://numpy.org/neps/nep-0029-deprecation_policy.html.', 'comment_created': datetime.datetime(2020, 6, 18, 20, 3, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 442473846, 'comment_body': ""@vishav1771 To drop Python 3.5, we'll have to do a few things (drop CI tests, update documentation, etc.). It's fine to leave this shim in here for Python 3.5 for the moment, it won't hurt anything. We can drop support on `master` and merge it into this branch before finalizing your PR."", 'comment_created': datetime.datetime(2020, 6, 18, 20, 6, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 444436196, 'comment_body': 'I tried it. I found out that the `__instancecheck__` method should be defined on _metaclass_. I think in _abc module_ documentation, they are talking about `__subclasshook__` not `__instancecheck__`. ', 'comment_created': datetime.datetime(2020, 6, 23, 18, 50, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 446538344, 'comment_body': '@vishav1771 it looks like you just removed the docstring, are you planning to replace this?', 'comment_created': datetime.datetime(2020, 6, 27, 15, 36, 22, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446538497, 'comment_body': ""@vishav1771 you'll also want to do this on the base `SyncedCollection` class, it looks like you've done it everywhere else though 👍 "", 'comment_created': datetime.datetime(2020, 6, 27, 15, 38, 12, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446540289, 'comment_body': 'Do we need to consider other keys? Things like `_safe_sync` or the other methods like `load` and `sync`? (It\'s been a while since I\'ve considered how the ""protection"" works, I may be wrong.)', 'comment_created': datetime.datetime(2020, 6, 27, 15, 58, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 446540482, 'comment_body': 'This error might be more informative.\r\n```suggestion\r\n            raise ValueError(""Unsupported type: {}. The data must be a mapping or None."".format(type(data)))\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 0, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 446540598, 'comment_body': '```suggestion\r\n            raise ValueError(""Unsupported type: {}. The data must be a non-string sequence or None."".format(type(data)))\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 1, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 446540980, 'comment_body': 'What is the purpose of checking equality and resetting/constructing items individually based on whether their index is before or after `len(self._data)`? I would have expected this block would just delete `self._data` and build a new set of synced items from scratch.', 'comment_created': datetime.datetime(2020, 6, 27, 16, 6, 26, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 446541467, 'comment_body': ""The way that this is currently being used is not actually safe. Since `self._data` is a dict, `backup` will just be a reference to that dict, so any modifications will still persist. For now, I think the only easy option is making a copy of `self._data`; this will be a significant performance hit, so we'll want to think about more performant methods of accomplishing this going forward. One option would be to maintain a flag (similar to `_suspend_sync_` that, whenever set, any time we modify `self._data` we write the original unmodified version to a new dict. That way we only backup things that were modified, and we can discard this in an `else` clause to this `try-except` block."", 'comment_created': datetime.datetime(2020, 6, 27, 16, 12, 43, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446541590, 'comment_body': 'I would prefer the argument order used above:\r\n```suggestion\r\n    def __init__(self, data=None, filename=None, parent=None, write_concern=False):\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 14, 25, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 446541657, 'comment_body': 'Looks like the default is `False` in the constructor below. Are these different for a reason?', 'comment_created': datetime.datetime(2020, 6, 27, 16, 15, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 446541674, 'comment_body': '```suggestion\r\n            raise ValueError(""The data must be a mapping or None, not {}."".format(type(data)))\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 15, 20, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446541916, 'comment_body': 'Why do we need to do this reset? Once we reassign `self._data[key]` in the next line, Python should automatically clean the old object up for us.', 'comment_created': datetime.datetime(2020, 6, 27, 16, 18, 39, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542015, 'comment_body': '```suggestion\r\n                ""SyncedDict keys must be str, int, bool or None, not {}"".format(type(key).__name__))\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 20, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542017, 'comment_body': 'Since this `__init__` logic and error message is shared exactly between `JSONDict` and `JSONList`, it should be possible to abstract it into `JSONCollection` and allow the definitions of `JSONDict` and `JSONList` to be as simple as:\r\n```python\r\nclass JSONDict(JSONCollection, SyncedAttrDict):\r\n    pass\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 20, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 446542040, 'comment_body': '```suggestion\r\n                    ""SyncedDict keys may not contain dots (\'.\'): {}"".format(key))\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 20, 9, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542230, 'comment_body': '```suggestion\r\n    def __init__(self, data=None, **kwargs):\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 22, 27, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542311, 'comment_body': 'Feel free to merge the classes at this point.', 'comment_created': datetime.datetime(2020, 6, 27, 16, 23, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542495, 'comment_body': '```suggestion\r\n    def __init__(self, data=None, **kwargs):\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 25, 32, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542574, 'comment_body': 'Same question as above.', 'comment_created': datetime.datetime(2020, 6, 27, 16, 26, 25, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542785, 'comment_body': 'Do we need to call the object (which requires a copy), or can we just call `repr(self._data)`?', 'comment_created': datetime.datetime(2020, 6, 27, 16, 29, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446542932, 'comment_body': 'No need to address this now, but file away for later: this could be a significant performance bottleneck since it requires a conversion to the base type for each equality check.', 'comment_created': datetime.datetime(2020, 6, 27, 16, 30, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446543158, 'comment_body': '```suggestion\r\n    def __init__(self, filename=None, write_concern=True, **kwargs):\r\n        self._filename = os.path.realpath(filename) if filename is not None\r\n```', 'comment_created': datetime.datetime(2020, 6, 27, 16, 33, 23, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446543285, 'comment_body': 'This logic should go in subclasses that test the specific data types.', 'comment_created': datetime.datetime(2020, 6, 27, 16, 35, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446543370, 'comment_body': 'Why is the explicit sync call necessary? This should be transparently handled by the API, right?', 'comment_created': datetime.datetime(2020, 6, 27, 16, 35, 48, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446543919, 'comment_body': ""I agree that this seems unnecessary and made similar comments here and above. I think there's an aspect to this that's optimization-related, which is whether we can avoid rebuilding parts of a list if they're going to be identical before and after the reset. However, this solution (particularly for lists) is probably suboptimal anyway since there are ordering constraints."", 'comment_created': datetime.datetime(2020, 6, 27, 16, 42, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446544376, 'comment_body': 'Yes, this is valid and I think we might benefit from constructing this list programatically rather than keeping it manually up to date. The purpose is to avoid conflicts between setting, getting and deleting elements of the dictionary and attributes that are actually methods of a dictionary.', 'comment_created': datetime.datetime(2020, 6, 27, 16, 48, 6, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 446547512, 'comment_body': 'I left that intentionally so that it would raise a warning when not required `kwargs` is passed.', 'comment_created': datetime.datetime(2020, 6, 27, 17, 23, 47, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 446547990, 'comment_body': 'It also works something like `dfs_update`. So every time data is loaded it does not create a different instance. But I agree with @vyasr  as it takes order into consideration.', 'comment_created': datetime.datetime(2020, 6, 27, 17, 29, 9, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 446548361, 'comment_body': ""Sorry, that's a mistake. Will correct it."", 'comment_created': datetime.datetime(2020, 6, 27, 17, 32, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 446550849, 'comment_body': ""This gives `reset` the behavior of `dfs_update`. It doesn't change the instance for the underlying object until it is required.\r\nIt also optimizes it, as it doesn't create instances."", 'comment_created': datetime.datetime(2020, 6, 27, 17, 58, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 446553470, 'comment_body': 'Yeah, I was planning to rewrite so I removed for now.', 'comment_created': datetime.datetime(2020, 6, 27, 18, 25, 47, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 447067805, 'comment_body': ""Actually on further reading, I'm not sure I follow what the code is trying to accomplish. I don't think `reset` should behave like `dfs_update`, though. Correct me if I'm misunderstanding, but currently this is what the code is doing:\r\n```\r\nfor key in data:\r\n    if key in self._data:\r\n        # Do the reset if data[key] is resettable, reset its value to key, then continue\r\n    # set data[key]\r\n```\r\nPassing `key` as the argument to reset means that if `self._data['foo'] == {'bar': 1}` and `data['foo'] == 1`, the result of `reset` will be a `ValueError` because you're calling it with a non-Mapping, right? But even if that wasn't an error, the result would be that `self._data['foo'] == 'foo'`. Neither of these seem like the desired outcome.\r\n\r\nI think perhaps we need to clarify the intended semantics of `reset`. I assumed this function would simply erase the contents of the current object, and if `data` is provided, load all the contents of `data` into `self._data` afterward. Is that not the intent?"", 'comment_created': datetime.datetime(2020, 6, 29, 15, 41, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 447087853, 'comment_body': 'Sorry, There a typo. It should be\r\n```\r\n self._data[key].reset(data[key])\r\n```', 'comment_created': datetime.datetime(2020, 6, 29, 16, 10, 42, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 447090664, 'comment_body': ""If `self._data['foo'] = {'bar': 1}` and `data['foo']=1`, then `reset` will return `ValueError` and \r\n `self._data['foo'] = from_dict(data['foo'])` will be executed which is `self._data['foo'] = data['foo']` in this case"", 'comment_created': datetime.datetime(2020, 6, 29, 16, 14, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 447120524, 'comment_body': ""> I don't think reset should behave like dfs_update, though.\r\n\r\nI will make separate functions for both."", 'comment_created': datetime.datetime(2020, 6, 29, 17, 2, 41, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 450501271, 'comment_body': ""Now that we don't support python 3.5 this can be dropped"", 'comment_created': datetime.datetime(2020, 7, 6, 21, 58, 20, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 450505649, 'comment_body': 'Why not import this at the start of the file?', 'comment_created': datetime.datetime(2020, 7, 6, 22, 10, 8, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 450736294, 'comment_body': 'We either need a comment or a doc-string here to provide some explanation on what the purpose of this method is. It is not immediately apparent from either the method name or its implementation for me.', 'comment_created': datetime.datetime(2020, 7, 7, 9, 36, 50, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450736797, 'comment_body': ""I don't think it's necessary to create an addition reference here. Afaik `__mro__` should be static."", 'comment_created': datetime.datetime(2020, 7, 7, 9, 37, 32, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450738785, 'comment_body': '```suggestion\r\n    class Collection(Sized, Iterable, Container):  # type: ignore\r\n\r\n        @classmethod\r\n```', 'comment_created': datetime.datetime(2020, 7, 7, 9, 40, 44, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450739102, 'comment_body': ""Shouldn't it be called something like `SyncedCollectionABCMeta` then?"", 'comment_created': datetime.datetime(2020, 7, 7, 9, 41, 21, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450740042, 'comment_body': 'The long description does not seem to be 100% consistent with the short description. Is it about `SyncedCollection` or `Synced Classes`? Also, is `Synced Classes` a special name? If yes, where is it defined? If no, why is it not just `synced classes`?', 'comment_created': datetime.datetime(2020, 7, 7, 9, 42, 49, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450740409, 'comment_body': '```suggestion\r\n            if not cls.__abstractmethods__:\r\n```\r\nThe `bool` should be unnecessary.', 'comment_created': datetime.datetime(2020, 7, 7, 9, 43, 24, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450740793, 'comment_body': ""In general, we need much more explanation here. I don't follow why these classes are being registered and how that is useful."", 'comment_created': datetime.datetime(2020, 7, 7, 9, 44, 3, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450741371, 'comment_body': '```suggestion\r\n    """"""The base synced collection represents a collection that is synced with a file.\r\n    \r\n    The class is intended for use as an ABC. In addition, it declares abstract\r\n    methods that must be implemented by any subclass.\r\n```\r\nAll doc-strings must have a single first line, and in case that there is a longer description, it must be separated by an empty line. I\'m getting a little annoyed with this comment, because I know that I have pointed this out before. Are you using an editor with automated line-wrapping or so?', 'comment_created': datetime.datetime(2020, 7, 7, 9, 45, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450742377, 'comment_body': '```suggestion\r\n        """"""This method dynamically resolves the type of object to the\r\n```', 'comment_created': datetime.datetime(2020, 7, 7, 9, 46, 38, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450742610, 'comment_body': '```suggestion\r\n            Name of backend for synchronization. Default to backend of class.\r\n```', 'comment_created': datetime.datetime(2020, 7, 7, 9, 47, 2, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450742981, 'comment_body': 'Are we assuming that *every* `SyncedCollection` will be associated with a file? I thought the point of this was to make this class more abstract. This looks like a serious design flaw to me.', 'comment_created': datetime.datetime(2020, 7, 7, 9, 47, 42, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450744108, 'comment_body': '```suggestion\r\n        ""Dynamically resolve the synced collection to the corresponding base type.""\r\n```', 'comment_created': datetime.datetime(2020, 7, 7, 9, 49, 33, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450744671, 'comment_body': ""I'm still very confused about `Synced Class`. The capitalization makes it seem like this is some kind of name. But it is not a class, so what is it?"", 'comment_created': datetime.datetime(2020, 7, 7, 9, 50, 27, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450745167, 'comment_body': 'invalid doc-string', 'comment_created': datetime.datetime(2020, 7, 7, 9, 51, 13, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450745224, 'comment_body': 'invalid doc-string', 'comment_created': datetime.datetime(2020, 7, 7, 9, 51, 18, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450745495, 'comment_body': '```suggestion\r\n        """"""Checks whether the data is of base type of SyncedDict.\r\n        \r\n        Parameters\r\n```', 'comment_created': datetime.datetime(2020, 7, 7, 9, 51, 48, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450746543, 'comment_body': 'How was this solved in the previous implementation? Same bottleneck?', 'comment_created': datetime.datetime(2020, 7, 7, 9, 53, 44, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450747727, 'comment_body': '```suggestion\r\n        ""Load the data from a JSON-file.""\r\n```\r\n""JSON"" as a name must be block-capitalized.', 'comment_created': datetime.datetime(2020, 7, 7, 9, 55, 39, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450747964, 'comment_body': 'see above', 'comment_created': datetime.datetime(2020, 7, 7, 9, 56, 4, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450748181, 'comment_body': 'I know that this is basically just copied from the old implementation, but maybe we could use the opportunity to add a few comments here on how the write-concern is implemented.', 'comment_created': datetime.datetime(2020, 7, 7, 9, 56, 26, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450749356, 'comment_body': 'Might be to avoid a circular-import.', 'comment_created': datetime.datetime(2020, 7, 7, 9, 58, 36, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450750226, 'comment_body': 'Since this a completely new test implementation for this class, I might suggest to use a more pytest-onic approach to providing fixtures: \r\n - https://docs.pytest.org/en/stable/fixture.html#fixtures-as-function-arguments\r\n - https://docs.pytest.org/en/stable/fixture.html#fixture-finalization-executing-teardown-code\r\n\r\nAfaik, the use of `setUp` in this way is just a backwards-compatible approach to mixing the old unittest style with pytest.', 'comment_created': datetime.datetime(2020, 7, 7, 10, 0, 5, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450751130, 'comment_body': 'This should be a fixture.', 'comment_created': datetime.datetime(2020, 7, 7, 10, 1, 44, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450751367, 'comment_body': 'Should be a fixture.', 'comment_created': datetime.datetime(2020, 7, 7, 10, 2, 10, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450752129, 'comment_body': 'should be fixture argument', 'comment_created': datetime.datetime(2020, 7, 7, 10, 3, 38, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450752530, 'comment_body': 'fixture argument', 'comment_created': datetime.datetime(2020, 7, 7, 10, 4, 24, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450926568, 'comment_body': 'This entire except block will be removed, so no need to address the comments within it. @csadorf just for your information, I pulled this code directly out of the CPython library source code from the implementation of the Collection class in Python 3.7.', 'comment_created': datetime.datetime(2020, 7, 7, 14, 52, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450927256, 'comment_body': '@vishav1771 I agree, we need to be clear that this is used when recursively converting synced data structures to determine what to convert their children into.', 'comment_created': datetime.datetime(2020, 7, 7, 14, 53, 44, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450931098, 'comment_body': ""@vishav1771 to avoid issues like this going forward, you can change [this line](https://github.com/vishav1771/signac/blob/syncedCollection/setup.cfg#L18) to something like `collection_api.py|jsoncollection.py|...` where you just list all of the files that you are modifying as part of this PR. Then if you `pip install flake8-docstrings` the style of your docstrings will get checked every time you commit (you will have to manually run it the first time since it only checks your changes, so you'll have to run it manually to get the current version into a working state). Once you do that docstring issues like this should get caught automatically."", 'comment_created': datetime.datetime(2020, 7, 7, 14, 58, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450934665, 'comment_body': 'I think we still want to assume that every synced collection is synchronized with _something_, right? It might be a Redis cache or a MySQL db, but we still assume synchronization is happening? The question of how to handle a single centralized database as opposed to our current distributed model is something I think we won\'t be able to address until we try such a back end (which is why we *must* implement additional backends before we can consider this branch feature complete), but I suspect you\'d still want to store the filename (or resource) in every collection, except that multiple collections could point to the same place. The `sync` method would have to appropriately handle this for a particular backend.\r\n\r\nIf you\'re asking about the naming, we can certainly choose something other than ""file"".', 'comment_created': datetime.datetime(2020, 7, 7, 15, 3, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450935695, 'comment_body': '```suggestion\r\n        """"""Check whether data is of same base type as Synced Class""""""\r\n```', 'comment_created': datetime.datetime(2020, 7, 7, 15, 4, 41, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450936183, 'comment_body': 'Yes, I believe this is copied verbatim.', 'comment_created': datetime.datetime(2020, 7, 7, 15, 5, 21, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450944239, 'comment_body': ""We should very clearly split the docstrings between the different classes. Specifically, the description of persistent file storage at a high level should be at the SyncedCollection level (I think that class needs to have an extensive docstring). Every specific collection type (e.g. JSONCollection) should document the backend it implements, and every data type (e.g. SyncedDict) should document the core Python data type it mimics. Then the bottom level classes (e.g. JSONDict) will just have very short descriptions and point to their parents for documentation on *how* this is implemented (since that's where the implementation will be)."", 'comment_created': datetime.datetime(2020, 7, 7, 15, 16, 16, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450944726, 'comment_body': ""Having said that, the examples below are good to have here, and I'm fine with duplicating warnings if we think that's necessary (although we can decide that later)."", 'comment_created': datetime.datetime(2020, 7, 7, 15, 17, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450948432, 'comment_body': 'Add some documentation of what makes it an ""AttrDict"".', 'comment_created': datetime.datetime(2020, 7, 7, 15, 22, 22, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450949470, 'comment_body': 'This docstring needs to be fixed for all classes to refer to the correct type.', 'comment_created': datetime.datetime(2020, 7, 7, 15, 23, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450956060, 'comment_body': ""In the list implementation, you directly call setitem on `_data`, can we do that here too since we're suspending synchronization?"", 'comment_created': datetime.datetime(2020, 7, 7, 15, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450960242, 'comment_body': ""I've always personally found the `_dfs` naming confusing. I would prefer to name this `_update`, IMO it's more important to name the function based on what it does rather than how it does it. However, we should absolutely document internally that it uses a depth first algorithm; developer documentation is where algorithmic information belongs I think.\r\n\r\nI'm commenting on this in the list implementation rather than the dict implementation, but this change needs to be made in the other functions too. Would it be possible to unify the implementations? Aside from the default type of `data` and the error (both of which can be set using class variables), the other differences don't seem critical to maintain. Could we merge implementations and consider optimizing after, or are there significant performance problems with getting rid of the list-specific optimizations here?"", 'comment_created': datetime.datetime(2020, 7, 7, 15, 39, 20, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450964410, 'comment_body': ""You could also consider is using [hypothesis](https://hypothesis.readthedocs.io/en/latest/) to write tests. The idea is that instead of encoding specific key values (for instance) in your test, you ask hypothesis to generate keys for you. You could use that in almost all the methods below, and it's very good at catching edge cases that you might otherwise miss (for example, empty strings, or strings with forbidden key types, or nested dict/list combinations...). If you don't want to try that here, we could add that to the to-do list for this project."", 'comment_created': datetime.datetime(2020, 7, 7, 15, 45, 32, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 450987738, 'comment_body': ""Okay that is a good reason, but if it isn't really needed, importing once would be nice since it is used a few different times in this file. "", 'comment_created': datetime.datetime(2020, 7, 7, 16, 20, 47, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 450999344, 'comment_body': ""Let's not overload this PR by introducing more complexity."", 'comment_created': datetime.datetime(2020, 7, 7, 16, 39, 39, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 450999758, 'comment_body': '> This entire except block will be removed, so no need to address the comments within it. @csadorf just for your information, I pulled this code directly out of the CPython library source code from the implementation of the Collection class in Python 3.7.\r\n\r\nThen I assume that requires an attribution??', 'comment_created': datetime.datetime(2020, 7, 7, 16, 40, 18, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451001989, 'comment_body': 'Well, if it is related to some abstract resource then we **have** to call it something other than file.', 'comment_created': datetime.datetime(2020, 7, 7, 16, 43, 49, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451003014, 'comment_body': 'Is the assumption that *any* resource that our backends supports can be described by a single string argument? Like a URI? That is a potential design choice, but we need to be intentional about it.', 'comment_created': datetime.datetime(2020, 7, 7, 16, 45, 27, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451070144, 'comment_body': ""This is a mistake. `Filename` is intended to be a backend-specific. I removed the `filename` from `SyncedCollection` but forgot the documentation. I'll correct it."", 'comment_created': datetime.datetime(2020, 7, 7, 18, 43, 56, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 451147339, 'comment_body': ""If we were keeping it then yes, but it's being removed..."", 'comment_created': datetime.datetime(2020, 7, 7, 21, 14, 44, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 451147625, 'comment_body': ""Agreed, I'll add it to the list of open tasks."", 'comment_created': datetime.datetime(2020, 7, 7, 21, 15, 16, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 451339166, 'comment_body': ""Let's make sure to always add the correct attributions when code is copied from a different code base even when it is planned to be removed. Reasons are simple: 1. It is already part of the code base now, because every commit is part of the code base, not just the latest. 2. There is always a chance that it is not removed after all (intentional or by accident) in which case this is simply plagiarism."", 'comment_created': datetime.datetime(2020, 7, 8, 7, 30, 30, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451492128, 'comment_body': 'I want to echo @csadorf explicitly on this. All committed code should attribute snippets like this, even if it is temporary.', 'comment_created': datetime.datetime(2020, 7, 8, 12, 9, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 451599288, 'comment_body': ""To clarify, I'm not asking about general policy, only about this specific instance. I agree that I wasn't explicit enough when originally suggesting to Vishav, I simply sent him a code snippet along with a link and I should have clearly indicated that we should cite. I'm just not sure what you want to do about it now, given that we a) are removing, and b) squash and merge our PRs. The latter means that this commit actually _won't_ be part of the commit history, so now that we know we are removing it I'm not sure what action you want to take. Should we modify an upstream commit to add in the attribution? That commit and all associated parts of this snippet will be removed by the merge."", 'comment_created': datetime.datetime(2020, 7, 8, 14, 42, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 451743313, 'comment_body': 'If we actually make sure that it is removed then no further action is needed.', 'comment_created': datetime.datetime(2020, 7, 8, 18, 26, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451746077, 'comment_body': 'It is still not clear to me what the purpose of the meta class is or how I as a developer would need to use it. Specifically I don\'t understand what a ""synced data structure definition"" is.\r\n\r\nMeta classes are a more advanced and somewhat abstract language feature and should therefore be used with caution, because it reduces code clarity and limits who can maintain this code. So if we are using meta classes, then we should have strong justification for it and on top need to document extremely well what the purpose is and how they work.\r\n\r\nI have admittedly not followed the full discussion leading up to the class structure that is implemented here and forgot the details of the proposal, however I am otherwise very familiar with the code base and the general purpose of these classes and I think it is a bit of a red flag that I can\'t fully follow what is happening here. So we definitely need to improve the code documentation here, but we should also consider whether we can achieve the same thing maybe in a more obvious way without meta classes.', 'comment_created': datetime.datetime(2020, 7, 8, 18, 30, 59, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451751158, 'comment_body': '```suggestion\r\n    The class is intended for use as an ABC. In addition, it declares abstract\r\n    methods that must be implemented by any subclass. The SyncedCollection is a\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 18, 40, 16, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451751480, 'comment_body': ""> In addition, it declares abstract methods [...]\r\n\r\nIsn't that the definition of an abstract base class? That it defines abstract methods? Sounds like a tautology to me"", 'comment_created': datetime.datetime(2020, 7, 8, 18, 40, 43, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451751711, 'comment_body': 'This doc-string formatting is still invalid. @vyasr Is the linter not working?', 'comment_created': datetime.datetime(2020, 7, 8, 18, 41, 10, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451752640, 'comment_body': '```suggestion\r\n        """"""Prepares context where load and sync are suspended.""""""\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 18, 42, 50, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451753440, 'comment_body': '```suggestion\r\n        """"""Check whether data is of same base type as Synced Class""""""\r\n```\r\nIs ""Synced Class"" a name? I\'m not familiar with it.', 'comment_created': datetime.datetime(2020, 7, 8, 18, 44, 14, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451754879, 'comment_body': 'I find the name of that module weird. If it only contains the abstract base classes, maybe we should call it `synced_collection_abc`? @vyasr Do you have a better idea?', 'comment_created': datetime.datetime(2020, 7, 8, 18, 46, 50, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451755530, 'comment_body': 'The module should be called `synced_list`.', 'comment_created': datetime.datetime(2020, 7, 8, 18, 48, 5, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451756158, 'comment_body': 'Just name this `synced_collection` following general pytest naming conventions.', 'comment_created': datetime.datetime(2020, 7, 8, 18, 49, 19, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451756292, 'comment_body': '```suggestion\r\n        assert len(get_synced_collection) == 0\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 18, 49, 33, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 451756623, 'comment_body': '```suggestion\r\ndef testdata():\r\n```', 'comment_created': datetime.datetime(2020, 7, 8, 18, 50, 11, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 452121178, 'comment_body': ""I was having some issues with linter. It's sorted now. I will correct it in next commit."", 'comment_created': datetime.datetime(2020, 7, 9, 10, 29, 48, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 452122666, 'comment_body': 'I was referring to classes like `JSONDict` and `JSONList`.   ', 'comment_created': datetime.datetime(2020, 7, 9, 10, 32, 46, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 452355588, 'comment_body': '""and if necessary construct a new."" A new what? Do you mean ""a new SyncedList""', 'comment_created': datetime.datetime(2020, 7, 9, 16, 50, 14, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 452471288, 'comment_body': 'I think that module should be called `synced_collection` and only define the parent class for the hierarchy (`SyncedCollection`). The original name is a holdover from my original prototype where everything was in one file.', 'comment_created': datetime.datetime(2020, 7, 9, 20, 28, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 452478179, 'comment_body': 'I\'m very open to finding a simpler solution if you can think of one. The problem we\'re attempting to solve is the following. The open ""hard-to-solve"" issues regarding synced dicts in the current codebase generally have to do with nesting synced dicts/lists and finding that things break. The metaclass approach is designed to solve this by defining the conversion from base collections to the corresponding synced collections as a recursive conversion that searches for the appropriate corresponding type in the registry of available synced collections. This ensures that a `dict[dict[list]]` doesn\'t lead to a `SyncedDict[SyncedDict[list]]` instead of `SyncedDict[SyncedDict[SyncedList]]`. The main reason the metaclass is necessary (and I\'m very open to alternate solutions) is to enable the flexibility for users to define their own collections after importing the class and ensuring that the appropriate types of objects are created by the recursion. An auxiliary benefit is that it solves any circular import issues that might otherwise arise in the package where the SyncedCollection class would need to know which of its children should be instantiated in any particular case. The latter problem could probably be solved in other ways, but I\'m not sure if there\'s a simpler or more elegant solution than a metaclass for the former.', 'comment_created': datetime.datetime(2020, 7, 9, 20, 42, 28, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 453342679, 'comment_body': ""Yes, I meant 'SyncedList'. I already changed it."", 'comment_created': datetime.datetime(2020, 7, 12, 17, 30, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 453797625, 'comment_body': ""Unless I'm missing some kind of obvious flaw with this, one very simple alternative approach would be to simply register those classes with the base class with a class attribute and method:\r\n```python\r\nJsonCollection.register(JsonDict)\r\nJsonCollection.register(JsonList)\r\n# ...\r\n```\r\nUse `*args` if you want this to be more concise:\r\n```python\r\nJsonCollection.register(JsonDict, JsonList, ...)\r\n```"", 'comment_created': datetime.datetime(2020, 7, 13, 17, 4, 35, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 453817597, 'comment_body': 'Okay, I will try that.', 'comment_created': datetime.datetime(2020, 7, 13, 17, 37, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 453818693, 'comment_body': 'I will correct that.', 'comment_created': datetime.datetime(2020, 7, 13, 17, 39, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 453843314, 'comment_body': ""I have changed it with `synced data structure` but I'm not sure that it is correct or not?"", 'comment_created': datetime.datetime(2020, 7, 13, 18, 22, 22, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 453844149, 'comment_body': 'I have done the changes.', 'comment_created': datetime.datetime(2020, 7, 13, 18, 23, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 453847188, 'comment_body': ""I don't think we are using specific optimization in both methods but I don't know how to combine both of them."", 'comment_created': datetime.datetime(2020, 7, 13, 18, 28, 49, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 454492434, 'comment_body': ""@csadorf I don't see any significant flaws in that approach, other than the fact that it just doesn't handle this automatically. I'm fine with choosing the more explicit approach here for simplicity."", 'comment_created': datetime.datetime(2020, 7, 14, 16, 40, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 455499833, 'comment_body': ""I'm reviewing this PR now. I don't have strong opinions about metaclass vs. explicit registration. I think this conversation can be considered resolved."", 'comment_created': datetime.datetime(2020, 7, 16, 4, 15, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455500651, 'comment_body': ""I see some places where the docstrings are still incomplete. The pydocstyle linter settings on the `numpy_docs` branch is ultimately what we want to match, and I would like to move this PR forward and work with automated tooling to incrementally fix these issues at a later time. Specifically, I expect this to happen by merging `numpy_docs` into the main branch in #357 and then pulling the main branch into `feature/synced_collections` (not on @vishav1771's fork)."", 'comment_created': datetime.datetime(2020, 7, 16, 4, 19, 15, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455500993, 'comment_body': 'Marking this as resolved. The code has been moved to a different file and I am making a suggestion there instead.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 20, 39, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455501480, 'comment_body': '```suggestion\r\n    def is_base_type(cls, data):\r\n        """"""Check whether data is of the same base type (such as list or dict) as this class.""""""\r\n        pass\r\n```', 'comment_created': datetime.datetime(2020, 7, 16, 4, 22, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455501711, 'comment_body': 'This has been completed. Marking resolved.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 23, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455502698, 'comment_body': ""@vishav1771 @vyasr I looked at the code and I'm unsure if this conversation can be resolved. Currently the `SyncedCollection` class has the constructor signature: `def __init__(self, parent=None):`. I don't understand @vishav1771's comment about raising a warning. Do we need to accept `**kwargs` there or not? Apologies in advance if I've missed another conversation on this topic. https://github.com/glotzerlab/signac/pull/336/files#diff-89d6453841b1887a33032d47f0728d7cR28"", 'comment_created': datetime.datetime(2020, 7, 16, 4, 27, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455503196, 'comment_body': 'Please replace ""dfs"" with ""depth-first traversal"" in all docstrings. It\'s not really search, just traversal, and the acronym is not obvious.\r\n```suggestion\r\n        """"""Update the instance of SyncedList with data using depth-first traversal.""""""\r\n```', 'comment_created': datetime.datetime(2020, 7, 16, 4, 29, 40, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455504240, 'comment_body': ""Please include a description of the algorithm that is used here in a code comment. I don't know if my proposed comment is correct, but marking it with `TODO:` could also help if there's room for future improvement.\r\n```suggestion\r\n                # This loop avoids rebuilding existing synced collections for performance.\r\n                # TODO: Potential improvements to this code are...\r\n                for i in range(min(len(self), len(data))):\r\n```\r\nPrevious discussion: https://github.com/glotzerlab/signac/pull/336#discussion_r446540980"", 'comment_created': datetime.datetime(2020, 7, 16, 4, 34, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455504346, 'comment_body': 'I have suggested a comment in the code that marks this as a place for potential optimization in the future. I will mark this as resolved for now.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 34, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455504950, 'comment_body': '@vishav1771 Please resolve this conversation if it has been handled completely.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 36, 47, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455505609, 'comment_body': 'This is copied verbatim. Marking resolved.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 39, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455505716, 'comment_body': '@vishav1771 Please resolve this conversation if it has been handled completely.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 39, 42, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455506452, 'comment_body': ""_Copied from a related conversation from earlier, which I have now marked as resolved:_ There are definitely some places where the docstrings are incomplete. The `pydocstyle` linter settings on the `numpy_docs` branch is ultimately what we want to match, and I would like to move this PR forward and work with automated tooling to incrementally fix these issues at a later time. Specifically, I expect this to happen by merging `numpy_docs` into the main branch in #357 and then pulling the main branch into `feature/synced_collections` (not on @vishav1771's fork)."", 'comment_created': datetime.datetime(2020, 7, 16, 4, 42, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455506721, 'comment_body': 'I have suggested an improvement to this docstring in my current review. The code has moved and I am marking this conversation as resolved.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 43, 47, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455508283, 'comment_body': 'There are a few separate topics to address in this conversation:\r\n- I looked at the code and I\'m not sure how I would combine these implementations for SyncedDict/SyncedList either. I think it is fine to leave it as it is.\r\n- _Copied from a separate comment in my current PR review:_ Please replace ""dfs"" with ""depth-first traversal"" in all docstrings. It\'s not really search, just traversal, and the acronym is not obvious.\r\n- I agree that the ""depth-first"" detail should be in developer documentation and not necessarily in the method name. The name has been changed to `_update` but the corresponding tests are still named `dfs_update`. I will make suggested changes to those test names in my PR review.\r\n\r\n@vyasr Vyas, please weigh in here if you have an idea for combining the `_update` implementations. Otherwise please resolve this conversation.', 'comment_created': datetime.datetime(2020, 7, 16, 4, 50, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455508493, 'comment_body': 'I think this name captures the purpose of the test more clearly. There may be a better name. The test ensures that synced child classes are replaced by scalar values if the underlying JSON is rewritten.\r\n```suggestion\r\n    def test_update_recursive(self, synced_collection, testdata):\r\n```', 'comment_created': datetime.datetime(2020, 7, 16, 4, 51, 9, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455509100, 'comment_body': 'There may be a better name. The test ensures that synced child classes are replaced by scalar values if the underlying JSON is rewritten.\r\n```suggestion\r\n    def test_dfs_recursive(self, synced_collection, testdata):\r\n```', 'comment_created': datetime.datetime(2020, 7, 16, 4, 53, 23, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 455664593, 'comment_body': ""I was talking about the warning when we pass `JSONDict('test.json', foo=1)`. IMO, We don't need to accept `kwargs` for `SyncedCollection`. As we don't pass  `kwargs` to any upper level (class). So, we have a definite set of `kwargs` that we allow for `SyncedCollection` which is only `parent` in this case. "", 'comment_created': datetime.datetime(2020, 7, 16, 9, 49, 30, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 455680812, 'comment_body': 'I think `test_update_recursive` applies better.', 'comment_created': datetime.datetime(2020, 7, 16, 10, 18, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 456035358, 'comment_body': 'I am not sure about this test (deleting a protected attribute). Please suggest any other way to test this. ', 'comment_created': datetime.datetime(2020, 7, 16, 19, 46, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460081514, 'comment_body': ""I'm confused by this sentence, did you mean:\r\n```suggestion\r\nSyncedCollection encapsulates the synchronization of different data-structures.\r\n```\r\n?"", 'comment_created': datetime.datetime(2020, 7, 24, 14, 18, 9, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460086486, 'comment_body': 'We should use the convention to use the module name as backend name to avoid accidental name collisions:\r\n```suggestion\r\n    backend = __name__  # type: ignore\r\n```\r\nIf adopted, this must be documented as part of the ABC documentation!', 'comment_created': datetime.datetime(2020, 7, 24, 14, 25, 58, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460087812, 'comment_body': '```suggestion\r\n            raise ValueError(""No backend found."")\r\n```\r\nThe style of error messages should be be ""calm and collected"".', 'comment_created': datetime.datetime(2020, 7, 24, 14, 27, 54, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460089001, 'comment_body': 'This is an abstract base class, we are not requiring that the backend is reading from or writing to files. In so far this doc-string should not imply some kind of implementation that involves files.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 29, 43, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460089180, 'comment_body': 'same as above', 'comment_created': datetime.datetime(2020, 7, 24, 14, 29, 59, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460089646, 'comment_body': 'Comment unclear. The other methods were not common?', 'comment_created': datetime.datetime(2020, 7, 24, 14, 30, 44, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460090536, 'comment_body': 'Why do we not need to load prior to these ?', 'comment_created': datetime.datetime(2020, 7, 24, 14, 32, 11, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460090914, 'comment_body': 'Again, not necessarily a file.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 32, 47, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460092372, 'comment_body': 'This is not a sufficient or comprehensive summary of the purpose of this class.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 35, 8, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460093043, 'comment_body': ""I don't see any warnings."", 'comment_created': datetime.datetime(2020, 7, 24, 14, 36, 19, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460093950, 'comment_body': '```suggestion\r\n            data = {}\r\n            \r\n        if isinstance(data, Mapping):\r\n```\r\nBetter conceptual grouping.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 37, 47, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460095151, 'comment_body': ""@glotzerlab/signac-maintainers Large parts of this code here and elsewhere were copied from other modules which is now no longer reflected in either the git history or the copyright notice meaning that information about the original authorship is lost.\r\n\r\nI'm not exactly sure what do about this, but maybe we can imply it like this?\r\n```suggestion\r\n# Copyright (c) 2020 The Regents of the University of Michigan\r\n# Copyright (c) 2018 The Regents of the University of Michigan\r\n```"", 'comment_created': datetime.datetime(2020, 7, 24, 14, 39, 47, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460096579, 'comment_body': ""I don't think that the name 'doc' makes sense here."", 'comment_created': datetime.datetime(2020, 7, 24, 14, 42, 11, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460099680, 'comment_body': 'Why do we need this base test class at all? This awkward if-condition implies to me that we should just implement the test classes for a specific backend and then just swap out the fixtures. All tests should by definition work exactly the same regardless of backend or backend configuration.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 47, 7, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460101151, 'comment_body': 'I have no clue what is being tested here. What kwargs?', 'comment_created': datetime.datetime(2020, 7, 24, 14, 49, 18, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460101834, 'comment_body': 'There should be no backend specific code in the general tests IMO. So this should not be in the tests base class. I believe the base class should not be a base class anyways in which case this would be ok.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 50, 17, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460103077, 'comment_body': 'I think it would be much easier to understand the test implementation if you would just override the fixture.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 52, 21, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460103630, 'comment_body': 'The test classes should behave exactly the same regardless of backend, so this last test line must be removed.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 53, 14, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460104825, 'comment_body': ""I don't think we need the extra `sd` or `d` references. Just use `synced_collection` and `testdata`. This applies to all other tests as well."", 'comment_created': datetime.datetime(2020, 7, 24, 14, 55, 12, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460105858, 'comment_body': 'I think `del sd._x` should generally be considered unsafe, so the fact that you are testing the behavior at all can be commended. So no further action needed IMO.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 56, 49, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460106070, 'comment_body': 'Why are we overriding the type here? Also, tests must be backend-generic.', 'comment_created': datetime.datetime(2020, 7, 24, 14, 57, 9, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 460226856, 'comment_body': 'Okay I will change that.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 43, 32, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460227558, 'comment_body': 'These are the methods that have common implementation for `SyncedAttrDict` and `SyncedList`.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 45, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460228048, 'comment_body': 'Sorry, will change.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 46, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460228551, 'comment_body': 'Okay, will add more content.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 47, 16, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460229156, 'comment_body': 'Okay, will remove that.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 48, 40, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460229626, 'comment_body': 'True, will change.', 'comment_created': datetime.datetime(2020, 7, 24, 18, 49, 44, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460231195, 'comment_body': 'The `JSONDict` raises an error when neither `filename` nor `parent` is passed. ', 'comment_created': datetime.datetime(2020, 7, 24, 18, 53, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 460232221, 'comment_body': 'This base test contains the tests that are common for both `JSONDict` and `JSONList`. Will change,', 'comment_created': datetime.datetime(2020, 7, 24, 18, 55, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 461026573, 'comment_body': ""I'm not sure what you mean. Where are these copied from that would no longer be in the git history? The fact that some of the history will be hard to follow (because it's from files like the original synced_dict.py that will be removed once this is done) is a common problem with large-scale refactoring. As long as the original code was from within our code base I don't think we need to worry about this. If you're worried about crediting people appropriately w.r.t. authorship, we could start including a credits file in signac like we do in other projects."", 'comment_created': datetime.datetime(2020, 7, 27, 16, 46, 39, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 461030298, 'comment_body': ""You're right, it's probably fine."", 'comment_created': datetime.datetime(2020, 7, 27, 16, 52, 33, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461033035, 'comment_body': 'This seems like it was accidentally added. Please make sure to use `git add -up` instead of `git add` or `git add -u` alone and use `git diff --staged` to review every single line of code prior to creating the commit.\r\n\r\nThe reason that these kind of mistakes are highly problematic is because it means I can now no longer trust that you put in due diligence when you created the commit, but need to review *every single line* of the diff for similar issues, vastly increasing the required effort.', 'comment_created': datetime.datetime(2020, 7, 27, 16, 56, 42, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461033385, 'comment_body': ""Can you briefly explain why `autouse=True` is necessary?\r\n\r\nAddendum: After reading the rest of the code, I assume it's because of the use of the implicit `self._cls` class variable. I've provided explanation below as to why that is a very bad idea. Please remove this."", 'comment_created': datetime.datetime(2020, 7, 27, 16, 57, 18, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461033750, 'comment_body': 'Why is there still a test base class? It seems to me like this is a JSON-specific test class, because there are lot of references to JSON classes in its implementation. This should be reflected in the class name.', 'comment_created': datetime.datetime(2020, 7, 27, 16, 57, 55, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461370768, 'comment_body': ""I appreciate your explanation as to the purpose of this test as part of your response to my questions on the PR, but this won't help anyone who stumbles upon this piece of code in the future. The tests must be self-explanatory, and in cases where they are not, you must provide sufficient in-code commentary.\r\n\r\nIn general, whenever someone asks for more context/explanation regarding as specific code section, it is *almost always* warranted to at least add more comments for explanation and sometimes to refactor the code to make it clearer.\r\n\r\nFurthermore, as pointed out above, using this kind of implicitly created hidden class variable is a serious design flaw. If you wanted to test the constructor of a fixture use `type(fixture)()`."", 'comment_created': datetime.datetime(2020, 7, 28, 7, 21, 18, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461374352, 'comment_body': ""I don't think we should be introducing some kind of hidden class variable as part of the fixture creation. And then especially, we should never reference it outside of the fixture implementation. That is a serious flaw in test design."", 'comment_created': datetime.datetime(2020, 7, 28, 7, 28, 2, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461375488, 'comment_body': 'As pointed out before, the `self._cls` variable defeats the purpose of using fixtures in the first place.', 'comment_created': datetime.datetime(2020, 7, 28, 7, 30, 13, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461379486, 'comment_body': 'Same issue as with the other test class: please remove the use of the implicit class variable.', 'comment_created': datetime.datetime(2020, 7, 28, 7, 37, 50, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461379909, 'comment_body': 'I think it would be preferable for clarity to override the fixture also for the control of this fixture constructor parameter.', 'comment_created': datetime.datetime(2020, 7, 28, 7, 38, 38, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461380803, 'comment_body': 'Your comment is still not providing sufficient explanation.\r\n```suggestion\r\n    # The following methods share a common implementation for all data structures and regardless of backend.\r\n```\r\nIs this correct?', 'comment_created': datetime.datetime(2020, 7, 28, 7, 40, 13, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 461382939, 'comment_body': 'Also, please put in more effort in reviewing your own diffs and commits to avoid the common occurrence of typos etc. (`implementaion`).', 'comment_created': datetime.datetime(2020, 7, 28, 7, 44, 6, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 462892223, 'comment_body': 'This class tests the code implemented in `Synced_Collection`. Currently, we only have JSON backend implemented so this class has a lot of references to JSON class. I will add more tests while adding another backend.', 'comment_created': datetime.datetime(2020, 7, 30, 10, 7, 42, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 462896545, 'comment_body': ""This fixture only sets temp directory for `TestSyncedCollectionBase` and cleanup after the test. It does not provide any Collection (`synced_dict`, `synced_list`). That's why I have used `autouse=True`. This is only for `TestSyncedCollectionBase`."", 'comment_created': datetime.datetime(2020, 7, 30, 10, 15, 49, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 462898316, 'comment_body': ""Sorry for the mistake. I'll make sure to check every single line of code before creating the commit. This commit actually changed the whole file, so I must have missed it. It will not happen again."", 'comment_created': datetime.datetime(2020, 7, 30, 10, 19, 18, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 462903036, 'comment_body': ""I apologize again, this has always been a serious shortcoming in my codes. I have been trying to overcome this problem for some time now. Will keep in mind your points. I'll try not to repeat this in the future."", 'comment_created': datetime.datetime(2020, 7, 30, 10, 28, 54, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}]","[{'commit_sha': '2db2f68ad0025c5a55dbbf696df26a1690e515e1', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '003466978af633d95733844dc4436da764ef6aff', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd1dbb453ea3937bca0b88cc9101100f9cdfd036c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5494f4fc19f6fc8191102631f2cef4bc2f9fcd42', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '99b9dbecd0184295c5fcffa6e2120e93518afa94', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4385161f2d9b503a84461a02ea925fbc04884434', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '698ac954fbcab66820a0260db7fa1c53e07d758d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c3fc1c3a3b12a5dd360b300ea6ca461ba979d85f', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b2cf49263cf8d0fd592fe4e16a76c566a5b2f582', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c88a9c431dc7ac03e5f384a727b9c29423a80bd2', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1f6068b5d02a7bdc488d6cbfa2d81dfeb3f3bcde', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e3af86394a5a0ed69236f88b0ade81c0a7ed2ec3', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a9291726fb6ba93ee5ba22095c4888793f304125', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '73f3d5b0216618a1c3f01b59d065d6f0168d52fd', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '32714b500c50d1f1fb184c01dc0a2d15e4502705', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd32293c8b4e6d9000fad4ef08764617284921857', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b37c750429f33d2ad6c2daad4886c83b0a6b7c3', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8c5bee5027906566a8ab38bd747bc7a0a10318e9', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9c8191961ddd068d8a76675fcd21e772cb87a87f', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7b973a3cc49d2751783bcc9c561b303517267fce', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e6f5add5946e59b9aca84ba3423528abf773d419', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '17cf07f3f6dcc01369dae03794d8b5b6e499b12a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8c75207ff4dcf108f845fc4d7712d570f27981c2', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0b4f6c1edf02873986e8d839b7c0d420281a54bc', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e839fcc95cedaaf329dc76c0db96b357e4917a46', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6dac3972261b1d8890d765e4e2dae6cebf652c25', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '130d6dffed5c31c4d9077c9ff8d53b435ab4f3c0', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3f48b615fa1f2a6741c9ed1c6db964362f3f3609', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ab1e630011e5987beb3874f9ba1b9713bfef34aa', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd87ca4b1be1a20d8d8d120eeb940f6f5f53d7ae2', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': '534a9e18a3694fb077ac4a17f60e5c907b2c1aa3', 'committer_username': '', 'committer_name': '', 'committer_email': '', 'commit_date': ''}, {'commit_sha': '51c311025da6f2d347c4d5fcc1fd46449f63699c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '96d7528e1c181021012a7763fb651d7248b31f31', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': '64bef8f7de5b29b42c6947671553d6fe363bc015', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ef50cd42133ef52eff04d771ab9eb5a6751582fd', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c326f8f70f13fe21e04146a31d09f5ce3e4f2bf2', 'committer_username': 'dependabot[bot]', 'committer_name': None, 'committer_email': None, 'commit_date': datetime.datetime(2019, 4, 16, 22, 34, 25, tzinfo=datetime.timezone.utc)}, {'commit_sha': '184613f9242f2a371b3274d21a0bd7f909176c50', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c0d37c46e6089876c077e52a55cfdfe60f1c3b36', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '641849376b8ddccad0b4f9641b5c7b705b2268fc', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c1a18083a2e6d3e4adfbf9a5588bb08a8e59b0d7', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1a446b61538d3fc722d3affbf54f6a22a3504562', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ac363ebb1d27f66042f80e0d9e5bd4235a72efff', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c597750c875d4d3fa150a446d2b712f786f64c7a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6303364ec0dcb5f9769a809ad88eca7fefd024c9', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'acec603c692fef88f2b55a3daf0caf6680d04039', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eceddd302b477abacf59f0146aee4cfc17a7d83b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3eddb2eabcec5d9813cd2a4b2e5513ad20e7531b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '51efd3177d1f125f1341ee1e5f0a6ff1d81401e3', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7c7cd31cb9ae38d59a6dfe03792e8504a0c66841', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd2512d99b3021ba1b08bca017f186884ca682f09', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '45cc23022290e5ee250ae98ed61215ea523e41a0', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '74a6b4c41aaf3347fbb34d584b83c58fa9c7c7dc', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '830660bd851d45f1e896089bc54e7c6bc8ed677b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c877ae076ee7b736ddade162acdb4c88e72cf979', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c105954d498bab56894f42f1bb0c22b198148b42', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '85ef4e4ad6ac1e82edb03705f7e8190f53eb7b05', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'db30f524127ac39b7aa0262f11a7231f23652992', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cc895ea425f404125eb50028f3024dfbd604ec78', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}]",Vishav Sharma,46069089,,User,,8,,2,4
437064843,Drop Support for Python 3.5,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
This PR drops support for Python 3.5. I have removed CI tests, updated do and updated setup.py
## Motivation and Context
#336
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->

## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [x] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [x] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [x] I have updated the [changelog](https://github.com/glotzerlab/signac/blob/master/changelog.txt) and added all related issue and pull request numbers for future reference (if applicable). See example below.


Example for a changelog entry: `Fix issue with launching rockets to the moon (#101, #212).`
",True,340,https://api.github.com/repos/glotzerlab/signac/pulls/340,https://github.com/glotzerlab/signac/pull/340,closed,16,156,9,4,10,0,2,2,"[{'name': 'enhancement'}, {'name': 'GSoC'}]",2020-06-19 12:07:36+00:00,2020-07-06 11:28:37+00:00,1466461.0,"16 days, 23:21:01",[],"[{'commit_sha': '953fbe2ac794efa4309fc7f9afbf875dacd5de19', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4705a1611ba08ff057e4ea39c7a241ce09d6985a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '47fbd8319e2588bab511ef3e564b4c13fa4156e4', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '72ede7aea2c5175235214610dffd25fc3f59f623', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}]",Vishav Sharma,46069089,,User,,8,,2,4
460475703,Added backends to synced_collection,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Implemented Redis, Zarr, and MongoDB backends for SyncedCollection API.
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Related to #249.
## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac/blob/master/changelog.txt) and added all related issue and pull request numbers for future reference (if applicable). See example below.


Example for a changelog entry: `Fix issue with launching rockets to the moon (#101, #212).`
",True,364,https://api.github.com/repos/glotzerlab/signac/pulls/364,https://github.com/glotzerlab/signac/pull/364,closed,602,40,12,40,4,37,1,1,[{'name': 'GSoC'}],2020-07-31 20:22:40+00:00,2020-08-20 07:38:11+00:00,1682131.0,"19 days, 11:15:31","[{'comment_id': 466658375, 'comment_body': ""`deepcopy` try to copy 'redis client' which raises error so I changed it to `copy`."", 'comment_created': datetime.datetime(2020, 8, 6, 20, 9, 44, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 468434440, 'comment_body': 'Please rename module to `collection_mongodb.py`.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 4, 23, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468434897, 'comment_body': '```suggestion\r\nThis implements the MongoDB-backend for SyncedCollection API by\r\n```\r\n""MongoDB"" is a name, please make sure to use it consistently correctly.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 5, 9, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468435163, 'comment_body': '```suggestion\r\nclass MongoDBCollection(SyncedCollection):\r\n```\r\nPlease use the name ""MongoDB"" and its translation into code objects correctly and consistently.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 5, 34, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468435570, 'comment_body': '```suggestion\r\n    """"""Implement sync and load using a MongoDB backend.""""""\r\n```', 'comment_created': datetime.datetime(2020, 8, 11, 9, 6, 15, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468441866, 'comment_body': ""We can massively simplify this constructor implementation and improve the API by only accepting an already instantiated instance of [`pymongo.Collection`](https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection) here. This has the benefit that we don't need to sanitize and validate the input arguments, deal with establishing the connection and related issues, and we don't need to import `pymongo` at all within this module. Finally, this API would be much more flexible for users and developers and decouples it from potential breaking upstream changes in the `pymongo` package.\r\n```suggestion\r\n    def __init__(self, collection, **kwargs):\r\n        self._collection = collection\r\n        super().__init__(**kwargs)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 11, 9, 17, 1, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468442587, 'comment_body': 'Looks like A+ abstraction here. 👍 \r\nDo we even need the `pass` statement here?', 'comment_created': datetime.datetime(2020, 8, 11, 9, 18, 25, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468443085, 'comment_body': 'Not sure if we even need the `pass` statement, but there is inconsistent spacing here compared to the previous class.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 19, 22, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468444191, 'comment_body': 'Similar to my arguments for MongoDB, I would try to move the establishment of connections out of the scope of this constructor as much as possible for a simpler and clearer API:\r\n```suggestion\r\n    def __init__(self, name=None, client=None, **kwargs):\r\n        self._client = client\r\n        self._name = name\r\n        super().__init__(**kwargs)\r\n```\r\n', 'comment_created': datetime.datetime(2020, 8, 11, 9, 21, 26, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468445101, 'comment_body': '```suggestion\r\n        return None if blob is None else json.loads(blob)\r\n```\r\nSlightly easier to interpret I think.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 23, 6, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468445555, 'comment_body': '```suggestion\r\n        self._client.set(self._name, json.dumps(self.to_base()).encode())\r\n```', 'comment_created': datetime.datetime(2020, 8, 11, 9, 23, 50, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468447745, 'comment_body': 'We keep repeating this particular check in all constructors, maybe we can move that into the parent constructor?', 'comment_created': datetime.datetime(2020, 8, 11, 9, 27, 11, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468448216, 'comment_body': 'Similar to the MongoDB and Redis backends, I suggest a slight shift of the API here. Since we are not using the `store` argument anywhere else, it would probably make sense to directly pass the `root` group to the constructor.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 27, 59, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468448606, 'comment_body': '```suggestion\r\n        try:\r\n            return self._root[self.name][0]\r\n        except KeyError:\r\n            return None\r\n```', 'comment_created': datetime.datetime(2020, 8, 11, 9, 28, 42, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468448987, 'comment_body': '?', 'comment_created': datetime.datetime(2020, 8, 11, 9, 29, 22, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468449421, 'comment_body': 'I would very much prefer to have the backend specific tests in their own respective test modules.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 30, 7, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468450423, 'comment_body': 'That changes the test fundamentally, not a good idea. Instead try to implement the `RedisDict.__deepcopy__()` function. Please see [here](https://docs.python.org/3.7/library/copy.html) for more information on how to do this.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 31, 57, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468452235, 'comment_body': 'Please catch the exception in the backend implementation and raise the correct exception type so that we can remove this backend-specific test.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 35, 6, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468453328, 'comment_body': 'And apply similar naming scheme to the other modules.', 'comment_created': datetime.datetime(2020, 8, 11, 9, 37, 5, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 468781415, 'comment_body': 'Okay, will add that.', 'comment_created': datetime.datetime(2020, 8, 11, 18, 30, 42, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 469023829, 'comment_body': ""If we choose to refer to all *MongoDB*-related classes with `MongoDB`, then we need to apply that consistently **everywhere**. However, I noticed that you probably followed the `pymongo` convention of dropping the `DB` everywhere, is that correct? I think that is a fair choice, so I'll leave it up to you to either call everything `MongoX` or `MongoDBX`, but please be consistent."", 'comment_created': datetime.datetime(2020, 8, 12, 6, 4, 5, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469498356, 'comment_body': ""No, we don't need that. I have removed it. "", 'comment_created': datetime.datetime(2020, 8, 12, 19, 44, 39, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 469499044, 'comment_body': ""I'll remove that."", 'comment_created': datetime.datetime(2020, 8, 12, 19, 45, 57, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 469717985, 'comment_body': 'For a proper deepcopy you have to deepcopy `self._client` as well.', 'comment_created': datetime.datetime(2020, 8, 13, 6, 10, 45, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469718779, 'comment_body': 'I did not notice this before, but the word ""data"" is typically assumed to be plural in this context:\r\n```suggestion\r\n        """"""Load data.""""""\r\n```\r\nFurthermore, I think it would make sense to be more explicit here:\r\n```suggestion\r\n        """"""Load data from zarr-file.""""""\r\n```\r\nPlease apply everywhere else as well.', 'comment_created': datetime.datetime(2020, 8, 13, 6, 13, 4, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469719227, 'comment_body': 'For a proper deepcopy, you would need to deepcopy `self._root` as well.', 'comment_created': datetime.datetime(2020, 8, 13, 6, 14, 10, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469721021, 'comment_body': 'For a proper deepcopy, you have to deepcopy `self._collection` as well.', 'comment_created': datetime.datetime(2020, 8, 13, 6, 19, 19, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 469937330, 'comment_body': 'Minor clarification: Dropping the article “the” is a stylistic choice, not one that depends on data being plural or singular. (Otherwise it’d be a debate of “a data” for singular vs “the data” for plural, not a question of dropping the article.) I am fine with the suggested changes, regardless.', 'comment_created': datetime.datetime(2020, 8, 13, 13, 8, 4, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 470142045, 'comment_body': 'I tried to do that but `deepcopy(self._client)` raise `TypeError`.', 'comment_created': datetime.datetime(2020, 8, 13, 17, 55, 47, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 470142905, 'comment_body': 'I tried to do that but `deepcopy(self._collection)` raise `TypeError`.', 'comment_created': datetime.datetime(2020, 8, 13, 17, 57, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 470144586, 'comment_body': 'I have changed it with `Load the data from zarr-store` as we can use database like Redis as zarr backend.', 'comment_created': datetime.datetime(2020, 8, 13, 17, 59, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 470424753, 'comment_body': 'In cases like this, do not silently **introduce a bug into the code**, but instead point out the problem in the discussion here and propose an alternative solution if you have any. I anticipated this as a potential issue, but I did not want to make any assumptions before we actually test this out.\r\n\r\nTo address this issue, I suggest that we rename `__deepcopy__` to `_pseudo_deepcopy` and use that function in the tests instead. In this way we ensure that tests are as closely similar as possible, without implementing a flawed `__deepcopy__()` function. So in the test, it should look like this:\r\n```python\r\ntry:\r\n    synced_dict2 = deepcopy(synced_dict)\r\nexcept TypeError:\r\n    # Use fallback implementation, deepcopy not supported by backend.\r\n    synced_dict2 = synced_dict._pseudo_deepcopy()\r\n```\r\nDoes this make sense? If not, please ask.', 'comment_created': datetime.datetime(2020, 8, 14, 5, 55, 26, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 470424799, 'comment_body': 'See comment above.', 'comment_created': datetime.datetime(2020, 8, 14, 5, 55, 32, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 470510347, 'comment_body': 'Yes, it makes sense.', 'comment_created': datetime.datetime(2020, 8, 14, 9, 18, 7, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 470943654, 'comment_body': '- [x] Please add a doc-string that describes the purpose of this function and the motivation for its implementation.\r\n- [x] Please remove the memo argument, because its use should be restricted to the `__deepcopy__` signature.', 'comment_created': datetime.datetime(2020, 8, 15, 6, 10, 27, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 472191031, 'comment_body': 'Should the `group` argument be documented as optional here? Perhaps it should also be the first parameter documented, since `ZarrCollection` explicitly lists `group` as the first argument and not as a part of `**kwargs`.', 'comment_created': datetime.datetime(2020, 8, 18, 13, 23, 19, tzinfo=datetime.timezone.utc), 'commenter': 'tommy-waltmann', 'type': 'User'}, {'comment_id': 472193106, 'comment_body': 'Should `group` be documented as optional here? If not, I think it would be a good idea to list it before `data`.', 'comment_created': datetime.datetime(2020, 8, 18, 13, 25, 12, tzinfo=datetime.timezone.utc), 'commenter': 'tommy-waltmann', 'type': 'User'}]","[{'commit_sha': '55317355e91d8d6130636c849b4b6d46bd9d8cd5', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '22c4235e040c56055500bba0077c1a1cd45f48ad', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '80ef22dda559daf83d09ad8cc0d6b20d8be16d7c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0203f28fd680c31b8e173e9f4c20ad918e3096e7', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '113b27401fb4dc884a92b7255464ced2b930a001', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b1795f6bfdf86095d74fef8d7a90890eb3d04196', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '84ec0b51381c87684f4501a4173af038339560e2', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8c0d31ba33fd7a3628ec12693385fc88a6747479', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '83492a4b84a27f543395af1b30f9695babbb7067', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '456878f93af1a366b15d2de87833baef5fe9552e', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5275f3acfcbccf7bf5090cab8fbca10106291efa', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0c8cc25239f6d7dc0edfe01d7efb9ace50d3526e', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dc7f8aedc8be8cd04e3ff207cd20f6ba5483471d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dd2e4fa5ef4d4884921d9291b317e1107f7ad5d1', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5d765b4eed0909559cb403ff59608ad3c2c827f1', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5dd9e154d4a5fe65fdb6feb2a6fc910f98f08465', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c1ded73d027b845524fba12baffece4435f18619', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1a1b0751e6880aa9fe03cf7255097cfdaae0c33b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c17abb8bcd31ca16bf963884132daec7c12769a3', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8632cdbc3c614d3fe9b04ff3a734ebbf6f6c846d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6cdb6f4b5e39df35c6e788a622e4244991e02b6f', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f1134523fb587a1aafc259d5405fe37b9fb06410', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3dc74131fa3a9b663abb0c3cbd68971d9641ebd4', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6ff7ecb664e9d9afca290193fdfacc6946c92494', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'db8a96e2fe0e0b71c73e640b5c4d61da8c5c6dc6', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '064eafc2f2732347e4a4d430a637765c449cb8db', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a61a5ebb2e330ed1a9edf531b6ac3c03340767c6', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '25b1139bdcd9c7d18cfdebb021f20b48d372ef2b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3bea2601d3f9e3761583dc0085641605950922b0', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4789b37f92c58f1f1e03407b017b5389c2fa3916', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '813fe90d38ea370c2741e841c4e41a51ef09e60b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c9b659a16f22eaca36e24910cdbf6e82ac5790b2', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a0f28aa2034736fc4a4ecef6555de3a4c4eccf6f', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c2e402e9510d573739f75c97e5598867986d59f1', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9b3304a80e727ee7b8ad4db20249efd8d677624', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c8b82cf499f442af63867cfd92ac428f548cfd4a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '62c346a0d32c1d5cf0938e38fd0427f3d1f2c64d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '49f2dffa752c9dd7065bff617e2f71abfda46b65', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '663781ca03d8b475ed9a1a02f4252870c1d3a49d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '36787edf64b8f486be460eaf131617e49e75d009', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}]",Vishav Sharma,46069089,,User,,8,,2,4
460407412,Added buffering to SyncedCollection,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
 Added buffering feature for `SyncedCollection`.
The buffering will be provided by `signac.buffered` and `SyncedCollection.buffered`.
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Related to #249. This is continuation of work in [PR](https://github.com/vishav1771/signac/pull/2)
## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md#code-style) of this project.
- [ ] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac/blob/master/changelog.txt) and added all related issue and pull request numbers for future reference (if applicable). See example below.


Example for a changelog entry: `Fix issue with launching rockets to the moon (#101, #212).`
",True,363,https://api.github.com/repos/glotzerlab/signac/pulls/363,https://github.com/glotzerlab/signac/pull/363,closed,1079,19,9,81,30,149,1,2,[{'name': 'GSoC'}],2020-07-31 18:57:10+00:00,2020-12-22 14:36:18+00:00,12425948.0,"143 days, 19:39:08","[{'comment_id': 467668745, 'comment_body': 'I saw some code below that is specific to the JSON backend. If there is general-purpose code as well as JSON-specific code, we should separate this into two files and clarify what is contained in each.\r\n```suggestion\r\n""""""Implements buffering for the JSON backend.""""""\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 3, 1, 11, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467668904, 'comment_body': '```suggestion\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 3, 1, 51, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467668997, 'comment_body': 'Use NumPy docstyle. https://numpydoc.readthedocs.io/en/latest/format.html', 'comment_created': datetime.datetime(2020, 8, 10, 3, 2, 30, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467670009, 'comment_body': 'Based on the Python source for `os.path.getsize` and `os.path.getmtime` linked below, I recommend this minor optimization. It performs one stat call instead of two. Reducing the number of `stat` calls can offer a performance boost, especially on slow filesystems and in situations where many files are being accessed.\r\n```suggestion\r\n        metadata = os.stat(filename)\r\n        return metadata.st_size, metadata.st_mtime\r\n```\r\n\r\nhttps://github.com/python/cpython/blob/61f23cb62d6bdd72b61fc36abf4c1492493d71af/Lib/genericpath.py#L48-L55', 'comment_created': datetime.datetime(2020, 8, 10, 3, 7, 51, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467670991, 'comment_body': ""Can you explain this code path in a comment? If `_BUFFERED_MODE_FORCE_WRITE` is True, this will just pop all the items out of the buffer. I don't know how this works well enough to know if that's correct. Perhaps you could check this flag at the beginning like:\r\n```\r\nif _BUFFERED_MODE_FORCE_WRITE:\r\n    # erase the buffer\r\nwhile _BUFFER:  # this doesn't do any work if the buffer is empty\r\n    # pop items from buffer...\r\n    # extract data from cache, etc.\r\n    # assuming _BUFFERED_MODE_FORCE_WRITE is False (already handled that case above)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 10, 3, 14, 1, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467671221, 'comment_body': '```suggestion\r\n    """"""Return True if in buffered read/write mode.""""""\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 3, 15, 25, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467671276, 'comment_body': 'Should this be a private method?', 'comment_created': datetime.datetime(2020, 8, 10, 3, 15, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467671330, 'comment_body': '```suggestion\r\n    force_write: bool\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 3, 16, 5, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467671481, 'comment_body': 'What about the opposite case? Can we enter ""non-force write"" from a ""force write"" mode? It would be good to have tests for that case and tests to ensure that the `BufferException` is raised here.', 'comment_created': datetime.datetime(2020, 8, 10, 3, 17, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467671934, 'comment_body': 'May need to fix the Sphinx reference to this class with the appropriate module prefix.\r\n```suggestion\r\n    buffering for an instance of :class:`SyncedCollection`.\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 3, 20, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467671988, 'comment_body': '```suggestion\r\n    # overwriting load and sync methods\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 3, 20, 42, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467672985, 'comment_body': ""Are these supposed to be marked as abstract methods? If you're expecting children of this class to define the behavior, you can just _not define them_ (delete the `def ... pass`) as shown by class `B` of this example. You can't instantiate `BufferedCollection` directly, so I believe this is what you want.\r\n\r\n```python\r\nfrom abc import ABCMeta, abstractmethod\r\n\r\nclass A(metaclass=ABCMeta):\r\n    @abstractmethod\r\n    def foo(self):\r\n        pass\r\n\r\nclass B(A):\r\n    pass\r\n\r\nclass C(B):\r\n    def foo(self):\r\n        print('foo!')\r\n\r\nif __name__ == '__main__':\r\n    obj = C()\r\n    obj.foo()\r\n```"", 'comment_created': datetime.datetime(2020, 8, 10, 3, 27, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467673457, 'comment_body': ""Why is this class separate from `BufferedCollection`? I looked at the inheritance hierarchy but didn't understand it. Maybe a small diagram could help explain? If they need to be separated, this would be a good place to add a code comment to explain this for future readers as well."", 'comment_created': datetime.datetime(2020, 8, 10, 3, 30, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467673482, 'comment_body': 'Can you explain why this is registered with `SyncedCollection` instead of `BufferedSyncedCollection` or `BufferedCollection`? Add a code comment to explain this for future readers.', 'comment_created': datetime.datetime(2020, 8, 10, 3, 30, 22, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467674351, 'comment_body': ""1. This is really awesome. Needs a docstring to explain its purpose. Specifically, I want to know:\r\n- What do users need to know about Redis behavior? It may be helpful to explain in 1-2 sentences what Redis does, and a link to its docs.\r\n- What do developers need to know about calling this function? Is it idempotent? Is it something that should be called only once by a backend?\r\n\r\nFor example, I find this piece of information important (from the Redis Python package's README):\r\n\r\n> By default, all responses are returned as bytes in Python 3 and str in Python 2. The user is responsible for decoding to Python 3 strings or Python 2 unicode objects.\r\n> \r\n> If all string responses from a client should be decoded, the user can specify decode_responses=True to Redis.__init__. In this case, any Redis command that returns a string type will be decoded with the encoding specified."", 'comment_created': datetime.datetime(2020, 8, 10, 3, 36, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467674484, 'comment_body': 'Why do we need to set/get a test key here?', 'comment_created': datetime.datetime(2020, 8, 10, 3, 37, 6, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467674505, 'comment_body': '2. Are redis stores specific to the application / caller? Do we need to worry about conflicts with other redis clients?', 'comment_created': datetime.datetime(2020, 8, 10, 3, 37, 11, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467675005, 'comment_body': ""3. I see we're calling this function on **every Collection initialization**. That's potentially very expensive. Is it possible to create *one cache at import time* and share it among Collection instances? Is it expensive to call `redis.Redis()`?"", 'comment_created': datetime.datetime(2020, 8, 10, 3, 40, 58, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467675017, 'comment_body': '4. If the Redis process is killed while signac is running in a Python shell, what happens? Is there potential for data loss or errors, or does it only slow down future calls to read data?', 'comment_created': datetime.datetime(2020, 8, 10, 3, 41, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467679753, 'comment_body': 'I\'m not sure this name is going to be a valid URL. You need to generate a URL that includes the class name and backend kwargs in the same ""name.""\r\n```suggestion\r\n    return uuid.uuid5(uuid.NAMESPACE_URL, \'signac://\'+class_name)\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 4, 10, 30, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467679879, 'comment_body': ""Why are you calling `uuid5` twice? This doesn't make sense to me. The first argument to `uuid5` is a namespace."", 'comment_created': datetime.datetime(2020, 8, 10, 4, 11, 22, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467680210, 'comment_body': 'Does this mean that all instances of `JSONCollection` with `filename=None` are going to share the same cache (same UUID key)? That seems incorrect / dangerous.', 'comment_created': datetime.datetime(2020, 8, 10, 4, 13, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467680318, 'comment_body': 'Why did you introduce the ""no sync"" option? It looks like a mechanism for handling buffer conflicts. I think we need to make that more explicit here. Add code comments describing when and why this ""no sync"" behavior would be used.', 'comment_created': datetime.datetime(2020, 8, 10, 4, 14, 1, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467680980, 'comment_body': ""We have inconsistency with how JSON files are referenced. Here it's `json file` but above it was `JSON-file`. Let's be consistent. My preference for both cases is `JSON file`."", 'comment_created': datetime.datetime(2020, 8, 10, 4, 17, 41, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467681363, 'comment_body': ""Call classmethods using the name of the class instead of `self`. However, based on the number of arguments that reference attributes of `self`, I'm not sure if this is really a good fit for a class method.\r\n```suggestion\r\n        JSONCollection._write_to_cache(self._id, data, self._cache)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 10, 4, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467681694, 'comment_body': ""Never, never catch a bare `Exception`. This will also catch tons of things that you wouldn't expect (like keyboard commands to kill a process like Ctrl+C!). You're looking for an element of a container by key, so catch `KeyError`.\r\n\r\n```suggestion\r\n        except KeyError:\r\n```\r\n\r\nIf it's possible to raise any other exceptions (Redis errors?), then you can catch those as well by putting them in a tuple:\r\n\r\n```suggestion\r\n        except (KeyError, SomeRedisException):\r\n```"", 'comment_created': datetime.datetime(2020, 8, 10, 4, 21, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467681986, 'comment_body': ""Call classmethods using the name of the class instead of `self`. As before, I'm not sure if this is a great fit for a `classmethod` since it refers to `self._id` and `self._cache`. Perhaps we should consolidate these two methods (class and instance) into one instance method.\r\n```suggestion\r\n        return JSONCollection._read_from_cache(self._id, self._cache)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 10, 4, 24, 7, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467682236, 'comment_body': 'This is a good abstraction! Do you need a corresponding `abstractmethod` in the parent class? It looks like the buffering implementation relies on this method existing.', 'comment_created': datetime.datetime(2020, 8, 10, 4, 25, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467683267, 'comment_body': ""Use the standard library's `inspect` module to determine if the class is abstract (i.e. has abstract methods). Put `import inspect` at the top.\r\n```suggestion\r\n            if not inspect.isabstract(_cls):\r\n```"", 'comment_created': datetime.datetime(2020, 8, 10, 4, 31, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467683396, 'comment_body': 'We can use f-strings here:\r\n```suggestion\r\n        raise ValueError(f""{backend} backend not found."")\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 4, 31, 47, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467683645, 'comment_body': ""I have some other comments on this topic elsewhere -- you might not need these class methods. It may be sufficient to just have the instance methods `write_to_cache` and `read_from_cache`. Let me know if I'm missing something."", 'comment_created': datetime.datetime(2020, 8, 10, 4, 33, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467683911, 'comment_body': 'I would prefer to see these renamed and made into private methods `_read_from_cache` and `_write_to_cache`. (Those names currently conflict with the class methods, which might be removed based on feedback to other comments.)', 'comment_created': datetime.datetime(2020, 8, 10, 4, 35, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467685559, 'comment_body': 'In my understanding, this order of operations means that the _cache is treated as the ""primary"" source of truth_. That is, (assuming non-buffered mode) if a file is modified outside of this process, I understand that the Redis cache takes precedence over the file\'s contents. Is that correct? (I think that\'s how the cache is designed to work, just wanted to verify my understanding.)\r\n\r\nDo we need to add a way to [explicitly purge, refresh, or ban elements of the cache](https://en.wikipedia.org/wiki/Cache_invalidation)? (Only one of those methods purge/refresh/ban would be necessary, not all of them.)', 'comment_created': datetime.datetime(2020, 8, 10, 4, 44, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467686223, 'comment_body': 'I vaguely recall something like this being in the old implementation? It may prevent a loss of data if an error occurs in the context manager. The goal is to guarantee the final flush occurs. I recommend looking over other parts of the caching/buffering implementation to look for similar patterns where this might be an issue.\r\n```suggestion\r\n        try:\r\n            yield buffered_collection\r\n        finally:\r\n            buffered_collection.flush()\r\n```', 'comment_created': datetime.datetime(2020, 8, 10, 4, 47, 51, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 467686633, 'comment_body': ""Don't add a top-level protected key without an underscore. Also, is this missing the key `backend`? I see it's defined in the class `JSONCollection`. Please verify that you're not missing anything by carefully reviewing the output of `dir(cls)` for the synced collections and subclasses.\r\n```suggestion\r\n                       '_cache', '_backend_kwargs')\r\n```"", 'comment_created': datetime.datetime(2020, 8, 10, 4, 50, 22, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 468819531, 'comment_body': 'Okay, I will add that.', 'comment_created': datetime.datetime(2020, 8, 11, 19, 37, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 468820623, 'comment_body': 'This method is from the previous implementation of buffering. I have tried to match the API as much as possible.', 'comment_created': datetime.datetime(2020, 8, 11, 19, 39, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 468824034, 'comment_body': 'This class implements the global buffering whereas BufferedCollection is backend where all the writes and reads are disabled. The `BufferedCollection` is used to provide buffering for a single instance: `synced_list.buffered`.', 'comment_created': datetime.datetime(2020, 8, 11, 19, 46, 56, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 468827358, 'comment_body': 'Yes, that is correct. \r\n>Do we need to add a way to explicitly purge, refresh, or ban elements of the cache? (Only one of those methods purge/refresh/ban would be necessary, not all of them.)\r\n\r\n I will add that.', 'comment_created': datetime.datetime(2020, 8, 11, 19, 53, 21, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 468829958, 'comment_body': 'We are not storing cache if  `filename` is `None`.', 'comment_created': datetime.datetime(2020, 8, 11, 19, 58, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 468830858, 'comment_body': 'The first call is to generate name_space and second is to generate id.', 'comment_created': datetime.datetime(2020, 8, 11, 19, 59, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 468831826, 'comment_body': 'This is to check whether we have a running redis-server. If the server is not running call to `redis.Redis` do not raise any `Exception` but `set` do.', 'comment_created': datetime.datetime(2020, 8, 11, 20, 2, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 469442450, 'comment_body': 'Which part are you referring to? I tried to make this is independent of backend.', 'comment_created': datetime.datetime(2020, 8, 12, 18, 0, 59, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 477692982, 'comment_body': ""@vishav1771 no need to necessarily match old APIs. If checking whether something is buffered is something that signac has to do, then we can leave this public, but I think based on our more recent discussions it should be private since whether or not we're in buffered mode should be entirely transparent to signac."", 'comment_created': datetime.datetime(2020, 8, 26, 23, 42, 41, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477702711, 'comment_body': ""Rather than creating these registries here, let's just define the `registry` and the `backend_registry` directly in `SyncedCollection` class. This usage is the exact opposite of what we've been discussing in the validation PR, in which every class needs to know its own validators. Here, there is only one registry, and it is stored at the top of the hierarchy."", 'comment_created': datetime.datetime(2020, 8, 26, 23, 49, 11, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477736751, 'comment_body': 'Is there a reason not to just initially set `_JSON_CACHE = get_cache()`, when the variable is first defined, then access it directly everywhere inside `BufferedJSONCollection`? That seems cleaner and easier than having this function and an extra class variable `_cache` that just always references the global cache anyway.', 'comment_created': datetime.datetime(2020, 8, 27, 0, 9, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478572188, 'comment_body': ""This is leftover from my old implementation. I'll change that."", 'comment_created': datetime.datetime(2020, 8, 27, 17, 12, 46, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 479805219, 'comment_body': '@bdice do you know what you were talking about here?', 'comment_created': datetime.datetime(2020, 8, 30, 19, 13, 22, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479805462, 'comment_body': '@vishav1771 did you intend to make this change?', 'comment_created': datetime.datetime(2020, 8, 30, 19, 15, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479806107, 'comment_body': 'There are many typos and inaccuracies in this docstring. It also needs to be updated to the current API. I would also suggest moving the information that is specific to the Redis backend to a separate paragraph to clearly indicate that a Redis cache has different limitations than an in-memory cache.\r\n\r\nThe limitations of the Redis cache with respect to specific data types also makes me wonder, do we need to start placing limitations on what data is cache-able? How do we handle cases where buffering is turned on and we get data types not supported by our cache.', 'comment_created': datetime.datetime(2020, 8, 30, 19, 23, 5, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479806197, 'comment_body': ""Describe the object being returned, don't just write its name."", 'comment_created': datetime.datetime(2020, 8, 30, 19, 23, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479806292, 'comment_body': 'As far as I can tell these kwargs are not actually used. Can we remove this argument entirely?', 'comment_created': datetime.datetime(2020, 8, 30, 19, 24, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479806342, 'comment_body': ""Rename CACHE to cache, it's not a global variable here."", 'comment_created': datetime.datetime(2020, 8, 30, 19, 25, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479806830, 'comment_body': ""Right now this logic will fail if `import redis` fails, because the corresponding `except ImportError` block does not set `CACHE=None`. However, I think this whole function will be simpler and more readable if you just have one try-except instead of two nested ones. Move the import inside the second try, catch the ImportError in the same place you're catching the ConnectionError and AssertionError, then just set cache = dict() in that except block. Then you can remove the outer try-except block as well as this subsequent if-else block (you can move the logger calls into the try-except as well to keep the information)."", 'comment_created': datetime.datetime(2020, 8, 30, 19, 30, 7, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479806978, 'comment_body': 'You can undo this change, this variable no longer exists.', 'comment_created': datetime.datetime(2020, 8, 30, 19, 31, 20, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479807139, 'comment_body': ""I'm confused what this additional layer of sync/load calls adds on top of the `_sync` and `sync` functions. Why do we need these two functions, which right now are just directly calling the underlying functions?"", 'comment_created': datetime.datetime(2020, 8, 30, 19, 33, 22, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479808972, 'comment_body': 'OK, I see the purpose of these methods now in the context of buffering. My overall review comment will address how we can simplify this.', 'comment_created': datetime.datetime(2020, 8, 30, 19, 54, 10, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480317392, 'comment_body': ""I was initially planning to do it, but I don't think we need this in the implementation you proposed."", 'comment_created': datetime.datetime(2020, 8, 31, 18, 42, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 483245481, 'comment_body': 'The reason for having two nested `try except` is if `import redis` fails it raises an error (`redis.exceptions.ConnectionError` is not defined).', 'comment_created': datetime.datetime(2020, 9, 3, 20, 47, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 483674682, 'comment_body': ""That's a good point. However, you can resolve this using multiple except clauses:\r\n```\r\ntry:\r\n    import redis\r\n    ...\r\nexcept ImportError:\r\n    # Do stuff if import failed.\r\nexcept redis.connection.ConnectionError:\r\n    # Do stuff if connection failed.\r\n```\r\n\r\nNot quite as nice as what I originally suggested, but preferable to nested trys IMO."", 'comment_created': datetime.datetime(2020, 9, 4, 15, 1, 25, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 487633497, 'comment_body': 'This needs additional developer documentation. I need more descriptions of what this function and its options like `store_hash` are intended to do.', 'comment_created': datetime.datetime(2020, 9, 14, 3, 33, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487633521, 'comment_body': ""```suggestion\r\n            self._cache['HASH::' + filename] = _hash(blob)\r\n```"", 'comment_created': datetime.datetime(2020, 9, 14, 3, 34, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487633593, 'comment_body': ""```suggestion\r\n        hash_key = 'HASH::' + filename\r\n```"", 'comment_created': datetime.datetime(2020, 9, 14, 3, 34, 30, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487634138, 'comment_body': '```suggestion\r\n    This method returns a Redis client if available, or otherwise an instance of ``dict`` for an in-memory cache.\r\n```', 'comment_created': datetime.datetime(2020, 9, 14, 3, 36, 50, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487634900, 'comment_body': 'I see that in the buffering logic, a method `_pop_from_cache` is implemented. Rather than returning a raw Redis instance in this function, I would recommend creating a small wrapper class for Redis-based caches that is based on `MutableMapping` so that ""pop"" is automatically implemented. That way, it would be much easier to swap out the types of caches available by adhering to a common interface (since `dict` and a class implementing `MutableMapping` will behave the same way). This would be closer to the ideas of [""SOLID design""](https://en.wikipedia.org/wiki/SOLID) in object-oriented programming.', 'comment_created': datetime.datetime(2020, 9, 14, 3, 40, 19, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487635167, 'comment_body': '```suggestion\r\n    return {}\r\n```', 'comment_created': datetime.datetime(2020, 9, 14, 3, 41, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487635318, 'comment_body': ""```suggestion\r\n            assert cache.get(test_key) == b'0'  # Redis store data as bytes\r\n```"", 'comment_created': datetime.datetime(2020, 9, 14, 3, 42, 28, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487635337, 'comment_body': '```suggestion\r\n            logger.info(""Using Redis cache."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 14, 3, 42, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487636381, 'comment_body': 'It is an unusual/confusing pattern to `return` an error and check the error code in the calling code. It would be better style (more Pythonic?) to `raise` and handle this in the calling code with a `try:`/`except OSError:` block. It could make sense to wrap the exception in a custom error class whose message includes the filename, like `CacheFlushError(filename)`.', 'comment_created': datetime.datetime(2020, 9, 14, 3, 47, 42, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487636552, 'comment_body': 'Is it correct to name this a JSON buffer, or would another name be better? (Remove the hyphen if JSON buffer is correct.)\r\n```suggestion\r\n        """"""Flush the data in JSON buffer.\r\n```', 'comment_created': datetime.datetime(2020, 9, 14, 3, 48, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487638144, 'comment_body': ""Would it work to use `getset` to retrieve the existing list and replace it with an empty list? That would be one (atomic) operation, which is probably much more efficient if it works. https://redis-py.readthedocs.io/en/stable/index.html#redis.Redis.getset\r\n```suggestion\r\n            filenames = cls._cache.getset('filenames', []).decode()\r\n```"", 'comment_created': datetime.datetime(2020, 9, 14, 3, 56, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487638614, 'comment_body': 'Use object literals to initialize lists and dicts.\r\n```suggestion\r\n        issues = {}\r\n```', 'comment_created': datetime.datetime(2020, 9, 14, 3, 58, 23, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487639560, 'comment_body': ""At the end of this method, is it expected that the key `filenames` is **set as an empty list** (`assert cls._cache['filenames'] == []`), or that it is **unset** (`assert 'filenames' not in cls._cache`)? It is not clear to me which is desired. Currently I would anticipate (without testing it) that the `dict` cache key is **unset** while the Redis cache key is **an empty list**. Please clarify the intended behavior in the docstring and verify both caches."", 'comment_created': datetime.datetime(2020, 9, 14, 4, 2, 48, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487639634, 'comment_body': 'The `pop` used here mutates the list `filenames`, when all you really need to do is iterate over it. Mutating the data structure to remove each element will be slower than simply reading each element. I suggest the following (note I also applied my separate comment above about raising vs. returning):\r\n\r\n```suggestion\r\n        for filename in filenames:\r\n            try:\r\n                cls._flush(filename)\r\n            except OSError as err:\r\n                issues[filename] = err\r\n        return issues\r\n```', 'comment_created': datetime.datetime(2020, 9, 14, 4, 3, 6, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 487639869, 'comment_body': 'The `isinstance` check could be avoided if we had a small wrapper around the Redis cache that performed the desired operations as a `MutableMapping`. See other comments.', 'comment_created': datetime.datetime(2020, 9, 14, 4, 4, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 488834571, 'comment_body': 'I think the name `file buffer` will be more appropriate?', 'comment_created': datetime.datetime(2020, 9, 15, 17, 22, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 488841916, 'comment_body': 'Redis client removes the key if all the data is removed from the list. So, I expected `filenames` to unset. ', 'comment_created': datetime.datetime(2020, 9, 15, 17, 31, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 488849014, 'comment_body': 'Agreed!\r\n```suggestion\r\n        """"""Flush the data in the file buffer.\r\n```', 'comment_created': datetime.datetime(2020, 9, 15, 17, 38, 39, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 488866860, 'comment_body': ""@bdice  I have added docstring.\r\n>Are redis stores specific to the application / caller? Do we need to worry about conflicts with other redis clients?\r\n\r\nRedis stores are not specific to the application. Redis stores are specific to the port they listen to. We use default port in implementation. So all calls to `redis.Redis()` will connect to the same port. I think we need to handle the conflict with other client.\r\n\r\n>I see we're calling this function on every Collection initialization. That's potentially very expensive. Is it possible to create one cache at import time and share it among Collection instances? Is it expensive to call redis.Redis()?\r\n\r\nIn current implementation, `cache` is class attribute. `redis.Redis()` is called once for a backend.\r\n\r\n>If the Redis process is killed while signac is running in a Python shell, what happens? Is there potential for data loss or errors, or does it only slow down future calls to read data?\r\n \r\nIt will raise `redis.exceptions.ConnectionError`. As `cache` is used in buffering so reads and writes operations to buffer will raise error. Should we have a method to switch between redis.client and dict?  "", 'comment_created': datetime.datetime(2020, 9, 15, 18, 10, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 492292197, 'comment_body': 'I have added  `MetacheckError(filename)` . Any other suggestion for the name?', 'comment_created': datetime.datetime(2020, 9, 21, 19, 21, 15, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 497665328, 'comment_body': 'This should be defined in `core/errors.py` instead of in this file.', 'comment_created': datetime.datetime(2020, 9, 30, 17, 1, 45, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497666366, 'comment_body': '```suggestion\r\n    def _get_file_metadata(filename):\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 3, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497666538, 'comment_body': ""```suggestion\r\n                self._cache['METADATA::' + filename] = self._get_file_metadata(filename)\r\n```"", 'comment_created': datetime.datetime(2020, 9, 30, 17, 3, 54, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497666628, 'comment_body': '```suggestion\r\n                if meta and cls._get_file_metadata(filename) != meta:\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 4, 4, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497667133, 'comment_body': '```suggestion\r\n        """"""Return metadata of file.\r\n        \r\n        This method returns file size and last modification time.\r\n        """"""\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 4, 54, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497668664, 'comment_body': 'Errors are handled by raising now, not returning. This can be removed from the docstring.\r\n```suggestion\r\n        """"""Write the data from buffer to the file.""""""\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 7, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497669245, 'comment_body': '```suggestion\r\n        issues : dict\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 8, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497670228, 'comment_body': ""This should use the method with a default value: `dict.pop(key, default)`. https://docs.python.org/3/library/stdtypes.html#dict.pop\r\n```suggestion\r\n        filenames = cls._cache.pop('filenames', [])\r\n```"", 'comment_created': datetime.datetime(2020, 9, 30, 17, 10, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497672649, 'comment_body': 'The `__contains__` method is the same as the `in` keyword, which should be preferred as an implementation.\r\n```suggestion\r\n        key in self._client\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 12, 25, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497673658, 'comment_body': '```suggestion\r\n    serialization to convert data into bytes.\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 13, 39, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497674550, 'comment_body': ""Is pickling necessary here? What do we need feature-wise that isn't natively supported by Redis? I believe pickling is somewhat slow, so if we can just use JSON-encoded strings and other supported primitives, that would probably be best."", 'comment_created': datetime.datetime(2020, 9, 30, 17, 15, 9, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497675398, 'comment_body': '```suggestion\r\n_BUFFERED_BACKENDS: List[Any] = []\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 16, 39, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497675474, 'comment_body': '```suggestion\r\n    for backend in _BUFFERED_BACKENDS:\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 16, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497675560, 'comment_body': '```suggestion\r\n    _BUFFERED_BACKENDS.append(backend)\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 16, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497675813, 'comment_body': 'Define this in `core/errors.py` instead of in this file.', 'comment_created': datetime.datetime(2020, 9, 30, 17, 17, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497675905, 'comment_body': 'Define this in `core/errors.py` instead of in this file.', 'comment_created': datetime.datetime(2020, 9, 30, 17, 17, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497676355, 'comment_body': ""Doesn't match the implementation.\r\n```suggestion\r\n    files:\r\n```"", 'comment_created': datetime.datetime(2020, 9, 30, 17, 18, 15, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497676540, 'comment_body': '```suggestion\r\n    issues = {}\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 18, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497678348, 'comment_body': '```suggestion\r\n        enter_state = \'enabled\' if force_write else \'disabled\'\r\n        current_state = \'enabled\' if _BUFFERED_MODE_FORCE_WRITE else \'disabled\'\r\n        raise BufferException(\r\n            f""Unable to enter buffered mode with force write {enter_state}, because ""\r\n            f""buffered mode is already active with force write {current_state}."")\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 21, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 497681140, 'comment_body': 'Should ""force write"" be cleared ...\r\n1. ... after the context manager in which it was enabled is no longer active, or\r\n2. ... after all buffering is ended?\r\n\r\nI believe this code is doing the second (force write persists until all buffering is done) but the first would make more sense to me.\r\n\r\n```\r\nenter buffer 0\r\nenter buffer 1 with force write enabled\r\nexit buffer 1\r\n# force write is cleared here in option 1\r\nexit buffer 0\r\n# force write is cleared here in option 2\r\n```', 'comment_created': datetime.datetime(2020, 9, 30, 17, 26, 25, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 510142880, 'comment_body': 'Also, this should return the result of that check, otherwise the function is useless.', 'comment_created': datetime.datetime(2020, 10, 22, 13, 3, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 539431799, 'comment_body': ""I'm going to remove the force write mode entirely with the new implementation. I don't think there's much reason to support it; if we're buffering with a class that implements integrity checks, failure should always be an error. If we see a use case for this in the future, we can reimplement it."", 'comment_created': datetime.datetime(2020, 12, 9, 16, 1, 35, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 543656456, 'comment_body': ""I don't think it's as much a question of what Redis doesn't support as a question of what objects can be converted into bytes via JSON. The question is how we want to restrict the input data. See my main comment on the conversation for a more detailed discussion."", 'comment_created': datetime.datetime(2020, 12, 15, 20, 15, 37, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 544002382, 'comment_body': ""It sounds like there are unresolved concerns to address here in the Redis backend. **In the interest of getting this PR merged, I would recommend that we disable Redis and make an issue about the remaining items:**\r\n- Regarding (1), we're still missing some important information about Redis, its assumptions, and limits of its functionality.\r\n- Regarding (2), do we need to handle interaction with multiple clients potentially using the same server? Does each signac process need a unique identifier of some kind? I don't know enough about Redis to offer insight here.\r\n- Regarding (4), I'm fine with raising an error but I'd like to test this and get a better understanding for the error and what a user would see if the Redis server fails or is killed. It may be necessary to provide the user some kind of additional error info, I'm not sure. I'd prefer to defer this until a later PR.\r\n\r\nI'm fine with the resolution of (3), using this at a class level (so it's not called repeatedly).\r\n\r\n"", 'comment_created': datetime.datetime(2020, 12, 16, 6, 2, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544007350, 'comment_body': ""@vyasr In my understanding, the cache (Redis or dict) stores the contents of entire files (i.e. valid JSON strings, represented as bytes). If that's correct, we should never need to pickle and we shouldn't have any issues with object types -- we only use byte-strings of JSON-encoded data, right? Please correct me if I'm missing something.\r\n\r\n(Reminder to update the docstring to match whatever changes are made here, or make no claims about serialization in the docstring.)"", 'comment_created': datetime.datetime(2020, 12, 16, 6, 8, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544010004, 'comment_body': ""There's inconsistencies between `cls` and the explicit name `FileBufferedCollection`. Is this intentional (to control some behavior of subclasses) or should these all use `cls`? *This affects several places below, which I won't mark.*\r\n```suggestion\r\n        return cls._CURRENT_BUFFER_SIZE\r\n```"", 'comment_created': datetime.datetime(2020, 12, 16, 6, 12, 13, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544025445, 'comment_body': ""So this should implicitly return `None` if the error is `ENOENT`? Just want to be sure we're handling edge cases appropriately. That's not a documented return value and it could cause problems in the calling code?"", 'comment_created': datetime.datetime(2020, 12, 16, 6, 31, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544027624, 'comment_body': 'What do we mean here? This is a private method, it\'s not really ""exposed."" If we mean ""subclasses can override this method to implement other encoding-decoding schemes"" then that can be stated as such.', 'comment_created': datetime.datetime(2020, 12, 16, 6, 33, 57, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544028256, 'comment_body': 'I would copy the docstring from the previous method instead of vaguely referring to it here.', 'comment_created': datetime.datetime(2020, 12, 16, 6, 34, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544030450, 'comment_body': '```suggestion\r\n        # The `_buffered` attribute _must_ be defined prior to calling the\r\n```', 'comment_created': datetime.datetime(2020, 12, 16, 6, 37, 16, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544031049, 'comment_body': 'This section seems like a TODO that should be marked or converted to `# comments`.', 'comment_created': datetime.datetime(2020, 12, 16, 6, 37, 59, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544038684, 'comment_body': ""I'm trying to understand this case, so help me out if I don't get it. Invalid states might occur in a number of weird ways, especially if the cache is an external process like Redis. How we should handle those is tricky. For example, if the state is invalid, how do we even know that a `clear()` will work? I think I want to just raise directly, and just let the state be invalid (rather than attempting to go back to a valid state by removing all data from the cache). Is that a legitimate choice (or a bad idea for some reason), and am I understanding the question correctly?"", 'comment_created': datetime.datetime(2020, 12, 16, 6, 47, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544051800, 'comment_body': 'The overwrite is exactly what I expect, based on the implementation. Exiting the context manager should involve writing to disk, and the modification in the middle should be regarded as an invalidation of the assumptions of buffered mode. Allowing `synced_dict` to overwrite `synced_dict2` seems fine, given that we\'re in the territory of potentially undefined behavior for buffering.\r\n\r\nIf we wanted to make this ""defined and invalid"" instead of ""undefined,"" we could store _only_ the file metadata (size and modification time) upon entering the context manager, and wait to load the file contents until accessed. That would let us catch metadata inconsistencies caused by this case of ""external modification before buffer load."" This would involve splitting the method `_initialize_data_in_cache` into two parts, I believe.', 'comment_created': datetime.datetime(2020, 12, 16, 7, 3, 5, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544069773, 'comment_body': 'Wow. I spent some time thinking about this and played with the code on my own machine for a considerable amount of time. I think it\'s such a weird edge case that I don\'t want to devote further engineering effort to it. If a user has problems with this sharp edge AND has opinions on how to solve it, I\'m happy to consider it with that user\'s input. I won\'t personally do such a torturous thing to my buffers and would recommend the same course of action to all users.\r\n\r\nWe can keep this test and skip it, but I\'d rather see it commented out or removed to avoid the appearance of an ""optional"" skipped test.', 'comment_created': datetime.datetime(2020, 12, 16, 7, 25, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544072239, 'comment_body': 'This is a bug, right? 🐛  The hash should not equal the cache\'s _contents_. We store a `""hash""` key specifically for this purpose and it\'s not used elsewhere.\r\n```suggestion\r\n                if self._hash(blob) != cached_data[""hash""]:\r\n```', 'comment_created': datetime.datetime(2020, 12, 16, 7, 30, 40, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544073033, 'comment_body': 'Does this need to be a call to `_decode`, or is that a separate thing that happens to match the implementation here?', 'comment_created': datetime.datetime(2020, 12, 16, 7, 32, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544073292, 'comment_body': 'Does this need to be a call to `_encode`, or is that a separate thing that happens to match the implementation here?', 'comment_created': datetime.datetime(2020, 12, 16, 7, 32, 50, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 544073450, 'comment_body': 'Does this need to be a call to `_encode`, or is that a separate thing that happens to match the implementation here?', 'comment_created': datetime.datetime(2020, 12, 16, 7, 33, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545256612, 'comment_body': ""I'm fine with waiting to add Redis support. Once this PR is done the buffering infrastructure will be in place, so it would be an almost completely independent change. I'm going to leave this code here so that we have it as a base, but I'll change the call to `get_cache` in the `FileBufferedSyncedCollection` to just always make a dict so that this isn't used anywhere for now."", 'comment_created': datetime.datetime(2020, 12, 17, 17, 11, 11, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545262619, 'comment_body': ""What you're missing is that SyncedCollections are not intrinsically restricted to JSON-encodeable data. That restriction is only made at the level of validators, and for using these classes in signac the plan is to employ JSON validation for all collections. That's also why I created the `_encode` and `_decode` hooks in the `FileBufferedSyncedCollection` class, so that other choices could be made in subclasses if necessary. I think the most extensible solution for this is to initialize a Redis cache with pointers to the encode/decode methods of the associated collection (which we would probably want to be staticmethods in that case), that way the same data restrictions would apply in both cases and different buffering classes could configure it.\r\n\r\nSince we're holding off on merging the Redis caching anyway, the easiest solution for now is to have the `FileBufferedSyncedCollection` default to JSON encoding and document that as a restriction, then come back to it at a later point. I don't know of any better alternatives at the moment, and since buffering is an internal implementation detail that we only require to support signac at the moment, it's not a big deal. I think the hooks I've added should be sufficient to enable alternative encodings easily if necessary.\r\n\r\n@csadorf would also be interested in your thoughts on this."", 'comment_created': datetime.datetime(2020, 12, 17, 17, 19, 54, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545274239, 'comment_body': ""Yes there is a reason. At one point I was creating a separate cache for every subclass of this one, so that if (for example) JSONCollections and PickleCollections both created buffered versions, they would be stored in different classes. Once I implemented global buffering mode, though, I realized that this behavior could cause significant confusion with respect to things like setting the total buffer size. Would you be setting it per backend? What about between different data types (JSONList vs JSONDict)? I decided that the most natural expectation is that it would be truly global, so all backends would share one buffer, so that a user setting a particular buffer size wouldn't have to keep track of how many backends were available, or whether setting it for one backend would affect others. For that reason, I tried to replace all references to class variables relating to caching (the cache itself, its size and capacity, etc) with explicit references to FileBufferedSyncedCollection to avoid any ambiguity. \r\n\r\nIt's entirely possible that I missed some references, so I'll do a quick review to make sure I changed it everywhere. I also should probably move the `[get|set]_buffer_capacity` methods out of the class entirely to avoid any implication that it's class-dependent (even if I make them staticmethods rather than classmethods it might be confusing).\r\n\r\nLet me know if this rationale and the choices I made make sense to you. Happy to restructure if you think it can be improved."", 'comment_created': datetime.datetime(2020, 12, 17, 17, 35, 57, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545283565, 'comment_body': ""Good point, I'll document this return value. It does make sense to do this; imagine that an empty collection is initialized and then buffered mode is enabled. At that point, no file exists, so we need a way to identify a problem if the file is created by something else while the collection is in buffered mode."", 'comment_created': datetime.datetime(2020, 12, 17, 17, 49, 35, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545284341, 'comment_body': 'Yes, it should be.', 'comment_created': datetime.datetime(2020, 12, 17, 17, 50, 47, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545284829, 'comment_body': 'Yep, bug.', 'comment_created': datetime.datetime(2020, 12, 17, 17, 51, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545285957, 'comment_body': 'Another bug, thanks.', 'comment_created': datetime.datetime(2020, 12, 17, 17, 53, 9, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545287447, 'comment_body': 'Yes, this is precisely what I am referring to in our conversation on the Redis cache in caching.py. You\'re right that it\'s not exposed, I\'ll reword to indicate that it\'s a ""hook"" for subclasses to override serialization behavior. However, there\'s an open question as to whether or not we like having this restriction here, since it implicitly adds restrictions to any non-JSON SyncedCollection that has a FileBuffered version.', 'comment_created': datetime.datetime(2020, 12, 17, 17, 55, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545287902, 'comment_body': ""Will do, I'm going to leave this conversation unresolved until we come to a consensus on the proper choice/documentation of the data/encoding restrictions of this class."", 'comment_created': datetime.datetime(2020, 12, 17, 17, 56, 7, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545295778, 'comment_body': 'You\'re getting the gist of the problem, but I don\'t think you\'re quite grasping the cases that I want to avoid. Let me provide an example:\r\n\r\nFor now, let\'s assume that we\'re only dealing with a simple in-memory dict as a cache (the current behavior in signac). I agree that Redis introduces additional complexities, which we can now ignore for the purposes of this pull request. Now assume that the user does something that leads to a `MetadataError`, but they put this code into a try-except block so that they can catch the error. If they try and make _any_ modification of that collection again after the exception has been raised, it will re-raise the same exception because the cache remains invalid (the metadata will always look out-of-date). Therefore, catching a `MetadataError` becomes basically an invalid code path because there\'s no real way to recover from it. At minimum, I think this needs to be documented and `MetadataError` should clearly state that recovery is not possible.\r\n\r\nHowever, it would be _nice_ if we could provide some additional guarantees of safety. There are additional problems that arise in global buffering; if half the flushes work before one fails, then half the user\'s changes will have been persisted to disk while all of the remaining changes (of which potentially there\'s only one invalid one) won\'t have been. That might itself result in an invalid state for the set of collections; we wouldn\'t know what the ""right"" solution is, but a user could try to catch the `MetadataError` in an attempt to correct for that problem. Making our code robust to that wouldn\'t be too difficult; the buffer could retain an `original_contents` field so that we could always restore to the pre-buffered state for all changes that don\'t introduce metadata errors. Of course then we could run into race conditions if something else is indeed modifying the file while this process is running, but we make no promise to support concurrent access.\r\n\r\nI\'m not saying we have to address all of these edge cases, but the ones that aren\'t too difficult I would like to at least fail very loudly and clearly if we choose not to help the user.', 'comment_created': datetime.datetime(2020, 12, 17, 18, 7, 27, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545296707, 'comment_body': ""@csadorf any thoughts on which approach you prefer? I agree with the statement that this is the expected behavior _based on the implementation_ and that the proposed solution would give something well-defined, so I'm mostly trying to get a sense for what people think a reasonable expectation would be for someone who _doesn't_ know the implementation details."", 'comment_created': datetime.datetime(2020, 12, 17, 18, 9, 1, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545297849, 'comment_body': ""I'd rather not remove it entirely so that we have a record of a known failure case, but I'm fine punting on a solution since I truly don't know whether there is a suitable choice for the preferred source of truth here. Either using `xfail` or commenting out would be OK with me. @csadorf thoughts?"", 'comment_created': datetime.datetime(2020, 12, 17, 18, 10, 57, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545339200, 'comment_body': ""@bdice I assume that this comment is no longer relevant to the newer implementation, so please resolve this if you agree (or can't remember what this was for :))."", 'comment_created': datetime.datetime(2020, 12, 17, 19, 15, 29, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545530059, 'comment_body': 'That\'s fine as a way to move this forward. Generally I think it might be fine to assume that any cache that can store ""bytes"" is sufficient, which would cover data formats beyond JSON and would apply to most forms of cache (`dict`, Redis, ...).', 'comment_created': datetime.datetime(2020, 12, 18, 2, 20, 48, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545530285, 'comment_body': 'There was consensus on Slack, this is fine to remove. Resolving this conversation.', 'comment_created': datetime.datetime(2020, 12, 18, 2, 21, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545531164, 'comment_body': ""This design decision is fine with me, I just wanted to be sure that was intentional. It would help to have a comment in the code to indicate that the buffer is shared by all backends, since I wouldn't necessarily assume that behavior as a developer/user."", 'comment_created': datetime.datetime(2020, 12, 18, 2, 24, 35, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545531676, 'comment_body': ""Sounds good. I hadn't thought of that case. This can be resolved if/when the changes have been made."", 'comment_created': datetime.datetime(2020, 12, 18, 2, 26, 4, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545532308, 'comment_body': 'That rewording is what I was looking for, sorry if I was unclear. It sounds like we are settling on having that restriction that data must be JSON-serializable here, at least for this iteration of the design.', 'comment_created': datetime.datetime(2020, 12, 18, 2, 27, 55, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545535281, 'comment_body': '> At minimum, I think this needs to be documented and `MetadataError` should clearly state that recovery is not possible.\r\n\r\nYes, I think that is the right choice. I would document ""Raises: `MetadataError`"" for the context managers, explain that signac will not attempt to recover, and state that clearing will allow the user to return to a valid state at the cost of potential data loss. Then if a user catches this error on purpose, it should be up to the user to attempt to fix the problem (clearing the buffer) or to exit as gracefully as possible.\r\n\r\nTo improve safety in the case you mentioned, it might be possible to defer raising the `MetadataError` until the buffer writes out all the data that hasn\'t been modified in the interim?\r\n\r\nThe idea you suggest for `original_contents` might be useful but I would prefer to ""not clear"" and let the user handle the problem. And the buffer class and the global buffer data storage are private anyway, right?', 'comment_created': datetime.datetime(2020, 12, 18, 2, 37, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545538434, 'comment_body': 'No `else` needed. Also do you mean ""canNOT"" be compared for metadata validation?\r\n```suggestion\r\n            # A return value of None indicates that the file does not\r\n            # exist and cannot be used for metadata-based validation.\r\n            return None\r\n```', 'comment_created': datetime.datetime(2020, 12, 18, 2, 47, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545539381, 'comment_body': 'This call should probably raise `ValueError` or some buffer-specific exception if the current buffer size is larger than the new capacity (otherwise the next store operation will fail, right?). At least, that behavior should be clearly documented.', 'comment_created': datetime.datetime(2020, 12, 18, 2, 50, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545540825, 'comment_body': ""Another reason that I 'm pretty confident that the cache _must_ store its values as `bytes`: that's also an expectation of the hashing function."", 'comment_created': datetime.datetime(2020, 12, 18, 2, 55, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545540960, 'comment_body': 'See [conversation about bytes](https://github.com/glotzerlab/signac/pull/363#discussion_r545540825).\r\n```suggestion\r\n    _cache: Dict[str, bytes] = {}\r\n```', 'comment_created': datetime.datetime(2020, 12, 18, 2, 55, 28, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545544761, 'comment_body': ""Will do, I'll add that in the class docstring."", 'comment_created': datetime.datetime(2020, 12, 18, 3, 8, 42, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545545296, 'comment_body': ""Yes, I think so. Including this hook means that it is possible to use this class as a parent for another object and redefine the data->bytes encoding, so I don't think it's a heavy restriction to default to JSON encoding. @csadorf if you disagree or have a more general solution let us know."", 'comment_created': datetime.datetime(2020, 12, 18, 3, 10, 50, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545546079, 'comment_body': 'Right, that\'s the problem. The details of the cache are all internal, so the user has no way to clear the cache. _That effectively means that there is no way for a user to recover from this state even if they catch the error on purpose, the only option is to exit ""as gracefully as possible"", which might not be very graceful given this constraint._ Is that really the behavior that we want?', 'comment_created': datetime.datetime(2020, 12, 18, 3, 13, 57, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545546364, 'comment_body': ""I meant that the `None` value can be reasonably compared against since `other_metadata == None` will reliably return `False`. I'll reword to clarify."", 'comment_created': datetime.datetime(2020, 12, 18, 3, 15, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545546582, 'comment_body': ""Good catch. Rather than raising an error, shouldn't that just trigger a flush?"", 'comment_created': datetime.datetime(2020, 12, 18, 3, 15, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545550596, 'comment_body': ""This isn't quite right, but I can try to make this more precise. The cache contains more than just the blob, it also contains the hash and the metadata, so if we really want to be precise I think it's `Dict[str, Dict[str, Union[bytes, str, Tuple[int, float]]]]`."", 'comment_created': datetime.datetime(2020, 12, 18, 3, 30, 30, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 545556458, 'comment_body': ""Discussed with @vyasr. We could return all unwritten buffer contents as an attribute of the `BufferedError` and clear the buffer's remaining data. It might be possible to add a method to the `BufferedError` that would forcibly overwrite the data on disk with the unwritten buffer contents. We should not worry about `original_contents` or supporting rollback."", 'comment_created': datetime.datetime(2020, 12, 18, 3, 52, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 545556491, 'comment_body': ""@bdice and I chatted about this briefly. We're in agreement that we don't need to support rollback in buffered mode. The current code already returns the data in the buffer within the Exception, so it makes sense to go ahead and clear the buffer contents so that future operations will work again if the user chooses to catch the exception and continue."", 'comment_created': datetime.datetime(2020, 12, 18, 3, 52, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}]","[{'commit_sha': 'c72edec473d55edc0a045407e8ee8f4fb7e28c2e', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd413a79068e59f549dc64377b587f88f1bd18282', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ecf00af01461b5c3794299c6595b657aac29a86f', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7060709ba3e437017793600d9d3bda51d2e60f86', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '91cffa0b540a545e627e3705859208cd16feb41c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '83a4233b1bdd6ee9e793f8c76d03f649fee51d9c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e6e17226e689d510b830e7bcb5086f97229e72a4', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0b6251637fcb27cc95aace84055caade0242e5e9', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1d327cba0192cfc7b76aa4d7cd3889d5ffacec85', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '057aeb6bbd28e193c94c2aa3af1db0552635eead', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7156aa5a31b45c923750bdf1c01d10224df23ef5', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e7166a5d2459d1fdf70980975fd447066aa7d4d5', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2c4ac30000d25dd82a211d23392bf3f2a01cf3e8', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'add15158bd074135fc8131022ab379a6e9fa4d5c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cf9f86b8247844a7262ac1b8c9d39ef50e8c34a4', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '05a2c94bb34be1773febd51aaca06c3eefe0f24a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '223558f330ad44d0a2289c7f67752a33a9c26275', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '95e2592419555cee28ea43b4e5dddaf00e1479b0', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf134731d8449debb3637258bf12e6d81844df0a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b5ae8974009b5b19d227deed86a1e555ba3a24f4', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '89b3c4ff27a293d9f158edba5f5cb4ca55c50a5e', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dcc401712241d369072c8ad7a1f08380a8633fbe', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2639d9efc1a5ebc08ae29f8fb9b1a106aca9dc83', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6d1729dca31677702b0e4fc8f02ac84c044eaf0c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '75c4057f7a81216b2df0ee60ecc12b5e20a1b327', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fb74bfa99ca792f2db275434a8ec71bc2db800e0', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3c48deb7b70efc5c068a2ee7122a7190f03cfa14', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8155e03784b9b65e8adb8380b9798bd7e4d2193d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3c65f0358842fac826d89457a46c4ea6d3640337', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '91f2998683174d3aa23034ac0c74052c9332ef0b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1b0faa31394e6ffbb463777b0b7882c94991ac64', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '38419b5045aa7b0558319ad26d914c4684932c5c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '50c96635409d3f578e939ff16f0e28be2e86a53c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b30cb0fc00a08f049d349ed88f5fc3924767b1e6', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '173a131146fa8505e8cd8f868fcd8eadf3c3edb2', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a57d10e52db958b2cfb9b2d2678de24d62371d1d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a811bf5615874bdb3b21beaae4625d8335ebc48e', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '680273f5e7f460d82226561a5bea8d2586337097', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '503cf4cba2a17cf138440d1459d41167d05366f0', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a4e1c6b8264e86e89c853951cd3bb82312b9a9a6', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3bf8d009aef718d1f19a28e616ecade8a2b6aa92', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5f0707329d9b549bca0fa4a2eeee3ca1b676b7c8', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c9255590f54c759fd33ee26b17531cf30cc371a8', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1223ecc03badda3df79f58280381041fff341b3e', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b376ab557d1c23f1890d70b151501592af230e28', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '88f00d0c533ca27d3c58d7346bc486c31e0fe35d', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '67183f9fb59bdd93131bd30509446486bfad7035', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '23a3fae18c45c7b983f9166c8cd67bf3b4855a2d', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '43f9eac8b375f221f3c1ec566673d9e302efe2a1', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1d044ccff7e8e2102e570246aebb1595bdb56639', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '893e7e46513508fe914fe90b54c733cc10f335f6', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a96ab398ef1688e89334ebec5d56be42e9056ffe', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9ca4828b14aa01e255cd2be4cba98dab7416ee7e', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3c149125c68727f711eb4894d64ee8cc53f4dd76', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '19badcc724af49be593cf60652b20d356faceaa9', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2fa9fb61aafacf17bd3370f226af746e27d2cb14', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '251590506b436fe801dda1665596c3e0feea04d2', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8ea722eefb3c324d08f462d6618385e116ff856c', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '98e27b1763ef4c5609faf5cb9dddc64329914eab', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f6b175714e36bc69ecbe8c93d9742252fc5c0884', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '15629d36a2dcdc14f91ef4d954717c115a10418a', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b35dee6ac394a5d0435479fb64731f40ebcb237', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4a3ba3612de776281a0e383adcb13a31e4739faa', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4825129f92ea27e05b4810109b5d03000038fd9e', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '13fbab37e0a03946dc5e904f4d069b25a47b2df6', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2630282e95ae7210da85ec7986110f5a6eafb094', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1480071c1bbcc6f4affc6b0efd7517a738507770', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a1c673c1548faa7422a816481b25c008a650bda', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cb0cb8436ea0c18f893cceb513f91b4cc8f1e5a7', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1f8f21a20ad63a9a441fc886c339c9feb6f6106f', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eb3211b895b443f7f5124fe7d9bcf924907830df', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '54e5300449610fedfc28f0253d9ec96ac83ef9d3', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f1d1f2f9376fc0ace90d76dd6e919667bb9e86b0', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'afabcb52fa85c37c1a540d27e65568929c748210', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ff0401b355ff0c73ce5ef6854e1334cdcfc490b2', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f28e4e888e50e388a2e568e8ec86b0415fa2aaa4', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8998b5ba5b3545c7dfd8b9ede5e9d35950390227', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '03753ce078937c08ab73a4cfbe662c308d274665', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '90236074da21857e0e729abd8e9f2eb9019d68e4', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e1b0184412e6ec2dfebf32bfb1e4a7c85350132', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0833add041c1ee7fd3dddfb1110e28c1f1abf688', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}]",Vishav Sharma,46069089,,User,,8,,2,4
461862887,Added hypothesis based tesing to SyncedCollection,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
Added hypothesis based tesing to SyncedCollection
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Related to #249
## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [x] I have updated the API documentation as part of the package doc-strings.
- [x] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [x] I have updated the [changelog](https://github.com/glotzerlab/signac/blob/master/changelog.txt) and added all related issue and pull request numbers for future reference (if applicable). See example below.


Example for a changelog entry: `Fix issue with launching rockets to the moon (#101, #212).`
",False,373,https://api.github.com/repos/glotzerlab/signac/pulls/373,https://github.com/glotzerlab/signac/pull/373,closed,278,221,3,5,4,42,0,0,[],2020-08-02 21:27:30+00:00,2020-08-04 16:59:00+00:00,156690.0,"1 day, 19:31:30","[{'comment_id': 464134117, 'comment_body': 'Just so you know, `hypothesis` changes its version numbers a lot. Every PR that is merged causes a version update.', 'comment_created': datetime.datetime(2020, 8, 2, 23, 6, 5, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464134182, 'comment_body': 'Is this configurable via `setup.cfg` or another file? If so, I would prefer that.', 'comment_created': datetime.datetime(2020, 8, 2, 23, 6, 47, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464134251, 'comment_body': 'It may be desirable to put all of our strategies into a separate module like `strategies.py` if they are re-used in multiple test files.', 'comment_created': datetime.datetime(2020, 8, 2, 23, 7, 31, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464134294, 'comment_body': 'Define this after `DictKeyStrategy` and replace:\r\n```suggestion\r\n        DictKeyStrategy, children, max_size=5),  max_leaves=5)\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 8, 9, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464134575, 'comment_body': ""Seems like this should just be defined in one line. We're not using any inheritance from the base class to the children classes so I don't see a reason to have the extra variable here.\r\n```suggestion\r\n        yield JSONDict(filename=self._fn_, write_concern=False)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 2, 23, 11, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464134678, 'comment_body': '`testdata` was a more descriptive variable name than `d`. Please change it back to `testdata`.', 'comment_created': datetime.datetime(2020, 8, 2, 23, 12, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464135872, 'comment_body': "":warning: *Do not change test behavior* because it may invalidate the purpose of the tests.\r\n\r\nWe shouldn't need to clear the `synced_dict`. It should be newly constructed before each test execution. There is an underlying issue with pytest fixtures and hypothesis that prevents this from working as desired, described here: https://hypothesis.works/articles/hypothesis-pytest-fixtures/\r\n\r\nThese are related issues from pytests and hypothesis:\r\nhttps://github.com/pytest-dev/pytest/issues/916\r\nhttps://github.com/HypothesisWorks/hypothesis/issues/377\r\n\r\nI think one possible workaround would be to avoid the use of a pytest fixture and call a function in the test itself, like:\r\n```python\r\n@given(...)\r\ndef test_stuff(self, ...):\r\n    synced_dict = self.make_synced_dict()\r\n    ...\r\n```"", 'comment_created': datetime.datetime(2020, 8, 2, 23, 24, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464135916, 'comment_body': "":warning: Don't change test behavior. See above about fixtures/hypothesis."", 'comment_created': datetime.datetime(2020, 8, 2, 23, 24, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464135920, 'comment_body': "":warning: Don't change test behavior. See above about fixtures/hypothesis."", 'comment_created': datetime.datetime(2020, 8, 2, 23, 24, 47, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464135930, 'comment_body': "":warning: Don't change test behavior. See above about fixtures/hypothesis."", 'comment_created': datetime.datetime(2020, 8, 2, 23, 24, 50, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464135952, 'comment_body': "":warning: Don't change test behavior. See above about fixtures/hypothesis."", 'comment_created': datetime.datetime(2020, 8, 2, 23, 24, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464135957, 'comment_body': "":warning: Don't change test behavior. See above about fixtures/hypothesis. *I won't mark any more of these below.*"", 'comment_created': datetime.datetime(2020, 8, 2, 23, 25, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464136237, 'comment_body': ""Please don't delete this code from the tests. If it's a problem due to the pytest/hypothesis fixture, then address it a different way."", 'comment_created': datetime.datetime(2020, 8, 2, 23, 27, 26, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464136955, 'comment_body': 'Why did this change?', 'comment_created': datetime.datetime(2020, 8, 2, 23, 34, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464137145, 'comment_body': 'Why did you re-order this test? It makes the diff hard to read (I thought it was a new test, but it was deleted elsewhere below).', 'comment_created': datetime.datetime(2020, 8, 2, 23, 35, 58, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464137299, 'comment_body': 'Deleting this line defeats the purpose of the test. If the `synced_dict` is not deleted, how are we supposed to know that the copy operation acted correctly?', 'comment_created': datetime.datetime(2020, 8, 2, 23, 37, 13, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464137533, 'comment_body': 'This is not an acceptable refactoring because you changed the key. This altered the purpose of the test, which was to attempt to set an invalid type to a **new** key.', 'comment_created': datetime.datetime(2020, 8, 2, 23, 39, 34, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464137888, 'comment_body': 'I would suggest calling this strategy `DictKeyConvertibleStrategy` with a comment at the top of the file.\r\n\r\n```suggestion\r\n    @given(key=DictKeyConvertibleStrategy, testdata=JSONDataStrategy)\r\n```\r\n\r\nTop of the file:\r\n```\r\nDictKeyConvertibleStrategy = st.none() | st.booleans() | st.integers() | DictKeyStrategy\r\n# Any type that can be implicitly converted to a signac SyncedDictionary key.\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 42, 54, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464138357, 'comment_body': '`allow_nan` should be true (the default). The test should still fail with nan values.\r\n```suggestion\r\n    @given(key1=st.tuples(st.integers(), st.integers()) | st.floats(),\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 47, 4, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464138631, 'comment_body': ""I'm not sure why this should raise a different error. Is there an explanation for this? If not, please file an issue so that we can make it return `KeyTypeError` like the other failing cases.\r\n\r\nIf we decide to change this so that the same error is raised, then you can combine `key1` and `key2` into one strategy."", 'comment_created': datetime.datetime(2020, 8, 2, 23, 49, 45, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464138764, 'comment_body': 'This test is being repeated on every invocation of the hypothesis strategy but it only needs to be run once. It could be factored out into its own test (`test_keys_invalid_type_class`) and executed one time.', 'comment_created': datetime.datetime(2020, 8, 2, 23, 50, 40, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464138879, 'comment_body': 'Refactor into one line.\r\n```suggestion\r\n        yield JSONList(filename=self._fn_, write_concern=False)\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 51, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464138914, 'comment_body': 'Refactor into one line.\r\n```suggestion\r\n        yield JSONDict(filename=self._fn_, write_concern=True)\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 52, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464138943, 'comment_body': 'Refactor into one line.\r\n```suggestion\r\n        yield JSONList(filename=self._fn_, write_concern=True)\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 52, 31, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464139037, 'comment_body': 'Use a name for the `@given` arguments. Please apply to the whole PR.\r\n```suggestion\r\n    @given(testdata=JSONDataStrategy)\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 53, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464139178, 'comment_body': ""This test no longer contains the intended behavior: without the calls to `.extend`, this doesn't actually test the right thing. *Passing tests are not indicative of correct refactoring.*"", 'comment_created': datetime.datetime(2020, 8, 2, 23, 54, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464139248, 'comment_body': ""Why was `testdata` renamed to `testdata1`? Doesn't look like there's any reason. Please revert."", 'comment_created': datetime.datetime(2020, 8, 2, 23, 55, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464139537, 'comment_body': 'A negative index is clearer here.\r\n```suggestion\r\n        assert synced_list[-1] == testdata2\r\n```', 'comment_created': datetime.datetime(2020, 8, 2, 23, 57, 43, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464139738, 'comment_body': 'If you have two unique pieces of test data, I prefer the names `testdata1` and `testdata2` instead of `testdata` and `testdata1`.', 'comment_created': datetime.datetime(2020, 8, 2, 23, 59, 33, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464139811, 'comment_body': ""There's an extra space from the old code that can be removed.\r\n```suggestion\r\n    def test_reversed(self, synced_list, data):\r\n```"", 'comment_created': datetime.datetime(2020, 8, 3, 0, 0, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464140001, 'comment_body': 'You use this strategy enough times that it should have a name. In general, I would create a name for any strategy that is used more than two times (with a comment line describing its usage and contents) at the top of the file.', 'comment_created': datetime.datetime(2020, 8, 3, 0, 1, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464140549, 'comment_body': 'We should add a test for removing an element that is not at the front of the list. For example, removing `2` from `[1, 2, 1]` should leave `[1, 1]`. This would be easy, just copy and alter the second half of this test method (highlighted here). You can leave it as part of `test_remove`, just put it at the end below this chunk of code.', 'comment_created': datetime.datetime(2020, 8, 3, 0, 6, 59, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464140656, 'comment_body': 'A small improvement for additional rigor.\r\n```suggestion\r\n        assert not isinstance(synced_list(), SyncedCollection)\r\n        assert not isinstance(synced_list(), type(synced_list))\r\n```', 'comment_created': datetime.datetime(2020, 8, 3, 0, 8, 12, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464140705, 'comment_body': '😄', 'comment_created': datetime.datetime(2020, 8, 3, 0, 8, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464140819, 'comment_body': ""This may be another example of the same problematic pattern with pytest fixtures / hypothesis. I commented on this specifically because it doesn't look like the other instances and would be easy to miss in a refactoring."", 'comment_created': datetime.datetime(2020, 8, 3, 0, 9, 28, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464140886, 'comment_body': 'Why is this possibly unsafe? The previous code did not indicate that it could be unsafe.', 'comment_created': datetime.datetime(2020, 8, 3, 0, 10, 1, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464140990, 'comment_body': ""This deletes the copy instead of the original. *This changes the behavior of the test!* :warning: Too many variables were switched in this test -- I'm not sure if the refactoring you've done here is correct. Please look carefully."", 'comment_created': datetime.datetime(2020, 8, 3, 0, 10, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464141387, 'comment_body': 'This doesn\'t seem right. In the old code, `child1` is a list: `[2, 4]`. Here, it looks like `child1` is a ""data element"" (not a list). Carefully review this test.', 'comment_created': datetime.datetime(2020, 8, 3, 0, 14, 25, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464141788, 'comment_body': ""I don't think that any action needs to be taken -- just letting you know."", 'comment_created': datetime.datetime(2020, 8, 3, 0, 18, 6, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 464625032, 'comment_body': '@bdice I have gone through these issues while implementing this. The workaround I am implementing is using class scope fixture (as they generally discourage the use of function scope fixtures) but that would still require to clear `synced_dict`.\r\nAnd the workaround being proposed here also seems good but I have implemented this type of  testing in #336 and @csadorf asked me to change to fixture [here](https://github.com/glotzerlab/signac/pull/336#discussion_r450751367).\r\n\r\nWhat should I do about this?', 'comment_created': datetime.datetime(2020, 8, 3, 19, 45, 12, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 464627820, 'comment_body': 'I think we can merge this right now as it raises `KeyTypeError` ( `KeyTypeError` inherits from `TypeError`) . ', 'comment_created': datetime.datetime(2020, 8, 3, 19, 51, 41, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 464630424, 'comment_body': 'This is in reference to the [warning](https://github.com/vishav1771/signac/blob/cc895ea425f404125eb50028f3024dfbd604ec78/signac/core/jsoncollection.py#L85-L91) we added to `JSONDict`. I forgot to add this last time.\r\n', 'comment_created': datetime.datetime(2020, 8, 3, 19, 57, 25, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}]","[{'commit_sha': '1a2334d8988aa414ccff2453b09a21d2e621792f', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '80519cfb704b57eae1e42f9a007ed56ef65f2370', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '861735bf81d500a9888d231364a4f2ea8678de83', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '31a55c68cd9643cb47c65dd70f56b04990dffc9e', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1133dbb478c0c0db2889dda0337f73f0311dc0eb', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}]",Vishav Sharma,46069089,,User,,8,,2,4
471219106,Added validation layer to SyncedCollection,"<!-- Provide a general summary of your changes in the Title above -->

## Description
<!-- Describe your changes in detail -->
This PR adds the validation layer to the `SyncedCollection`.
Currently, we only validate the key of `SyncedAttrDict`. This PR extends the behavior to validate the data input to `SyncedCollection`. It adds `AttrFormatValidator` for `SyncedAttrDict` and `JSONFormatValidator` for `JSONCollection`. 
## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->
Related to #249 and #316.
## Types of Changes
<!-- Please select all items that apply either now or after creating the pull request: -->
- [ ] Documentation update
- [ ] Bug fix
- [x] New feature
- [ ] Breaking change<sup>1</sup>

<sup>1</sup>The change breaks (or has the potential to break) existing functionality.

## Checklist:
<!-- Please select all items that apply either now or after creating the pull request. -->
<!-- If you are unsure about any of these items, do not hesitate to ask! -->
- [x] I am familiar with the [**Contributing Guidelines**](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md).
- [x] I agree with the terms of the [**Contributor Agreement**](https://github.com/glotzerlab/signac/blob/master/ContributorAgreement.md).
- [x] My name is on the [list of contributors](https://github.com/glotzerlab/signac/blob/master/contributors.yaml).
- [x] My code follows the [code style guideline](https://github.com/glotzerlab/signac/blob/master/CONTRIBUTING.md#code-style) of this project.
- [x] The changes introduced by this pull request are covered by existing or newly introduced tests.

If necessary:
- [ ] I have updated the API documentation as part of the package doc-strings.
- [ ] I have created a separate pull request to update the [framework documentation](https://docs.signac.io/) on [signac-docs](https://github.com/glotzerlab/signac-docs) and linked it here.
- [ ] I have updated the [changelog](https://github.com/glotzerlab/signac/blob/master/changelog.txt) and added all related issue and pull request numbers for future reference (if applicable). See example below.


Example for a changelog entry: `Fix issue with launching rockets to the moon (#101, #212).`
",True,378,https://api.github.com/repos/glotzerlab/signac/pulls/378,https://github.com/glotzerlab/signac/pull/378,closed,404,78,11,50,6,151,1,1,[{'name': 'GSoC'}],2020-08-20 20:17:25+00:00,2020-09-09 03:40:31+00:00,1668186.0,"19 days, 7:23:06","[{'comment_id': 475779128, 'comment_body': ""This isn't validation for the `JSONCollection` class, it's validation that the input data constitutes input that could be encoded into valid JSON. This is a critical difference, because we plan to use this validation scheme even when using a non-JSON backend."", 'comment_created': datetime.datetime(2020, 8, 24, 17, 28, 11, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475785546, 'comment_body': ""@csadorf how do we want to handle validation classes from an API perspective? I think they need to be public because client code must be able to request specific validators, but I don't know if we need to expose an API to directly use them. In other words, should we leave the validate method private? This pattern would be a bit strange in one sense, because then a validator becomes useless except to be passed to a synced collection. On the other hand, I expect a validator to raise errors if data is invalid, but otherwise be a no-op. This validator is actually converting some invalid data to valid data. Since the reason for this is to support deprecated behavior (and otherwise the operation is either error or no-op) I'm fine with doing it this way, but I would like to eventually move to the method not returning anything, which would constitute an API change. Thoughts?"", 'comment_created': datetime.datetime(2020, 8, 24, 17, 40, 19, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475798622, 'comment_body': ""@vishav1771 as per my comment on the docstring of the `JSONFormatValidator` class, that format validator is not specific to just this collection but could be used for any collection. This also means that `SyncedCollection` should expose an API to register validators to specific subclasses (like `JSONCollection`). However, I don't think that the validation should be controlled by our infrastructure, i.e. a user of the `SyncedCollection` family of classes should be able to freely mix and match validators and backends. I think the best way to enable this is for `SyncedCollection` to define a method `add_validator` or accept validators as a constructor argument. So the prototype in signac I'm imagining would look something like\r\n\r\n```\r\n# Need to import from wherever these actually live.\r\nfrom synced_collection... import JSONDict, JSONFormatValidator\r\n\r\nclass Job:\r\n    def __init__(self, ...):\r\n        ...\r\n        # Option 1\r\n        self._sp = JSONDict(..., validator=JSONFormatValidator)\r\n        # Option 2\r\n        self._sp = JSONDict(...)\r\n        self._sp.add_validator(JSONFormatValidator)\r\n\r\n```\r\n\r\nAn alternative would be to do this on a class level, i.e. to define `add_validator` as a `classmethod` of `SyncedCollection`. This approach introduces complexities such as whether you should inherit validators from parent classes. For instance, if you do `JSONCollection.add_validator(...)` and `JSONDict.add_validator(...)`, I would probably expect `JSONDict` to use the validators added to `JSONCollection` irrespective of the order in which those two calls occurred. On the plus side, this approach is more concise since you don't have to reassign the validator to every instance. @csadorf thoughts?"", 'comment_created': datetime.datetime(2020, 8, 24, 18, 3, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475799194, 'comment_body': 'Is there a reason this inheritance order needed to change? The design of the classes was intended to avoid any collisions that might require nonintuitive method resolution order.', 'comment_created': datetime.datetime(2020, 8, 24, 18, 5, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475799331, 'comment_body': ""Same as above, shouldn't have to hardcode."", 'comment_created': datetime.datetime(2020, 8, 24, 18, 5, 17, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475799761, 'comment_body': 'Was the try-except just performing the JSON validation before?', 'comment_created': datetime.datetime(2020, 8, 24, 18, 6, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475800515, 'comment_body': '```suggestion\r\n    The SyncedAttrDict inherits from :class:`~core.synced_collection.SyncedCollection`\r\n```', 'comment_created': datetime.datetime(2020, 8, 24, 18, 7, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475801591, 'comment_body': 'Having read the whole PR, I assume the reason has to do with the validators associated with the `SyncedAttrDict` class. I think this change can be reverted, see my comment below.', 'comment_created': datetime.datetime(2020, 8, 24, 18, 9, 34, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475803657, 'comment_body': ""I don't think this class needs to exist. There's no case (at least right now) where the `JSONFormatValidator` wouldn't be what we wanted to use in all cases. Also in practice (although we don't have to impose this restriction anywhere in the API) I expect that validation is something that will be used for compatibility with backend specifications, not for filtering specific data types (although that's certainly possible). Also, as I said in a previous comment the validators and collections should be more independent, so the `SyncedAttrDict` doesn't need any validators hardcoded into its initializer anyway."", 'comment_created': datetime.datetime(2020, 8, 24, 18, 13, 34, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475830709, 'comment_body': 'This was changing the exception type (`InvalidDocument` to `TypeError`).  Now, this exception is raised by validator .', 'comment_created': datetime.datetime(2020, 8, 24, 19, 1, 50, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 475831329, 'comment_body': 'Sorry, I will change that.', 'comment_created': datetime.datetime(2020, 8, 24, 19, 3, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 475832419, 'comment_body': 'I will change this to the old implementation (`_valiadate_key`). ', 'comment_created': datetime.datetime(2020, 8, 24, 19, 5, 13, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 475875764, 'comment_body': 'No problem, you can directly apply this suggestion.', 'comment_created': datetime.datetime(2020, 8, 24, 20, 30, 39, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 475881234, 'comment_body': ""That's not what I'm suggesting. To understand the context here, the reason that `SyncedAttrDict` and the `JSONDict` behave differently in current signac is that the `SyncedAttrDict` is used for statepoints and `JSONDict` is used for job documents. The statepoint I/O is not buffered because data integrity absolutely requires that the statepoint be accurate, and we don't expect to change them frequently so we wouldn't gain much from buffering. The job document is more likely to be read and written frequently so it's more important to avoid constantly reading from and writing to disk. We need to be able to replicate these behaviors with the new synced collections.\r\n\r\nThere's no reason for _validation_ to behave differently for these two use cases. The only thing that really needs to differ is whether or not they are buffered. As a result, once the `SyncedCollection` is ready I would expect to use a `JSONDict` for the statepoint and the `BufferedJSONDict` for the job document. So I don't think the `SyncedAttrDict` needs to have the validation method at all.\r\n\r\nHaving said that, from my other comments on the PR it should be clear that I also don't think these classes should have validators assigned by default in the constructor anyway. If you remove that, then since you've already removed the `_validate_key` method I think you're done."", 'comment_created': datetime.datetime(2020, 8, 24, 20, 41, 16, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 476676909, 'comment_body': ""I need to walk back one part of this: certain backends may _require_ some validation, in which case those validators should be applied automatically. In particular, all `JSONCollection` instances need to have the `JSONFormatValidator` applied (even outside the signac context), whereas in signac we plan to apply that validator irrespective of backend because we require the data to be valid JSON no matter what backend is used. So you probably still need to add the validator here.\r\n\r\nSince there need to be some default validators for certain classes, that might lead us to prefer the `classmethod` approach I described, but it also wouldn't be hard to implement either of the instance-based approaches and simply have a separate class constant that just stores the default validators used for instances of a class. As a result, I think both approaches are still feasible even with this requirement."", 'comment_created': datetime.datetime(2020, 8, 25, 19, 10, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 476714891, 'comment_body': '@vyasr What should we done regarding this? Should I revert the change? (as this was removed because I added `JSONFormatValidator` in `MongoDBCollection`)', 'comment_created': datetime.datetime(2020, 8, 25, 20, 23, 11, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 476743186, 'comment_body': ""Since you chose the classmethod approach, we need to consider how to handle the inheritance of validators. For example, have you tested whether a `JSONDict` will throw an error if you try to use a dotted key? With the current implementation I don't think that it will, because those validators only belong to the parent class but won't be inherited by the child."", 'comment_created': datetime.datetime(2020, 8, 25, 21, 18, 26, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 476743339, 'comment_body': 'Have we been typing in other places in the recent PRs?', 'comment_created': datetime.datetime(2020, 8, 25, 21, 18, 46, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 476743999, 'comment_body': ""I don't think either of the validators in this file need to be classes, I would implement them as functions."", 'comment_created': datetime.datetime(2020, 8, 25, 21, 19, 31, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 476756187, 'comment_body': ""I haven't used typing in any of my PRs.  I got an [error](https://app.circleci.com/pipelines/github/glotzerlab/signac/1300/workflows/64d8599a-d2c3-4f0e-b5ad-63dbb194d158/jobs/8088) while testing on CI for this case."", 'comment_created': datetime.datetime(2020, 8, 25, 21, 33, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 476760857, 'comment_body': 'Yes, I have tested it. We also have a test for that. https://github.com/glotzerlab/signac/blob/1906db8dc0f91c3950de06ad9e370c46275b07e9/tests/test_synced_collection.py#L344-L346', 'comment_created': datetime.datetime(2020, 8, 25, 21, 38, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 476999797, 'comment_body': ""Ah OK I see the issue with the current design. The `_validators` list is defined for the `SyncedCollection` class, so when any subclass (for instance, `JSONCollection`) calls `add_validator`, it's actually just extending the same list. As a result, adding a validator to any of the classes adds it to all of them. This example illustrates the problem:\r\n\r\n```\r\nclass A:\r\n    _validators = list()\r\n\r\n    @classmethod\r\n    def add(cls, *val):\r\n        cls._validators.extend(val)\r\n\r\n\r\nclass B(A):\r\n    pass\r\n\r\n\r\nclass C(B):\r\n    pass\r\n\r\n\r\nA.add(1)\r\nB.add(2)\r\nC.add(3)\r\n\r\nprint(A._validators)\r\nprint(B._validators)\r\nprint(C._validators)\r\n\r\nprint(A._validators is B._validators)\r\nprint(A._validators is C._validators)\r\n\r\n# Output \r\n[1, 2, 3]\r\n[1, 2, 3]\r\n[1, 2, 3]\r\nTrue\r\nTrue\r\n```\r\n\r\nThe easiest solution that maintains the class-based approach to validators and still ensures that all instances of `SyncedCollection` get their own `_validators` list is using the `__init_subclass__` hook:\r\n\r\n```\r\nclass A:\r\n    @classmethod\r\n    def __init_subclass__(cls):\r\n        cls._validators = list()\r\n\r\n    @classmethod\r\n    def add(cls, *val):\r\n        cls._validators.extend(val)\r\n\r\n\r\nclass B(A):\r\n    pass\r\n\r\n\r\nclass C(B):\r\n    pass\r\n\r\n\r\nprint(hasattr(A, '_validators'))\r\nprint(hasattr(B, '_validators'))\r\nprint(hasattr(C, '_validators'))\r\nprint(B._validators is C._validators)\r\n\r\n# Output \r\nFalse\r\nTrue\r\nTrue\r\nFalse\r\n```\r\n\r\nNote that this method is called whenever subclasses are created, but not for the creation of the original class, so you will still need to define the `_validators` variable in the `SyncedCollection` class. *Please document why we are using this hook when you write this method.*"", 'comment_created': datetime.datetime(2020, 8, 26, 2, 46, 7, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477000034, 'comment_body': ""Got it, I don't recall when exactly we added mypy validation but makes sense."", 'comment_created': datetime.datetime(2020, 8, 26, 2, 47, 2, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477596087, 'comment_body': 'See suggestion below.\r\n```suggestion\r\nfrom typing import List, Any\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 21, 20, 11, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477596141, 'comment_body': '`Any` is preferred over `object`.\r\n```suggestion\r\n    _validators: List[Any] = list()  # list of callable objects\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 21, 20, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477596992, 'comment_body': 'Need to use raw strings with escaped asterisks to document `*args` and `**kwargs`.\r\n```suggestion\r\n        r""""""Register validator.\r\n\r\n        Parameters\r\n        ----------\r\n        \\*args\r\n            Validator to register\r\n        """"""\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 21, 22, 5, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477597348, 'comment_body': '```suggestion\r\n        """"""Validate the input data.""""""\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 21, 22, 50, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477599330, 'comment_body': 'By returning `data`, it appears validators can also manipulate the data. It introduces the possibility of having the order of validations matter. I see the utility of this for some cases but I\'m not sure if it\'s an ideal design because a ""validator"" doesn\'t sounds like it mutates data (it just sounds like it transparently passes with no return value for valid data and errors on invalid data).', 'comment_created': datetime.datetime(2020, 8, 26, 21, 27, 1, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477603567, 'comment_body': 'However, this reintroduces my original question in [this comment](https://github.com/glotzerlab/signac/pull/378#discussion_r475798622): if we do the class-based approach, we need to handle inheritance of validators from parent classes. @bdice I noticed your response here, what are your thoughts?  I think it would be very confusing to register a `JSONFormatValidator` to the `JSONCollection`, and then have to re-register it to the `JSONDict` and `JSONList` classes. On the other hand, as a user of this code, how would you expect this to behave if you instantiated your own synced collections? Would you expect that modifying a parent of a class changed the validators of that class? I think that is the most consistent behavior we could define.\r\n\r\nAlso, from an implementation point of view, the only way I can think of to enable this is to define `SyncedCollection.validators` as a property that walks the MRO tree and finds the validators registered to all parents. Is there a simpler alternative? ', 'comment_created': datetime.datetime(2020, 8, 26, 21, 36, 30, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477614771, 'comment_body': '@vyasr I read the comments above and in the linked thread. I like the class-based approach you suggested. I would like to register validators with `JSONCollection` and have those apply automatically to `JSONList` and `JSONDict`.\r\n\r\nI haven\'t tried this myself so I don\'t know the pros/cons of the functionality of `__init_subclass__` (which I wasn\'t aware of) vs. walking the MRO entries. (Also in my understanding, it\'s not really an ""MRO tree"" due to C3 linearization, but that\'s subtle.)', 'comment_created': datetime.datetime(2020, 8, 26, 22, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477616994, 'comment_body': 'See #362 - I think the colon is unnecessary unless a data type is specified.\r\n```suggestion\r\n    data\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 22, 8, 51, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477617064, 'comment_body': '```suggestion\r\n    Validated data.\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 22, 9, 6, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477617115, 'comment_body': '```suggestion\r\n    KeyTypeError\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 22, 9, 15, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477617373, 'comment_body': '```suggestion\r\n    data\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 22, 9, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477619897, 'comment_body': 'I don\'t think `bytes` is JSON-serializable -- this could be a bug. I wonder if this is a holdover from Python 2, when `str` and `bytes` were handled differently?\r\n\r\n```pytb\r\n>>> some_bytes = b\'123\'\r\n>>> import json\r\n>>> json.dumps(some_bytes)\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 1, in <module>\r\n  File ""/home/bdice/miniconda3/envs/dice/lib/python3.8/json/__init__.py"", line 231, in dumps\r\n    return _default_encoder.encode(obj)\r\n  File ""/home/bdice/miniconda3/envs/dice/lib/python3.8/json/encoder.py"", line 199, in encode\r\n    chunks = self.iterencode(o, _one_shot=True)\r\n  File ""/home/bdice/miniconda3/envs/dice/lib/python3.8/json/encoder.py"", line 257, in iterencode\r\n    return _iterencode(o, 0)\r\n  File ""/home/bdice/miniconda3/envs/dice/lib/python3.8/json/encoder.py"", line 179, in default\r\n    raise TypeError(f\'Object of type {o.__class__.__name__} \'\r\nTypeError: Object of type bytes is not JSON serializable\r\n```', 'comment_created': datetime.datetime(2020, 8, 26, 22, 16, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477632225, 'comment_body': ""I think we can support any array-like object here with a simple change, but I don't want to complicate this PR. I created a separate issue #380 that can be handled later (not in scope for GSoC)."", 'comment_created': datetime.datetime(2020, 8, 26, 22, 44, 57, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 477647915, 'comment_body': ""I discuss this exact question in [this comment](https://github.com/glotzerlab/signac/pull/378#discussion_r475785546), but in a slightly different context. In early iterations (i.e. last week) the validators were callable classes, so I was asking the question in the context of whether the `validate` method should be public, but I've suggested switching from that approach to using functions because validators are stateless. Let's continue this conversation on that thread though."", 'comment_created': datetime.datetime(2020, 8, 26, 23, 5, 57, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477651043, 'comment_body': ""@bdice now that the validators are just arbitrary callables and not classes, the original public/private discussion is now moot. However, that makes deciding on the appropriate API for validators even more important. As noted in [this thread](https://github.com/glotzerlab/signac/pull/378#discussion_r477599330) in the review, validators in this API are allowed to manipulate data and return it. Is that really what we want? @bdice you and I have independently noted that this is unexpected behavior, so there's definitely something off. I think our options are: 1) change validators to be either raise exceptions or be no-ops, or 2) rename validators to preprocessors or something like that to be more general. I like (1) for it simplicity, but I'm not sure if there's a way around (2). Currently, @vishav1771 is using the modification capability to a) convert non-`str` key types to `str`, which is deprecated behavior that will be removed in version 2.0, and b) convert numpy arrays to lists. If we don't release synced collections until signac 2.0, usage (a) goes away, but we still need (b), which indicates that we need some non-validation pre-processing layer. Thoughts?"", 'comment_created': datetime.datetime(2020, 8, 26, 23, 9, 32, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477656220, 'comment_body': ""The two aren't mutually exclusive, but rather one implies the other. If validators are stored per class, then you _have_ to traverse the MRO (you're right, it's not a tree with new-style classes but I recycled old terminology there) to find the validators added to parent classes. The only way I can see to avoid this is to either 1) not share validators with subclasses, which I don't think makes sense, or 2) to use the instance-based where validators are added to every instance of a class. Option 2 is simpler from an implementation perspective than the class-based approach, but I think it's a poorer design since validation really should apply to all instances of the class, so I would prefer the class approach. What I'm asking is whether you can think of any way to avoid having to traverse the list of parent classes to find this; if not, then I think we just need to implement a `SyncedCollection.validators` `classmethod` property that collects this in the same we handle operations in the FlowProject in signac-flow."", 'comment_created': datetime.datetime(2020, 8, 26, 23, 14, 19, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 477667019, 'comment_body': ""Good catch. That certainly seems likely, and I'm fine just disallowing bytes."", 'comment_created': datetime.datetime(2020, 8, 26, 23, 24, 22, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 478605435, 'comment_body': ""@vyasr I don't think we can use `classmethod` as property. I have implemented it in `_validate`. https://github.com/glotzerlab/signac/blob/39d630d5032bed09d7d08b412e726ee5067a4af8/signac/core/synced_collection.py#L160-L168"", 'comment_created': datetime.datetime(2020, 8, 27, 18, 11, 33, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 478615835, 'comment_body': 'I think we can remove converting NumPy arrays to lists from validators as `SyncedList` handle NumPy arrays. I moved that to validation because I think the serializing of arrays is done to store to JSON backend. In the current implementation, we handle (b) internally so can be removed from validation. ', 'comment_created': datetime.datetime(2020, 8, 27, 18, 31, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 478657330, 'comment_body': '@bdice In #336, we decided not to add backend specific tests in this class. Should I remove this test or not?', 'comment_created': datetime.datetime(2020, 8, 27, 19, 49, 59, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 478657820, 'comment_body': 'I have removed it.', 'comment_created': datetime.datetime(2020, 8, 27, 19, 50, 59, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 478667153, 'comment_body': '@vishav1771 If possible, I would only implement this test for the JSON backend (instead of defining it for all backends and skipping on zarr/redis). I would add a comment to the test that says it should be changed in signac 2.0 and mention issue #316.', 'comment_created': datetime.datetime(2020, 8, 27, 20, 9, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478673902, 'comment_body': ""@vishav1771 I agree with your statement that `@property` and `@classmethod` don't work together. It's possible to create a custom `@classproperty` decorator (like [this example from Django](https://github.com/django/django/blob/4b146e0c83891fc67a422aa22f846bb7654c4d38/django/utils/functional.py#L52-L65)) but that's too complicated in my opinion. This is an alternative using `@property` with `type(self)` instead of `cls`:\r\n\r\n```python\r\nclass AwesomeClass:\r\n    @property\r\n    def name(self):\r\n        return type(self).__name__\r\n\r\nawesome = AwesomeClass()\r\nprint(awesome.name)\r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 20, 22, 28, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478676932, 'comment_body': '@vyasr @vishav1771 I am in favor of **1) change validators to be either raise exceptions or be no-ops.** We shouldn\'t make forward-thinking design decisions based on deprecated behavior. As noted above, that would require us to break deprecated behavior if we just dropped the non-str keys. I would consider inserting a ""workaround"" in `JSONCollection`, which would be separate from (perhaps before?) validation. Its implementation would be similar to the previous approach to handling this. There should be a clear comment to remove the workaround in signac 2.0, since it only affects the JSON backend with specific key types.', 'comment_created': datetime.datetime(2020, 8, 27, 20, 28, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478678436, 'comment_body': '```suggestion\r\n        """"""Add  `_validator` attribute to every subclass.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 31, 33, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478679256, 'comment_body': '```suggestion\r\n        Subclasses contain a list of validators that are applied to collection input data.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 33, 14, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478683413, 'comment_body': ""I _think_ we want to use `cls.__mro__` instead, because it's the cached result of `cls.mro()` at the time the class is instantiated (not an _instance_ of the class, in my understanding). (The `mro` method is defined by `type`.) [https://docs.python.org/3/library/stdtypes.html#class.\\_\\_mro\\_\\_](https://docs.python.org/3/library/stdtypes.html#class.__mro__)\r\n```suggestion\r\n        for _cls in cls.__mro__:\r\n```"", 'comment_created': datetime.datetime(2020, 8, 27, 20, 41, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478684760, 'comment_body': 'New file, new year. 😄\r\n```suggestion\r\n# Copyright (c) 2020 The Regents of the University of Michigan\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 44, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478685150, 'comment_body': '```suggestion\r\n    """"""Raise an exception if there is a dot (``.``) in a mapping\'s key.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 45, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478685444, 'comment_body': '```suggestion\r\n    """"""Implement the validation for JSON serializable data.\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 45, 54, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478685755, 'comment_body': 'Use f-strings.\r\n```suggestion\r\n                        f""Mapping keys may not contain dots (\'.\'): {key}""\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 46, 33, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478686473, 'comment_body': '```suggestion\r\n                    f""Mapping keys must be str, int, bool or None, not {type(key).__name__}"")\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 48, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478687024, 'comment_body': '```suggestion\r\n                    f""Use of {type(key)} as key is deprecated and will be removed in version 2.0"",\r\n                    DeprecationWarning)\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 49, 11, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478687242, 'comment_body': '```suggestion\r\n                    f""Keys must be str, int, bool or None, not {type(key).__name__}"")\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 49, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478687443, 'comment_body': '```suggestion\r\n    raise TypeError(f""Object of {type(data)} is not JSON-serializable"")\r\n```', 'comment_created': datetime.datetime(2020, 8, 27, 20, 49, 59, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478853494, 'comment_body': 'Should the item be validated before loading and suspending synchronization? Seems like it should be the first step. Also for all the other methods below.', 'comment_created': datetime.datetime(2020, 8, 28, 6, 18, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478854381, 'comment_body': 'I would rather copy the try/except snippet into this file, rather than import `synced_collection`.\r\n```suggestion\r\n\r\ntry:\r\n    import numpy\r\n    NUMPY = True\r\nexcept ImportError:\r\n    NUMPY = False\r\n```', 'comment_created': datetime.datetime(2020, 8, 28, 6, 21, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478857168, 'comment_body': 'Why does the `synced_dict.backend` property exist? A type check seems more appropriate, especially since `JSONDict` has already been imported.\r\n```suggestion\r\n        if isinstance(synced_dict, JSONDict):\r\n```', 'comment_created': datetime.datetime(2020, 8, 28, 6, 27, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 478858944, 'comment_body': ""Upon further investigation, I'm almost positive that `backend` should be a private property `_backend`, and it may be possible to eliminate it altogether. I think you can handle the registry using the knowledge you have about synced collection classes without needing to define a string for the backend name."", 'comment_created': datetime.datetime(2020, 8, 28, 6, 31, 48, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 479432981, 'comment_body': ""`synced_dict.backend` is not a property. It is a class attribute. Will change it to private. But I don't think we can remove this. This is also used to find type of child class (`JSONDict` child should be `JSONDict` and `JSONList` )."", 'comment_created': datetime.datetime(2020, 8, 28, 17, 11, 7, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 479802413, 'comment_body': '```suggestion\r\n        # Classes inherit the validators of their parent classes.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 18, 42, 18, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479802639, 'comment_body': ""I don't think you can guarantee that the MRO sequence will go through all classes with validators before all classes without validators. For example, nothing guarantees that JSONCollection will be seen before SyncedDict for the JSONDict class except the inheritance order that we choose.\r\n```suggestion\r\n            if hasattr(_cls, '_validators'):\r\n                for validator in _cls._validators:\r\n                    if validator not in validators:\r\n                        validators.append(validator)\r\n        return validators\r\n```"", 'comment_created': datetime.datetime(2020, 8, 30, 18, 44, 43, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479802732, 'comment_body': ""The property isn't necessary, I just suggested it as a way for collecting the relevant validators. Doing so directly in `_validate` is fine with me as well."", 'comment_created': datetime.datetime(2020, 8, 30, 18, 45, 45, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479802965, 'comment_body': '```suggestion\r\n        Subclasses contain a list of validators that are applied to collection input data.\r\n        Every subclass must have a separate list so that distinct sets of validators can\r\n        be registered to each of them.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 18, 48, 49, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479803882, 'comment_body': '```suggestion\r\n        The registry is used by :meth:`from_base` to determine the appropriate subclass\r\n        of :class:`SyncedCollection` that should be constructed from a particular object.\r\n        This functionality is necessary for converting nested data structures because\r\n        given, for instance, a dict of lists, it must be possible to map the nested lists to\r\n        the appropriate subclass of :class:`SyncedList` corresponding to the desired\r\n        backend.\r\n```', 'comment_created': datetime.datetime(2020, 8, 30, 18, 58, 51, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 479804611, 'comment_body': ""You need to change all validators to not return the data anymore. I didn't comment on this in the other files since it's everywhere and will be easier for you to just go through and delete all instances of `data = validator.validate(data)` or whatever. Removing the returns from these two validators should automatically cause your tests to fail until you fix this everywhere, so that will be easy enough to check."", 'comment_created': datetime.datetime(2020, 8, 30, 19, 6, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 480255874, 'comment_body': '""Code font"" requires two backticks.\r\n```suggestion\r\n        """"""Add  ``_validator`` attribute to every subclass.\r\n```', 'comment_created': datetime.datetime(2020, 8, 31, 16, 48, 10, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480260930, 'comment_body': 'I un-resolved this comment -- it still appears that `data` is mutable in this code.', 'comment_created': datetime.datetime(2020, 8, 31, 16, 55, 59, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480493584, 'comment_body': 'This function requires base-type classes (`dict`, `list`) as input. That should be documented.\r\n- [x] Add suggested docstring (content may need to be wrapped differently for flake8).\r\n- [x] Raise a deprecation warning if a key is not a string (that is, if the `str(key)` forces a conversion) -- see my other comment below for a suggested code snippet.\r\n- [x] Make this a static method or perhaps a standalone private function (outside the class).\r\n- [x] Rename to `_convert_keys_to_str`.\r\n- [x] If there\'s any way that input data (including nested inputs) might be of a collection type that _isn\'t_ `dict` or `list` (e.g. `tuple`, or `set`, or any other `Mapping`-like or `Sequence`-like) then we need to perform the `isinstance` checks differently. However, if we can be sure the inputs are of ""base type"" `dict` or `list` (as noted in the docstring) then we don\'t need to change the current behavior.\r\n```suggestion\r\n    def _convert_non_str_key_to_str(self, data):\r\n        """"""Recursively converts non-string keys to strings for (potentially nested) input collections.\r\n        \r\n        This retains compatibility with auto-casting keys to strings, and will be removed in signac 2.0.\r\n        Input collections must be of ""base type"" (dict or list).\r\n        """"""\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 23, 48, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480497188, 'comment_body': 'Two changes: use a function to cast-and-warn if needed, and use a dict comprehension to return early.\r\n```suggestion\r\n            def _str_key(key):\r\n                if not isinstance(key, str):\r\n                    # raise DeprecationWarning here\r\n                    key = str(key)\r\n                return key\r\n            return {_str_key(key): self._convert_non_str_key_to_str(value) for key, value in data.items()}\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 29, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480497956, 'comment_body': 'Two changes here: exit early (return inside the `elif`) and use a list comprehension.\r\n```suggestion\r\n            return [self._convert_non_str_key_to_str(value) for value in data]\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 30, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480504219, 'comment_body': 'JSON (capitalized) should be used as the proper name for the format. `json` in lowercase should only be used for the Python module name and filename extensions. Please standardize this elsewhere in your code, if needed.\r\n```suggestion\r\n        """"""Write the data to JSON file.""""""\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 40, 9, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480505972, 'comment_body': ""We can be stricter here and use `Callable`. Then the comment no longer carries any information and can be removed. Also in general I recommend literals like `[]` or `{}` instead of `list()` or `dict()`. It's [faster because it doesn't require a function call](https://stackoverflow.com/questions/5790860/and-vs-list-and-dict-which-is-better), and I find it equally readable.\r\n```suggestion\r\n    _validators: List[Callable] = []\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 0, 42, 53, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480506055, 'comment_body': 'See below.\r\n```suggestion\r\nfrom typing import List, Callable\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 43, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480507929, 'comment_body': '```suggestion\r\n        cls._validators = []\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 45, 58, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480510966, 'comment_body': '```suggestion\r\n                validators.extend([v for v in base_cls._validators if v not in validators])\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 49, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480516319, 'comment_body': 'This is a small change but I want to explain my reasoning since it may be helpful when choosing variable names in the future.\r\n1. Why I don\'t like `_cls`: Typically underscores before a variable indicate it is ""private"" (for internal use). But that concept of ""privacy"" isn\'t applicable to a temporary variable like `_cls` here.\r\n2. Alternative `cls`: In this specific case, you could use `cls` instead, because it wouldn\'t shadow any other variables named `cls` (this isn\'t a `classmethod` because we can\'t mix `classmethod` and `property` as previously discussed). Even though we could use `cls`, I think that would be potentially confusing since that typically refers to ""this class.""\r\n3. Alternative `cls_`: The recommended approach to avoid shadowing a variable or conflicting with a keyword is to add an underscore at the end, like `cls_`. This is discussed in [PEP8\'s Descriptive Naming Styles](https://www.python.org/dev/peps/pep-0008/#descriptive-naming-styles). I\'m guessing that this kind of reason was why you selected `_cls` in the first place.\r\n4. Alternative `base_cls`: Descriptive variable names are always a good choice, unless other constraints (like conflicting names or the length of the name) impact readability or line wrapping in an adverse way.\r\n```suggestion\r\n        for base_cls in type(self).__mro__:\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 0, 54, 41, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480523474, 'comment_body': ""```suggestion\r\n            if hasattr(base_cls, '_validators'):\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 1, 1, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480524506, 'comment_body': '```suggestion\r\n            Validator(s) to register.\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 1, 2, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480525346, 'comment_body': '```suggestion\r\n        cls._validators.extend([v for v in args if v not in cls._validators])\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 1, 3, 8, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480533149, 'comment_body': ""Is it correct/safe to remove this call to `self.load()`? I want to be sure we're taking appropriate precautions against I/O errors and that we are keeping the same behavior as before with regards to the in-memory state of `self._data` and on-disk data in the case of I/O errors. I looked at this for a moment but not deeply enough to come to a conclusion."", 'comment_created': datetime.datetime(2020, 9, 1, 1, 10, 30, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480535393, 'comment_body': ""We may wish to change the name of this variable from `mapping` to `other` for consistency with the built-in `dict` documentation. I would like to review this as a whole and follow the built-in types' naming conventions for all synced data structures, where applicable -- I'll create an issue. https://docs.python.org/3/library/stdtypes.html?#dict.update"", 'comment_created': datetime.datetime(2020, 9, 1, 1, 12, 37, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480550120, 'comment_body': 'Does this logic need to be changed, now that the JSON backend converts keys to strings? I think this validator should never warn and should only issue hard errors, because the cast-and-warn should be happening before validation, and only for the JSON backend (no new backends should be allowed to use non-string keys).\r\n```suggestion\r\n            if not isinstance(key, str):\r\n                raise KeyTypeError(\r\n                    f""Keys must be strings, not {type(key).__name__}"")\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 1, 26, 18, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480552127, 'comment_body': 'Is there a reason to do this by-index instead of by-element? This suggestion should be faster/simpler.\r\n```suggestion\r\n        for value in data:\r\n            JSONFormatValidator(value)\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 1, 28, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480558213, 'comment_body': '```suggestion\r\n        # dict key containing dot\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 1, 33, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480558852, 'comment_body': ""It looks like the `JSONFormatValidator` is designed to act _recursively_, but this class is not. Is that an error? I would like to ensure that nested dicts or lists of dicts are handled correctly here:\r\n```\r\nexample1 = {'nested': {'key.with.dots': 'very bad if valid'}}\r\nexample2 = [{'key.with.dots': 'very bad if valid'}]"", 'comment_created': datetime.datetime(2020, 9, 1, 1, 34, 22, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480560729, 'comment_body': ""This may need to be changed if non-string keys are converted before validation in the JSON backend (we aren't going to support non-string keys in new backends). See other comment on `JSONFormatValidator`. If this change does need to be made, then please simplify the logic (since only one type is valid).\r\n```suggestion\r\n    VALID_KEY_TYPES = (str, )\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 1, 36, 3, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480563977, 'comment_body': 'This test should also assert that a deprecation warning is raised.', 'comment_created': datetime.datetime(2020, 9, 1, 1, 39, 2, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480564650, 'comment_body': 'This test may need to be changed based on above suggestions about types, and also example data with nested collections.', 'comment_created': datetime.datetime(2020, 9, 1, 1, 39, 41, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480571703, 'comment_body': 'This change would match the exact error text of the built-in `json` encoding error.\r\n```suggestion\r\n    raise TypeError(f""Object of type {type(data).__name__} is not JSON serializable"")\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 1, 46, 21, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480579682, 'comment_body': 'This is not a sufficient check, see traceback below. It may be sufficient to reject complex values. I\'m not immediately aware of other exceptions. _edit: Extended-precision values can\'t be JSON serialized, but I have not yet identified a good way to detect and handle this problem._\r\n```python\r\n>>> import numpy as np\r\n>>> import json\r\n>>> complex_value = np.complex128(3 + 2j)\r\n>>> assert isinstance(complex_value, np.number)\r\n>>> json.dumps(complex_value.item())\r\nTraceback (most recent call last):\r\n...\r\nTypeError: Object of type complex is not JSON serializable\r\n>>> type(complex_value.item())\r\n<class \'complex\'>\r\n```\r\n```suggestion\r\n    if NUMPY and isinstance(data, (numpy.ndarray, numpy.number)):\r\n        if np.iscomplex(data).any():\r\n            raise TypeError(""NumPy object with complex value(s) is not JSON serializable"")\r\n        else:\r\n            return\r\n```', 'comment_created': datetime.datetime(2020, 9, 1, 1, 53, 52, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 480581747, 'comment_body': 'Add another case that tests complex-valued NumPy arrays. Something like `test_invalid_numpy_data`.', 'comment_created': datetime.datetime(2020, 9, 1, 1, 55, 46, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481304219, 'comment_body': 'Thanks for the information, Will use it.', 'comment_created': datetime.datetime(2020, 9, 1, 17, 13, 11, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 481305578, 'comment_body': 'Thank you for the information. I will keep in mind these points while using variable names in the future.', 'comment_created': datetime.datetime(2020, 9, 1, 17, 15, 27, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 481324288, 'comment_body': 'This `self.load()` is removed from function `reset`. We create a new instance for `self._data` regardless of data in the disk in `reset` so we do not need `self._data` to be synchronized with disk.', 'comment_created': datetime.datetime(2020, 9, 1, 17, 48, 31, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 481328068, 'comment_body': ""Validation is done before we pass the data to the backend. So, I think we need to support all the non-string key types here.\r\n> (we aren't going to support non-string keys in new backends)\r\n\r\nI think we are only removing support for non-string keys in JSON backend."", 'comment_created': datetime.datetime(2020, 9, 1, 17, 54, 57, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 481341073, 'comment_body': 'I have also found this on link\r\n>update() accepts either another dictionary object or an iterable of key/value pairs (as tuples or other iterables of length two). If keyword arguments are specified, the dictionary is then updated with those key/value pairs: d.update(red=1, blue=2).\r\n\r\nCurrently, we support only mapping as input. Should we add iterable of key/value pairs or `kwargs` also?', 'comment_created': datetime.datetime(2020, 9, 1, 18, 18, 36, tzinfo=datetime.timezone.utc), 'commenter': 'vishav1771', 'type': 'User'}, {'comment_id': 481382646, 'comment_body': ""@vishav1771 I'll make a code suggestion."", 'comment_created': datetime.datetime(2020, 9, 1, 19, 31, 51, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481387799, 'comment_body': ""@vishav1771 I can't make a code suggestion inline because it would alter deleted lines, but here's the snippet I would try. You may need to add `from collections.abc import Mapping`.\r\n\r\n```python\r\n    def update(self, other=None, **kwargs):\r\n        self.load()\r\n        if other is not None:\r\n            # Convert sequence of key, value pairs to dict before validation\r\n            if not isinstance(other, Mapping):\r\n                other = dict(other)\r\n            self._validate(other)\r\n        if kwargs:\r\n            self._validate(kwargs)\r\n        with self._suspend_sync():\r\n            for key, value in other.items():\r\n                self._data[key] = self.from_base(data=value, parent=self)\r\n            for key, value in kwargs.items():\r\n                self._data[key] = self.from_base(data=value, parent=self)\r\n        self.sync()\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 19, 41, 45, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481494862, 'comment_body': ""Would it be safe to cache this property in a class attribute like `_cached_validators`? I don't think we need to re-compute the list of supported validators on every call to `self._validate(data)`.\r\n\r\nIt would look something like:\r\n```python\r\nclass SyncedCollection:\r\n    _cached_validators = None\r\n\r\n    @property\r\n    def validators(self):\r\n        # Use @cached_property after dropping Python 3.7\r\n        if self._cached_validators is None:\r\n            self._cached_validators = []\r\n            # Classes inherit the validators of their parent classes.\r\n            for base_cls in type(self).__mro__:\r\n                if hasattr(base_cls, '_validators'):\r\n                    self._cached_validators.extend([v for v in base_cls._validators if v not in validators])\r\n        return self._cached_validators\r\n```\r\n\r\nIt would be awesome if we could use `@cached_property` but that's only available in Python 3.8+. https://docs.python.org/dev/library/functools.html#functools.cached_property"", 'comment_created': datetime.datetime(2020, 9, 1, 23, 53, 56, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481496502, 'comment_body': ""Codecov notes that this line isn't covered. We should add a test for `update` that uses a sequence of (key, value) pairs.\r\n\r\nLike:\r\n```python\r\ndata.update([('key1', 'value1'), ('key2', 'value2')])\r\n```"", 'comment_created': datetime.datetime(2020, 9, 1, 23, 59, 33, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481498866, 'comment_body': '@csadorf @vyasr @mikemhenry I think you\'ve all weighed in on @Vishav\'s design for new backends at some point. One thing I want to clarify is non-string keys. The JSON backend will cast-and-warn when given non-string keys (e.g. ints) until signac 2.x, when we will drop support for non-string keys. But what about other backends? Should other backends be restricted to string keys (with no dots), or should non-string keys be allowed? e.g. Python dictionaries support integers and other hashable types as keys. (I\'m not sure exactly what Zarr/Redis/Mongo support.) I was under the impression that we were only going to allow ""strings with no dots"" as keys for all backends (with _no support for non-string keys in 1.x in the new backends_), but I think @vishav1771 and I might have interpreted that differently. Can someone offer guidance here?\r\n\r\n**edit: Discussed with @vyasr over Slack. We will drop support for non-str keys in signac 2.0 -- this PR\'s current design is fine.**', 'comment_created': datetime.datetime(2020, 9, 2, 0, 7, 36, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481500586, 'comment_body': 'These `return`s should be removed in favor of an `elif`.\r\n```suggestion\r\n    elif isinstance(data, Sequence) and not isinstance(data, str):\r\n        for value in data:\r\n            no_dot_in_key(value)\r\n```', 'comment_created': datetime.datetime(2020, 9, 2, 0, 13, 42, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481504117, 'comment_body': ""@bdice @vishav1771 this change is not necessary and the current implementation is in line with the design that I proposed. The `SyncedCollection` layer is to completely support the use cases in signac while remaining entirely independent of signac. Any validator can be registered with any class prior to its use, which that signac can (and should) apply the `JSON_format_validator` to _all_ back ends. However, a `SyncedAttrDict` used outside the context of signac (which is completely feasible) still needs to avoid having dots in keys because that breaks the attribute-based access to stored items, which is why this validator is shipped with the framework and registered by default to this class. In the context of signac, we'll need both validators.\r\n\r\nOne thing that we haven't discussed but we might need to at some point is, if applying both validators becomes a noticeable performance drag we may need to add a method to clear validators and write a single validator that performs both functions. However, at the moment this would be premature optimization."", 'comment_created': datetime.datetime(2020, 9, 2, 0, 25, 20, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 481506466, 'comment_body': 'We might want to mark the validators as private/for internal use:\r\n```suggestion\r\ndef _json_format_validator(data):\r\n```', 'comment_created': datetime.datetime(2020, 9, 2, 0, 34, 20, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481506626, 'comment_body': 'We might want to mark the validators as private/for internal use:\r\n```suggestion\r\ndef _no_dot_in_key(data):\r\n```', 'comment_created': datetime.datetime(2020, 9, 2, 0, 34, 57, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481507048, 'comment_body': '```suggestion\r\n    """"""Validate input data can be serialized to JSON.\r\n```', 'comment_created': datetime.datetime(2020, 9, 2, 0, 36, 30, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481508356, 'comment_body': '```suggestion\r\n        # dict key containing dot\r\n```', 'comment_created': datetime.datetime(2020, 9, 2, 0, 41, 44, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481508381, 'comment_body': '```suggestion\r\n        # nested dict key containing dot\r\n```', 'comment_created': datetime.datetime(2020, 9, 2, 0, 41, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481512681, 'comment_body': ""@vyasr If I understand you correctly, we intend to apply the JSON format validator to all backends, not just the JSON backend. Regardless, we need to alter the JSON format validator so that it only allows string keys (requiring string keys would match the JSON spec). Currently it's permitting keys that are one of `(str, int, bool, type(None))`.\r\n\r\n**edit: We will drop support for non-str keys in signac 2.0 -- this PR's current design is fine.**"", 'comment_created': datetime.datetime(2020, 9, 2, 0, 51, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481519519, 'comment_body': ""I came here straight from a comment on Slack and I think I missed the point here. @vishav1771 I agree with @bdice that we shouldn't support non-str keys. I actually think we should remove the automatic casting to str altogether. That's deprecated behavior, and I think when synced collections get merged we should go ahead and break it, with the intention of releasing synced collections as part of the 2.x line of signac. \r\n\r\nTo clarify: the purpose of my previous comment was regarding the discussion of what should be supported in new back ends. The SyncedCollection layer should not apply any more validation than is necessary to generate valid input for a given back end. That means that back ends that support non-str keys should not be required to provide them. However, at the signac level we will require valid JSON for state points/documents, so the signac layer should add the `JSON_format_validator` to whatever back end is being used."", 'comment_created': datetime.datetime(2020, 9, 2, 1, 7, 29, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 481529415, 'comment_body': '```suggestion\r\n            # Support for non-str keys will be removed in version 2.0.\r\n            # See issue #316.\r\n            if not isinstance(key, (str, int, bool, type(None))):\r\n```', 'comment_created': datetime.datetime(2020, 9, 2, 1, 31, 24, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481545260, 'comment_body': ""@vyasr Let's drop non-str keys in a follow-up PR. I don't want to introduce any further design changes here right now. This has been through many iterations and I'm confident in the current behavior doing what it intends to do correctly (even though it's not what we want for signac 2.0)."", 'comment_created': datetime.datetime(2020, 9, 2, 1, 56, 17, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481556858, 'comment_body': 'Actually I intended for the validators should be exposed as part of the API. That would allow users to freely apply validators in the event that we start prepackaging more of them.', 'comment_created': datetime.datetime(2020, 9, 2, 2, 14, 52, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 481559972, 'comment_body': ""OK wow my computer just didn't refresh any of your comments. I made my last two without even seeing the ones immediately before them, but now I think I see the whole thread.\r\n\r\nYes, more precisely _signac_ will apply the JSON format validator to all back ends. I make this distinction to make the point that nowhere in any of the files defining SyncedCollection subclasses will we include `cls.add_validator(JSON_format_validator)` except in collection_json.py. Therefore, whatever back end the user chooses to use with signac, signac will internally need to call cls.add_validator prior to creating any instances of that class. _Note that for this reason it also makes sense for validators to be part of the public API._\r\n\r\nI'm fine with waiting to that until a future PR. The necessary conversion for backwards compatibility has been added to the JSONCollection class's sync method, so we would just remove that at some future point."", 'comment_created': datetime.datetime(2020, 9, 2, 2, 19, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 481611511, 'comment_body': ""@vyasr Making them public sets a much higher bar for us to ensure their correctness, performance, and API stability. I suggest we make them internal for now, and reconsider making them public in the future. It's very hard to retract or alter public APIs, as you know."", 'comment_created': datetime.datetime(2020, 9, 2, 3, 34, 38, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 481653618, 'comment_body': 'Agreed, the validator layer(s) should be independent of the backend and we should apply one consistent set of validators to all backends that we natively support.', 'comment_created': datetime.datetime(2020, 9, 2, 4, 18, 17, tzinfo=datetime.timezone.utc), 'commenter': 'csadorf', 'type': 'User'}, {'comment_id': 482106155, 'comment_body': ""While I agree with you in principle, I think in this case we are actually better serving this interest by making these functions public. I think we should be designing the synced collections as a complete abstraction layer relative to the rest of signac, which means that signac should only consume the public API of these classes. Enforcing that requirement will force us to critically evaluate what should be public and private in the synced collections. Since `SyncedCollection.add_validator` is public, it makes sense for us to provide examples of what validators should look like; if we foresaw that changing, that would indicate that `add_validator` would also have to be internal, and that doesn't make any sense to me since (as I mentioned in [this comment](https://github.com/glotzerlab/signac/pull/378#discussion_r481559972)) signac will be applying the `JSON_format_validator` to all backends.  Exposing `add_validator` means the fundamental validator API must be clearly established before we can release this. Regarding correctness and performance, I would argue that issues with correctness constitute bugs that we'll have to fix anyway, and we don't make any performance guarantees with respect to validation, and optimizations are internal changes.\r\n\r\nSince we've decided not to deal with removing non-str support for keys as of yet, we will be able to merge synced collections and make a 1.x release, so we'll have time to evaluate the API and if necessary make changes for 2.0. Alternatively, if you are particularly wary, we could leave them internal for now and make them public at the point of a 2.0 release. However, I would need a very strong reason to keep them internal after a 2.0 release; the need to do that would indicate in my view a significant flaw the design."", 'comment_created': datetime.datetime(2020, 9, 2, 14, 19, 24, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 482266415, 'comment_body': 'I agree with @csadorf we need to have one set of validation that runs for every backend. It would be really annoying to be using a redis backend for performance but when it comes time to archive the data, find out that the keys used for redis are incompatible with json. I also agree that we should wait for a future PR to modify the current behavior.', 'comment_created': datetime.datetime(2020, 9, 2, 18, 7, 24, tzinfo=datetime.timezone.utc), 'commenter': 'mikemhenry', 'type': 'User'}, {'comment_id': 484587165, 'comment_body': 'Unrelated comment, but I noticed that the docstring for SyncedList says it ""behaves like a dictionary"". Change that to say it behaves like a list.', 'comment_created': datetime.datetime(2020, 9, 7, 23, 42, 21, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484587932, 'comment_body': 'While the function signature in the [Python docs](https://docs.python.org/3/tutorial/datastructures.html) does say that the input to `list.extend` is an iterable, technically it also accepts iterators, and in particular generators. For example:\r\n```\r\nx = []\r\ndef f():\r\n    for i in range(10):\r\n        yield i\r\n\r\nx.extend(f())\r\nprint(x)  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n```\r\n\r\nBy calling `list(iterable)` and not saving the result, you will exhaust a generator and fail to add its elements. If the cast is necessary, make sure to save the intermediate result in a variable and pass that to `_validate`, then use that later.', 'comment_created': datetime.datetime(2020, 9, 7, 23, 48, 42, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484587948, 'comment_body': 'Same comment as `extend`.', 'comment_created': datetime.datetime(2020, 9, 7, 23, 48, 50, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484590487, 'comment_body': 'I noticed that the module-level docstrings for both `synced_list.py` and `synced_dict.py` say that these classes implement `to_base` and `from_base`. However, after our registry-based solution was implemented, only `to_base` needs to be implemented by subclasses because `from_base` uses the `SyncedCollection` implementation that calls the appropriate subclass constructors, so these docstrings need to be updated.', 'comment_created': datetime.datetime(2020, 9, 8, 0, 8, 5, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484590587, 'comment_body': ""While it is possibly premature, I think it's worth applying some minor easy optimizations to `setdefault`. If the key is already in the dict, there's no need to call `_validate`, `_data._setdefault`, or `from_base`: you can just set `ret = self._data[key]` after a load and skip the sync. I can't directly suggest because there are deleted lines in this function, but I'm thinking something like:\r\n```\r\ndef setdefault(self, key, default=None):\r\n    self.load()\r\n    try:\r\n        ret = self._data[key]\r\n    except KeyError:\r\n        self._validate({key: default})\r\n        ret = self.from_base(default, parent=self))\r\n        with self._suspend_sync():\r\n            self._data[key] = ret\r\n        self.sync()\r\n    return ret\r\n```\r\nThis method avoids a lot of extra work when the key is in the dict. I purposely chose not to use `self.__getitem__(key)` to avoid depending on that function calling `load` (in case we somehow change that implementation, just trying to avoid subtle bugs). I didn't test this implementation, please make sure I didn't make any errors, in particular with the order of when I call `from_base`."", 'comment_created': datetime.datetime(2020, 9, 8, 0, 8, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484591285, 'comment_body': '```suggestion\r\nA validator is any callable that raises Exceptions when called with invalid data.\r\nValidators should act recursively for nested data structures and should not\r\nreturn any values, only raise errors.\r\n```', 'comment_created': datetime.datetime(2020, 9, 8, 0, 13, 43, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484592207, 'comment_body': 'I would also link the issue directly.', 'comment_created': datetime.datetime(2020, 9, 8, 0, 20, 25, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484592571, 'comment_body': ""All the extraneous `return` statements here are kind of like writing a reverse switch statement and shouldn't be necessary. Just convert all the `if` statements to `elif` so that nothing extra gets run, then you can remove the naked returns. Also, the final `raise TypeError` would then need to be in an `else` clause."", 'comment_created': datetime.datetime(2020, 9, 8, 0, 23, 4, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484593116, 'comment_body': ""Can you make a short comment here indicating that `key` is a string `update`? I did a double take reading this test and had to go back to realize why `synced_dict[key] == 2` and not 1 after this test (I didn't immediately realize `key` wasn't quoted and was actually a variable holding the string `'update'`)."", 'comment_created': datetime.datetime(2020, 9, 8, 0, 26, 49, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484593404, 'comment_body': ""```suggestion\r\n```\r\nThis line isn't necessary, you can just run both validations in one loop."", 'comment_created': datetime.datetime(2020, 9, 8, 0, 28, 59, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484593750, 'comment_body': '@bdice @vishav1771 Was there any further discussion on this? My inclination is that this may not really be safe because users could always add new validators, but we could also forbid that explicitly.\r\n\r\nIf it was just decided that this request is out of scope for this PR, that is fine with me.', 'comment_created': datetime.datetime(2020, 9, 8, 0, 31, 12, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484599703, 'comment_body': 'Test added in 06c249ec6b282e2bfdc24d0c99f97a0fef74206a. Fixed in 1ca00fcbaf102fe5e2a598912fe1f3da3bc36ab1.', 'comment_created': datetime.datetime(2020, 9, 8, 1, 8, 27, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 484599775, 'comment_body': 'Fixed in ce11ad68faf58946aa4948cf2c96279b60e59bab.', 'comment_created': datetime.datetime(2020, 9, 8, 1, 8, 48, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 484600573, 'comment_body': 'Test added in 2516cbe533c85569b01f00a20a311ad935daa9cc. Fixed in 1ca00fcbaf102fe5e2a598912fe1f3da3bc36ab1.', 'comment_created': datetime.datetime(2020, 9, 8, 1, 12, 49, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 484602361, 'comment_body': ""@vyasr Hmm. I guess that caching wouldn't be safe if new validators were applied to a parent class (it would be easy to empty the cache if a validator were added to _this_ class, but it would be hard to propagate that information from a parent class if the parent class's validators changed). Maybe we just leave this as it is for now. I was concerned that constructing this list of validators every time might affect performance. We'll need to do thorough benchmarking/profiling before releasing the new backends. I recommend that we should defer this discussion until we look at the performance more carefully."", 'comment_created': datetime.datetime(2020, 9, 8, 1, 21, 57, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 484604367, 'comment_body': ""Yes we'll need to profile everything once everything is feature complete. On the plus side, we've added a pretty good test suite so if we need to optimize we should be able to validate the changes relatively easy."", 'comment_created': datetime.datetime(2020, 9, 8, 1, 31, 41, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484606940, 'comment_body': '@vishav1771 @vyasr Be aware that handling exceptions can be expensive. I recommend LBYL (`if key in self._data:` / `else:`) instead of EAFP (`try:` / `except KeyError:`) here.\r\n\r\nUpdated code sample:\r\n```python\r\ndef setdefault(self, key, default=None):\r\n    self.load()\r\n    if key in self._data:\r\n        ret = self._data[key]\r\n    else:\r\n        self._validate({key: default})\r\n        ret = self.from_base(default, parent=self))\r\n        with self._suspend_sync():\r\n            self._data[key] = ret\r\n        self.sync()\r\n    return ret\r\n```\r\n\r\nEvidence / demo of LBYL being faster:\r\n\r\n```python\r\nimport timeit\r\n\r\nhit = """"""data = {\'foo\': 0, \'bar\': 0}""""""\r\nmiss = """"""data = {\'baz\': 0, \'bar\': 0}""""""\r\n\r\nlbyl = """"""if \'foo\' in data:\r\n  data[\'foo\'] += 1\r\nelse:\r\n  data[\'bar\'] += 1\r\n""""""\r\n\r\neafp = """"""try:\r\n  data[\'foo\'] += 1\r\nexcept KeyError:\r\n  data[\'bar\'] += 1\r\n""""""\r\n\r\nhit_lbyl_time = timeit.timeit(setup=hit, stmt=lbyl, number=1000000)\r\nhit_eafp_time = timeit.timeit(setup=hit, stmt=eafp, number=1000000)\r\nmiss_lbyl_time = timeit.timeit(setup=miss, stmt=lbyl, number=1000000)\r\nmiss_eafp_time = timeit.timeit(setup=miss, stmt=eafp, number=1000000)\r\n\r\nprint(\'Hit, LBYL:\', hit_lbyl_time)\r\nprint(\'Hit, EAFP:\', hit_eafp_time)\r\nprint(\'Miss, LBYL:\', miss_lbyl_time)\r\nprint(\'Miss, EAFP:\', miss_eafp_time)\r\n```\r\n\r\nResults:\r\n```\r\nHit, LBYL: 0.0599388\r\nHit, EAFP: 0.0484887\r\nMiss, LBYL: 0.0627916\r\nMiss, EAFP: 0.2142205\r\n```\r\n\r\nLBYL and EAFP have nearly the same performance if the key is already present. However, misses are far more expensive for EAFP.', 'comment_created': datetime.datetime(2020, 9, 8, 1, 44, 16, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 484613151, 'comment_body': 'That\'s true, but the typical use case for `setdefault` is when keys are likely to be present. In this case EAFP expresses the expected usage pattern more appropriately. Having said that, I don\'t think there\'s any ""representative"" use case to know how the trade offs play out in practice. Based on your timings you would need >10:1 hit:miss ratio for EAFP to be faster. That\'s actually probably a pretty realistic in any case where I would actually use `setdefault`; in practice unless I expect mostly hits I write LBYL code myself rather than use `setdefault`. However, I don\'t really know what others usually do (tbh in my experience very few people use this method in general) so I don\'t have a strong opinion if your usage pattern indicates that switching would constitute a meaningful performance improvement.', 'comment_created': datetime.datetime(2020, 9, 8, 2, 12, 14, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 484623568, 'comment_body': 'I would find it hard to justify an assumed ratio of >10:1 or more. I lean towards LBYL, because we cannot know the true ratio to expect. For example, I have used `setdefault` in cases where I end up using the “default” more frequently than the stored value, which is the opposite of the “mostly read from existing key” (mostly hits) scenario posed above.', 'comment_created': datetime.datetime(2020, 9, 8, 2, 57, 29, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 484626517, 'comment_body': 'I looked through the CPython standard library for implementations of `setdefault` and it’s a mixture of LBYL and EAFP approaches, depending on the class. There is no clear preference as far as I can tell.', 'comment_created': datetime.datetime(2020, 9, 8, 3, 11, 1, tzinfo=datetime.timezone.utc), 'commenter': 'bdice', 'type': 'User'}, {'comment_id': 484626923, 'comment_body': ""That's fine with me. Frankly I almost always end up using a `defaultdict` anywhere that I might otherwise use `setdefault`, the only real exception being if I'm modifying a dict produced by some third party code, so I'm probably not a representative user of `setdefault` insofar as such a user still exists in Python 3.8. I don't think there's a definite best answer, but I also think it'll have a minor impact since it's a relatively uncommonly used method."", 'comment_created': datetime.datetime(2020, 9, 8, 3, 13, 3, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485306956, 'comment_body': '```suggestion\r\n        # Convert input to a list so that iterators work as well as iterables.\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 2, 54, 55, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485307510, 'comment_body': '```suggestion\r\nThis implements the list data structure for SyncedCollection API by\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 2, 56, 58, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485307607, 'comment_body': '```suggestion\r\nimplementing the convert method `to_base` for lists.\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 2, 57, 22, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485307787, 'comment_body': '```suggestion\r\nimplementing the convert method `to_base` for dictionaries.\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 2, 58, 8, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485308530, 'comment_body': '```suggestion\r\n        If key data type is not supported.\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 3, 0, 53, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485308665, 'comment_body': '```suggestion\r\n        If the key contains invalid characters or is otherwise malformed.\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 3, 1, 23, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485308837, 'comment_body': '```suggestion\r\n        If key data type is not supported.\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 3, 1, 54, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}, {'comment_id': 485309202, 'comment_body': '```suggestion\r\n        If the data type of ``data`` is not supported.\r\n```', 'comment_created': datetime.datetime(2020, 9, 9, 3, 3, 27, tzinfo=datetime.timezone.utc), 'commenter': 'vyasr', 'type': 'User'}]","[{'commit_sha': '009a1b6458af95a04395af228a568fc40a186570', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8fc224ecb628fa06103bba773690d73ae4c685e7', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0117187bf1ad7339884f458fcbc3d9c5e6f28c37', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c13222df276809a4196fba26b95b37f72e874c2b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '43f1072f8d60ed9d1b6cfa2219711dfd520ac294', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '64df46177e84c3c430332e69a63b8628cd6571ce', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c546c8a34419006ca7ec44d501a02e1ff4ca766f', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4d3a1981f82ae5e9eee34ebdf3259415e83acf46', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0e70dd0a4350273298b5a63891b2c6da9dcec398', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4e87740d4d92f961709db1bae4a81a2d214d212c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cf04fb1afc2ac21a3317efc0aa2a66adfe385c9a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '59430574b3b8cf39188d9be3a218580d7d0e8341', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a157e4cc8831e228a65fa37290afcd0c2a4e27ef', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0518d766dd8faf2c5a6358860c92aa481b817719', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2accf51e799f4a2fa2bb9264fefbb640b3ddcf3d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fb0570402fc5f63f11269174b47428ab52a5eedf', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0021865142a641ecbb34ffe462f3cf6c59c7a2f6', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3b4ae94f1dc1c13b3b0f288b61e5438633d3e90a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '39d630d5032bed09d7d08b412e726ee5067a4af8', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'cfbb9e66bf6d66dd9ab2d1a11f4f2ebdb94e848a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a18d68e92bacf709dffc156576568605c70b0800', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '51c0afc0deb4cce96b5baa702983a469fcf0934b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5a90b035b0e2bd272f74df9aad7a224948c3ce8a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '098883599e40e3a69d4d3fa0192aa6d944cad343', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f558e4a0b8f83c671933bd748235e4fa77990b2c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4e86e310783c074a9822adbecaae5bc69d1dc820', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c9d65ef493ec0b0496bc5da8b7cad56be54cb0bc', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '86843a28a63ea3a37af51e61e4ee0c40abdad051', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '09fe82fe0e34cf0f499d86a850a58993678e3db3', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '18d2c41f95a4b9c18265994bb5b05cfbf6a96bf0', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6a742bfec861d38ad2331dac8cc197d24bd21eac', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2f87459c5e61f690503ede815076ecf9264e03a0', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3e6f33bab32d2852093d8b7069acfb42c25a087b', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '624221978f56e088e3cab353f34017b961ef8483', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9e8453a6b646f5d4b597f44fed6e8f23fed8650c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '262052168f8d0efdaad8807e59174386769f9fbe', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6bda14e4a928b4382c4a29abf46bf583f04e4d53', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6af93617ae434fc10914c695df000ff2ab70a13d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e625c984a3e41a8863c661bdb387bed3d1ce4b7a', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ce11ad68faf58946aa4948cf2c96279b60e59bab', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '06c249ec6b282e2bfdc24d0c99f97a0fef74206a', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1ca00fcbaf102fe5e2a598912fe1f3da3bc36ab1', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2516cbe533c85569b01f00a20a311ad935daa9cc', 'committer_username': 'bdice', 'committer_name': 'Bradley Dice', 'committer_email': 'bdice@bradleydice.com', 'commit_date': datetime.datetime(2013, 3, 22, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '60f7d08a6e36a08ea715a28959b9a2f3489a7bb5', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd771b3ce4e9d95b7b382bf637cb6b9ad7a98c6fd', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9e5d47e0b0cde751c3272955df94a1835e14a67a', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c3d5b3747c8818f1b37d792c29cf630ca856777d', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3e9ae47cd356f83cef8ab0f8faa68110971fff5c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c4a698da64c8f70cf8887ceb87db7276af60e05c', 'committer_username': 'vishav1771', 'committer_name': 'Vishav Sharma', 'committer_email': None, 'commit_date': datetime.datetime(2018, 12, 22, 13, 2, 36, tzinfo=datetime.timezone.utc)}, {'commit_sha': '48c44ed9d9a363c3a55ddf2bbf99a69fb910222d', 'committer_username': 'vyasr', 'committer_name': 'Vyas Ramasubramani', 'committer_email': 'vyas.ramasubramani@gmail.com', 'commit_date': datetime.datetime(2012, 3, 14, 21, 27, 38, tzinfo=datetime.timezone.utc)}]",Vishav Sharma,46069089,,User,,8,,2,4

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
168432220,signac,glotzerlab/signac,Python,36,129,13,41,2564,10,55,1,"[{'id': 471219106, 'number': 378, 'closed': datetime.datetime(2020, 9, 9, 3, 40, 31, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 20, 20, 17, 25, tzinfo=datetime.timezone.utc), 'time_taken': 1668186.0, 'time_delta': '19 days, 7:23:06', 'additions': 404, 'deletions': 78, 'state': 'closed'}, {'id': 461862887, 'number': 373, 'closed': datetime.datetime(2020, 8, 4, 16, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 2, 21, 27, 30, tzinfo=datetime.timezone.utc), 'time_taken': 156690.0, 'time_delta': '1 day, 19:31:30', 'additions': 278, 'deletions': 221, 'state': 'closed'}, {'id': 460475703, 'number': 364, 'closed': datetime.datetime(2020, 8, 20, 7, 38, 11, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 31, 20, 22, 40, tzinfo=datetime.timezone.utc), 'time_taken': 1682131.0, 'time_delta': '19 days, 11:15:31', 'additions': 602, 'deletions': 40, 'state': 'closed'}, {'id': 460407412, 'number': 363, 'closed': datetime.datetime(2020, 12, 22, 14, 36, 18, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 31, 18, 57, 10, tzinfo=datetime.timezone.utc), 'time_taken': 12425948.0, 'time_delta': '143 days, 19:39:08', 'additions': 1079, 'deletions': 19, 'state': 'closed'}, {'id': 437064843, 'number': 340, 'closed': datetime.datetime(2020, 7, 6, 11, 28, 37, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 19, 12, 7, 36, tzinfo=datetime.timezone.utc), 'time_taken': 1466461.0, 'time_delta': '16 days, 23:21:01', 'additions': 16, 'deletions': 156, 'state': 'closed'}, {'id': 426779441, 'number': 336, 'closed': datetime.datetime(2020, 7, 31, 14, 39, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 2, 19, 15, 27, tzinfo=datetime.timezone.utc), 'time_taken': 5081072.0, 'time_delta': '58 days, 19:24:32', 'additions': 1356, 'deletions': 13, 'state': 'closed'}, {'id': 410845801, 'number': 332, 'closed': datetime.datetime(2021, 2, 10, 18, 18, 44, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 29, 17, 20, 10, tzinfo=datetime.timezone.utc), 'time_taken': 24800314.0, 'time_delta': '287 days, 0:58:34', 'additions': 408, 'deletions': 240, 'state': 'closed'}, {'id': 401870017, 'number': 324, 'closed': datetime.datetime(2020, 4, 13, 18, 23, 50, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 10, 11, 20, 49, tzinfo=datetime.timezone.utc), 'time_taken': 284581.0, 'time_delta': '3 days, 7:03:01', 'additions': 16, 'deletions': 0, 'state': 'closed'}, {'id': 401045121, 'number': 323, 'closed': datetime.datetime(2020, 4, 23, 22, 28, 59, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 8, 19, 47, 53, tzinfo=datetime.timezone.utc), 'time_taken': 1305666.0, 'time_delta': '15 days, 2:41:06', 'additions': 27, 'deletions': 4, 'state': 'closed'}, {'id': 391686565, 'number': 309, 'closed': datetime.datetime(2021, 11, 2, 17, 43, 28, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 20, 18, 41, 19, tzinfo=datetime.timezone.utc), 'time_taken': 51145329.0, 'time_delta': '591 days, 23:02:09', 'additions': 119, 'deletions': 1773, 'state': 'closed'}, {'id': 382082881, 'number': 300, 'closed': datetime.datetime(2020, 3, 19, 13, 8, 5, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 1, 19, 17, 6, tzinfo=datetime.timezone.utc), 'time_taken': 1533059.0, 'time_delta': '17 days, 17:50:59', 'additions': 480, 'deletions': 14, 'state': 'closed'}, {'id': 377393364, 'number': 296, 'closed': datetime.datetime(2020, 2, 28, 18, 40, 50, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 2, 19, 20, 59, 31, tzinfo=datetime.timezone.utc), 'time_taken': 769279.0, 'time_delta': '8 days, 21:41:19', 'additions': 131, 'deletions': 105, 'state': 'closed'}, {'id': 369077939, 'number': 282, 'closed': datetime.datetime(2020, 1, 31, 8, 17, 57, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 1, 30, 13, 37, 16, tzinfo=datetime.timezone.utc), 'time_taken': 67241.0, 'time_delta': '18:40:41', 'additions': 37, 'deletions': 28, 'state': 'closed'}, {'id': 368530760, 'number': 280, 'closed': datetime.datetime(2020, 2, 10, 15, 22, 2, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 1, 29, 12, 29, 46, tzinfo=datetime.timezone.utc), 'time_taken': 1047136.0, 'time_delta': '12 days, 2:52:16', 'additions': 17, 'deletions': 5, 'state': 'closed'}, {'id': 366556866, 'number': 275, 'closed': datetime.datetime(2020, 1, 29, 18, 18, 32, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 1, 23, 20, 38, 40, tzinfo=datetime.timezone.utc), 'time_taken': 509992.0, 'time_delta': '5 days, 21:39:52', 'additions': 2620, 'deletions': 2687, 'state': 'closed'}, {'id': 363119364, 'number': 271, 'closed': datetime.datetime(2020, 1, 24, 0, 45, 1, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 1, 15, 12, 45, 3, tzinfo=datetime.timezone.utc), 'time_taken': 734398.0, 'time_delta': '8 days, 11:59:58', 'additions': 28, 'deletions': 1, 'state': 'closed'}]"

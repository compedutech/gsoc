pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
421543470,"sync_offset, reshape datasets and get coords for UDFs","## Google Summer of Code '20 project [(page)](https://summerofcode.withgoogle.com/archive/2020/projects/5402292951449600/)

Fixes #256, fixes #553 and fixes #726 and

* The Python API and GUI now allows specifying `nav_shape` and `sig_shape` parameters to set a different shape
* `scan_size` and `detector_size` parameters are deprecated in favor of `nav_shape` and `sig_shape` respectively
* All datasets handle missing data gracefully
* The Python API and GUI now allow specifying a `sync_offset` to handle synchronization/acquisition problems
* Users can now access the coordinates of a tile/partition slice through UDFMeta.coordinates

## Todo

* [ ] https://github.com/LiberTEM/LiberTEM/issues/441#issuecomment-735218240
* [x] #911

## Contributor Checklist:

* [x] I have added or updated my entry in [the creators.json file](https://github.com/LiberTEM/LiberTEM/blob/master/packaging/creators.json)
* [x] I have added [a changelog entry](https://github.com/LiberTEM/LiberTEM/tree/master/docs/source/changelog) for my contribution
* [x] I have added/updated documentation for all user-facing changes
* [x] I have added/updated test cases
* [x] I have included the [rebuilt production build of the client](https://libertem.github.io/LiberTEM/contributing.html?#building-the-client)
",True,793,https://api.github.com/repos/LiberTEM/LiberTEM/pulls/793,https://github.com/LiberTEM/LiberTEM/pull/793,closed,4294,760,93,3,125,110,5,0,"[{'name': 'enhancement'}, {'name': 'GUI'}, {'name': 'Web API'}, {'name': 'Python API'}, {'name': 'GSOC'}]",2020-05-21 19:39:58+00:00,2020-12-14 19:58:00+00:00,17885882.0,"207 days, 0:18:02","[{'comment_id': 430334999, 'comment_body': 'While this is a possible implementation, I would prefer if this was done at a higher level - especially as the logic (and possibly implementation) could more likely be shared among `DataSet` subclasses. I think a previous version of this modified `get_partitions` and `make_slices` - I would prefer that approach! That should also allow negative offsets more easily.', 'comment_created': datetime.datetime(2020, 5, 26, 11, 12, 38, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 430339175, 'comment_body': 'Style: to improve readability, the expression computing the number of ignored frames could be extracted into a variable (especially helpful for more complex expressions, which can be formatted in a more readable way if they are not embedded in a JSX expression)', 'comment_created': datetime.datetime(2020, 5, 26, 11, 21, 18, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 430339552, 'comment_body': 'This could be extracted into its own small helper function, as it is also used in the `Form`.', 'comment_created': datetime.datetime(2020, 5, 26, 11, 22, 10, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 433940815, 'comment_body': 'I think it should be possible to merge the two `make_slices_*` functions again: the overall structure seems to be the same, only that in one case, there is an offset added to `start` and `stop`, and in the other, the offset is added to the origin of the slice. Maybe this can be done with additional variables, where only one of them is non-zero, depending on the sign of the offset?', 'comment_created': datetime.datetime(2020, 6, 2, 14, 55, 56, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 433943370, 'comment_body': 'The new `sync_offset` parameter should be added to the docstring below', 'comment_created': datetime.datetime(2020, 6, 2, 14, 59, 14, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 433999805, 'comment_body': 'Just curious, what happens if `start - sync_offset < 0` and `stop - sync_offset >0`? For example, with `start=0, stop=10, sync_offset=2`? Doesn\'t that mean it will start at `-2`, so two ""from the right""? Or does this never happen, because `start` and `sync_offset` are, in a way, synchronized?\r\n\r\nMaybe in the case mentioned above, the function should throw an exception? Also, the docstring should explicitly mention the allowed ranges and possibly the relation between `sync_offset` and `start`. Regarding the docstring, it should be updated to make very clear what `start` and `stop` are relative to - in the updated function, they are relative to the start indices, before applying the `sync_offset`, right?', 'comment_created': datetime.datetime(2020, 6, 2, 16, 8, 36, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 434048085, 'comment_body': 'Instead of the ternary expressions, for readability, either use full `if`-statements, or in this case, as you are clamping to 0, you can also use expressions like `Math.max(0, scanSizeProduct - values.image_count + values.sync_offset)` instead, which should also be easy enough to read.', 'comment_created': datetime.datetime(2020, 6, 2, 17, 26, 38, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 434049871, 'comment_body': 'As this is the same logic as in the other component, maybe it can be put into a helper function? Then you can also easily add a test case checking all the boundary conditions (as there are not many tests in the GUI code yet, let me know if you need any support!)', 'comment_created': datetime.datetime(2020, 6, 2, 17, 29, 43, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 434060767, 'comment_body': 'Submit button could also be deactivated if the offset is invalid', 'comment_created': datetime.datetime(2020, 6, 2, 17, 47, 58, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 434063167, 'comment_body': 'Having `image_count` in the parameter structure is okay for now — just a reminder that we should work on separating the information that comes from the server from the parameters which will be sent back - just like with `DatasetParamsHDF5.dataset_paths`', 'comment_created': datetime.datetime(2020, 6, 2, 17, 52, 4, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 434128491, 'comment_body': '> Just curious, what happens if start - sync_offset < 0 and stop - sync_offset >0? For example, with start=0, stop=10, sync_offset=2? Doesn\'t that mean it will start at -2, so two ""from the right""? Or does this never happen, because start and sync_offset are, in a way, synchronized?\r\n\r\nYup, that won\'t happen.\r\n\r\n> Also, the docstring should explicitly mention the allowed ranges and possibly the relation between `sync_offset` and `start`. \r\n\r\n👍 \r\n\r\n> in the updated function, they are relative to the start indices, before applying the sync_offset, right?\r\n\r\nYup.', 'comment_created': datetime.datetime(2020, 6, 2, 19, 33, 3, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 434131202, 'comment_body': 'Right, I should have used an additional variable but I separated the function instead, just to make codeclimate happy.', 'comment_created': datetime.datetime(2020, 6, 2, 19, 38, 25, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 434712182, 'comment_body': 'Possibly should tell the user what is in correct about it, i.e. the range that it should be in', 'comment_created': datetime.datetime(2020, 6, 3, 16, 48, 29, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 435448909, 'comment_body': 'Doubt, is this regarding the Formik validation? Similar to here: https://github.com/LiberTEM/LiberTEM/blob/master/client/src/dataset/__tests__/validate.ts ?', 'comment_created': datetime.datetime(2020, 6, 4, 18, 5, 14, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 435793599, 'comment_body': 'I think this comment was about the ignored and inserted blank frames and testing the logic that calculates those. The point is to have tests covering any business logic, if possible. So if you are writing a custom formik validation function, that should also be tested, yes. ', 'comment_created': datetime.datetime(2020, 6, 5, 9, 13, 10, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 436579358, 'comment_body': 'As this no longer depends on `image_count`, I think this can be moved to the constructor - it is often best to fail fast. ', 'comment_created': datetime.datetime(2020, 6, 8, 9, 50, 14, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 436584394, 'comment_body': 'This is much better than the version before!\r\n\r\nAbout the code climate complaint here: maybe you can extract the calculation of `frame_offset` and `origin_offset` into its own function? That should reduce the complexity here, and also allows to independently test that function.', 'comment_created': datetime.datetime(2020, 6, 8, 9, 59, 29, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 436587647, 'comment_body': 'Really good to have these tests, also the ones for the client-side code!\r\n\r\nIt would be good to add a test that hits the ""offset should be in (...)"" exception (both the min and max case would be great). To find missing coverage cases like this one, it helps to look at the coverage report generated in the ""htmlcov"" directory (generated when running the tests via tox, or manually via `pytest --cov=libertem --cov-report=html ...`', 'comment_created': datetime.datetime(2020, 6, 8, 10, 5, 41, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 436589510, 'comment_body': 'As the two cases are structurally the same, maybe the generation of the `Row` can be extracted into its own function', 'comment_created': datetime.datetime(2020, 6, 8, 10, 9, 23, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 438718133, 'comment_body': '`RuntimeWarning: overflow encountered in long_scalars` was thrown when I loaded the k2is dataset', 'comment_created': datetime.datetime(2020, 6, 11, 11, 29, 6, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 438718842, 'comment_body': 'Good catch!', 'comment_created': datetime.datetime(2020, 6, 11, 11, 30, 47, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 443501353, 'comment_body': 'So... K2IS is a bit of a special format in that the scan size we can read from the `gtg` file is not equal to the ""real"" number of frames in the .bin files. In the .bin files, each block of data has a small header, which has, among others, a `sync` flag. So in a typical K2IS data set, you get a few frames of data at the beginning where the sync flag is not set, and then you get the rest of the data, with the `sync` flag set.\r\n\r\nSo, `_get_scansize` will, basically, only give you the number of frames that have the `sync` flag set. The underlying data can have more frames before that, and possibly also after (I haven\'t checked that one, would be interesting to play around with).\r\n\r\nIn the current version, we use this `sync` flag to automatically find something like a `sync_offset` (see the `K2Syncer` class, `first_block_offset`, `_start_offsets` and `_skip_frames`), but in the future we should allow to access the frames without the `sync` flag set. So, in summary: `scan_size_product` != `image_count`.\r\n\r\nLet me know if this is clear!', 'comment_created': datetime.datetime(2020, 6, 22, 11, 46, 59, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 443501781, 'comment_body': '`roi` needs to be passed down here, I think', 'comment_created': datetime.datetime(2020, 6, 22, 11, 47, 47, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 443530452, 'comment_body': ""Yup, it's incomplete. I'm sorry I left the work halfway on `memory`. I'll get back to it later."", 'comment_created': datetime.datetime(2020, 6, 22, 12, 43, 33, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 443534184, 'comment_body': ""Thanks! I'll try to get a better understanding of this and let you know later."", 'comment_created': datetime.datetime(2020, 6, 22, 12, 50, 11, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 444046595, 'comment_body': ""Why is `dest_sel` needed here, shouldn't that always be the whole `buf`? Also, what is the idea of doing two independent `read_direct` calls? "", 'comment_created': datetime.datetime(2020, 6, 23, 8, 19, 48, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 444049895, 'comment_body': ""Just a note: this is quite a bit of code, which is executed for each tile. One has to be a bit careful about performance in `get_tiles`, compared to when working on a per-partition level (example: tiles have sizes on the order of 1MiB, while partitions are more like 256MiB to 1GiB, so anything you do in the `get_tiles` codepath gets executed up to 1000 times more!).\r\n\r\nDon't worry about it right now, but once #819 lands, there should be a benchmark measuring the overhead of applying an offset"", 'comment_created': datetime.datetime(2020, 6, 23, 8, 25, 13, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 444111154, 'comment_body': ""The idea is to fill the `buf` in two steps: `(slice_0_origin_with_offset) -> (slice_0_end)` and `(slice_0_end) -> (slice_1_origin_with_offset)` and so on. Two `read_direct` calls were needed because I needed slices from two rows at once. I can also combine the slices and read once using `np.r_` or use numpy's `stride_tricks` if required. I'll definitely benchmark and try the different approaches.\r\n\r\n> shouldn't that always be the whole buf?\r\n\r\nI'm not sure, I'll look into it again."", 'comment_created': datetime.datetime(2020, 6, 23, 10, 5, 50, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 444179724, 'comment_body': 'Okay, no worries!', 'comment_created': datetime.datetime(2020, 6, 23, 12, 20, 37, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 444184529, 'comment_body': ""Ah, I think I know what you mean - it gets a bit complicated to fold the 1D offset into the ND slice that is then used to index the HDF5 dataset... then this approach may be needed.\r\n\r\n> I'll definitely benchmark and try the different approaches.\r\n\r\n:+1:"", 'comment_created': datetime.datetime(2020, 6, 23, 12, 29, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458117182, 'comment_body': 'Instead of requiring existing test data for raw tests, you can also generate it on-the-fly; see [the `default_raw` fixture](https://github.com/LiberTEM/LiberTEM/blob/1b372535e303a5fa9ae715033ec5f151626cc099/conftest.py#L148) for an example how to do this.\r\n\r\nThe same goes for HDF5; if your tests (and benchmarks) can work with synthetic data, it would be very good to do so, as it means the tests will be able to run in CI, which is sadly not yet possible for tests using test data.', 'comment_created': datetime.datetime(2020, 7, 21, 13, 57, 20, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458122617, 'comment_body': ""Thanks for trying! I think the performance can be neglected here, at least as long as it causes no noticeable lag in the UI. One has to think a bit about when the code in a component is actually executed; and usually this is only when re-rendering.\r\n\r\nAs far as I remember, the problem here was mostly getting the types right; I couldn't convince TypeScript to accept the generalized variant..."", 'comment_created': datetime.datetime(2020, 7, 21, 14, 4, 32, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458195809, 'comment_body': 'There is some duplication here. I think at least the yield statement can be put after the if-then-else statements, right?', 'comment_created': datetime.datetime(2020, 7, 21, 15, 39, 45, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458196478, 'comment_body': 'This line should not be needed, as the slice from `memmap` is assigned to the same name below', 'comment_created': datetime.datetime(2020, 7, 21, 15, 40, 41, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458201803, 'comment_body': ""As you reported strange results for empty frames, maybe have a look in detail at this code: `np.ndarray` doesn't initialize the underlying buffer, so maybe something is going wrong here? Instead, `data` could be initialized using `np.zeros` and `empty_frames` could be removed.\r\n\r\nHmm, also, hard-coding `float32` here looks wrong - the data should be returned in its original `dtype`.\r\n\r\nAs this case (negative offset) does make a copy anyways, maybe it makes sense to use `_get_tiles_w_copy` for this case instead? Then we only need to handle this at once place. What do you think?"", 'comment_created': datetime.datetime(2020, 7, 21, 15, 47, 53, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458208767, 'comment_body': 'Why the explicit array creation, instead of putting a `0` there and letting numpy broadcast?', 'comment_created': datetime.datetime(2020, 7, 21, 15, 57, 35, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458213335, 'comment_body': 'What happens in the case of using a `roi` and having a `sync_offset` set?', 'comment_created': datetime.datetime(2020, 7, 21, 16, 3, 54, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458215898, 'comment_body': 'Hmm, I like that this is extracted as a function, but maybe needs to be restructured a bit: I was surprised that the function returns a different type depending on the input values (either a `Slice` or a `tuple` of stuff). Indeed this is a code smell and should be refactored. Maybe `dest_tile_slice` can be computed in a second function, taking `tile_slice_with_offset` as input?', 'comment_created': datetime.datetime(2020, 7, 21, 16, 7, 32, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458217013, 'comment_body': 'Naming: method name should ideally not repeat the class name, maybe just `reshape` could work?', 'comment_created': datetime.datetime(2020, 7, 21, 16, 9, 12, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458223986, 'comment_body': 'Could you add a comment detailing why you need to subtract 1 and re-add it afterwards? Is this because you want to treat the shape as indices, and convert back afterwards?', 'comment_created': datetime.datetime(2020, 7, 21, 16, 19, 29, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458226581, 'comment_body': 'This logic looks like it should be fairly similar to the other `DataSet` classes, right? Maybe possible to extract into helper functions?', 'comment_created': datetime.datetime(2020, 7, 21, 16, 23, 18, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458233921, 'comment_body': 'Instead of directly using `o[:-sig_dims]` etc. in expressions, maybe extract them into their own variables to make clear what is happening? I think something like `np.ravel_multi_index(nav_origin, nav_shape)` could be easier to read than this.', 'comment_created': datetime.datetime(2020, 7, 21, 16, 34, 47, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458234014, 'comment_body': 'Good to have these comments here! Could you also add an explanation _why_ there are two slices required? I vaguely remember that we already had a discussion about this, but maybe it is good to permanently document this also as a comment, as these index calculations are really non-trivial. Maybe would also good to have a proper docstring for this method - for example, just from looking at this method, it is not clear to me why you can just look at `ds_shape[1]` to make these decisions - from the name, I would guess that it is the original nD shape?', 'comment_created': datetime.datetime(2020, 7, 21, 16, 34, 55, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 458535081, 'comment_body': ""> I couldn't convince TypeScript to accept the generalized variant...\r\n\r\nMe too\r\n\r\n> I think the performance can be neglected here, at least as long as it causes no noticeable lag in the UI\r\n\r\n👍 - I'll take a look again asap"", 'comment_created': datetime.datetime(2020, 7, 22, 5, 0, 46, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 458536382, 'comment_body': '> maybe it makes sense to use _get_tiles_w_copy for this case instead?\r\n\r\nNot sure, will look into it, thanks!', 'comment_created': datetime.datetime(2020, 7, 22, 5, 5, 27, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 458536705, 'comment_body': ""> Is this because you want to treat the shape as indices, and convert back afterwards?\r\n\r\nYes! Are there any cases you already know where this wouldn't work? I've two simple tests and I'll be adding more."", 'comment_created': datetime.datetime(2020, 7, 22, 5, 6, 38, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 458540254, 'comment_body': ""I'm using `if sync_offset < 0 and roi is None:` to skip tiles or empty some frames of a tile in case of a negative offset without a `roi`.\r\n\r\n> What happens in the case of using a roi and having a sync_offset set?\r\n\r\nThe read_ranges code computes `frames_indices` to be yielded accurately, so there's no need of skipping tiles or emptying frames in this case. I'll put more comments in my code too"", 'comment_created': datetime.datetime(2020, 7, 22, 5, 19, 31, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 458542645, 'comment_body': ""Didn't cross my mind, thanks!"", 'comment_created': datetime.datetime(2020, 7, 22, 5, 27, 42, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 458550004, 'comment_body': ""> it is not clear to me why you can just look at `ds_shape[1]` to make these decisions\r\n\r\nSorry! The offset code for HDF5 is hard coded for 4D right now, and I'm yet to generalize it.\r\n\r\n> why there are two slices required\r\n\r\nBecause, in case of a 4D HDF5 dataset, a single slice object can't access frames from two different rows (necessary when an offset is applied) and slice objects don't support concatenation. So I've to slice twice and combine the results.\r\n(Please correct me if I got something wrong, thanks!)"", 'comment_created': datetime.datetime(2020, 7, 22, 5, 51, 21, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 458658570, 'comment_body': ""> Sorry! The offset code for HDF5 is hard coded for 4D right now, and I'm yet to generalize it.\r\n\r\nNo worries, good to know!\r\n\r\n> Because, in case of a 4D HDF5 dataset, a single slice object can't access frames from two different rows (necessary when an offset is applied) and slice objects don't support concatenation. So I've to slice twice and combine the results.\r\n\r\nSounds right, you could also split into two tiles in this case - the `DataSet` classes have quite a bit of freedom on how to return the data, in the sense that a single tile *can* have less frames in it than defined in the tiling scheme, for example for border conditions like this."", 'comment_created': datetime.datetime(2020, 7, 22, 9, 24, 54, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 461566967, 'comment_body': ""> you could also split into two tiles in this case - the DataSet classes have quite a bit of freedom on how to return the data, in the sense that a single tile can have less frames in it than defined in the tiling scheme\r\n\r\nThank you! I wish I had thought of that much earlier! I spent too much time on HDF5's offset and thinking about how to generalize it for n-D data, thanks again! :)"", 'comment_created': datetime.datetime(2020, 7, 28, 13, 11, 23, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 468549346, 'comment_body': 'Can this maybe call `_get_nav_shape`? Maybe needs a refactor so we have a function that accepts a path as input', 'comment_created': datetime.datetime(2020, 8, 11, 12, 41, 59, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468559052, 'comment_body': 'I think the exception message here can be improved - when does this `IndexError` happen? I guess only if `files` is an empty list?', 'comment_created': datetime.datetime(2020, 8, 11, 12, 58, 26, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468560120, 'comment_body': 'The warning text can be improved, I think: 1) the argument is not really ignored, 2) the user should be pointed to the new argument name `nav_shape` directly in the message. Other than that the deprecation looks good!', 'comment_created': datetime.datetime(2020, 8, 11, 13, 0, 2, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468562064, 'comment_body': 'Maybe can be reordered such that `nav_shape` and `sig_shape` are after one another; maybe put `dtype` to the end?', 'comment_created': datetime.datetime(2020, 8, 11, 13, 3, 19, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468562613, 'comment_body': 'Again should point to its replacement and clarify that it is not ignored but used for `nav_shape` right now.', 'comment_created': datetime.datetime(2020, 8, 11, 13, 4, 12, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468563362, 'comment_body': 'Same as other `DataSet`s.', 'comment_created': datetime.datetime(2020, 8, 11, 13, 5, 19, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468565854, 'comment_body': ""Maybe should add some comments here describing the condition you are actually testing for here, as I don't think it is intuitively clear from reading the code"", 'comment_created': datetime.datetime(2020, 8, 11, 13, 9, 16, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468566798, 'comment_body': 'What happens with a combination of `roi` and negative `sync_offset`?', 'comment_created': datetime.datetime(2020, 8, 11, 13, 10, 41, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468567716, 'comment_body': 'Instead of `List` the coordinates could also be put into an `ndarray`; this would make ""bulk actions"" on them easier, and perform better for example in the case of whole-partition processing', 'comment_created': datetime.datetime(2020, 8, 11, 13, 12, 10, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468569699, 'comment_body': 'You can also do this unconditionally, it should not hurt if the shape already matches', 'comment_created': datetime.datetime(2020, 8, 11, 13, 15, 16, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468577231, 'comment_body': 'Conceptually, I think it might make sense to have the coordinates available not only via the `UDFMeta`, but also for every consumer of the `DataTile` stream (i.e. everyone who calls `get_tiles`), if possible. Would it maybe make sense to calculate the coords in a method/property of `DataTile`? And then also provide it in `UDFMeta`, similar to how `set_slice` works (just a simple setter).\r\n\r\nWhat do you think?\r\n\r\n/cc @uellue ', 'comment_created': datetime.datetime(2020, 8, 11, 13, 26, 26, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468582366, 'comment_body': ""Hmm, we should see if this is possible without having this loop here, as it will always iterate over all indices for `ds_slice`. Isn't it possible to just slice `indices`?"", 'comment_created': datetime.datetime(2020, 8, 11, 13, 33, 51, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468586127, 'comment_body': 'Is it possible to maybe just call `unravel_index` / `ravel_multi_index` once, with `np.arange(start_idx, end_idx)` or similar? As this function is called for each tile it is a bit performance sensitive, so we have to be careful here to not introduce too much overhead. Maybe would be also a good benchmark to add, with large tiles as test data (for example whole partition)', 'comment_created': datetime.datetime(2020, 8, 11, 13, 39, 16, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468587147, 'comment_body': ""Why do we need to copy if the tile depth exactly matches the number of frames per file? I'm not sure I follow here."", 'comment_created': datetime.datetime(2020, 8, 11, 13, 40, 43, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468590991, 'comment_body': ""`shape` can be `tile_slice.shape` here, right? We don't necessarily have to construct a new `Shape` object, as only the `origin` is different."", 'comment_created': datetime.datetime(2020, 8, 11, 13, 46, 1, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468591690, 'comment_body': 'Yes, a comment would be good here!', 'comment_created': datetime.datetime(2020, 8, 11, 13, 47, 1, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468594725, 'comment_body': ""There needs to be some special coordinate handling for `method == 'frame'` here, I think, maybe generate the whole coordinate list for the `tile` once, and then index into that with `frame_idx` in the inner loop?"", 'comment_created': datetime.datetime(2020, 8, 11, 13, 51, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 468735050, 'comment_body': 'Perhaps it would be better to offer this as a function that a UDF can call with the required information `slice, shape, roi`? Most UDFs actually don\'t need it, so it would save us some processing time in a relatively ""hot"" loop.', 'comment_created': datetime.datetime(2020, 8, 11, 17, 9, 45, tzinfo=datetime.timezone.utc), 'commenter': 'uellue', 'type': 'User'}, {'comment_id': 469075075, 'comment_body': 'So it should be a method/property of `DataTile` which a UDF should be able to call to get the coordinates, right?', 'comment_created': datetime.datetime(2020, 8, 12, 7, 56, 38, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 469094221, 'comment_body': ""Yes, just not necessarily of the `DataTile`. The current `set_coordinates()` method could actually become a `get_coordinates()` method of `UDFMeta` since all current parameters are actually properties of `UDFMeta`, right?\r\n\r\nAs an additional remark, this method should probably also get a benchmark since it might potentially be called very often. That way we make sure it is within reasonable limits, and it helps to catch any regressions. The benchmarks are based on `pytest` like the unit tests and are in the `benchmarks` folder, in case you haven't seen them yet. :-)"", 'comment_created': datetime.datetime(2020, 8, 12, 8, 29, 47, tzinfo=datetime.timezone.utc), 'commenter': 'uellue', 'type': 'User'}, {'comment_id': 469104741, 'comment_body': '...as @sk1p already suggested! 🙈 ', 'comment_created': datetime.datetime(2020, 8, 12, 8, 47, 55, tzinfo=datetime.timezone.utc), 'commenter': 'uellue', 'type': 'User'}, {'comment_id': 469188002, 'comment_body': ""> So it should be a method/property of `DataTile` which a UDF should be able to call to get the coordinates, right?\r\n\r\n> Yes, just not necessarily of the `DataTile`.\r\n\r\nMaybe this index transform code could be in its own class, which can then be used and tested independently of the UDF interface, but still be made available in `UDFMeta`.\r\n\r\n(I was thinking that maybe we could actually move `UDFMeta.slice` and the new coordinate stuff to `DataTile`, and make `DataTile` part of the external interface. For by-frame processing, we could slice into the `DataTile`, yielding a new `DataTile` that is a view into the tile, including coordinates. But that doesn't have to happen in this PR, if ever)"", 'comment_created': datetime.datetime(2020, 8, 12, 11, 24, 8, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 471079109, 'comment_body': 'In case of `DM` files, when a shape < number of files was given, the tile depth is sometimes equal to number of frames per file and `get_tiles_straight` was used instead of `get_tiles_w_copy`.', 'comment_created': datetime.datetime(2020, 8, 16, 7, 42, 41, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 471081880, 'comment_body': ""I've separated the coordinates generation code from the UDF interface. So the UDFs which need the coordinates can `self.set_coordinates(self.meta.slice, self.meta.dataset_shape, self.meta.roi)` and the coords would be available in the `self.meta.coordinates`. Other functions outside the UDF interface can use `libertem.io.dataset.base import get_coordinates` directly. The tests should make this more clear. Please take a look, thanks!"", 'comment_created': datetime.datetime(2020, 8, 16, 8, 11, 29, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 471082123, 'comment_body': ""Okay, the new coords generation code is out of the UDF interface and I've added a test for `method == 'frame'` too."", 'comment_created': datetime.datetime(2020, 8, 16, 8, 14, 22, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 471098705, 'comment_body': ""> the tile depth is sometimes equal to number of frames per file and `get_tiles_straight` was used instead of `get_tiles_w_copy`.\r\n\r\nHmm, why is it a problem to use `_get_tiles_straight` in that situation? It is only used if we don't need to do any additional decoding (i.e. `dtype` matches, no corrections need to be applied etc.), so it should be fine to be used, no? Saving a copy can be very beneficial to performance.\r\n\r\nAre there any other reasons we need to do a copy, which are not currently covered by `need_copy`?"", 'comment_created': datetime.datetime(2020, 8, 16, 11, 3, 59, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 471102477, 'comment_body': ""Hmm, but the SER code doesn't involve read ranges (yet), I guess it is handled by the code above (L277+)?"", 'comment_created': datetime.datetime(2020, 8, 16, 11, 41, 57, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 471103605, 'comment_body': ""Why is `nav_shape` a string? Shouldn't it be, for consistency, a 1-tuple in this case? Otherwise, you have a mismatch of types on the TypeScript side, that is, the API response doesn't match the types in `DatasetParamsCommon`."", 'comment_created': datetime.datetime(2020, 8, 16, 11, 52, 46, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 471103692, 'comment_body': 'See comment above about read ranges', 'comment_created': datetime.datetime(2020, 8, 16, 11, 53, 43, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 471104097, 'comment_body': 'Can we maybe unify these two branches? The only real difference here is how `nav_shape` is set, so maybe just do `nav_shape = image_count` in one branch, `nav_shape = nav_shape_from_hdr(...)` in the other? Should remove a bit or duplication.', 'comment_created': datetime.datetime(2020, 8, 16, 11, 57, 30, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 471300675, 'comment_body': ""> Hmm, but the SER code doesn't involve read ranges (yet), I guess it is handled by the code above (L277+)?\r\n\r\nHaha, right. It was a copy-paste mistake, sorry."", 'comment_created': datetime.datetime(2020, 8, 17, 7, 46, 45, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 471302871, 'comment_body': ""> Hmm, why is it a problem to use `_get_tiles_straight` in that situation?\r\n\r\nIn the case mentioned above, `_get_tiles_straight` yielded empty tiles (0 in the tile_slice shape).\r\n\r\n> It is only used if we don't need to do any additional decoding (i.e. `dtype` matches, no corrections need to be applied etc.), so it should be fine to be used, no?\r\n\r\nThat sounds right, I think there's a bug in `DM`'s `fileset` part of code. I'll check.\r\n\r\n> Are there any other reasons we need to do a copy, which are not currently covered by `need_copy`?\r\n\r\nNot sure, will look into it."", 'comment_created': datetime.datetime(2020, 8, 17, 7, 51, 1, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 476391123, 'comment_body': ""I think these three lines can be pulled out of the loop, as they don't depend on the current tile"", 'comment_created': datetime.datetime(2020, 8, 25, 11, 55, 53, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 476392215, 'comment_body': 'There are also the `sig` and `nav` properties of `Shape`, so it could be `s_nav = tile_slice.shape.nav` etc. instead, which could be easier to read', 'comment_created': datetime.datetime(2020, 8, 25, 11, 57, 58, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 476393031, 'comment_body': 'I think the HDF5 `dataset` should also be passed down here, otherwise it has to be re-opened for each tile, which could have some overhead.', 'comment_created': datetime.datetime(2020, 8, 25, 11, 59, 33, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 476397452, 'comment_body': 'If it is possible to re-use `buf` for consecutive tiles, it could offer some speedup.', 'comment_created': datetime.datetime(2020, 8, 25, 12, 7, 56, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 476403589, 'comment_body': ""Could you add docstrings for the new methods? Especially a description of all parameters and how the recursion works (why it's guaranteed to arrive at the base case, for example) would be very helpful."", 'comment_created': datetime.datetime(2020, 8, 25, 12, 19, 21, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 476404834, 'comment_body': 'This means only the last navigation axis is split, right? I think this is fine in practice, but maybe the tile shape should be guaranteed to fit this axis (in `adjust_tileshape`)', 'comment_created': datetime.datetime(2020, 8, 25, 12, 21, 22, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 476406651, 'comment_body': 'As commented above, `dataset` should be opened once and passed down to this place.', 'comment_created': datetime.datetime(2020, 8, 25, 12, 23, 38, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 476407905, 'comment_body': ""Can't this be a `break` instead? Once `skip_tile` is set, it's never unset and no further tiles are yielded"", 'comment_created': datetime.datetime(2020, 8, 25, 12, 26, 1, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 518676976, 'comment_body': 'Just a note to look at the reason again - something related to the dm format?', 'comment_created': datetime.datetime(2020, 11, 6, 10, 59, 20, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 532028020, 'comment_body': 'Opened #911 and resolving this since we decided to solve this in another PR', 'comment_created': datetime.datetime(2020, 11, 28, 11, 15, 12, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 532602121, 'comment_body': ""The `sync_offset` also needs to be copied to `data` here, otherwise  it won't have any effect when loading data using the GUI"", 'comment_created': datetime.datetime(2020, 11, 30, 13, 38, 25, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 532620800, 'comment_body': 'This is duplicated with the `_pattern` function, maybe `_pattern` can be refactored to use the same code as this?', 'comment_created': datetime.datetime(2020, 11, 30, 14, 6, 17, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 532621509, 'comment_body': 'No need to read all headers if only the first one is used - how about `header = _read_file_header(filenames[0])` or something like that?', 'comment_created': datetime.datetime(2020, 11, 30, 14, 7, 21, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 532627265, 'comment_body': 'Oh, and something else: what happens if the `sync_offset` is left out of the request? It is not marked as required, so the validation will pass in that case, but conversion to python possibly crashes here. I think this is the same in the other formats.', 'comment_created': datetime.datetime(2020, 11, 30, 14, 15, 32, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 532630779, 'comment_body': 'There is again some duplication with `_filenames`, could possibly be extracted as a helper function and called here instead. May also need to pass the (currently undocumented) `_disable_glob` parameter (use case: you have multiple `.mib` files from different data sets in the same directory, named with a number at the end, for example `dataset-1.mib`, `dataset-2.mib` etc. - this was solving a real, if uncommon, issue).', 'comment_created': datetime.datetime(2020, 11, 30, 14, 20, 21, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 532645728, 'comment_body': ""I think the `roi` parameter can be removed again, no? It doesn't appear to be used anymore."", 'comment_created': datetime.datetime(2020, 11, 30, 14, 41, 8, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 532648288, 'comment_body': ""The UDFs shouldn't be named like test cases - `pytest` will actually complain if they have a `Test` prefix and aren't actually `unittest.TestCase` subclasses. Names should also follow pep8, so camel case for classes, without underscores."", 'comment_created': datetime.datetime(2020, 11, 30, 14, 44, 34, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 533199250, 'comment_body': 'Sorry and thanks!', 'comment_created': datetime.datetime(2020, 12, 1, 9, 17, 1, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 537510114, 'comment_body': 'Validation looks good! Having `native_sig_shape` in the form values is a bit unclean, as it means the values need to be separated again afterwards. Instead, `CustomValidationFn` could also take the `props` as parameter, and would have access to all the `info` fields via `props.info` (`helpers.ts`):\r\n\r\n\r\n```patch\r\n@@ -65,13 +69,13 @@ export function isKnownDatasetType(detectedType: string) {\r\n \r\n type FormToJsonFn<SubmitParams, FormParams> = (inParams: FormParams, path: string) => SubmitParams;\r\n type PropsToValuesFn<SubmitParams, FormParams, FormInfo> = (props: OpenFormProps<SubmitParams, FormInfo>) => FormParams;\r\n-type CustomValidationFn<FormParams> = (inParams: FormParams) => FormikErrors<FormikValues>;\r\n+type CustomValidationFn<SubmitParams, FormParams, FormInfo> = (inParams: FormParams, props: OpenFormProps<SubmitParams, FormInfo>) => FormikErrors<FormikValues>;\r\n \r\n interface WithValidationOpts<SubmitParams extends object, FormParams, FormInfo> {\r\n     formToJson: FormToJsonFn<SubmitParams, FormParams>,\r\n     mapPropsToValues: PropsToValuesFn<SubmitParams, FormParams, FormInfo>,\r\n     type: DatasetTypes,\r\n-    customValidation?: CustomValidationFn<FormParams>\r\n+    customValidation?: CustomValidationFn<SubmitParams, FormParams, FormInfo>\r\n     // WrappedComponent: React.FunctionComponent<FormikProps<FormParams> & OpenFormProps<SubmitParams>>\r\n }\r\n \r\n@@ -87,7 +91,7 @@ export function withValidation<SubmitParams extends object, FormParams, FormInfo\r\n             formikBag.setSubmitting(false);\r\n         },\r\n         validate: (values, props) => {\r\n-            return validateOpen(opts.type, opts.formToJson(values, props.path), opts.customValidation?.(values));\r\n+            return validateOpen(opts.type, opts.formToJson(values, props.path), opts.customValidation?.(values, props));\r\n         },\r\n         enableReinitialize: true,\r\n         validateOnChange: true,\r\n```\r\n\r\nThis is also true for `image_count` btw.: \r\n\r\n```patch\r\n@@ -34,6 +34,7 @@ const MIBFileParamsForm: React.SFC<MergedProps> = ({\r\n     isValidating,\r\n     onCancel,\r\n     setFieldValue,\r\n+    info,\r\n }) => {\r\n \r\n     return (\r\n@@ -43,7 +44,7 @@ const MIBFileParamsForm: React.SFC<MergedProps> = ({\r\n                 <ErrorMessage name=""name"" />\r\n                 <Field name=""name"" id=""id_name"" />\r\n             </Form.Field>\r\n-            <Reshape navShape={values.nav_shape} sigShape={values.sig_shape} syncOffset={values.sync_offset} imageCount={values.image_count} setFieldValue={setFieldValue} />\r\n+            <Reshape navShape={values.nav_shape} sigShape={values.sig_shape} syncOffset={values.sync_offset} imageCount={info?.image_count} setFieldValue={setFieldValue} />\r\n             <Button primary={true} type=""submit"" disabled={isSubmitting || isValidating}>Load Dataset</Button>\r\n             <Button type=""button"" onClick={onCancel}>Cancel</Button>\r\n             <Button type=""button"" onClick={handleReset}>Reset</Button>\r\n```\r\n\r\nThen, the form values passed to formik are really only those that the user can edit.\r\n\r\nAdditionally, the code can be improved by extracting the common case (validating sig shape and sync offset) into a helper function, and to use that function instead of copying code. This should be warranted in this case, as there are more than two duplicates.', 'comment_created': datetime.datetime(2020, 12, 7, 13, 35, 41, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 537516504, 'comment_body': 'i think this can be shortened by having an empty default value for the custom validation errors:\r\n\r\n```suggestion\r\nexport function throwErrors(validateErrors : ErrorObject[] | null = [], customValidateErrors: FormikErrors<FormikValues> = {}) {\r\n    if (validateErrors) {\r\n        const converted = { ...convertErrors(validateErrors), customValidateErrors };\r\n        throw converted;\r\n    } else {\r\n        throw new Error(""unspecified error while validating fields"");\r\n    }\r\n}\r\n```\r\n\r\nWhat do you think?', 'comment_created': datetime.datetime(2020, 12, 7, 13, 45, 6, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 538712483, 'comment_body': 'Thanks!', 'comment_created': datetime.datetime(2020, 12, 8, 18, 43, 24, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 538713891, 'comment_body': 'Thanks! I also made a few changes on top of your suggested way.', 'comment_created': datetime.datetime(2020, 12, 8, 18, 45, 22, tzinfo=datetime.timezone.utc), 'commenter': 'anandbaburajan', 'type': 'User'}, {'comment_id': 538755882, 'comment_body': 'I think the union here with `... Omit<DatasetInfoBLO, ""type"" | ""native_sig_shape""> & { native_sig_shape:string };` can now also be removed from all formats, right? None of the `info` fields are directly accessed from `values` anymore, so this should no longer be needed.', 'comment_created': datetime.datetime(2020, 12, 8, 19, 43, 47, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 538756798, 'comment_body': 'Combined with the comment above: these values derived from `info` should now be no longer needed (same for other formats)', 'comment_created': datetime.datetime(2020, 12, 8, 19, 45, 14, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 538768852, 'comment_body': 'Here, in addition to `image_count` and `native_sig_shape`, `dataset_paths` can also be removed from `values`, if  `dsPathOptions` is constructed directly from `info.dataset_paths` instead.', 'comment_created': datetime.datetime(2020, 12, 8, 20, 4, 36, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 538786722, 'comment_body': 'I think this should be:\r\n```suggestion\r\n                ""sync_offset"": 0,\r\n```', 'comment_created': datetime.datetime(2020, 12, 8, 20, 34, 11, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}, {'comment_id': 538811270, 'comment_body': 'This breaks `test_dm_dist` - please have a look at [the docs](https://libertem.github.io/LiberTEM/dist_tests.html) to see how to run these tests, which should reproduce the problem.', 'comment_created': datetime.datetime(2020, 12, 8, 21, 12, 59, tzinfo=datetime.timezone.utc), 'commenter': 'sk1p', 'type': 'User'}]","[{'commit_sha': '76b6e587281b993a640368e74ff3c59f31f86ce2', 'committer_username': 'anandbaburajan', 'committer_name': 'Anand Baburajan', 'committer_email': None, 'commit_date': datetime.datetime(2012, 11, 1, 13, 15, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e319d0deb9dfff2147378cd7e7bb712926d68ea3', 'committer_username': 'anandbaburajan', 'committer_name': 'Anand Baburajan', 'committer_email': None, 'commit_date': datetime.datetime(2012, 11, 1, 13, 15, 26, tzinfo=datetime.timezone.utc)}, {'commit_sha': '82a1f19678ca27e21e248c1ef6118d3d8e85de6b', 'committer_username': 'anandbaburajan', 'committer_name': 'Anand Baburajan', 'committer_email': None, 'commit_date': datetime.datetime(2012, 11, 1, 13, 15, 26, tzinfo=datetime.timezone.utc)}]",Anand Baburajan,2698932,,User,,16,,101,140

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
116963730,LiberTEM,LiberTEM/LiberTEM,Python,66,109,13,29,4361,192,10,17,"[{'id': 838037553, 'number': 1202, 'closed': datetime.datetime(2022, 2, 14, 21, 12, 19, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2022, 2, 2, 7, 59, 11, tzinfo=datetime.timezone.utc), 'time_taken': 1084388.0, 'time_delta': '12 days, 13:13:08', 'additions': 27297, 'deletions': 275, 'state': 'closed'}, {'id': 618518131, 'number': 1019, 'closed': datetime.datetime(2021, 5, 27, 8, 33, 16, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 4, 19, 20, 59, 30, tzinfo=datetime.timezone.utc), 'time_taken': 3238426.0, 'time_delta': '37 days, 11:33:46', 'additions': 20865, 'deletions': 129, 'state': 'closed'}, {'id': 477292384, 'number': 871, 'closed': datetime.datetime(2020, 9, 2, 9, 24, 17, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 9, 1, 19, 41, 17, tzinfo=datetime.timezone.utc), 'time_taken': 49380.0, 'time_delta': '13:43:00', 'additions': 11, 'deletions': 0, 'state': 'closed'}, {'id': 447499941, 'number': 844, 'closed': datetime.datetime(2020, 7, 13, 14, 21, 17, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 10, 15, 20, 52, tzinfo=datetime.timezone.utc), 'time_taken': 255625.0, 'time_delta': '2 days, 23:00:25', 'additions': 33, 'deletions': 29, 'state': 'closed'}, {'id': 421543470, 'number': 793, 'closed': datetime.datetime(2020, 12, 14, 19, 58, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 21, 19, 39, 58, tzinfo=datetime.timezone.utc), 'time_taken': 17885882.0, 'time_delta': '207 days, 0:18:02', 'additions': 4294, 'deletions': 760, 'state': 'closed'}, {'id': 415266307, 'number': 782, 'closed': datetime.datetime(2020, 5, 8, 14, 57, 18, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 8, 14, 35, 22, tzinfo=datetime.timezone.utc), 'time_taken': 1316.0, 'time_delta': '0:21:56', 'additions': 20, 'deletions': 2, 'state': 'closed'}, {'id': 415150035, 'number': 779, 'closed': datetime.datetime(2020, 5, 19, 16, 13, 48, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 8, 9, 51, 4, tzinfo=datetime.timezone.utc), 'time_taken': 973364.0, 'time_delta': '11 days, 6:22:44', 'additions': 186, 'deletions': 62, 'state': 'closed'}, {'id': 414514328, 'number': 775, 'closed': datetime.datetime(2020, 5, 7, 9, 37, 15, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 7, 7, 39, 16, tzinfo=datetime.timezone.utc), 'time_taken': 7079.0, 'time_delta': '1:57:59', 'additions': 7, 'deletions': 1, 'state': 'closed'}, {'id': 410891069, 'number': 765, 'closed': datetime.datetime(2020, 5, 4, 15, 13, 15, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 29, 18, 53, 56, tzinfo=datetime.timezone.utc), 'time_taken': 418759.0, 'time_delta': '4 days, 20:19:19', 'additions': 67, 'deletions': 25, 'state': 'closed'}, {'id': 408868303, 'number': 752, 'closed': datetime.datetime(2020, 4, 27, 20, 59, 33, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 25, 7, 57, 10, tzinfo=datetime.timezone.utc), 'time_taken': 219743.0, 'time_delta': '2 days, 13:02:23', 'additions': 3230, 'deletions': 3194, 'state': 'closed'}, {'id': 408363431, 'number': 750, 'closed': datetime.datetime(2020, 4, 28, 7, 12, 4, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 24, 6, 47, 26, tzinfo=datetime.timezone.utc), 'time_taken': 347078.0, 'time_delta': '4 days, 0:24:38', 'additions': 35, 'deletions': 11, 'state': 'closed'}, {'id': 407906417, 'number': 748, 'closed': datetime.datetime(2020, 4, 24, 13, 25, 52, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 23, 13, 12, 17, tzinfo=datetime.timezone.utc), 'time_taken': 87215.0, 'time_delta': '1 day, 0:13:35', 'additions': 25, 'deletions': 17, 'state': 'closed'}, {'id': 405005182, 'number': 732, 'closed': datetime.datetime(2020, 4, 20, 8, 40, 43, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 17, 8, 48, 18, tzinfo=datetime.timezone.utc), 'time_taken': 258745.0, 'time_delta': '2 days, 23:52:25', 'additions': 151, 'deletions': 113, 'state': 'closed'}, {'id': 403037198, 'number': 718, 'closed': datetime.datetime(2020, 4, 14, 13, 14, 8, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 14, 8, 16, 36, tzinfo=datetime.timezone.utc), 'time_taken': 17852.0, 'time_delta': '4:57:32', 'additions': 11, 'deletions': 8, 'state': 'closed'}, {'id': 397830369, 'number': 700, 'closed': datetime.datetime(2020, 4, 16, 10, 34, 50, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 4, 2, 22, 2, 15, tzinfo=datetime.timezone.utc), 'time_taken': 1168355.0, 'time_delta': '13 days, 12:32:35', 'additions': 3313, 'deletions': 3204, 'state': 'closed'}, {'id': 395644106, 'number': 696, 'closed': datetime.datetime(2020, 3, 30, 15, 56, 24, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 30, 13, 18, 14, tzinfo=datetime.timezone.utc), 'time_taken': 9490.0, 'time_delta': '2:38:10', 'additions': 40, 'deletions': 36, 'state': 'closed'}, {'id': 384629690, 'number': 666, 'closed': datetime.datetime(2020, 3, 10, 10, 4, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 6, 4, 36, 24, tzinfo=datetime.timezone.utc), 'time_taken': 365256.0, 'time_delta': '4 days, 5:27:36', 'additions': 66, 'deletions': 36, 'state': 'closed'}, {'id': 382060199, 'number': 659, 'closed': datetime.datetime(2020, 3, 2, 14, 54, 4, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 3, 1, 15, 47, 43, tzinfo=datetime.timezone.utc), 'time_taken': 83181.0, 'time_delta': '23:06:21', 'additions': 19, 'deletions': 0, 'state': 'closed'}, {'id': 378672043, 'number': 642, 'closed': datetime.datetime(2020, 2, 26, 13, 23, 12, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 2, 23, 7, 12, 10, tzinfo=datetime.timezone.utc), 'time_taken': 281462.0, 'time_delta': '3 days, 6:11:02', 'additions': 73, 'deletions': 62, 'state': 'closed'}, {'id': 378582787, 'number': 639, 'closed': datetime.datetime(2020, 2, 22, 18, 44, 7, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 2, 22, 11, 57, 13, tzinfo=datetime.timezone.utc), 'time_taken': 24414.0, 'time_delta': '6:46:54', 'additions': 34, 'deletions': 23, 'state': 'closed'}]"

pr_id,pr_title,pr_body,is_merged,pr_number,pr_url,pr_html_url,pr_state,additions,deletions,pr_changed_files,pr_commits_count,pr_comments_count,pr_review_comments_count,pr_labels_count,pr_assignees_count,pr_labels,pr_created_at,pr_closed_at,time_taken,time_delta,pr_review_comments,pr_commits,contributor,contributor_id,contributor_email,contributor_type,contributions,contributor_public_repos,contributor_private_repos,contributor_followings,contributor_followers
433140671,Sentinel 2 NDVI script for remote data module,"<!--- Provide a general summary of your changes in the Title above -->
<!--- Please select appropriate Priority, Status,and Type labels-->
<!--- If you do not have permission to select labels please state which labels you would like -->

## Description
This PR uses satellitetool's functions to calculate NDVI from Sentinel 2 data. 

## Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->
These scripts will be used to create an automated workflow for the remote data module.
To test the PR please install these python dependencies [requirements.txt](https://github.com/ayushprd/PEcAn-GEE/blob/master/requirements.txt) These will later be added to the PEcAn dependencies. 

## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [ ] Within one week
- [x] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [ ] I have updated the documentation accordingly.
- [ ] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [x] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2634,https://api.github.com/repos/PecanProject/pecan/pulls/2634,https://github.com/PecanProject/pecan/pull/2634,closed,837,0,3,13,3,10,0,0,[],2020-06-11 15:02:45+00:00,2020-06-16 11:14:13+00:00,418288.0,"4 days, 20:11:28","[{'comment_id': 438854558, 'comment_body': 'Is it safe to remove this already?', 'comment_created': datetime.datetime(2020, 6, 11, 15, 5, 43, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 438862597, 'comment_body': 'Yes, removed.', 'comment_created': datetime.datetime(2020, 6, 11, 15, 17, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 439332315, 'comment_body': '```suggestion\r\n    qi_threshold (float) -- From satellitetools: Threshold value to filter images based on used qi filter. qi filter holds labels of classes whose percentages within the AOI is summed. If the sum is larger then the qi_threshold, data will not be retrieved for that date/image. The default is 1, meaning all data is retrieved\r\n```', 'comment_created': datetime.datetime(2020, 6, 12, 10, 14, 38, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 439332933, 'comment_body': '```suggestion\r\n    # if specified output directory does not exist, create it.\r\n```', 'comment_created': datetime.datetime(2020, 6, 12, 10, 16, 5, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 439334988, 'comment_body': '```suggestion\r\n        list of variable names as string.\r\n```', 'comment_created': datetime.datetime(2020, 6, 12, 10, 20, 51, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 439336426, 'comment_body': ""I'm not familiar with python, but just to confirm, does this also work without having satellitetools as a library?"", 'comment_created': datetime.datetime(2020, 6, 12, 10, 24, 20, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 439342474, 'comment_body': 'satellitetools is just the name of the folder which contains the original script `gee.py`, this script is required.', 'comment_created': datetime.datetime(2020, 6, 12, 10, 38, 46, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 439343334, 'comment_body': ""Yup that much I followed, I wasn't just aware if one can simply import a function from a folder"", 'comment_created': datetime.datetime(2020, 6, 12, 10, 40, 55, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 439424294, 'comment_body': 'could you move `test.geojson` into `satellitetools` folder and update this, not a big deal but that feels like a more appropriate place', 'comment_created': datetime.datetime(2020, 6, 12, 13, 40, 16, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 439425013, 'comment_body': 'Sure.', 'comment_created': datetime.datetime(2020, 6, 12, 13, 41, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}]","[{'commit_sha': '0682e0f80b98c424f726ae3e34e16da692545c75', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ff14d55e48ea580f0adf86bc09eef7e49a539f60', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '457a1046b1ce6addae55c601c00dd44301d96d60', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f3b9e7e638543e6043c30a2748611454db86e8f4', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5c8b1856f9ecd1644791de3b1723ea4e1808f7de', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6ae3d65e750f2ead3ae0b6895a9cd4a119e2dfae', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b46b5036dc15c7425c88794f803d8adfaedd6f30', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0148a8dcc5a61407d32d7204c44b4b757cccee99', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd61495a1c1fcf7f97c0287ad092a12c9dfd69df', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b65874d0296c7cc94b7fd68c7668a65ffbffe1b1', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b6c2d1c3c309e5933611884e99a8566f433a6896', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '74060def8c0ce4bac3451c391f6be3629f820603', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7ae230e2cf3116ab16a226734ce23b27dc250a0d', 'committer_username': 'mdietze', 'committer_name': 'Michael Dietze', 'committer_email': 'dietze@bu.edu', 'commit_date': datetime.datetime(2012, 12, 19, 14, 18, 27, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13
435178571,LAI script for remote data module,"<!--- Provide a general summary of your changes in the Title above -->
<!--- Please select appropriate Priority, Status,and Type labels-->
<!--- If you do not have permission to select labels please state which labels you would like -->

## Description
This PR adds the SNAP biophysical processor and uses it to calculate LAI.
The auxiliary data required for SNAP is directly fetched from the original repository. 
Also adds `remote_process.py`, which will be used to control the individual functions.

## Motivation and Context
The scripts in this PR along with #2634 will be used to create the initial workflow for the remote data module.

Dependencies required: [requirements.txt](https://github.com/ayushprd/PEcAn-GEE/blob/master/requirements.txt) (same as the referenced PR)

## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [ ] Within one week
- [x] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [ ] I have updated the documentation accordingly.
- [ ] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [x] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2637,https://api.github.com/repos/PecanProject/pecan/pulls/2637,https://github.com/PecanProject/pecan/pull/2637,closed,462,27,5,8,4,30,0,0,[],2020-06-16 12:23:48+00:00,2020-06-19 12:11:41+00:00,258473.0,"2 days, 23:47:53","[{'comment_id': 440839226, 'comment_body': ""This function takes us a step past the estimation of LAI and adds a (overly) simplistic GPP calculation with a lot of hard-coded parameters. @istfer is this really needed for the application you envisioned? I'd really prefer to drop this and `GPP_LUE_models` as likely to cause more trouble than benifit (e.g. attempts to calibrate or benchmark models against models)."", 'comment_created': datetime.datetime(2020, 6, 16, 13, 14, 35, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 440842531, 'comment_body': ""I think these are creeping in from Olli's code without being intended, GPP calculation is not a part of the GEE-GSOC work (it's an exercise from another project of Olli's)\r\n\r\nI'll only be able to review this code tomorrow @ayushprd then we can comb out what we need"", 'comment_created': datetime.datetime(2020, 6, 16, 13, 19, 29, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441290165, 'comment_body': 'This dictionary containing the model details is not required.', 'comment_created': datetime.datetime(2020, 6, 17, 5, 34, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441290421, 'comment_body': 'This function is not required.', 'comment_created': datetime.datetime(2020, 6, 17, 5, 35, 6, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441290657, 'comment_body': 'This function is not required for LAI.', 'comment_created': datetime.datetime(2020, 6, 17, 5, 35, 51, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441290796, 'comment_body': 'Not required for LAI.', 'comment_created': datetime.datetime(2020, 6, 17, 5, 36, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441291096, 'comment_body': 'I can make this part specifically for LAI instead of the generalized approach.', 'comment_created': datetime.datetime(2020, 6, 17, 5, 37, 16, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441291183, 'comment_body': 'Var can be hardcoded to LAI', 'comment_created': datetime.datetime(2020, 6, 17, 5, 37, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441293963, 'comment_body': ""The reason why I did not remove this plus the other features such as calculation of FAPAR, FCOVER, etc is that I thought these functions could be helpful to you all later on even if not used immediately. The other file included in this PR, `s2lai.py` simply calculates the LAI and does not estimate GPP or make use of the other functions present in SNAP. However, I understand these are not helpful, so I've marked the parts based on my understanding and testing which can be removed and will not affect the calculation of LAI. Sorry for the confusion. Henceforth, I will only think of NDVI and LAI while developing this project."", 'comment_created': datetime.datetime(2020, 6, 17, 5, 46, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441323423, 'comment_body': ""Hi Ayush, no please don't only think of NDVI and LAI while developing this project, we will need all sorts of data types and derivations. But as Sentinel2-GEE-NDVI-LAI pipeline already exists, that is what you can focus first of course, if that's what you mean.\r\n\r\nIt is fine that you weren't sure if other features were wanted or not. We normally want this module to give us data to compare to model predictions, but remote sensing data usually need some operation first. As you can see LAI is already more of a modeled-output than data, but most models do predict LAI, so we don't need the extra massaging it into GPP etc. Some models can already predict spectral bands, then we can directly use those and don't even need the LAI calculation step.\r\n\r\nThanks for marking the parts that are not needed for LAI calculation already, I'll get back to this PR/you after my morning meetings."", 'comment_created': datetime.datetime(2020, 6, 17, 7, 1, 26, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441356939, 'comment_body': ""Ayush, I still see these PRs as an exercise where you play with Olli's functions and get a feeling of the pipeline, but just wanted to point it out early on that if/when we will generalize the module, we will need to think a bit more about the function names. I will post something on our gee-slack channel to explain what I mean.\r\n\r\nFor now, I'm fine with having this function in so that anyone who has a geojson file can already use it for getting LAI values for their ROI :+1: "", 'comment_created': datetime.datetime(2020, 6, 17, 8, 1, 52, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441363472, 'comment_body': 'up until here, this function overlaps with s2ndvi.py which seems redundant. Two options here:\r\n1) modify this function to pick it up from where s2ndvi.py left\r\n2) delete/modify s2ndvi.py in favor of this one\r\n\r\n(2) is fine because there is not much use for NDVI only, and as I said, I don\'t see these functions as the main functions of the module yet (see the post on our slack channel). After this PR we will have one function that gets LAI for a ROI which is already good. \r\n\r\nBut going with (1) would be a good exercise for you to figure out how to divide the pipeline into subtasks. It could give you some design ideas. Then, for example, you would need a ""master"" function that calls `s2ndvi.py` first (you may also consider renaming it to something more general like `gee2bands.py`, but `s2ndvi.py` is also fine for now) and then `bands2lai.py` which calculates LAI', 'comment_created': datetime.datetime(2020, 6, 17, 8, 12, 41, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441369995, 'comment_body': ""I think I like the generalization, let's not lose it yet"", 'comment_created': datetime.datetime(2020, 6, 17, 8, 23, 32, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441370404, 'comment_body': ""As said in the previous comment, let's keep it this way for now"", 'comment_created': datetime.datetime(2020, 6, 17, 8, 24, 16, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441371730, 'comment_body': 'I think this is safe to remove', 'comment_created': datetime.datetime(2020, 6, 17, 8, 26, 30, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441372499, 'comment_body': 'can remove but not sure what it does', 'comment_created': datetime.datetime(2020, 6, 17, 8, 27, 40, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441372835, 'comment_body': ""let's remove"", 'comment_created': datetime.datetime(2020, 6, 17, 8, 28, 15, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441373042, 'comment_body': ""let's remove"", 'comment_created': datetime.datetime(2020, 6, 17, 8, 28, 34, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441392078, 'comment_body': 'directly pointing to the s2tbx was a neat idea :+1: ', 'comment_created': datetime.datetime(2020, 6, 17, 8, 58, 14, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441393142, 'comment_body': ""(1) is exactly what I have planned, I didn't do it yet because I cannot decide for sure till we discuss the automation/db part."", 'comment_created': datetime.datetime(2020, 6, 17, 9, 0, 1, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441411443, 'comment_body': 'For now you can ignore the DB part, as being discussed on the slack channel, it will require some more thought. This PR can focus on providing users some stand-alone mini-workflow that calculates LAI for a ROI (using Sentinel 2, GEE & SNAP combo)', 'comment_created': datetime.datetime(2020, 6, 17, 9, 29, 34, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441439610, 'comment_body': 'Right now for this PR if I were to follow (1), then I would remove `s2lai.py` completely, and then until we have the module ready, the LAI function will have to be used through `s2ndvi.py`(I can change its name)', 'comment_created': datetime.datetime(2020, 6, 17, 10, 16, 36, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441444593, 'comment_body': 'Why would you need to remove it completely? I was suggesting `s2ndvi.py` (could be renamed) would write the area data (`area.data.to_netcdf`), and `s2lai.py` (could be renamed) will take it from there, read the data back in and calculate LAI. Would that work?', 'comment_created': datetime.datetime(2020, 6, 17, 10, 25, 49, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441450250, 'comment_body': 'What I am suggesting is, \r\n\r\n1. Temporarily until the module is ready, there would be one main script to access the contents of satellitetools (`biophys_xarray.py` and `geeapi.py`.)\r\n\r\n2. Since both `s2ndvi.py` and `s2lai.py` themselves do not perform any calculations and instead rely on `geeapi.py` and `biophys_xarray.py`, I could remove one of them. For example, `s2lai.py` uses `run_snap_biophys()` to calculate lai, I can directly call this function `run_snap_biophys.py` inside the main script, instead of calling it through an intermediate script.', 'comment_created': datetime.datetime(2020, 6, 17, 10, 36, 42, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441452842, 'comment_body': '> Why would you need to remove it completely? I was suggesting `s2ndvi.py` (could be renamed) would write the area data (`area.data.to_netcdf`), and `s2lai.py` (could be renamed) will take it from there, read the data back in and calculate LAI. Would that work?\r\n\r\nThis is what I am suggesting too, except that there is no need of `s2lai.py` I can directly call its contents from `biophys_xarray.py`.', 'comment_created': datetime.datetime(2020, 6, 17, 10, 41, 47, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441455700, 'comment_body': ""Sure, that is more in-line with (2), and I'm fine with it as long as we don't have duplicate code. Granted, `s2lai.py` would only read data back, call `bio.run_snap_biophys` and write the results. Probably not worth having it as a separate function, as I said it was only meant to be an exercise."", 'comment_created': datetime.datetime(2020, 6, 17, 10, 47, 31, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441457527, 'comment_body': 'I second @istfer point -- my request to remove GPP was not a blanket request to remove everything that\'s not LAI. I agree that FAPAR and FCOVER are useful.\r\n\r\nAs a broader point, when it comes to remote sensing there\'s definitely a grey area when it comes to the question of what is ""data"" and what is a prediction from a model that\'s using remote sensing as one of its inputs. Raw bands are definitely in the first category, but very few of our ecosystem models predict that so they\'re not particularly useful validation. Also in this category are simple mathematical transforms of raw bands (e.g. NDVI) but process-models are likewise not routinely calculating this. GPP is definitely in the second category -- satellites are by no means observing this, but instead there are models that take satellite LAI as an input (along with light, temperature, humidity, etc. as well as a bunch of vegetation specific parameters) to try and predict GPP. In between these extremes of NDVI and GPP are a lot of algorithms that fall in a grey area of being more than an analytical transform but not fully a model, with fAPAR and LAI being great examples -- they are mostly physics, but require some assumptions about the canopy structure and leaf chemistry -- and different assumptions can lead to different numbers (though generally different algorithms are all pretty close).', 'comment_created': datetime.datetime(2020, 6, 17, 10, 51, 5, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 441459193, 'comment_body': 'Since I am removing some files, should I close this PR and a open a new one? or continue here itself?', 'comment_created': datetime.datetime(2020, 6, 17, 10, 54, 27, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 441463030, 'comment_body': ""Hmm good question, if this was my PR I would just keep working on it since the added/deleted files are small and related to the code (as opposed to the netcdf and excel data files in the previous PR). What's the procedure we want to stick here @robkooper ?"", 'comment_created': datetime.datetime(2020, 6, 17, 11, 2, 13, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 441570238, 'comment_body': ""Yeah, this is a small diff on text files, so it doesn't need a new PR"", 'comment_created': datetime.datetime(2020, 6, 17, 14, 3, 20, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}]","[{'commit_sha': 'c5d7169f0506df54287866ec65af443f7b7abe46', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1921baa7797fd5cd007234ba693a9bcc1b94ff28', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e15bf8de2e038af9459b409bbd13a7cb41bd4717', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '22c5ce12bd6772a48ec7a9e074736b40cc569b33', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '390d1839b1443c06fb32d64dd06c110780301c03', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3ee0d5a88bda65adb619c090d059e2841bc55c30', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3cf8cd7fc7e0c34e839235bad44e49c1055f60c9', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'be7098f045c1c650b2c8caa0133cf696b917358e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13
440906973,GEE - Landsat script and remote_process update,"<!--- Provide a general summary of your changes in the Title above -->
<!--- Please select appropriate Priority, Status,and Type labels-->
<!--- If you do not have permission to select labels please state which labels you would like -->

## Description
<!--- Describe your changes in detail -->
This PR adds the `l8gee2pecan_bands()` function which can be used for calculating NDVI and getting surface reflectance band data from Landsat 8. 

Currently, if ROI type is a point this function can be used for getting SR data from Landsat 7, 5 and 4 as well.

## Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->
To be used in the remote data module.

## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [ ] Within one week
- [x] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [x] I have updated the documentation accordingly.
- [x] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [x] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2642,https://api.github.com/repos/PecanProject/pecan/pulls/2642,https://github.com/PecanProject/pecan/pull/2642,closed,950,485,12,34,5,35,0,0,[],2020-06-27 12:39:03+00:00,2020-07-09 15:02:40+00:00,1045417.0,"12 days, 2:23:37","[{'comment_id': 450188288, 'comment_body': 'can `algorithm` also be `NULL` (or I guess in python syntax `None`) by default?', 'comment_created': datetime.datetime(2020, 7, 6, 12, 32, 24, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450189695, 'comment_body': 'could there be examples listed:\r\n```suggestion\r\n    source (str) -- source from where data is to be downloaded, e.g. ""gee"" or ""appEEARS"" etc. Currently only ""gee"" implemented\r\n```', 'comment_created': datetime.datetime(2020, 7, 6, 12, 35, 14, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450190102, 'comment_body': '```suggestion\r\n    qc (float) -- quality control parameter, only required for gee queries, None by default\r\n```', 'comment_created': datetime.datetime(2020, 7, 6, 12, 36, 4, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450191022, 'comment_body': 'could you also elaborate on this one, e.g.\r\n```suggestion\r\n    algorithm (str) -- algorithm used for processing data in process_data(), currently only SNAP is implemented to estimate LAI from Sentinel-2 bands, None by default\r\n```', 'comment_created': datetime.datetime(2020, 7, 6, 12, 37, 47, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450191652, 'comment_body': 'let\'s be a little more explicit:\r\n```suggestion\r\n    output (dict) -- ""get_data"" - the type of output variable requested from get_data module, ""process_data"" - the type of output variable requested from process_data module\r\n```', 'comment_created': datetime.datetime(2020, 7, 6, 12, 39, 3, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450192558, 'comment_body': 'this is fine, but I was wondering if this will be temporary indeed. We have lots of DB functions written in R that you can make use of, maybe before calling remote_process, you may have a small R script that figures out the stage and then pass it on to python code. Just a thought/note. ', 'comment_created': datetime.datetime(2020, 7, 6, 12, 40, 48, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450198648, 'comment_body': 'ID sounds like a number, maybe better to say `name`? Could you give examples here also, e.g.:\r\n```suggestion\r\n    collection (str) -- dataset or product name as it is provided on the source, e.g.  ""LANDSAT/LC08/C01/T1_SR"",  ""COPERNICUS/S2_SR"" for gee\r\n```\r\nthen, when appEEARS is in, you can add something like `""SPL3SMP"" for appEEARS`', 'comment_created': datetime.datetime(2020, 7, 6, 12, 52, 2, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450206513, 'comment_body': ""`ic` and `vi` don't seem to be arguments to this function?"", 'comment_created': datetime.datetime(2020, 7, 6, 13, 5, 56, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450207525, 'comment_body': 'could you explain what this is and if it could be a function arg if we want the flexibility for users to change', 'comment_created': datetime.datetime(2020, 7, 6, 13, 7, 44, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450208573, 'comment_body': ""I'm surprised that all bands need to be listed out, just curious, isn't there some `ee.select()` function feature that gets all bands if nothing is specified explicitly? or of they have some function arg like `all=TRUE` that returns everything or something like that?  there isn't much you can do otherwise of course"", 'comment_created': datetime.datetime(2020, 7, 6, 13, 9, 32, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450210474, 'comment_body': 'I wonder what this does? Also even though they might not be used in other functions yet, `reduce_region` and `mask` almost seem like they belong to gee_utils?', 'comment_created': datetime.datetime(2020, 7, 6, 13, 12, 45, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450211678, 'comment_body': ""also this probably belongs to gee_utils with an additional argument that specifies which bands to use\r\n\r\nAlthough I know you don't use it for S2 yet"", 'comment_created': datetime.datetime(2020, 7, 6, 13, 14, 50, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450218310, 'comment_body': 'just for the sake of resemblance with the previous function name, could this be called `get_sitecoord` or something like that', 'comment_created': datetime.datetime(2020, 7, 6, 13, 25, 45, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450222916, 'comment_body': 'could we have a more informative message that says something along these lines ""Please check if the collection name you requested is one of these and spelled correctly [prints collection_dict first column]. If not, you need to implement a corresponding gee2pecan_* function and add it to the lookup table.""', 'comment_created': datetime.datetime(2020, 7, 6, 13, 33, 4, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450225251, 'comment_body': 'I know you already know this, just to document it: we would ideally like to compute ndvi on the GEE side and return with the other bands for S2 too, like we do for the L8.', 'comment_created': datetime.datetime(2020, 7, 6, 13, 36, 55, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 450238234, 'comment_body': 'Yes forgot to remove.', 'comment_created': datetime.datetime(2020, 7, 6, 13, 56, 43, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 450245917, 'comment_body': ""It's the pixel resolution of the image https://developers.google.com/earth-engine/scale . I have sort of used a generic value here and in the other functions. This will probably need to be configured depending upon the use case. I didn't pass it as an argument because `gee2pecan_s2` does not do it currently (it's listed in the TODO). I can make it configurable there as well? Overall, I think all the gee extraction functions should have the same type of arguments."", 'comment_created': datetime.datetime(2020, 7, 6, 14, 8, 18, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 450246762, 'comment_body': ""There isn't any function which does that. `.select()` exists but it's used for selecting the bands from the collection."", 'comment_created': datetime.datetime(2020, 7, 6, 14, 9, 27, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 450252788, 'comment_body': 'This reduces the image depending as per the type of the aggregation function used (I used mean here) [more details here](https://developers.google.com/earth-engine/reducers_intro) I can put these in the `gee_utils` but then these have to be configured on a case-by-case basis for every image collection.', 'comment_created': datetime.datetime(2020, 7, 6, 14, 18, 3, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 450253810, 'comment_body': ""Yes, I'll change this should be None"", 'comment_created': datetime.datetime(2020, 7, 6, 14, 19, 29, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 450261836, 'comment_body': 'Nice!', 'comment_created': datetime.datetime(2020, 7, 6, 14, 30, 30, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 451417227, 'comment_body': '@istfer `gee2pecan_s2()` now calculates NDVI on GEE and all the bands are being retrieved without causing any issue in SNAP. Shall I add the initial book documentation in this PR itself?', 'comment_created': datetime.datetime(2020, 7, 8, 9, 42, 45, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 451425212, 'comment_body': ""Hi Ayush, I'll check this PR again as soon as I can but it might have to wait until tomorrow. In the meantime, yes, it would be wonderful if you could already add the initial book documentation to this PR :+1: "", 'comment_created': datetime.datetime(2020, 7, 8, 9, 56, 49, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452095727, 'comment_body': '```suggestion\r\nRemote data module retrieves remote sensing data from MODISTools and Google Earth Engine (with plans to support AppEEARS in near future). The downloaded data can be used for performing further analysis in PEcAn.\r\n```', 'comment_created': datetime.datetime(2020, 7, 9, 9, 43, 36, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452096658, 'comment_body': 'sorry, by ""one time step"" do you mean this action needs to be done first time only? Or does it mean something else?', 'comment_created': datetime.datetime(2020, 7, 9, 9, 45, 11, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452097719, 'comment_body': ""I'm a bit confused by this, is it only B5 and B4 or all the bands listed above? Code below seems to get all"", 'comment_created': datetime.datetime(2020, 7, 9, 9, 46, 59, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452105898, 'comment_body': '>I think all the gee extraction functions should have the same type of arguments.\r\n\r\nAgreed. Then, they could also be explained in the book-documentation.\r\n\r\nIt would be great if you could make it configurable, even though it is not currently used in gee2pecan_s2.\r\n\r\nAlso, could you add it to the book documentation with the link you shared here? it was very informative, thank you.', 'comment_created': datetime.datetime(2020, 7, 9, 10, 0, 59, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452106066, 'comment_body': 'you may delete this', 'comment_created': datetime.datetime(2020, 7, 9, 10, 1, 17, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452112970, 'comment_body': ""Thanks for the explanation. This also looks kind of important, that's why if it is moved to `gee_utils` it may be easier for people to realize what is going on under the hood, otherwise it is buried here. But, if you are using these only in `gee2pecan_l8` for now, then they can stay here for this PR. But as soon as they are need by another gee function it would be great to move them to `gee_utils` and make them configurable"", 'comment_created': datetime.datetime(2020, 7, 9, 10, 14, 2, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452115217, 'comment_body': 'When we finalize the output data format we can describe it here :+1: ', 'comment_created': datetime.datetime(2020, 7, 9, 10, 18, 22, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452119454, 'comment_body': 'This entire ""set-up"" is a first time and one time only step. Maybe I should write this at the top.', 'comment_created': datetime.datetime(2020, 7, 9, 10, 26, 24, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 452120388, 'comment_body': 'This is also a remnant from the previous version forgot to remove. All the bands are downloaded.', 'comment_created': datetime.datetime(2020, 7, 9, 10, 28, 18, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 452139669, 'comment_body': ""So I have 2 options here,\r\n1. I only make it configurable in l8. In this case, I will have to add an additional `if` in `get_remote_data` which would check if the scale is passed in the arguments and then call the appropriate function.\r\n2. I can also make it configurable in s2 even though it's not required (currently). This will not require adding the above `if`. \r\nBTW AppEEARS doesn't have this option to specify the scale. There we need to specify the type of projection required \r\n\r\nI think I should go with the 2nd option."", 'comment_created': datetime.datetime(2020, 7, 9, 11, 7, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 452150575, 'comment_body': '2nd option sounds good to me as well', 'comment_created': datetime.datetime(2020, 7, 9, 11, 30, 23, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 452210408, 'comment_body': '```suggestion\r\n#### Set-Up instructions (first time and one time only):\r\n```', 'comment_created': datetime.datetime(2020, 7, 9, 13, 18, 46, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}]","[{'commit_sha': '01b0fdf2c7507d03b987a1863fe232137fe0bf0f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ce7a9a757ff6c22f9bbdb5476444a4f4d2f9b1d3', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '99bde1c9e8712e2585bf5a7891bb6783be4e82c4', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c4cbe5729261d7e8859334d847b6191af4a3d59e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd45690cf60bceb67d13a1c4414c218bc64049fe0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6615858a53481bd3ce83a7f005353b9fce18190d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '57ff0e347a0b0b55662ade7059abc370b440d22a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '196e80deea9e37c957b18061bd369dbb56a45bfa', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f8c90c347ea37264c8b9596cabd4e3abc1eeb26c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '473f822d2c6143898ff4d985b20acb7df537319f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ebb49853a292c21a38cc621f294c8ee20eae6851', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '79e234869637f8d0e9484402c400e6286e16d00d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b6213c64308555dbeda80aec909b20e2abcacb2a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '72bab4526d96db81277eab2d5a51529b394484d7', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2be30528eef40262c019ce620f861ec2cae338bd', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a80e6bc908a91721d1adb0a57526158cf9e88fe', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7b9b07d95d9f1ba5c4e36961445136fae7404117', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '70b8d1a008a53589efecbf89f800239a69e6c484', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f5bf36f28df82009f122b2ed3a53d16db2414fe8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '42e5aa3216135aeb90c465b5b5caa61db72f7009', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1e5f865163438b432389fcdb7e8bc3086e9a1d57', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eea3d1838833a7e27ad4c3d29164d8e63daba522', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4e181c3bbd0c04429d76bea7d56efbbf9576ab30', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b91596502ddceecea3f85de2fb5e4bea7354347a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2a6892410b7c63769de69e94f205c94dd9adf4d8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3eb68d34d35e1633e6c54643e66d4ed9b07fd5ea', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2e23c56bfcb8a1248e06ec2f5b757a5e6d2d978d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7a2729cef2990cdd429ddbadeb089d810d3a802d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '37a9f74f682072b1c2399050269a0a255e2bfdb6', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f90541f961e41fdf10d78d435a8a6975ae7a19d2', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1f311be2b28e9e6270c1268d42df2bae2b9df924', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '90e6acc5aaf26fd6d897c3896bdddfc7026b87ef', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3a7dd6dec447b18f4af9282788b1d2691e1d0a9c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe47b7b9cdaf699666c33a2c4b95356dd950d6f1', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13
442003582,GEE - SMAP script,"<!--- Provide a general summary of your changes in the Title above -->
<!--- Please select appropriate Priority, Status,and Type labels-->
<!--- If you do not have permission to select labels please state which labels you would like -->

## Description
<!--- Describe your changes in detail -->
This PR adds the `gee2pecan_smap()` function which can be used for getting soil moisture data from Earth Engine.

## Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->
To be used in the remote data module.

## Installation instructions
As the module is not yet integrated with the PEcAn workflow, these steps will have to be performed manually.
This script requires Python3 and the python package manager pip

1. Sign up for the Google Earth Engine https://earthengine.google.com/new_signup/

2. Install the earth engine python api.
 `pip install earthengine-api` on Linux use `pip3` instead of `pip`
 Detailed steps including instructions for the alternative conda version are available [here](https://developers.google.com/earth-engine/python_installl)

3. Install the dependencies: download this [requirements.txt](https://raw.githubusercontent.com/ayushprd/PEcAn-GEE/master/requirements.txt) file to your working directory and run
 `pip install -r requirements.txt`

3. Once you have the earth engine account, run the following inside a python shell, (one time step)
 `import ee`
`ee.Authenticate()` [this will open up a browser and ask you to sign in with the google account registered for ee]

## Usage instructions
This module requires the input ROI (point and polygon type) in a geojson file format. The existing test file in `data.remote` cannot be used as SMAP data is not available for that region. This [test file](https://raw.githubusercontent.com/ayushprd/PEcAn-GEE/master/test2.geojson) can be downloaded for testing. I used [this](https://geojson.io/) for creating the geojson file. 
Please ensure that you have the name of the site/ROI inside the ""properties"" tag, this info is required for saving the file.

Example run:
At the location where `gee2pecan_smap.py` is present, open a python shell
```
from gee2pecan_smap import gee2pecan_smap

gee2pecan_smap(""./test2.geojson"", ""./out/"", ""2018-01-01"", ""2018-12-31"", ""ssm"")
```
The output netCDF file should be saved at the specified path. More info about the function arguments can be found out by `help(gee2pecan_smap)`


## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [ ] Within one week
- [x] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [ ] I have updated the documentation accordingly.
- [x] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [x] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2645,https://api.github.com/repos/PecanProject/pecan/pulls/2645,https://github.com/PecanProject/pecan/pull/2645,closed,152,0,1,1,2,0,0,0,[],2020-06-30 12:46:07+00:00,2020-06-30 13:32:10+00:00,2763.0,0:46:03,[],"[{'commit_sha': '766922b3e7d7ed4d047e3aee2baf346432675e5a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13
449912442,AppEEARS download function,"<!--- Provide a general summary of your changes in the Title above -->
<!--- Please select appropriate Priority, Status,and Type labels-->
<!--- If you do not have permission to select labels please state which labels you would like -->

## Description
This PR adds the function which can be used for downloading remote sensing data from AppEEARS.

## Motivation and Context
To be used in the remote data module.

## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [ ] Within one week
- [x] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [x] I have updated the documentation accordingly.
- [x] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [x] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2659,https://api.github.com/repos/PecanProject/pecan/pulls/2659,https://github.com/PecanProject/pecan/pull/2659,closed,282,19,5,15,1,21,0,0,[],2020-07-16 05:40:28+00:00,2020-07-30 13:36:23+00:00,1238155.0,"14 days, 7:55:55","[{'comment_id': 455523325, 'comment_body': ""I have also removed the `output` dict and replaced it with `process_data` because the `get_data` variable wasn't being used anywhere other than in `process_remote_data` and I felt that it was a bit confusing."", 'comment_created': datetime.datetime(2020, 7, 16, 5, 45, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 455643067, 'comment_body': '```suggestion\r\n[AppEEARS (Application for Extracting and Exploring Analysis Ready Samples)](https://lpdaacsvc.cr.usgs.gov/appeears/) is an online tool which provides an easy to use interface for downloading analysis ready remote sensing data. [Products available on AppEEARS.](https://lpdaacsvc.cr.usgs.gov/appeears/products) Note: AppEEARS uses a task based system for processing the data request, it is possible for a task to run for long hours before it gets completed. The module checks the task status after every 60 seconds and saves the files when the task gets completed.\r\n```', 'comment_created': datetime.datetime(2020, 7, 16, 9, 14, 13, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455643330, 'comment_body': 'just a typo in whhich', 'comment_created': datetime.datetime(2020, 7, 16, 9, 14, 42, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455656728, 'comment_body': 'I think we need to reconcile this so that `AppEEARS_PRODUCTNAME_site_SITEID` output files can have the same format', 'comment_created': datetime.datetime(2020, 7, 16, 9, 36, 25, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455669217, 'comment_body': 'maybe mention that ""as listed on AppEEARS website"" ', 'comment_created': datetime.datetime(2020, 7, 16, 9, 57, 14, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455670609, 'comment_body': ""so does the user need to change the lines within the code? wouldn't it be possible to pass it as a fcn arg, defaults to `None`?"", 'comment_created': datetime.datetime(2020, 7, 16, 9, 59, 40, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455671101, 'comment_body': 'this bit needs to throw a warning at least that subsetting happens', 'comment_created': datetime.datetime(2020, 7, 16, 10, 0, 24, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455680488, 'comment_body': 'I see what you mean, since we changed the logic for gee function names to use collection names instead :+1: \r\n\r\nBut I was wondering if we are losing some generality this way, now you hardcode `bands` in the `process_remote_data`, it\'s true that we only have one processing function (`bands2lai_snap`) for now, but it may not be the case in the future (just making this up, `images2ndvi_algX`). I can\'t think of an example for now, but for some future remote sources we might also need the original logic in case we need to formulate functions like `source2pecan_varname` where `varname==output[""get_data""]`. So I would vote for keeping it.', 'comment_created': datetime.datetime(2020, 7, 16, 10, 17, 21, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455684431, 'comment_body': ""That's right. Ok, then what should be the value of `get_data` say in case of AppEEARS?"", 'comment_created': datetime.datetime(2020, 7, 16, 10, 24, 40, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 455686718, 'comment_body': 'Yes, currently that needs to be done. Yes, passing it through an argument can be made as an option although I am a bit worried about having too many arguments, hard to imagine how the XML would be configured. If we know beforehand where to store the file (in Linux it should probably be in `.config/` then maybe I can also create the JSON file automatically once the user enters their credentials for the first time and then use that for subsequent runs.', 'comment_created': datetime.datetime(2020, 7, 16, 10, 28, 52, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 455694057, 'comment_body': ""Could the default values of this list for both levels be `None`? Since the current implementation of AppEEARS also doesn't use `process_data` Or it can always stay as `bands` by default.. I was thinking of providing the flexibility that users pass these via xml"", 'comment_created': datetime.datetime(2020, 7, 16, 10, 42, 25, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455701943, 'comment_body': ""Alright, I'll change it back and keep it as None by default.\r\n"", 'comment_created': datetime.datetime(2020, 7, 16, 10, 57, 39, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 455712859, 'comment_body': ""Do you mean I should convert csv to netCDF? Also currently gee output files do not follow this naming convention if this is final, I'll update the functions to follow this."", 'comment_created': datetime.datetime(2020, 7, 16, 11, 20, 4, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 455721504, 'comment_body': ""Not related to this specific instance, one question which I have is would the print statements, warnings etc from python be visible when executing the pecan workflow? Because I can't use the pecan logger functions."", 'comment_created': datetime.datetime(2020, 7, 16, 11, 37, 9, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 455755603, 'comment_body': ""No worries, I'm aware that gee output doesn't have this convention because naming convention, formats and DB interaction is the next step\r\n\r\nOur load_data functions can work with both csv and netcdf, maybe it is not important that they share the same file format at this point, we can fix it later if it turns out we need them to have the same format"", 'comment_created': datetime.datetime(2020, 7, 16, 12, 41, 40, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455757088, 'comment_body': ""Yeah I think any solution that doesn't require touching code would be better. Otherwise, this also makes other kinds of small nuisance possible. e.g. others to commit their hardcoded paths by mistake etc."", 'comment_created': datetime.datetime(2020, 7, 16, 12, 44, 25, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455757724, 'comment_body': ""Good question, I don't know really, does reticulate pass along logs etc?"", 'comment_created': datetime.datetime(2020, 7, 16, 12, 45, 25, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455807371, 'comment_body': 'as far as I know, print statements can be passed but not logs. This will make it very difficult to debug when something goes wrong.', 'comment_created': datetime.datetime(2020, 7, 16, 13, 59, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 455849711, 'comment_body': 'feel free to ask around on slack or open up an issue. This is a broader issue that we would hopefully like to address generally within PEcAn ', 'comment_created': datetime.datetime(2020, 7, 16, 14, 54, 40, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455852748, 'comment_body': 'how long was this taking example approximately? Maybe add a sentence around here as well that it may take couple of minutes', 'comment_created': datetime.datetime(2020, 7, 16, 14, 58, 43, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 455858321, 'comment_body': '20 mins', 'comment_created': datetime.datetime(2020, 7, 16, 15, 6, 17, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}]","[{'commit_sha': '3a33940cd1184790b603ff1ea12ba7804ad3fc21', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '189f545ded51b2a5aaf4da6ebed2ee57ee966c69', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ee91f769d003effb83bf2dc4db1a92c9c1356d7e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '492a01dd64109fbcdd66fee3833e1383b6ed08e3', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '84a599d5c9a39ff487a1994ffde3beb67a15dd3c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3fb64f2c7b9205349d304f901984cae0c31e94c1', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bd3755916fe28c2b6f5986094f1814e5db24ddc5', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ecbb036a129db7bf6a97fb57e49ca3f66e6a530c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9c4c35ef98dc0ce70d78d970815da389cd936883', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f25252bcd15bad4dadcf44b519f5cbfb499d6379', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '84f55f7ddc089eea3b5e9f34d55cdbbd4f405ec0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '36ac374fc1dd822117856fb4d34a823f81324d65', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0e8becf5c735265f727b15b275ac23b89158ba76', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bfd893f2cf6af9e506f96a65f4e96e639817694d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6566e4919c38fdb7ce5280cc151b8c3ce46cb3ac', 'committer_username': 'mdietze', 'committer_name': 'Michael Dietze', 'committer_email': 'dietze@bu.edu', 'commit_date': datetime.datetime(2012, 12, 19, 14, 18, 27, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13
462004888,Integrating remote_process with PEcAn,"<!--- Provide a general summary of your changes in the Title above -->
<!--- Please select appropriate Priority, Status,and Type labels-->
<!--- If you do not have permission to select labels please state which labels you would like -->

## Description
This PR adds `call_remote_process.R` which would control the Python remote_process for downloading, processing and storing remote sensing data in PEcAn. With the current implementation, only `call_remote_process.R` has PEcAn dependencies, `remote_process` can be used on its own apart from the workflow.

## Motivation and Context
This PR connects all the GEE and AppEEARS scripts.

@istfer I still haven't edited the workflow.R or add dependencies to docker, I will do these as soon as the overall idea of  `call_remote_process` gets reviewed.

## XML tags required in settings
```
<remotedata>
<source>gee</source>
<collection>COPERNICUS/S2_SR</collection>
<scale>10.0</scale>
<projection><projection/>
<qc>1.0</qc>
<algorithm>snap</algorithm>
<credfile></credfile>
<out_get_data>bands</out_get_data>
<out_process_data>lai</out_process_data>
<raw_id></raw_id>
<raw_path></raw_path>
<pro_id></pro_id>
<pro_id></pro_path>
<overwrite></overwrite>
</remotedata>

```
For now please do the following inside the rstudio container:
```
apt-get update
apt-get install python3-pip
pip3 install --upgrade setuptools

navigate to /pecan/modules/data.remote/inst/RpTools
pip3 install -e .
```






<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->

## Review Time Estimate
<!---When do you want your code reviewed by?-->
- [ ] Immediately
- [x] Within one week
- [ ] When possible
## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue) <!-- please add issue number -->
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)

## Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My change requires a change to the documentation.
- [ ] I have updated the CHANGELOG.md.
- [x] I have updated the documentation accordingly.
- [x] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [x] All new and existing tests passed.

<!--this template is from https://www.talater.com/open-source-templates/#/page/99--> 
",True,2672,https://api.github.com/repos/PecanProject/pecan/pulls/2672,https://github.com/PecanProject/pecan/pull/2672,closed,2483,388,35,127,6,121,0,0,[],2020-08-03 07:34:21+00:00,2020-10-29 18:06:19+00:00,7554718.0,"87 days, 10:31:58","[{'comment_id': 464324175, 'comment_body': 'This is wrong and will not work from when being called from anywhere else but the only other way I have been able to get this work is by directly specifying the absolute path `/pecan/modules/data.remote/inst` which I think is also not appropriate? Using `file.path(system.file(""remote_process.py"", package = ""PEcAn.data.remote""))` gives me a module not found error. I have no idea why.', 'comment_created': datetime.datetime(2020, 8, 3, 10, 17, 56, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 464463046, 'comment_body': 'Other input processing functions of this type don\'t start with ""call_"" so I\'d recommend dropping that to keep the pattern consistent. All also take an ""overwrite"" arg that tells the function whether to overwrite the existing DB record or not (defaults to false). Some also take additional args. I think taking all of \'settings\' is fine for now, since that\'s what the other functions like this do, but based on the Phase 3 planning meeting I think we want to move towards just taking the relevant subsections (e.g. the specific `input` record being processes)', 'comment_created': datetime.datetime(2020, 8, 3, 14, 48, 59, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464464976, 'comment_body': '`system.file` is the correct way to do this (not sure you need `file.path` also). You definitely need to build and install the package for that to work. ', 'comment_created': datetime.datetime(2020, 8, 3, 14, 52, 5, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464471297, 'comment_body': 'Things like mimetype and formatname are going to be fixed for a specific data source, and thus shouldn\'t need to be provided by the user (this would just be a potential source of error and makes it harder for users as they have to look up info that only has one \'right\' answer). In met we solve this problem by putting simple ""registry"" metadata files for each data type/source in the package itself.', 'comment_created': datetime.datetime(2020, 8, 3, 15, 1, 52, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464472104, 'comment_body': ""Also, if you're adding a bunch of stuff to the Settings, you definitely need to update the PEcAn documentation to document any new settings options."", 'comment_created': datetime.datetime(2020, 8, 3, 15, 2, 59, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464473388, 'comment_body': ""there should be an on.exit(db.close()) right here, rather than having the db.close at the end of the function (which you'll never get to if you exit prematurely)."", 'comment_created': datetime.datetime(2020, 8, 3, 15, 4, 53, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464475390, 'comment_body': 'Not sure why you have two variables (collection_lut and getpecancode) that store the identical information. Also, if you have registry files you could generate tables like this on the fly, rather than having a place developers have to update a hard-coded table every time they add a product.', 'comment_created': datetime.datetime(2020, 8, 3, 15, 7, 50, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464476848, 'comment_body': 'feel like this line is reinventing `dbfile.input.check`', 'comment_created': datetime.datetime(2020, 8, 3, 15, 10, 16, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464483361, 'comment_body': ""Function exits without returning updated `input` information to the settings file (i.e. the input ids and file paths to the data that's been downloaded). Take a look at the end of `met.process` for an analogy\r\n\r\nAlso, function appears to strictly assume that the processing is running locally, and doesn't consider the case where the data needs to be downloaded and processed directly onto a remote machine (e.g. HPC).  Similarly, it's not clear how this function behaves if the user is trying to download additional data to append onto the end of an existing time-series. Take a look at `convert.inputs` and `remote.execute.R`. "", 'comment_created': datetime.datetime(2020, 8, 3, 15, 21, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 464817827, 'comment_body': 'I just saw the pattern argument, will see if I can replace.', 'comment_created': datetime.datetime(2020, 8, 4, 6, 1, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 464818653, 'comment_body': ""> Similarly, it's not clear how this function behaves if the user is trying to download additional data to append onto the end of an existing time-series.\r\n\r\nI have now added some documentation about this which I still have to extend.\r\n\r\n> Whenever a data product is requested the output files are stored in the inputs table of BETYdb. Subsequently when the same product is requested again with a different date range but with the same qc, scale, projection the previous file in the db would be extended. The DB would always contain only one file of the same type.\r\nAs an example, if a file `Reykajvik_gee_s2_10.0_NA_1.0_200802174519.nc` containing Sentinel 2 bands for start date: 2018-01-01, end date: 2018-06-30 exists in the DB and the same product is requested again for a different date range one of the following cases would happen,\r\n\r\n>1. New dates are ahead of the existing file: For example, if the requested dates are start: 2018-10-01, end: 2018-12-31 in this case the previous file will be extended forward meaning the effective start date of the file to be downloaded would be the day after the end date of the previous file record, i.e. 2018-07-01. The new and the previous file would be merged and the DB would now be having data for 2018-01-01 to 2018-12-31.\r\n\r\n>2. New dates are preceding of the existing file: For example, if the requested dates are start: 2017-01-01, end: 2017-06-30 in this case the effective end date of the new download would be the day before the start date of the existing file, i.e., 2017-12-31. The new and the previous file would be merged and the file in the DB would now be having data for 2017-01-01 to 2018-06-30. \r\n\r\n>3. New dates contain the date range of the existing file: For example, if the requested dates are start: 2016-01-01, end: 2019-06-30 here the existing file would be replaced entirely with the new file. A more efficient way of doing this could be to divide your request into two parts, i.e, first request for 2016-01-01 to 2018-01-01 and then for 2018-06-30 to 2019-06-30."", 'comment_created': datetime.datetime(2020, 8, 4, 6, 3, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 464831045, 'comment_body': ""I named it like this as I think having two files with the same name would be confusing. This R script just checks the DB status, sets stages, and inserts into the DB. The actual download, merging etc are triggered and handled by the Python `remote_process`. What do you all want this to be named @istfer ? \r\n\r\nI don't follow the second point, Can you explain here why should the user have to decide if its to be overwritten or not? This module checks about the status of the existing file and creates a new file with the same name, different timestamp every time the record is updated but the previous contents are merged in the new file,"", 'comment_created': datetime.datetime(2020, 8, 4, 6, 38, 20, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 464841380, 'comment_body': ""I don't have siteid here because I think that info is redundant and currently, siteid never goes beyond `call_remote_process` and reach the Python functions. But if it's required to make consistent with PEcAn guidelines I will do so."", 'comment_created': datetime.datetime(2020, 8, 4, 7, 2, 22, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 464891395, 'comment_body': 'I agree with Ayush that this is a different case than other input processing modules as it is written in python. The function that does the real work is justifiably called `remote_process` but it is in python. Someone who has the function arguments ready, can use the module independent of pecan. To integrate these functions with the rest of the workflow and also to make use of our DB functions written in R already, Ayush created this wrapper function which should ideally be called something else.\r\n\r\nBut I agree with Mike that in the future there might be some functionality that parallelize the calls of `***_process` functions in R (or something like that) and we might want to preserve this naming convention throughout input processing functions for one reason or the other. How about we call this R function `remote_process` and the python function `remote_module`, or something along those lines?', 'comment_created': datetime.datetime(2020, 8, 4, 8, 36, 10, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 464904365, 'comment_body': ""Yes, I agree with Mike that we won't be needing mimetypes and formats specified in the settings tags, I'll give Ayush's code a try and see if we can have registry files or some lookup table sort of thing for this"", 'comment_created': datetime.datetime(2020, 8, 4, 8, 57, 59, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 464920024, 'comment_body': '-Yeah I think we would like to have siteid instead of sitename because it is less ambiguous (also some sites really have long names with spaces in them (e.g. `Ontario - Turkey Point Mature Deciduous (CA-TPD)`) whereas siteid always have an expected form, e.g. `1000000109` turns into `site_1-109` in the filename. \r\n\r\n-Do we really need the time stamp in the filename? \r\n\r\n-Also we can think about the difference between foldername and filename, for example, foldername could be `source_siteid` and the filename can be `collection_scale_projection_qc_siteid`. \r\n```\r\nGEE_site_1-109\r\n  \\_  S2_10-1_site_1-109.nc\r\n  \\_  L8_10-1_site_1-109.nc\r\n```\r\nWe can play around with these a little', 'comment_created': datetime.datetime(2020, 8, 4, 9, 25, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 464953151, 'comment_body': "">  e.g. 1000000109 turns into site_1-109 in the filename.\r\n\r\nSorry not aware of the logic. How does this happen?\r\n\r\n> -Do we really need the time stamp in the filename?\r\n\r\nWe need something to make the file names unique otherwise when the same data is requested again in the same outdir then the previous file will be directly overwritten before we can do anything with it. I have also tried a different approach - when the merge flag is true, I renamed the original final with some random string before starting the new download and then after merging was completed I changed it back to its original name. This worked fine but I think it's risky because if anything unexpectedly goes wrong during download or merging then the file name in the DB would remain same and but the actual file name would be something random. I used timestamp because by nature it would always be unique and human-readable but I can use the cryptography functions to generate random strings or anything else as well to make every file name unique.\r\n"", 'comment_created': datetime.datetime(2020, 8, 4, 10, 26, 14, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 464963352, 'comment_body': ""> in the future there might be some functionality that parallelize the calls of ***_process functions in R (or something like that) \r\n\r\nI just wanted to point out that there are some limitations in parallelizing Python code in R using reticulate https://cran.r-project.org/web/packages/future/vignettes/future-4-non-exportable-objects.html  `remote_process.py` on its own can easily be modified to run and concurrently or parallelly, but I am not sure via R.  \r\n\r\n>   How about we call this R function remote_process and the python function remote_module, or something along those lines?\r\n\r\nOk I'll do this."", 'comment_created': datetime.datetime(2020, 8, 4, 10, 47, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 464973387, 'comment_body': '>Sorry not aware of the logic. How does this happen?\r\n\r\nSorry I was being cryptical, once we know about the `siteid`, we create this string, like `paste0(siteid %/% 1e+09, ""-"", siteid %% 1e+09)` You can see an example [here](https://github.com/PecanProject/pecan/blob/develop/modules/data.land/R/ic_process.R#L62-L65).\r\n\r\n>when the same data is requested again in the same outdir then the previous file will be directly overwritten before we can do anything with it. \r\n\r\nHmm this doesn\'t sound quite right, before we do anything we query the DB to see if there has been any input file for this site, previous file should be returned from that query with date info as they are stored in the DB. Sorry, I still haven\'t been able to check you code in detail yet, I don\'t know how the merge flag works. I\'ll come back to this discussion once I work through your PR', 'comment_created': datetime.datetime(2020, 8, 4, 11, 9, 10, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 465026246, 'comment_body': ""Overwrite should default to FALSE, and should rarely need to be invoked, but experience has taught us that theres a million little things that can go wrong (database errors, download errors, accidental file corruption, errors corrections on the data producer's side, etc) and sometimes you just need to force the code to skip all its checks and do a clean download."", 'comment_created': datetime.datetime(2020, 8, 4, 12, 51, 42, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 465027801, 'comment_body': ""Great to hear the function is smart about downloads -- what you describe is exactly the behavior we've implemented elsewhere. 👍 "", 'comment_created': datetime.datetime(2020, 8, 4, 12, 54, 16, tzinfo=datetime.timezone.utc), 'commenter': 'mdietze', 'type': 'User'}, {'comment_id': 470959041, 'comment_body': 'I\'m not able to install this\r\n\r\n```\r\n$ pip install -e .\r\nObtaining file:///home/istfer/pecan/modules/data.remote/inst/RpTools\r\nCollecting attrs>=19.3.0 (from RpTools==0.1)\r\n  Using cached https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\r\nCollecting cachetools>=4.1.1 (from RpTools==0.1)\r\n  Could not find a version that satisfies the requirement cachetools>=4.1.1 (from RpTools==0.1) (from versions: 0.0.0, 0.1.0, 0.2.0, 0.3.0, 0.3.1, 0.4.0, 0.5.0, 0.5.1, 0.6.0, 0.7.0, 0.7.1, 0.8.0, 0.8.1, 0.8.2, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.1.6, 2.0.0, 2.0.1, 2.1.0, 3.0.0, 3.1.0, 3.1.1)\r\nNo matching distribution found for cachetools>=4.1.1 (from RpTools==0.1)\r\nYou are using pip version 9.0.1, however version 20.2.2 is available.\r\nYou should consider upgrading via the \'pip install --upgrade pip\' command.\r\n\r\n```\r\nLooks like our python versions are out of date? When I try `pip install --upgrade pip` I get\r\n\r\n```\r\nCollecting pip\r\n  Using cached https://files.pythonhosted.org/packages/5a/4a/39400ff9b36e719bdf8f31c99fe1fa7842a42fa77432e584f707a5080063/pip-20.2.2-py2.py3-none-any.whl\r\nInstalling collected packages: pip\r\n  Found existing installation: pip 9.0.1\r\n    Uninstalling pip-9.0.1:\r\nException:\r\nTraceback (most recent call last):\r\n  File ""/usr/local/lib/python2.7/dist-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py"", line 215, in main\r\n    status = self.run(options, args)\r\n  File ""/usr/local/lib/python2.7/dist-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py"", line 342, in run\r\n    prefix=options.prefix_path,\r\n  File ""/usr/local/lib/python2.7/dist-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py"", line 778, in install\r\n    requirement.uninstall(auto_confirm=True)\r\n  File ""/usr/local/lib/python2.7/dist-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py"", line 754, in uninstall\r\n    paths_to_remove.remove(auto_confirm)\r\n  File ""/usr/local/lib/python2.7/dist-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove\r\n    renames(path, new_path)\r\n  File ""/usr/local/lib/python2.7/dist-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py"", line 267, in renames\r\n    shutil.move(old, new)\r\n  File ""/usr/lib/python2.7/shutil.py"", line 300, in move\r\n    rmtree(src)\r\n  File ""/usr/lib/python2.7/shutil.py"", line 247, in rmtree\r\n    rmtree(fullname, ignore_errors, onerror)\r\n  File ""/usr/lib/python2.7/shutil.py"", line 252, in rmtree\r\n    onerror(os.remove, fullname, sys.exc_info())\r\n  File ""/usr/lib/python2.7/shutil.py"", line 250, in rmtree\r\n    os.remove(fullname)\r\nOSError: [Errno 13] Permission denied: \'/usr/local/lib/python2.7/dist-packages/pip-9.0.1-py2.7.egg/pip/wheel.pyc\'\r\n```\r\n\r\n@mdietze is it possible to upgrade pecan2?', 'comment_created': datetime.datetime(2020, 8, 15, 9, 32, 14, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470959364, 'comment_body': '```suggestion\r\n  <projection>...</projection>\r\n```', 'comment_created': datetime.datetime(2020, 8, 15, 9, 36, 22, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470960973, 'comment_body': 'I think we should switch to using registration files like Mike suggested. Many of these arguments could be extracted from those files, we might as well replace the lookup table for function names. Could be one registration file per source, e.g. for register.GEE.xml:\r\n```\r\n<?xml version=""1.0""?>\r\n<GEE>\r\n  <collection>\r\n    <original_name>COPERNICUS/S2_SR</original_name>\r\n    <pecan_name>s2</pecan_name>\r\n    <scale>site</scale>\r\n    <format>\r\n     <id></id>\r\n     <name></name>\r\n     <mimetype>application/x-netcdf</mimetype>\r\n   </format>\r\n  </collection>\r\n  <collection>\r\n    <original_name>LANDSAT/LC08/C01/T1_SR</original_name>\r\n    <pecan_name>l8</pecan_name>\r\n    <scale>site</scale>\r\n    <format>\r\n     <id></id>\r\n     <name></name>\r\n     <mimetype>application/x-netcdf</mimetype>\r\n   </format>\r\n  </collection>\r\n    <collection>\r\n    <original_name>NASA_USDA/HSL/SMAP_soil_moisture</original_name>\r\n    <pecan_name>smap</pecan_name>\r\n    <scale>site</scale>\r\n    <format>\r\n     <id></id>\r\n     <name></name>\r\n     <mimetype>application/x-netcdf</mimetype>\r\n   </format>\r\n  </collection>\r\n</GEE>\r\n```\r\nI will work through an example as I go', 'comment_created': datetime.datetime(2020, 8, 15, 9, 57, 19, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470961261, 'comment_body': 'Could you try doing `pip3 install -e .`', 'comment_created': datetime.datetime(2020, 8, 15, 10, 0, 51, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 470961444, 'comment_body': ""```\r\npip3 install -e .\r\nThe program 'pip3' is currently not installed. To run 'pip3' please ask your administrator to install the package 'python3-pip'\r\n```\r\n"", 'comment_created': datetime.datetime(2020, 8, 15, 10, 3, 19, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470961713, 'comment_body': 'Oh ok I think you also have Python 2 installed.  **You will need pip3 here.**', 'comment_created': datetime.datetime(2020, 8, 15, 10, 6, 15, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 470962619, 'comment_body': ""Yeah that's why I need @mdietze's help, I happen to set up your branch on a machine where I don't have sudo privileges, even then I would be hesitant to do a system-wide installation"", 'comment_created': datetime.datetime(2020, 8, 15, 10, 18, 1, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470962667, 'comment_body': 'If these are the arguments used in the filename, we need to make sure they are not NULL, for example the check above should include an else to use some default (with a message):\r\n```\r\n\r\n  if (!is.null(scale)) {\r\n    scale <- as.double(settings$remotedata$scale)\r\n    scale <- format(scale, nsmall = 1)\r\n  }else{\r\n     scale <- 10\r\n     PEcAn.logger::info(""No sclae provided, Using 10 as default"")\r\n  }\r\n```\r\n\r\nIdeally, all remotedata tags should be checked to see if they are filled with sensible values in the beginning, probably you have checks later for some of those later on but I think beginning of the module is a good place to do that.\r\n\r\nWe should check even if the source is valid, e.g. ""GEE"" but not ""GoogleEarthEngine"". If we use registration files we can look if `register.SOURCE.xml` file exists, if not this also means that source is not implemented yet. Overall, I think registration files will help us on many levels\r\n\r\nSpeaking of which, maybe source should also be in the filename, a filename like `s2_10.0_***_site_1-26929` felt a bit uninformative as opposed to `GEE_s2_10.0_***_site_1-26929` even though the folder name has the source', 'comment_created': datetime.datetime(2020, 8, 15, 10, 18, 57, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470962731, 'comment_body': '```suggestion\r\n  raw_file_name <- construct_raw_filename(collection, siteid_short, scale, projection, qc)\r\n```', 'comment_created': datetime.datetime(2020, 8, 15, 10, 19, 35, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470962757, 'comment_body': '```suggestion\r\n  coords <- unlist(PEcAn.DB::db.query(sprintf(""select ST_AsGeoJSON(geometry) from sites where id=%f"", siteid), con = dbcon), use.names=FALSE)\r\n```', 'comment_created': datetime.datetime(2020, 8, 15, 10, 19, 48, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470962918, 'comment_body': 'I wonder if this bit should be refactored to its own function, e.g. remotedata_db_check', 'comment_created': datetime.datetime(2020, 8, 15, 10, 21, 49, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470963702, 'comment_body': 'can this be renamed to be a bit more informative, e.g. `remotefile_check_flag` or something like that? and could you document the meanings of each number in a single place, maybe as inline comments here (wherever it is used for the first time)', 'comment_created': datetime.datetime(2020, 8, 15, 10, 32, 5, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470964140, 'comment_body': 'this shouldn\'t be the workflow directory (they tend to be less stable), instead use this\r\n```suggestion\r\n  outdir <- file.path(settings$database$dbfiles, paste(source, ""site"", siteid_short, sep = ""_""))\r\n```', 'comment_created': datetime.datetime(2020, 8, 15, 10, 38, 20, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470967176, 'comment_body': '> `     PEcAn.logger::info(""No sclae provided, Using 10 as default"")`\r\n\r\nCurrently, all of the functions which require such arguments don\'t have a default value set in the Python function(except l8 qc which I see I forgot to remove) Do you think they should have a default value? If yes, I think that should not be set here in `remote_process` and should be set in the Python function because the values differ for every collection.\r\n\r\n> If these are the arguments used in the filename, we need to make sure they are not NULL\r\n\r\nCan you please explain about this? It is being checked if they are NULL and in that case ""NA"" is used in place of the value in the filename. I went this way so that there would be a same logic for constructing the file name regardless of source and collection.\r\n\r\n> Ideally, all remotedata tags should be checked to see if they are filled with sensible values in the beginning\r\n\r\nAgreed, I should have done that.\r\n\r\n> Speaking of which, maybe source should also be in the filename, a filename like s2_10.0_***_site_1-26929 felt a bit uninformative as opposed to GEE_s2_10.0_***_site_1-26929 even though the folder name has the source\r\n\r\nYes, will change it back.\r\n\r\n\r\n\r\n', 'comment_created': datetime.datetime(2020, 8, 15, 11, 18, 19, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 470967707, 'comment_body': 'before this could you do something like\r\n```\r\nfcn.args <- list()\r\nfcn.args$coords     <- coords\r\nfcn.args$outdir     <- outdir\r\nfcn.args$start      <- start\r\nfcn.args$end        <- end\r\nfcn.args$source     <- source\r\nfcn.args$collection <- collection\r\nfcn.args$siteid     <- siteid\r\nfcn.args$scale      <- as.double(scale)\r\nfcn.args$projection <- projection\r\nfcn.args$qc         <- as.double(qc)\r\nfcn.args$algorithm              <- algorithm\r\nfcn.args$input_file             <- input_file\r\nfcn.args$credfile               <- credfile\r\nfcn.args$out_get_data           <- out_get_data\r\nfcn.args$out_process_data       <- out_process_data\r\nfcn.args$stage_get_data         <- stage_get_data\r\nfcn.args$stage_process_data     <- stage_process_data\r\nfcn.args$raw_merge              <- raw_merge\r\nfcn.args$pro_merge              <- pro_merge\r\nfcn.args$existing_raw_file_path <- existing_raw_file_path\r\nfcn.args$existing_pro_file_path <- existing_pro_file_path\r\n\r\n\r\narg.string <- listToArgString(fcn.args)\r\n\r\ncmdFcn <- paste0(""RpTools$rp_control("", arg.string, "")"")\r\nPEcAn.logger::logger.debug(paste0(""Remote module executing the following function:\\n"", cmdFcn))\r\n```\r\nIt helps a lot with debugging', 'comment_created': datetime.datetime(2020, 8, 15, 11, 25, 14, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470969701, 'comment_body': '> Currently, all of the functions which require such arguments don\'t have a default value set in the Python function(except l8 qc which I see I forgot to remove) Do you think they should have a default value? \r\n\r\nNot sure if they have defaults, probably yes because the person who implements/develops the function typically knows better than most of the end users. But even if they don\'t have a default value, I think the module should fail here when some argument of the downstream function is missing or passed an invalid value.\r\n\r\n>If yes, I think that should not be set here in `remote_process` and should be set in the Python function because the values differ for every collection.\r\n\r\nI think we can use the registration files for inserting the defaults as well, which solves values differ for every collection and reduce user errors\r\n\r\n>  It is being checked if they are NULL and in that case ""NA"" is used in place of the value in the filename. I went this way so that there would be a same logic for constructing the file name regardless of source and collection.\r\n\r\nIt is a bit unusual to have `NA` in the file names (maybe even not advisable?). Again maybe registry files can help here, when that xml is read the filename can be constructed from certain tags. Do you have downstream functions that absolutely rely on this filename convention to be preserved regardless of source and collection?\r\n\r\n', 'comment_created': datetime.datetime(2020, 8, 15, 11, 52, 52, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 470974784, 'comment_body': ""I too haven't seen NA being used in filenames. I also used this so that the filenames could be more sensible, example: in GEE_s2_10.0, 10 means scale and in some other collection it might be the qc\r\n\r\n>  Do you have downstream functions that absolutely rely on this filename convention to be preserved regardless of source and collection?\r\n\r\nNothing as such, this was mostly to have a uniform naming convention, otherwise, it could be a little confusing for different sources and collections. e.g. appeears has projection but gee doesn't.\r\n\r\n But yeah maybe after trying with registry files I would be able to think better. \r\n\r\n"", 'comment_created': datetime.datetime(2020, 8, 15, 12, 50, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 471289785, 'comment_body': 'like I suggested refactoring the `remotedata_db_check` bit above, it would also be nice to move this section to its own function, e.g. `remotedata_db_insert_helper`', 'comment_created': datetime.datetime(2020, 8, 17, 7, 24, 42, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 471292307, 'comment_body': 'Is there a reason why `TRUE` and `FALSE` wouldn\'t work here instead of ""dont write""? Or can\'t this case be assigned to another flag number?', 'comment_created': datetime.datetime(2020, 8, 17, 7, 29, 27, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 471293566, 'comment_body': '```suggestion\r\n        raw_id <- raw_check$id\r\n```', 'comment_created': datetime.datetime(2020, 8, 17, 7, 32, 2, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 471293798, 'comment_body': '```suggestion\r\n      raw_id   <- raw_check$id\r\n```', 'comment_created': datetime.datetime(2020, 8, 17, 7, 32, 31, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 471293903, 'comment_body': '```suggestion\r\n      raw_path <- raw_check$file_path\r\n```', 'comment_created': datetime.datetime(2020, 8, 17, 7, 32, 46, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 471301976, 'comment_body': ""By the way, this was something we discussed but haven't decided: Currently you keep merging multiple years into single files, is this correct? @mdietze load_data functions can subset files downstream (like the Ameriflux csv files), but following the met example do we want files returned by the remotedata module to be yearly? I.e. are we OK if `GEE_***_site_1-26929` file has multiple years or do we want them split, e.g. `GEE_***_site_1-26929.2018.nc`, `GEE_***_site_1-26929.2019.nc` ...?\r\n\r\nAlso @mdietze some sources (e.g. AppEEARS) already returns csv format iirc, do we want remote module to reformat them into netcdf?"", 'comment_created': datetime.datetime(2020, 8, 17, 7, 49, 19, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 471306289, 'comment_body': ""> currently you keep merging multiple years into single files, is this correct?\r\n\r\nYes, they are merged in a single file. This entire module is designed with the idea that there should always be **only 1 file** of the same type in the DB regardless of years. Also, we support downloading data for months and days, I don't think we should be limiting that to yearly. "", 'comment_created': datetime.datetime(2020, 8, 17, 7, 58, 7, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 471403098, 'comment_body': 'As documented in L18, these ""write"" variables are not being used as flags, they contain the dates which has to be written in the DB. This date might be different from what must be sent to `rp_control` hence I used separate variables for these. They would contain ""don\'t write"" when the requested data is already present and the DB dates don\'t have to be changed. I think I can use FALSE if that is preferable.', 'comment_created': datetime.datetime(2020, 8, 17, 11, 1, 28, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 473655415, 'comment_body': '@infotroph sorry for bothering you about this again, but we are still at roxygen `7.0.2` rgiht?', 'comment_created': datetime.datetime(2020, 8, 20, 6, 41, 34, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 473678456, 'comment_body': ""We are but it may be time to change that. If someone wants to take it on before I can, the process is basically:\r\n\r\n* pick a date for the update and warn everyone\r\n* ideally close out as many open PRs as possible before then, to minimize merge conflicts\r\n* install the newest Roxygen on your dev machine\r\n* git pull, make sure your tree is clean, then `make clean && make document`\r\n* commit all the changed Rd and DESCRIPTION files\r\n* `grep -R 7.0.2 .` -> review, update appropriately, commit. I think at least three scripts `scripts/travis/install.sh`, `.github/workflows/styler-actions.yml`, and `docker/depends/Dockerfile` will need updating, but I may be forgetting others.\r\n* push, review, merge\r\n* remind everyone to update Roxygen on their own machine\r\n* monitor PRs for merge conflicts/accidental reversions (if it edits 300 files, it's probably an accidental reversion)"", 'comment_created': datetime.datetime(2020, 8, 20, 7, 11, 3, tzinfo=datetime.timezone.utc), 'commenter': 'infotroph', 'type': 'User'}, {'comment_id': 474474286, 'comment_body': 'if you have time, it would be great if you could include a workflow scheme around here that explains the high-level functionality, which function calls what, which decisions are made...', 'comment_created': datetime.datetime(2020, 8, 21, 7, 35, 17, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474475522, 'comment_body': 'great, thanks for adding this, but is there a `case 0` when nothing needs to be done?', 'comment_created': datetime.datetime(2020, 8, 21, 7, 36, 49, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474481281, 'comment_body': '```suggestion\r\n##\'   siteid=""0-721"",\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 7, 43, 38, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474487154, 'comment_body': ""Not really. In those cases, the `write_***_ start` and `write_***_end` contain `dont write` so nothing actually gets changed in the DB and the details of the existing data are returned. But maybe I could represent this using `0` case, I'll think about this."", 'comment_created': datetime.datetime(2020, 8, 21, 7, 50, 41, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 474492532, 'comment_body': 'could you modify this function such as the following lines so that we don\'t have `NA`s in the filenames, and also add the source to filename:\r\n\r\n```\r\nconstruct_raw_filename <-\r\n  function(source,\r\n           collection,\r\n           siteid,\r\n           scale = NULL,\r\n           projection = NULL,\r\n           qc = NULL) {\r\n    # skip if a parameter is not applicable and is NULL\r\n    if (is.null(scale)) {\r\n      scale_str <- ""_""\r\n    } else{\r\n      scale_str <- paste0(""_"", format(scale, nsmall = 1), ""_"")\r\n    }\r\n    if (is.null(projection)) {\r\n      prj_str <- """"\r\n    }else{\r\n      prj_str <- paste0(projection, ""_"")\r\n    }\r\n    if (is.null(qc)) {\r\n      qc_str <- """"\r\n    } else{\r\n      qc_str <- paste0(format(qc, nsmall = 1), ""_"")\r\n    }\r\n    raw_file_name <-\r\n      paste0(toupper(source), ""_"", collection, scale_str, prj_str, qc_str, ""site_"", siteid)\r\n```\r\n\r\nThen of course downstream naming convention also needs to change..passing `raw_file_name` to `RpTools$rp_control` could also help maybe, you already created the raw file name string why not re-use it later', 'comment_created': datetime.datetime(2020, 8, 21, 7, 56, 52, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474497916, 'comment_body': 'I think some of these are set now in the refactored functions, could you clean up the ones that are not needed', 'comment_created': datetime.datetime(2020, 8, 21, 8, 3, 7, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474505275, 'comment_body': '```suggestion\r\n            list(\r\n        remotefile_check_flag  = remotefile_check_flag,\r\n        start                  = start,\r\n        end                    = end,\r\n        stage_get_data         = stage_get_data,\r\n        write_raw_start        = write_raw_start,\r\n        write_raw_end          = write_raw_end,\r\n        raw_merge              = raw_merge,\r\n        existing_raw_file_path = existing_raw_file_path,\r\n        stage_process_data     = stage_process_data,\r\n        write_pro_start        = write_pro_start,\r\n        write_pro_end          = write_pro_end,\r\n        pro_merge              = pro_merge,\r\n        input_file             = input_file,\r\n        existing_pro_file_path = existing_pro_file_path,\r\n        raw_check              = raw_check,\r\n        pro_check              = pro_check\r\n      )\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 8, 11, 53, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474507347, 'comment_body': 'could you return a named list from this function so that you can access elements by their names? using indices is harder to maintain and more error-prone', 'comment_created': datetime.datetime(2020, 8, 21, 8, 14, 16, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474507569, 'comment_body': '```suggestion\r\n  remotefile_check_flag  <- dbstatus$remotefile_check_flag \r\n  start                  <- dbstatus$start                 \r\n  end                    <- dbstatus$end                   \r\n  stage_get_data         <- dbstatus$stage_get_data        \r\n  write_raw_start        <- dbstatus$write_raw_start       \r\n  write_raw_end          <- dbstatus$write_raw_end         \r\n  raw_merge              <- dbstatus$raw_merge             \r\n  existing_raw_file_path <- dbstatus$existing_raw_file_path\r\n  stage_process_data     <- dbstatus$stage_process_data    \r\n  write_pro_start        <- dbstatus$write_pro_start       \r\n  write_pro_end          <- dbstatus$write_pro_end         \r\n  pro_merge              <- dbstatus$pro_merge             \r\n  input_file             <- dbstatus$input_file            \r\n  existing_pro_file_path <- dbstatus$existing_pro_file_path\r\n  raw_check              <- dbstatus$raw_check             \r\n  pro_check              <- dbstatus$pro_check  \r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 8, 14, 33, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474514706, 'comment_body': 'could be nice to have source in capital letters\r\n```suggestion\r\n    file.path(outdir, paste(toupper(source), ""site"", siteid_short, sep = ""_""))\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 8, 22, 40, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474520711, 'comment_body': 'like we talked, it would be great if you could add the example of storing polygon in the DB to the documentation\r\n\r\n```\r\ndb.query(""insert into sites (country, sitename, geometry) values (\'FI\', \'Qvidja_ca6cm\', ST_SetSRID(ST_MakePolygon(ST_GeomFromText(\'LINESTRING(22.388957339620813 60.287395608412218 14.503780364990234, 22.389600591651835 60.287182336733203 14.503780364990234,\r\n22.38705422266651  60.285516177775868 14.503780364990234,      \r\n22.386575219445195 60.285763643883932 14.503780364990234,\r\n22.388957339620813 60.287395608412218 14.503780364990234 )\')), 4326));"", con = dbcon)\r\n```\r\n\r\nIf the site doesn\'t have the polygon it would return a point, e.g.\r\n```\r\n\r\n>   coords <-\r\n+     unlist(PEcAn.DB::db.query(\r\n+       sprintf(""select ST_AsGeoJSON(geometry) from sites where id=%f"", 1000000758),\r\n+       con = dbcon\r\n+     ), use.names = FALSE)\r\n> coords\r\n[1] ""{\\""type\\"":\\""Point\\"",\\""coordinates\\"":[-95.2001768,30.1625267,0]}""\r\n```\r\n\r\nWould we want to check if the downstream functions need a polygon type or not here?', 'comment_created': datetime.datetime(2020, 8, 21, 8, 29, 26, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474529066, 'comment_body': ""> If the site doesn't have the polygon it would return a point, e.g.\r\n\r\nDo you mean adding documentation for creating Point site? Because otherwise as you showed in your bottom example this query does return geojson info for Point site as well.\r\n\r\n> Would we want to check if the downstream functions need a polygon type or not here?\r\n\r\nThese are being taken care of by the functions in `RpTools`"", 'comment_created': datetime.datetime(2020, 8, 21, 8, 38, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 474529661, 'comment_body': 'sorry should have thought about this, will change.', 'comment_created': datetime.datetime(2020, 8, 21, 8, 39, 33, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 474539008, 'comment_body': '>Do you mean adding documentation for creating Point site?\r\n\r\nNo no for creating the polygon site, vast majority of the sites on Bety DB has point. But a lot of people could want to use your functions with the polygon\r\n\r\n>These are being taken care of by the functions in RpTools\r\n\r\nOK, but it could be harder for people to debug there, if the issue is as simple as forgetting to create the polygon for the site, we might as well let them know here. I fell like this will be a common issue just because we are not used to create these polygons for the sites. We can put this info into the registry files as well and put a high level warning here, e.g. assume these are the tags in the registry.xml:\r\n\r\n```\r\n<coord>\r\n  <coordtype>polygon</coordtype>\r\n</coord>\r\n```\r\nIf the code above returns point, we throw a warning (or an error if we are sure this is a user error and it will fail?)\r\n\r\nThis could be the registry for sources/collections that can work with both types:\r\n```\r\n<coord>\r\n  <coordtype>polygon</coordtype>\r\n  <coordtype>point</coordtype>\r\n</coord>\r\n```\r\n', 'comment_created': datetime.datetime(2020, 8, 21, 8, 50, 10, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474577100, 'comment_body': 'not a big deal, but you can only choose to return only `process_data_path` and `raw_data_path` with the `output` object, then `in.prefix` would just be `basename(output$process_data_path)`', 'comment_created': datetime.datetime(2020, 8, 21, 9, 31, 33, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474627072, 'comment_body': 'is there any reason why you want scale to have ""_"" and qc and projection to be "" "" when NULL? or is it just an example :smiley: ', 'comment_created': datetime.datetime(2020, 8, 21, 10, 59, 29, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 474629267, 'comment_body': 'it was just an example, `scale` is the first arg after `collection` within `paste0`, and I thought we always have collection name, so we just need a ""_"" after it to keep the construction going', 'comment_created': datetime.datetime(2020, 8, 21, 11, 5, 4, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474643079, 'comment_body': 'I\'ll keep on working on this, but you could already start applying some of these changes maybe. Let\'s create a registry read function along these lines:\r\n\r\n```\r\n  read_remote_registry <- function(source, collection){\r\n    \r\n    # get registration file\r\n    register.xml <- system.file(paste0(""registration/register."", toupper(source), "".xml""), package = ""PEcAn.data.remote"")\r\n    register <- XML::xmlToList(XML::xmlParse(register.xml))\r\n    #to test\r\n    # register <- XML::xmlToList(XML::xmlParse(""~/pecan/modules/data.remote/inst/registration/register.GEE.xml""))\r\n    \r\n    if(!(purrr::is_empty(register %>% keep(names(.) == ""collection"")))){\r\n      # this is a type of source that requires different setup for its collections, e.g. GEE\r\n      # then read collection specific information\r\n      register <- register[[which(register %>% map_chr(""original_name"") == collection)]]\r\n    } \r\n    \r\n    reg_list <- list()\r\n    reg_list$original_name  <- ifelse(is.null(register$original_name), collection, register$original_name)\r\n    reg_list$pecan_name     <- ifelse(is.null(register$pecan_name), collection, register$pecan_name)\r\n    reg_list$raw_mimetype   <- register$raw_format$mimetype\r\n    reg_list$raw_formatname <- register$raw_format$name\r\n    reg_list$pro_mimetype   <- register$pro_format$mimetype\r\n    reg_list$pro_formatname <- register$pro_format$name\r\n    reg_list$coordtype      <- unlist(register$coord)\r\n      \r\n    return(reg_list)\r\n  }\r\n```\r\n\r\nand remove these lines ', 'comment_created': datetime.datetime(2020, 8, 21, 11, 38, 34, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474643502, 'comment_body': 'remove `raw_*` to be read from the registry files below', 'comment_created': datetime.datetime(2020, 8, 21, 11, 39, 32, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474644495, 'comment_body': 'then this would be a good place to read the registry files, e.g.:\r\n\r\n```\r\n  # extract info from the registration file\r\n  reg_info <- read_remote_registry(source, collection)\r\n  raw_mimetype     <- reg_info$raw_mimetype\r\n  raw_formatname   <- reg_info$raw_formatname\r\n  pro_mimetype     <- reg_info$pro_mimetype\r\n  pro_formatname   <- reg_info$pro_formatname \r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 11, 41, 38, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474645174, 'comment_body': ""I haven't populated any `scale` or `qc` tags in the registry files example I provide, but we can now think of adding some defaults there and adding a check here to use that default unless the user hasn't pass anything with a warning"", 'comment_created': datetime.datetime(2020, 8, 21, 11, 43, 22, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474645732, 'comment_body': 'now the registry files can be used instead of this hardcoded lookup table', 'comment_created': datetime.datetime(2020, 8, 21, 11, 44, 37, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474646170, 'comment_body': 'Now we can add a simple check here to make sure user passed correct type\r\n\r\n```\r\n  if(!(tolower(gsub("".*type(.+),coordinates.*"", ""\\\\1"",  gsub(""[^=A-Za-z,0-9{} ]+"","""",coords))) %in% reg_info$coordtype)){\r\n    # error or warning\r\n  }\r\n```', 'comment_created': datetime.datetime(2020, 8, 21, 11, 45, 40, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474646875, 'comment_body': ""now you can parse the sources from the registry files (we will have one registry file per source), if the passed source doesn't have a `register.source.xml` file we throw an error"", 'comment_created': datetime.datetime(2020, 8, 21, 11, 47, 12, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 474653956, 'comment_body': 'Thank you very much Istem, this is very helpful. I will extend it from here.', 'comment_created': datetime.datetime(2020, 8, 21, 12, 3, 53, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 475055117, 'comment_body': '```suggestion\r\n    <scale>10</scale>\r\n```\r\nremoving spaces just in case', 'comment_created': datetime.datetime(2020, 8, 22, 6, 43, 48, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475055127, 'comment_body': '```suggestion\r\n    <qc>1</qc>\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 6, 43, 59, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475055158, 'comment_body': '```suggestion\r\n    <scale>30</scale>\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 6, 44, 14, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475055182, 'comment_body': '```suggestion\r\n    <qc>1</qc>\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 6, 44, 26, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475055291, 'comment_body': '```suggestion\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 6, 45, 30, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475056875, 'comment_body': '```suggestion\r\n  these_sources <- gsub(""^.+?\\\\.(.+?)\\\\..*$"", ""\\\\1"", list.files(system.file(""registration"", package = ""PEcAn.data.remote"")))\r\n  PEcAn.logger::severeifnot(paste0(""Source should be one of "", paste(these_sources, collapse = \' \')), toupper(source) %in% these_sources)\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 5, 36, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475057696, 'comment_body': 'I think we will need a more sophisticated  filename than this for the pro_file_name also, because for example there is no way to tell if a `snap_lai_site_1-26929` is derived from  a `GEE_s2_10.0_1.0_site_1-26929` or `GEE_s2_100.0_1.0_site_1-26929` which by design we assume can happen, so I suggest just appending `snap_lai` to the other string, we can move this into `construct_filename` too', 'comment_created': datetime.datetime(2020, 8, 22, 7, 16, 18, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475057787, 'comment_body': '```suggestion\r\n    construct_remotedata_filename(source, collection, siteid_short, scale, projection, qc, algorithm, out_process_data)\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 17, 17, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475057827, 'comment_body': ""```suggestion\r\n##' construct remotedata module file names\r\n```"", 'comment_created': datetime.datetime(2020, 8, 22, 7, 18, 9, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475057848, 'comment_body': ""```suggestion\r\n##' @name construct_remotedata_filename\r\n```"", 'comment_created': datetime.datetime(2020, 8, 22, 7, 18, 20, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475057877, 'comment_body': ""```suggestion\r\n##' @title construct_remotedata_filename\r\n```"", 'comment_created': datetime.datetime(2020, 8, 22, 7, 18, 34, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058065, 'comment_body': ""```suggestion\r\n##' @param qc qc_parameter, NULL by default\r\n##' @param algorithm algorithm name to process data, NULL by default\r\n##' @param out_process_data variable name requested for the processed file, NULL by default\r\n```"", 'comment_created': datetime.datetime(2020, 8, 22, 7, 20, 42, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058080, 'comment_body': ""```suggestion\r\n##' @return remotedata_file_names\r\n```"", 'comment_created': datetime.datetime(2020, 8, 22, 7, 21, 3, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058113, 'comment_body': ""```suggestion\r\n##' remotedata_file_names <- construct_remotedata_filename(\r\n```"", 'comment_created': datetime.datetime(2020, 8, 22, 7, 21, 37, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058170, 'comment_body': '```suggestion\r\n##\'   qc=1.0,\r\n##\'   algorithm=""snap"",\r\n##\'   out_process_data=""lai"")\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 22, 35, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058209, 'comment_body': '```suggestion\r\nconstruct_remotedata_filename <-\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 22, 54, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058231, 'comment_body': '```suggestion\r\n           qc = NULL,\r\n           algorithm = NULL,\r\n           out_process_data = NULL) {\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 23, 26, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058700, 'comment_body': '```suggestion\r\n    raw_file_name <- paste0(toupper(source), ""_"", collection, scale_str, prj_str, qc_str, ""site_"", siteid)\r\n        if(!is.null(out_process_data)){\r\n      alg_str <- paste0(algorithm, ""_"")\r\n      var_str <- paste0(out_process_data, ""_"")\r\n      pro_file_name <- paste0(toupper(source), ""_"", collection, scale_str, prj_str, qc_str, alg_str, var_str, ""site_"", siteid)\r\n    }else{\r\n      pro_file_name <- NULL\r\n    }\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 29, 52, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058786, 'comment_body': '```suggestion\r\n    remotedata_file_names <- list(raw_file_name = raw_file_name,\r\n                                  pro_file_name = pro_file_name)\r\n    \r\n    return(remotedata_file_names)\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 30, 20, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475058956, 'comment_body': 'then \r\n\r\n```\r\nraw_file_name <- remotedata_file_names$raw_file_name\r\npro_file_name <- remotedata_file_names$pro_file_name\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 32, 37, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475059643, 'comment_body': '```suggestion\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 41, 12, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475059660, 'comment_body': '```suggestion\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 41, 22, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475059669, 'comment_body': '```suggestion\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 41, 30, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475059686, 'comment_body': '```suggestion\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 7, 41, 39, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475063660, 'comment_body': 'could these `raw_check` and `pro_check` be documented more informatively? I believe these are lists that contains info regarding the DB check id, date etc.', 'comment_created': datetime.datetime(2020, 8, 22, 8, 32, 48, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475064363, 'comment_body': ""just to document: I think we will need an extra step(s) here (or we can continue after db_insert below) in the future that post-processes data further: e.g.  collapse the data (load_data functions downstream can subset and align but they don't spatially aggregate data) and calculate the uncertainties (e.g. #2677) etc.\r\n"", 'comment_created': datetime.datetime(2020, 8, 22, 8, 41, 33, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475065618, 'comment_body': '```suggestion\r\n              in.path    = dirname(output$process_data_path),\r\n```\r\nthese need to be path to folder not the full thing, so that they appear like this:\r\n![Screenshot from 2020-08-22 11-54-28](https://user-images.githubusercontent.com/13728388/90952684-47c74a80-e46e-11ea-8294-bae05f61b9aa.png)\r\n', 'comment_created': datetime.datetime(2020, 8, 22, 8, 55, 17, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475077202, 'comment_body': 'Actually, let\'s already have something in place so that it reminds us what to implement later and also allow us to demonstrate the functionality. This future step can be implemented post-GSOC.\r\n\r\nI guess it would be better if the collapse/postprocess/uncertainty module can come after insertion step below and the processed files have another DB insertion. \r\n\r\n```suggestion\r\n  # IF: this is extremely hacky but we will need a post-processing function/sub-module here\r\n  # this code can remind us to implement it later, for now it is only used for GEE - Sentinel2 - SNAP- LAI example\r\n  # it would be better if this sub-module comes after DB insertion below and the processed files have their own insertion\r\n  if(source == ""gee"" & collection == ""s2"" & !is.null(algorithm) & !is.null(out_process_data)){\r\n    settings$remotedata$collapse <- TRUE\r\n  }\r\n    \r\n  if(!is.null(settings$remotedata$collapse)){\r\n    latlon <- PEcAn.data.atmosphere::db.site.lat.lon(siteid, con = dbcon)\r\n    collapse_remote_data(output, out_process_data, latlon)\r\n  }\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 10, 37, 37, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475079104, 'comment_body': 'could all these be compatible with the standards https://github.com/PecanProject/pecan/blob/develop/base/utils/data/standard_vars.csv#L40\r\n```suggestion\r\n* `out_process_data`: (optional) type of processed output requested, e.g, LAI\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 11, 3, 43, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475089974, 'comment_body': 'should the one returned in settings list also be like this?', 'comment_created': datetime.datetime(2020, 8, 22, 13, 22, 49, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 475090335, 'comment_body': 'You mean these db_out$raw_path and db_out$pro_path? No they should have the full path, e.g.\r\n\r\n```\r\n> settings$remotedata$pro_path\r\n[1] ""/fs/data1/pecan.data/dbfiles/GEE_site_1-26929/GEE_s2_10.0_1.0_snap_lai_site_1-26929.nc""\r\n```', 'comment_created': datetime.datetime(2020, 8, 22, 13, 27, 12, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475189984, 'comment_body': '```suggestion\r\n                        nc$var$lai$dim[[3]]$vals, \r\n```\r\nunnecessary comment', 'comment_created': datetime.datetime(2020, 8, 23, 8, 28, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475196118, 'comment_body': '```suggestion\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 23, 9, 29, 51, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475196165, 'comment_body': '```suggestion\r\n\r\n```', 'comment_created': datetime.datetime(2020, 8, 23, 9, 30, 12, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475196196, 'comment_body': '```suggestion\r\n    collapse_remote_data(output, out_process_data, \r\n                         list(lat = settings$run$site$lat, lon = settings$run$site$lon))\r\n```', 'comment_created': datetime.datetime(2020, 8, 23, 9, 30, 26, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475197214, 'comment_body': ""does this have to be lowercase? \r\n\r\nIf possible please replace all checks and usages with uppercase. That's how we use this variable in xml tags, e.g.\r\n\r\n```\r\n  <ensemble>\r\n   <size>3</size>\r\n   <variable>LAI</variable>\r\n   <samplingspace>\r\n   <parameters>\r\n    <method>uniform</method>\r\n   </parameters>\r\n   <met>\r\n    <method>sampling</method>\r\n \t</met>\r\n   </samplingspace>\r\n  </ensemble>\r\n```\r\n\r\nIt's OK to punt it until after Monday but it needs to change before this PR can be merged"", 'comment_created': datetime.datetime(2020, 8, 23, 9, 40, 36, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475206870, 'comment_body': 'OK I just realized that if the requested files for both raw and pro exist, the rest of the downstream code should be skipped (unless `overwrite=TRUE`), so we need a check here to do that and the following paths need to be populated by raw_check and pro_check and return from the function:\r\n```\r\n    settings$remotedata$raw_id  \r\n    settings$remotedata$raw_path \r\n    settings$remotedata$pro_id  \r\n    settings$remotedata$pro_path \r\n    return(settings)\r\n```\r\n  ', 'comment_created': datetime.datetime(2020, 8, 23, 11, 19, 9, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475207422, 'comment_body': '```suggestion\r\n     <name>Remote_generic</name>\r\n```', 'comment_created': datetime.datetime(2020, 8, 23, 11, 24, 41, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475207464, 'comment_body': '```suggestion\r\n     <name>Remote_generic</name>\r\n```', 'comment_created': datetime.datetime(2020, 8, 23, 11, 25, 11, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475207502, 'comment_body': '```suggestion\r\n     <id>1000000129</id>\r\n```', 'comment_created': datetime.datetime(2020, 8, 23, 11, 25, 34, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475207521, 'comment_body': '```suggestion\r\n     <id>1000000129</id>\r\n```', 'comment_created': datetime.datetime(2020, 8, 23, 11, 25, 45, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475333696, 'comment_body': 'If I understood your comment correctly, this is already being done. E.g. L904', 'comment_created': datetime.datetime(2020, 8, 24, 4, 18, 54, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 475341441, 'comment_body': ""No, I meant once we know that the exact files exist, we should return and shouldn't run any of the downstream lines, e.g. we shouldn't even call Rptools, `output <- do.call(RpTools$rp_control, fcn.args)` it slows down the workflow for no reason"", 'comment_created': datetime.datetime(2020, 8, 24, 4, 52, 1, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475380084, 'comment_body': '```suggestion\r\n    settings$remotedata$raw_id   <-  raw_check$id\r\n```\r\nIs there a reason not to be more concise and directly pass the ids and paths like this and get rid of the 4 extra lines above?', 'comment_created': datetime.datetime(2020, 8, 24, 6, 58, 47, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 475381154, 'comment_body': ':eyes: ', 'comment_created': datetime.datetime(2020, 8, 24, 7, 1, 12, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 475381319, 'comment_body': ':eyes: ', 'comment_created': datetime.datetime(2020, 8, 24, 7, 1, 37, tzinfo=datetime.timezone.utc), 'commenter': 'ayushprd', 'type': 'User'}, {'comment_id': 475382213, 'comment_body': 'yup the docs need to be updated to explain the registry file logic and tags ', 'comment_created': datetime.datetime(2020, 8, 24, 7, 3, 52, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}, {'comment_id': 477231792, 'comment_body': ""```suggestion\r\nAdditional information are taken from the registration files located at pecan/modules/data.remote/inst/registration, each source has its own registration file. This is so because there isn't a standardized way to retrieve all image collections from GEE and each image collections may require its own way of performing quality checks, etc whereas all of the products available on AppEEARS can be retrieved using its API in a standardized way.\r\n```\r\nThanks, could you also link `pecan/modules/data.remote/inst/registration`"", 'comment_created': datetime.datetime(2020, 8, 26, 11, 33, 56, tzinfo=datetime.timezone.utc), 'commenter': 'istfer', 'type': 'User'}]","[{'commit_sha': 'e28a9c57cbc9a4ea6913fa3d1242937c0e15f31b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1037740080b037d9b2b860683bf4941f11a818c2', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ef0cd15a207edb6110d8021fc15a66cbb376cff9', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9dc87574972570b7ff784e006ba59fb4924b5ed', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0571367c08f5b774cf64ae817b1c3639c1b7b941', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5e09844b013471dacca92cd9e372efa24e7cabf1', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe11e73335c744d6cc774e6349d8f004064cbd67', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '751528c478ef7579a824d64ffb9981a7edac6ae8', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'fe12633eb1c6bf078d24fdde4ca0bba2215d283c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '985ff5152a7837c0b50efcae7a0f27f62d8bbe79', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '385889075cad4055ce01832ef386bffa0acca0e6', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '50ab11f43b2080d89ba60a9887cd190049c13010', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '43fe1d7b5096ae722869555208d41d0d2c41a4c4', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e431966f3b10c74ee3ad12024735a00a2f5e534c', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '860780f60a5e398f67b0a3efd31dbd37d97d01d1', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6aeff373acfd49b0f1ecd92fae3500789a198535', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8b7e128ad1f101805add1f1ee08845a5eb722fda', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3670006e63eff982014d7e1540d68b9bdba98843', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6afe804016a9d270e5f033d1d7416f99a03d4f07', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '27a5976baa62ed36020f79c11ca094869f55e308', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c951623ecfa0260872148c35f9a5011b661a7f30', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '87c36387a3c8ad8bb7f19aa01d9c76becec02db4', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6953050ad4a15bceaaabb6dada52a0359b500d63', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c9b7ab5241a650f387e0e6b555a76b81d8c03f59', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '582dce1bd8c7b68473148bc7bf97533e85901393', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c929ddbca678f609f241ca03d0c6d508390dd8d7', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4738fa737d6d570c9059781ab2cfed0fc1a04e30', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bf0acb1d3bbc397401ee6f79368e2081ea1c1606', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ee66a352fdf2ca3dd25cb7ecd0db546d0bd19c49', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '873d9648ddaddd1e030f01d9a694d2a3c3a94f38', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7dcfe0ce87cc75d6cb09823fdef3ae9c556a3de2', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '51cde8971c3626807e06cd4b325c11dee8a61d8a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ed8de44f9166a2938271512e581397485f148b52', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6888f5707f34ebc9c320c3ea93b28c34eba399b3', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '91cf94c774af8faa119ad9f72e20f63885b4bed7', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b1c921439fb297fe0670ad0ff5de095541aaaabf', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '53ec8f8910eda2fb09e5e493a0d26f094b062b44', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9fd5ecc9904e94ee531837cdba63335b7b9e11e5', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e08973a71abbe450b65633b3d13dc3498864a9d2', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'eea29a562d716e562e45a222fe462e64e562a7d9', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e576862b982d496c7032171c2889465b09cf23a1', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd3f029ae35699e3206359268a3369ccfc7c572ef', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '533bb504b2a7f004f22195d7c8fc1095451d1a4b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e6e05274fe766f659879a783aefa3ba1a5b258cf', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '27d854429ddc7b1de3b7158ef8d96da71d6ac67e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1535b87e8a0d52b24f548eb0dbf6cbcfd2dc52fa', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '44fe824b89d7b21745d7b23ada6d1acb954390c2', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'deccb2606f2eda1dad897ea220a444bc797fdfbd', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '53c88f8434b72f0cbdbd0dd18b2f32c97dd3fda0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1423dd4ec4a374a07c3df8399d69e471f8701aa9', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '02f2ab9c49e27270b66a0f0caa912556962fab96', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ca81ea82979e7ed85d48cab465ec6220809c40bc', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dc1441220a0afab1b11930335a627882df575f5b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'bccb93a6e4895f794cdc0c940b1051b09fa32861', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd9f4d736b0179fb82c2d95a585a5258c52cc6a54', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7ea2f22a159eca43fc96598644b78a564bce37e0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'df26527c828fddc5eec88e8cd3ac1c2a4647440f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'aea69f315c74bab7733f512b477eda1414dfcfff', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ec233f7d2c0c68babbfe52dcc3b53ffc9f1de158', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd8448d7bb2d1d1f8e02111e10888488c2acc02b0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6b0c0af06392fbd65d9c8becfbcd508cc9d9e1fa', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ca07ed7bb3ff7e72e843c18338fa61e6e55b331b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd0b04a89a81986623a5c28c88452b96106a52b8d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b8d4b67909b482e68ad0545841dcc99970a09f9b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8a49c702098697a35c766d051f8c479a9c27dc05', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '46457963a6385b61b063d05482b8db8463e23e46', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '955b6e413ff8b65df2899491871478fe82db4f5d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '50a7af8dd4c46f6073733b51d36c337b57068d54', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ba5c11353e402a50a2337f8020a1edc305b9d08e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4294770cb30ff4aedd3fe396090fc4c080998073', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '62f73c6bc238809862bd9c29ba1562fe64c13898', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7bdd6d01362e160e2fb76be614eb0d9a802f9939', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'a41cf1666a353ac76204021c38b5efad6b08475d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '203594adb2ed9fdc4b61cf857ee9f74ad17474d3', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2ceda390d029e5dcf365476d8d11704319b337db', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1c7571630dc8cdc15d80849835423080ec9b04c4', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '58cce01dab975f0681fed37629171d93c9d5bc0b', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c13025dc98e9710b8b44da3d0c9246db222085b6', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd2b43210812812937547a8cc72e00aa38a14ffd4', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4edb8b0ec9ed8000ef5ee6d5e849927395b8193e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c8e0a6d53ad6f4320fc40ae08ecd721cb349593a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '50a98d88d1224e9103b0f5d9f570412435ae2990', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4f936e17ff33f357bb8eaa4ac3715a1df6428357', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '24ecc7398ff49c17f69e0710e0a56b9c32153d9f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ce1fb5b71a4e3bfb40a0ae8b13168d8dc98c18e4', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'dae10c26a10aa85d54a5e0d0f01c53a47b96f3fa', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c384ab49fa6f8df167160d95f942f6f744c0fd32', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '5ca7db008928ba2886ce0e343cb084022991ba61', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '18677d32ddaded1c7944e5017f259fc7d003c298', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0c4aa2e434093efd534c92eded3174869f4802d2', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '8cd35a435ff1bc6858dfa66fd23931b7ead429aa', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '569ecd1ad3022d56badb3105ec48fb5bf9e0d9be', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9e826ab3b4cb926031e8ff30134f703d4dfe157d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c6f1a732e4754703bc01f59e2beb50ac69539d46', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'b499eeb0edbf6c9b8acbf82e3cca86343d9a8ae0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '930b8ac99189556d2750a2e0194d787d4643fa68', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '33bfa3c58c3f54b92417d64bf05d62c8658744da', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '0d33e66ff16ae317ed0a3760c068403a1709749e', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9a5c12f59c88abfd1d90d5b8ea7cfae0cf435f7a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'd3f21ff73af041d0afa2854f0dc137af7bc40e9f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2f73ceccdb02035d6c974636b766e3bf0f1e944d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '3fef97457f6c7ff8839e2c4ac59eac79ff1bd9d5', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '9816c9d7dd9ebbf00511c92c564413e032d228a7', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'babbc272bb40f440acc547549f08f412148caab0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'e521e8b648970bc5cde0ee49b2ba438d3412d342', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c7a0be981969f8557482563a9d6e6a86e1237132', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f1e9e92844478652c8bdaeea9e749e781853a1fb', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '81c6f4d841e2d7a092f1b2194012ae0c9829241a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c11539bc308cc6561eda92c8b187058940a999e7', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '109d74e54d05770110adfe82fab30dee10bd928d', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '663eb00fab5ba1ff04f18f0d4c5fa784960b5198', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '1144af0cf431b46c66446532f3f52fc6e0799f15', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '4e130ac09cced39c3f92634d4e0d032a0aaa9e56', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '2c5708f88a25be0985b0191547f3c2d30dc42826', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '14b0b1e0045926de2689099032b0fa6e7136ed06', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c1fef37a679019eec039955caa743901e318b67a', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'ee8d62a6edacc4625506c5a31a69c5956b1f1467', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '6785037d056d9f68cf5047473d5fc0d84820e3ec', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '73bc26cdd78051eb206b14e9aba190a2433e90e0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7f6f3c00f4dd1158b87e2248621af8f4a1554692', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'f3af8e2f3fe4d3b354a375d6ad3a45a08eb2f654', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '912f3c31bc40cf0ce11e11a4e4ed311859606a08', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '54e42a0539a301ccd55aa3f6910c5b1c91dc803f', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '71fd65f9055713f8245878a1676903b0409251e0', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '556fa435541e1a6cf50d2e4161a9d148b774a8d7', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': '7723bc92de53f7ab45ec231866232858cc074bd1', 'committer_username': 'ayushprd', 'committer_name': 'Ayush Prasad', 'committer_email': 'ayush.prd@gmail.com', 'commit_date': datetime.datetime(2015, 3, 20, 7, 25, 28, tzinfo=datetime.timezone.utc)}, {'commit_sha': 'c606265e84401b90aec0aca3743408222b71608b', 'committer_username': 'mdietze', 'committer_name': 'Michael Dietze', 'committer_email': 'dietze@bu.edu', 'commit_date': datetime.datetime(2012, 12, 19, 14, 18, 27, tzinfo=datetime.timezone.utc)}]",Ayush Prasad,11568631,ayush.prd@gmail.com,User,,21,,31,13

Project_ID,Name,Full_name,Language,Forks,Stars,Watchers,contributors,commits,issues,branches,PRs_count,contributor pullrequests
6857384,pecan,PecanProject/pecan,R,231,202,36,208,22867,449,18,24,"[{'id': 717124663, 'number': 2840, 'closed': datetime.datetime(2022, 3, 9, 10, 51, 14, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 8, 21, 9, 28, 17, tzinfo=datetime.timezone.utc), 'time_taken': 17284977.0, 'time_delta': '200 days, 1:22:57', 'additions': 608, 'deletions': 14, 'state': 'closed'}, {'id': 678275604, 'number': 2813, 'closed': datetime.datetime(2021, 8, 19, 19, 42, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2021, 6, 26, 4, 54, 34, tzinfo=datetime.timezone.utc), 'time_taken': 4718859.0, 'time_delta': '54 days, 14:47:39', 'additions': 608, 'deletions': 3, 'state': 'closed'}, {'id': 464505193, 'number': 2676, 'closed': datetime.datetime(2020, 8, 8, 19, 16, 48, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 7, 9, 41, 33, tzinfo=datetime.timezone.utc), 'time_taken': 120915.0, 'time_delta': '1 day, 9:35:15', 'additions': 10, 'deletions': 10, 'state': 'closed'}, {'id': 462004888, 'number': 2672, 'closed': datetime.datetime(2020, 10, 29, 18, 6, 19, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 8, 3, 7, 34, 21, tzinfo=datetime.timezone.utc), 'time_taken': 7554718.0, 'time_delta': '87 days, 10:31:58', 'additions': 2483, 'deletions': 388, 'state': 'closed'}, {'id': 449912442, 'number': 2659, 'closed': datetime.datetime(2020, 7, 30, 13, 36, 23, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 16, 5, 40, 28, tzinfo=datetime.timezone.utc), 'time_taken': 1238155.0, 'time_delta': '14 days, 7:55:55', 'additions': 282, 'deletions': 19, 'state': 'closed'}, {'id': 447776486, 'number': 2652, 'closed': datetime.datetime(2020, 8, 7, 9, 42, 46, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 7, 11, 14, 43, 8, tzinfo=datetime.timezone.utc), 'time_taken': 2314778.0, 'time_delta': '26 days, 18:59:38', 'additions': 3, 'deletions': 3, 'state': 'closed'}, {'id': 442003582, 'number': 2645, 'closed': datetime.datetime(2020, 6, 30, 13, 32, 10, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 30, 12, 46, 7, tzinfo=datetime.timezone.utc), 'time_taken': 2763.0, 'time_delta': '0:46:03', 'additions': 152, 'deletions': 0, 'state': 'closed'}, {'id': 440906973, 'number': 2642, 'closed': datetime.datetime(2020, 7, 9, 15, 2, 40, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 27, 12, 39, 3, tzinfo=datetime.timezone.utc), 'time_taken': 1045417.0, 'time_delta': '12 days, 2:23:37', 'additions': 950, 'deletions': 485, 'state': 'closed'}, {'id': 435178571, 'number': 2637, 'closed': datetime.datetime(2020, 6, 19, 12, 11, 41, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 16, 12, 23, 48, tzinfo=datetime.timezone.utc), 'time_taken': 258473.0, 'time_delta': '2 days, 23:47:53', 'additions': 462, 'deletions': 27, 'state': 'closed'}, {'id': 433140671, 'number': 2634, 'closed': datetime.datetime(2020, 6, 16, 11, 14, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 11, 15, 2, 45, tzinfo=datetime.timezone.utc), 'time_taken': 418288.0, 'time_delta': '4 days, 20:11:28', 'additions': 837, 'deletions': 0, 'state': 'closed'}, {'id': 432930906, 'number': 2633, 'closed': datetime.datetime(2020, 6, 11, 12, 31, 3, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 11, 8, 46, 45, tzinfo=datetime.timezone.utc), 'time_taken': 13458.0, 'time_delta': '3:44:18', 'additions': 46463, 'deletions': 0, 'state': 'closed'}, {'id': 431021138, 'number': 2630, 'closed': datetime.datetime(2020, 6, 8, 13, 45, 15, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 6, 8, 10, 4, 31, tzinfo=datetime.timezone.utc), 'time_taken': 13244.0, 'time_delta': '3:40:44', 'additions': 4, 'deletions': 4, 'state': 'closed'}, {'id': 417919922, 'number': 2611, 'closed': datetime.datetime(2020, 5, 18, 13, 25, 6, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 14, 11, 3, 2, tzinfo=datetime.timezone.utc), 'time_taken': 354124.0, 'time_delta': '4 days, 2:22:04', 'additions': 1, 'deletions': 1, 'state': 'closed'}, {'id': 416029683, 'number': 2606, 'closed': datetime.datetime(2020, 5, 13, 13, 7, 13, tzinfo=datetime.timezone.utc), 'created': datetime.datetime(2020, 5, 11, 10, 59, 14, tzinfo=datetime.timezone.utc), 'time_taken': 180479.0, 'time_delta': '2 days, 2:07:59', 'additions': 22, 'deletions': 21, 'state': 'closed'}]"
